-DOCSTART- -X- O
References -X- _ O

Acknowledgments -X- _ O

Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
SIEF -X- _ B-MethodName
consistently -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
base -X- _ O
models -X- _ O
in -X- _ O
different -X- _ O
domains, -X- _ O
and -X- _ O
that -X- _ O
it -X- _ O
improves -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

The -X- _ O
proposed -X- _ O
SIEF -X- _ B-MethodName
is -X- _ O
a -X- _ O
general -X- _ O
framework, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
various -X- _ O
base -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

We -X- _ O
design -X- _ O
a -X- _ O
sentence -X- _ O
importance -X- _ O
score -X- _ O
and -X- _ O
a -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
evidence -X- _ O
sentences. -X- _ O

[1] -X- _ O
RageAgainsttheMachineis -X- _ O
an -X- _ O
Americanrap -X- _ O
metal -X- _ O
band -X- _ O
from -X- _ O
LosAngeles, -X- _ O
California. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Sentence -X- _ B-MethodName
Information -X- _ I-MethodName
Estimation -X- _ I-MethodName
and -X- _ I-MethodName
Focusing -X- _ I-MethodName
(SIEF) -X- _ B-MethodName
approach -X- _ O
to -X- _ O
document -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
(DocRE). -X- _ B-TaskName

6 -X- _ O
Conclusion -X- _ O

By -X- _ O
contrast, -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
correct -X- _ O
predictions -X- _ O
when -X- _ O
different -X- _ O
non-evidence -X- _ O
sentences -X- _ O
are -X- _ O
removed, -X- _ O
demonstrating -X- _ O
its -X- _ O
robustness. -X- _ O

However, -X- _ O
the -X- _ O
base -X- _ O
GAIN -X- _ B-MethodName
model -X- _ O
makes -X- _ O
a -X- _ O
wrong -X- _ O
prediction -X- _ O
“not -X- _ O
MemberOf”, -X- _ O
as -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
is -X- _ O
below -X- _ O
the -X- _ O
threshold, -X- _ O
which -X- _ O
is -X- _ O
determined -X- _ O
by -X- _ O
validation -X- _ O
based -X- _ O
on -X- _ O
predicted -X- _ O
binary -X- _ O
probabilities -X- _ O
of -X- _ O
all -X- _ O
relations. -X- _ O

We -X- _ O
see -X- _ O
that -X- _ O
Sentence -X- _ O
3 -X- _ O
is -X- _ O
non-evidence, -X- _ O
and -X- _ O
in -X- _ O
principle, -X- _ O
it -X- _ O
should -X- _ O
not -X- _ O
affect -X- _ O
DocRE -X- _ B-TaskName
prediction -X- _ O
in -X- _ O
this -X- _ O
case. -X- _ O

For -X- _ O
the -X- _ O
entity -X- _ O
the -X- _ O
Machine), -X- _ O
pair -X- _ O
(Brad -X- _ O
Wilk, -X- _ O
Rage -X- _ O
Against -X- _ O
both -X- _ O
GAIN -X- _ B-MethodName
and -X- _ O
GAIN+SIEF -X- _ B-MethodName
predicts -X- _ O
the -X- _ O
relation -X- _ O
“MemberOf”, -X- _ O
which -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
reference. -X- _ O

Figure -X- _ O
6 -X- _ O
shows -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
of -X- _ O
GAIN -X- _ B-MethodName
and -X- _ O
GAIN+SIEF -X- _ B-MethodName
models. -X- _ O

Case -X- _ O
Study. -X- _ O

Moreover, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
our -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
learning -X- _ O
from -X- _ O
the -X- _ O
groundtruth -X- _ O
labels, -X- _ O
showing -X- _ O
that -X- _ O
the -X- _ O
soft -X- _ O
predictions -X- _ O
provide -X- _ O
more -X- _ O
information -X- _ O
than -X- _ O
one-hot -X- _ O
labels, -X- _ O
consistent -X- _ O
with -X- _ O
knowledge -X- _ O
distillation -X- _ O
literature -X- _ O
(Hinton -X- _ O
et -X- _ O
al., -X- _ O
2015). -X- _ O

This -X- _ O
confirms -X- _ O
that -X- _ O
removing -X- _ O
non-evidence -X- _ O
sentences -X- _ O
can -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
of -X- _ O
data -X- _ O
augmentation, -X- _ O
boosting -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

As -X- _ O
seen, -X- _ O
both -X- _ O
methods -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
base -X- _ O
models. -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
Ign -X- _ B-MetricName
F1. -X- _ I-MetricName

directly -X- _ O
from -X- _ O

n) -X- _ O

alternative -X- _ O
choice: -X- _ O
we -X- _ O
learn -X- _ O
ˆP -X- _ O
( -X- _ O
− -X- _ O
ij -X- _ O
the -X- _ O
groundtruth -X- _ O
label -X- _ O
rij. -X- _ O

Figure -X- _ O
6: -X- _ O
Case -X- _ O
Study. -X- _ O

n) -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
such -X- _ O
a -X- _ O
− -X- _ O
ij -X- _ O
sentence -X- _ O
focusing -X- _ O
loss, -X- _ O
we -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
an -X- _ O

We -X- _ O
encourage -X- _ O
the -X- _ O
DocRE -X- _ B-TaskName
models -X- _ O
to -X- _ O
generate -X- _ O
consistent -X- _ O
output -X- _ O
probabilities -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
non-evidence -X- _ O
(Section -X- _ O
4.2) -X- _ O
by -X- _ O
a -X- _ O
crossentropy -X- _ O
loss -X- _ O
between -X- _ O
two -X- _ O
soft -X- _ O
distributions -X- _ O
Pij -X- _ O
and -X- _ O
ˆP -X- _ O
( -X- _ O
. -X- _ O

Our -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
VS -X- _ O
learning -X- _ O
from -X- _ O
groundtruth. -X- _ O

Moroever, -X- _ O
SIEF -X- _ B-MethodName
is -X- _ O
superior -X- _ O
to -X- _ O
both -X- _ O
Rand -X- _ B-MethodName
and -X- _ O
NoMention, -X- _ B-MethodName
showing -X- _ O
that -X- _ O
our -X- _ O
sentence -X- _ O
importance -X- _ O
scores -X- _ O
is -X- _ O
a -X- _ O
more -X- _ O
effective -X- _ O
indicator -X- _ O
of -X- _ O
evidence -X- _ O
and -X- _ O
non-evidence -X- _ O
sentences. -X- _ O

The -X- _ O
NoMention -X- _ B-MethodName
heuristic -X- _ O
outperforms -X- _ O
Rand, -X- _ B-MethodName
as -X- _ O
sentences -X- _ O
without -X- _ O
entity -X- _ O
mentions -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
non-evidence. -X- _ O

As -X- _ O
seen, -X- _ O
the -X- _ O
simple -X- _ O
heuristic -X- _ O
Rand -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
base -X- _ O
model, -X- _ O
as -X- _ O
Rand -X- _ B-MethodName
can -X- _ O
be -X- _ O
thought -X- _ O
of -X- _ O
as -X- _ O
noisy -X- _ O
data -X- _ O
augmentation. -X- _ O

The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
Ign -X- _ B-MetricName
F1 -X- _ I-MetricName
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5. -X- _ O

We -X- _ O
consider -X- _ O
the -X- _ O
non-evidence -X- _ O
set -X- _ O
as -X- _ O
the -X- _ O
sentences -X- _ O
without -X- _ O
entity -X- _ O
mentions, -X- _ O
denoted -X- _ O
by -X- _ O
NoMention. -X- _ O

(3), -X- _ O
we -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
several -X- _ O
alternative -X- _ O
heuristics: -X- _ O
1) -X- _ O
We -X- _ O
randomly -X- _ O
select -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
as -X- _ O
the -X- _ O
nonevidence -X- _ O
set, -X- _ O
denoted -X- _ O
by -X- _ O
Rand; -X- _ O
and -X- _ O
2) -X- _ O

sentence -X- _ O
importance -X- _ O
score -X- _ O
in -X- _ O
Eqn. -X- _ O

Sentence -X- _ O
importance -X- _ O
score -X- _ O
VS -X- _ O
other -X- _ O
heurisTo -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
tics. -X- _ O

From -X- _ O
the -X- _ O
plots, -X- _ O
we -X- _ O
also -X- _ O
see -X- _ O
that -X- _ O
our -X- _ O
hyperparameter -X- _ O
β -X- _ B-HyperparameterName
is -X- _ O
insensitive -X- _ O
to -X- _ O
the -X- _ O
base -X- _ O
models, -X- _ O
justifying -X- _ O
our -X- _ O
design -X- _ O
of -X- _ O
Eqn. -X- _ O
(3). -X- _ O

Empirically, -X- _ O
a -X- _ O
moderate -X- _ O
β -X- _ B-HyperparameterName
around -X- _ O
(0.6–0.8) -X- _ B-HyperparameterValue
yields -X- _ O
the -X- _ O
highest -X- _ O
performance. -X- _ O

Intuitively, -X- _ O
if -X- _ O
β -X- _ B-HyperparameterName
is -X- _ O
too -X- _ O
small, -X- _ O
very -X- _ O
few -X- _ O
sentences -X- _ O
will -X- _ O
be -X- _ O
treated -X- _ O
as -X- _ O
non-evidence -X- _ O
and -X- _ O
our -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
is -X- _ O
less -X- _ O
effective; -X- _ O
if -X- _ O
β -X- _ B-HyperparameterName
is -X- _ O
too -X- _ O
large, -X- _ O
it -X- _ O
has -X- _ O
a -X- _ O
high -X- _ O
false -X- _ O
positive -X- _ O
rate -X- _ O
of -X- _ O
non-evidence -X- _ O
sentences. -X- _ O

As -X- _ O
seen, -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
approach -X- _ O
consistently -X- _ O
benefits -X- _ O
the -X- _ O
base -X- _ O
models -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
range -X- _ O
of -X- _ O
β -X- _ B-HyperparameterName
values. -X- _ O

Table -X- _ O
6: -X- _ O
Comparing -X- _ O
our -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
with -X- _ O
learning -X- _ O
from -X- _ O
groundtruth -X- _ O
labels -X- _ O
(denoted -X- _ O
by -X- _ O
GTruth). -X- _ O

We -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
β -X- _ B-HyperparameterName
in -X- _ O
Figure -X- _ O
4. -X- _ O

Our -X- _ O
SIEF -X- _ B-MethodName
framework -X- _ O
has -X- _ O
one -X- _ O
hyperaparameter -X- _ O
β -X- _ B-HyperparameterName
that -X- _ O
controls -X- _ O
how -X- _ O
strict -X- _ O
we -X- _ O
treat -X- _ O
a -X- _ O
sentence -X- _ O
as -X- _ O
evidence -X- _ O
or -X- _ O
nonevidence -X- _ O
(Section -X- _ O
4.3). -X- _ O

Analysis -X- _ O
on -X- _ O
hyperparameter -X- _ O
β. -X- _ B-HyperparameterName

n) -X- _ O

This -X- _ O
shows -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
SIEF-trained -X- _ B-MethodName
models, -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
non-evidences -X- _ O
sentences -X- _ O
for -X- _ O
DocRE. -X- _ B-TaskName

models -X- _ O
(left -X- _ O
magenta -X- _ O
plots) -X- _ O
scatters -X- _ O
over -X- _ O
a -X- _ O
wider -X- _ O
range, -X- _ O
whereas -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
training -X- _ O
(right -X- _ O
cyan -X- _ O
plots) -X- _ O
makes -X- _ O
them -X- _ O
more -X- _ O
concentrated -X- _ O
on -X- _ O
the -X- _ O
diagonal, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
prediction -X- _ O
Pij -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
is -X- _ O
mostly -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
ˆP -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
non− -X- _ O
ij -X- _ O
evidence -X- _ O
removed. -X- _ O

Figure -X- _ O
5: -X- _ O
Robustness -X- _ O
of -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
figure, -X- _ O
the -X- _ O
points -X- _ O
of -X- _ O
the -X- _ O
base -X- _ O

n) -X- _ O

We -X- _ O
show -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
the -X- _ O
scatter -X- _ O
plots -X- _ O
of -X- _ O
the -X- _ O
probability -X- _ O
P -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
and -X- _ O
the -X- _ O
probability -X- _ O
ˆP -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
non-evidence -X- _ O
− -X- _ O
ij -X- _ O
sentence -X- _ O
removed. -X- _ O

We -X- _ O
further -X- _ O
investigate -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
DocRE -X- _ B-TaskName
models -X- _ O
by -X- _ O
showing -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
predicted -X- _ O
distributions -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
non-evidence -X- _ O
sentences. -X- _ O

Robustness -X- _ O
of -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

This -X- _ O
further -X- _ O
verifies -X- _ O
that -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
framework -X- _ O
not -X- _ O
only -X- _ O
improves -X- _ O
relation -X- _ O
extraction -X- _ O
performance, -X- _ O
but -X- _ O
also -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
better -X- _ O
detect -X- _ O
evidence -X- _ O
and -X- _ O
non-evidence -X- _ O
sentences, -X- _ O
which -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
the -X- _ O
interpretability -X- _ O
of -X- _ O
machine -X- _ O
learning -X- _ O
models. -X- _ O

the -X- _ O
performance -X- _ O
improves -X- _ O
for -X- _ O
all -X- _ O
metrics, -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
2.95 -X- _ B-MetricValue
F1 -X- _ B-MetricName
points -X- _ O
across -X- _ O
three -X- _ O
base -X- _ O
models. -X- _ O

With -X- _ O
the -X- _ O
proposed -X- _ O
SIEF -X- _ B-MethodName
framework, -X- _ O

As -X- _ O
seen, -X- _ O
all -X- _ O
base -X- _ O
models -X- _ O
achieve -X- _ O
above -X- _ O
60% -X- _ B-MetricValue
F1, -X- _ B-MetricName
suggesting -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
importance -X- _ O
score -X- _ O
is -X- _ O
indeed -X- _ O
indicative -X- _ O
for -X- _ O
predicting -X- _ O
evidence -X- _ O
and -X- _ O
nonevidence -X- _ O
sentences. -X- _ O

Specifically, -X- _ O
for -X- _ O
entity -X- _ O
pair -X- _ O
(eih, -X- _ O
eit) -X- _ O
with -X- _ O
relation -X- _ O
j, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
importance -X- _ O
score -X- _ O
g( -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
and -X- _ O
cut -X- _ O
off -X- _ O
evidence/non− -X- _ O
ij -X- _ O
evidence -X- _ O
sentences -X- _ O
with -X- _ O
a -X- _ O
threshold -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
F1 -X- _ B-MetricName
score. -X- _ O

n) -X- _ O

In -X- _ O
this -X- _ O
analysis, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
perform -X- _ O
relation -X- _ O
prediction, -X- _ O
but -X- _ O
concern -X- _ O
about -X- _ O
entity -X- _ O
pairs -X- _ O
knowingly -X- _ O
having -X- _ O
certain -X- _ O
relations. -X- _ O

We -X- _ O
evaluate -X- _ O
such -X- _ O
performance -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
by -X- _ O
Precision, -X- _ B-MetricName
Recall, -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
against -X- _ O
manually -X- _ O
annotated -X- _ O
evidence -X- _ O
sentences -X- _ O
that -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
the -X- _ O
dataset. -X- _ O

annotation. -X- _ O

Table -X- _ O
4: -X- _ O
Results -X- _ O
of -X- _ O
the -X- _ O
evidence -X- _ O
prediction -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
DocRED. -X- _ B-DatasetName

Model -X- _ O
BiLSTM -X- _ O
+SIEF -X- _ O

Figure -X- _ O
4: -X- _ O
Performances -X- _ O
of -X- _ O
the -X- _ O
classification -X- _ O
(in -X- _ O
F1 -X- _ B-MetricName
scores) -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
different -X- _ O
hyperparameter -X- _ O
β -X- _ B-HyperparameterName
in -X- _ O
Eqn. -X- _ O
(6) -X- _ O
during -X- _ O
the -X- _ O
training. -X- _ O

In -X- _ O
our -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
sentence -X- _ O
importance -X- _ O
score -X- _ O
to -X- _ O
measure -X- _ O
how -X- _ O
much -X- _ O
a -X- _ O
sentence -X- _ O
contributes -X- _ O
to -X- _ O
the -X- _ O
classification -X- _ O
without -X- _ O
using -X- _ O
additional -X- _ O

Performance -X- _ O
of -X- _ O
predicting -X- _ O
evidence -X- _ O
sentences. -X- _ O

Based -X- _ O
on -X- _ O
this -X- _ O
analysis, -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
SIEF -X- _ B-MethodName
framework -X- _ O
with -X- _ O
multi-sentence -X- _ O
DocRE -X- _ B-TaskName
reasoning -X- _ O
in -X- _ O
our -X- _ O
future -X- _ O
work. -X- _ O

This -X- _ O
is -X- _ O
because -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
encourages -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
evidence -X- _ O
by -X- _ O
removing -X- _ O
one -X- _ O
sentence -X- _ O
at -X- _ O
a -X- _ O
time, -X- _ O
but -X- _ O
does -X- _ O
not -X- _ O
explicitly -X- _ O
model -X- _ O
sentence -X- _ O
relations. -X- _ O

However, -X- _ O
the -X- _ O
improvement -X- _ O
on -X- _ O
Intra-F1 -X- _ B-MetricName
is -X- _ O
larger -X- _ O
than -X- _ O
that -X- _ O
on -X- _ B-MetricName
Inter-F1. -X- _ I-MetricName

SIEF -X- _ B-MethodName
again -X- _ O
consistently -X- _ O
improves -X- _ O
base -X- _ O
models -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
both -X- _ O
Intra-F1 -X- _ B-MetricName
and -X- _ O
Inter-F1. -X- _ B-MetricName

The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3. -X- _ O

We -X- _ O
follow -X- _ O
Nan -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
and -X- _ O
approximate -X- _ O
it -X- _ O
by -X- _ O
checking -X- _ O
whether -X- _ O
two -X- _ O
entities -X- _ O
are -X- _ O
mentioned -X- _ O
in -X- _ O
one -X- _ O
sentence. -X- _ O

Ideally, -X- _ O
if -X- _ O
only -X- _ O
one -X- _ O
sentence -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
relation -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
pair, -X- _ O
then -X- _ O
it -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
intra-sentence -X- _ O
category; -X- _ O
if -X- _ O
two -X- _ O
or -X- _ O
more -X- _ O
sentences -X- _ O
are -X- _ O
needed, -X- _ O
then -X- _ O
it -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
inter-sentence -X- _ O
category. -X- _ O

We -X- _ O
breakdown -X- _ O
the -X- _ O
relation -X- _ O
classification -X- _ O
performance -X- _ O
into -X- _ O
intra-sentence -X- _ O
reasoning -X- _ O
and -X- _ O
inter-sentence -X- _ O
reasoning. -X- _ O

Intra- -X- _ O
and -X- _ O
Inter-Sentence -X- _ O
Performance. -X- _ O

All -X- _ O
base -X- _ O
models -X- _ O
use -X- _ O
GloVe -X- _ O
embeddings -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
BERT -X- _ O
due -X- _ O
to -X- _ O
efficiency -X- _ O
concerns. -X- _ O

In -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
present -X- _ O
in-depth -X- _ O
analyses -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
DocRED -X- _ B-DatasetName
as -X- _ O
the -X- _ O
testbed. -X- _ O

This -X- _ O
further -X- _ O
confirms -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
in -X- _ O
different -X- _ O
domains. -X- _ O

As -X- _ O
seen, -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
improvement -X- _ O
on -X- _ O
DocRED, -X- _ B-DatasetName
as -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
largely -X- _ O
improves -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
F1c -X- _ B-MetricName
for -X- _ O
both -X- _ O
base -X- _ O
models. -X- _ O

We -X- _ O
further -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
DialogRE -X- _ B-DatasetName
dataset, -X- _ O
and -X- _ O
compare -X- _ O
our -X- _ O
approach -X- _ O
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
baselines -X- _ O
in -X- _ O
Yu -X- _ O
et -X- _ O
al. -X- _ O
(2020). -X- _ O

Especially, -X- _ O
combining -X- _ O
SIEF -X- _ B-MethodName
and -X- _ O
GAIN -X- _ B-MethodName
(Zeng -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
with -X- _ O
BERTbase -X- _ O
encoding -X- _ O
yields -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ B-MetricName
F1. -X- _ I-MetricName

consistently -X- _ O
improves -X- _ O
the -X- _ O
base -X- _ O
models, -X- _ O
showing -X- _ O
that -X- _ O
SIEF -X- _ B-MethodName
is -X- _ O
complementary -X- _ O
to -X- _ O
the -X- _ O
modern -X- _ O
BERT -X- _ O
architecture. -X- _ O

Table -X- _ O
3: -X- _ O
Results -X- _ O
of -X- _ O
Intra-F1 -X- _ B-MetricName
results -X- _ O
and -X- _ O
Infer-F1 -X- _ B-MetricName
on -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
DocRED. -X- _ B-DatasetName

For -X- _ O
the -X- _ O
DocRE -X- _ B-TaskName
system -X- _ O
with -X- _ O
BERTbase, -X- _ B-MethodName
SIEF -X- _ B-MethodName
also -X- _ O

This -X- _ O
shows -X- _ O
that -X- _ O
SIEF -X- _ B-MethodName
is -X- _ O
compatible -X- _ O
with -X- _ O
both -X- _ O
sequence -X- _ O
and -X- _ O
graph -X- _ O
models, -X- _ O
indicating -X- _ O
the -X- _ O
generality -X- _ O
and -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method. -X- _ O

We -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
SIEF -X- _ B-MethodName
method -X- _ O
significantly -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
all -X- _ O
base -X- _ O
models, -X- _ O
including -X- _ O
the -X- _ O
sequence -X- _ O
model -X- _ O
(i.e., -X- _ O
BiLSTM) -X- _ B-MethodName
and -X- _ O
graph -X- _ O
models -X- _ O
(i.e., -X- _ O
HeterGSAN -X- _ B-MethodName
and -X- _ O
GAIN); -X- _ B-MethodName
the -X- _ O
average -X- _ O
improvement -X- _ O
is -X- _ O
2.05 -X- _ B-MetricValue
points -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
test -X- _ O
F1. -X- _ B-MetricName

We -X- _ O
first -X- _ O
compare -X- _ O
DocRE -X- _ B-TaskName
systems -X- _ O
with -X- _ O
GloVe -X- _ O
embeddings -X- _ O
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Table -X- _ O
1 -X- _ O
presents -X- _ O
the -X- _ O
detailed -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
the -X- _ O
DocRED -X- _ B-DatasetName
dataset. -X- _ O

Main -X- _ O
results. -X- _ O

5.2 -X- _ O
Results -X- _ O
and -X- _ O
Analyses -X- _ O

It -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
0.8, -X- _ B-HyperparameterValue
and -X- _ O
Section -X- _ O
5.2 -X- _ O
presents -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
tuning -X- _ B-HyperparameterName
β. -X- _ I-HyperparameterName

(5). -X- _ O

Our -X- _ O
SIEF -X- _ B-MethodName
has -X- _ O
one -X- _ O
hyperparameter -X- _ O
β -X- _ B-HyperparameterName
in -X- _ O
Eqn. -X- _ O

We -X- _ O
mostly -X- _ O
followed -X- _ O
the -X- _ O
standard -X- _ O
hyperparameters -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
base -X- _ O
models. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
repositories2,3,4,5 -X- _ O
of -X- _ O
base -X- _ O
models -X- _ O
to -X- _ O
implement -X- _ O
our -X- _ O
approach. -X- _ O

Implementation -X- _ O
Details. -X- _ O

Model -X- _ O

Bold -X- _ O
indicates -X- _ O
the -X- _ O
best -X- _ O
performance. -X- _ O

Table -X- _ O
1: -X- _ O
Results -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
the -X- _ O
DocRE -X- _ B-TaskName
dataset. -X- _ O

1 -X- _ O

2 -X- _ O

3 -X- _ O

1 -X- _ O

3 -X- _ O

2 -X- _ O

Mention-document -X- _ O
graph -X- _ O
Entity -X- _ O
graph -X- _ O

The -X- _ O
Bee -X- _ O
is -X- _ O
the -X- _ O
flagship -X- _ O
of -X- _ O
the -X- _ O
nationwide -X- _ O
McClatchy -X- _ O
Company. -X- _ O
… -X- _ O

[3] -X- _ O

[2] -X- _ O
Since -X- _ O
its -X- _ O
founding -X- _ O
in -X- _ O
1857, -X- _ O
The -X- _ O
Bee -X- _ O
has -X- _ O
become -X- _ O
the -X- _ O
27th -X- _ O
largest -X- _ O
paper -X- _ O
in -X- _ O
the -X- _ O
U.S. -X- _ O

[1] -X- _ O
The -X- _ O
Sacramento -X- _ O
Bee -X- _ O
is -X- _ O
a -X- _ O
daily -X- _ O
newspaper -X- _ O
published -X- _ O
in -X- _ O
Sacramento, -X- _ O
California -X- _ O
in -X- _ O
the -X- _ O
United -X- _ O
States. -X- _ O

Empirical -X- _ O
results -X- _ O
will -X- _ O
show -X- _ O
that -X- _ O
our -X- _ B-MethodName
SIEF -X- _ I-MethodName
consistently -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
base -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

For -X- _ O
prediction, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
trained -X- _ O
DocRE -X- _ B-TaskName
model -X- _ O
to -X- _ O
the -X- _ O
entire -X- _ O
document, -X- _ O
because -X- _ O
with -X- _ O
our -X- _ O
approach -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
already -X- _ O
robust -X- _ O
when -X- _ O
nonevidence -X- _ O
sentences -X- _ O
are -X- _ O
presented. -X- _ O

n) -X- _ O

n) -X- _ O

(4) -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
robustness. -X- _ O

If -X- _ O
the -X- _ O
sentence -X- _ O
important -X- _ O
− -X- _ O
ij -X- _ O
score -X- _ O
g( -X- _ O
in -X- _ O
Eqn. -X- _ O
(3) -X- _ O
is -X- _ O
below -X- _ O
a -X- _ O
threshold -X- _ O
β, -X- _ O
the -X- _ O
− -X- _ O
ij -X- _ O
sentence -X- _ O
is -X- _ O
treated -X- _ O
as -X- _ O
non-evidence -X- _ O
for -X- _ O
the -X- _ O
entity -X- _ O
pair -X- _ O
(eih, -X- _ O
eit) -X- _ O
and -X- _ O
relation -X- _ O
j. -X- _ O
We -X- _ O
apply -X- _ O
the -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
Eqn. -X- _ O

Then -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
output -X- _ O
probabilities -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
sentence, -X- _ O
Pij -X- _ O
and -X- _ O
ˆP -X- _ O
( -X- _ O
, -X- _ O
separately. -X- _ O

The -X- _ O
corresponding -X- _ O
nodes -X- _ O
and -X- _ O
edges -X- _ O
are -X- _ O
removed -X- _ O
in -X- _ O
the -X- _ O
GAIN’s -X- _ B-MethodName
graphs. -X- _ O

When -X- _ O
combining -X- _ O
SIEF -X- _ B-MethodName
with -X- _ O
GAIN, -X- _ B-MethodName
we -X- _ O
randomly -X- _ O
remove -X- _ O
one -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
document. -X- _ O

To -X- _ O
classify -X- _ O
the -X- _ O
relation, -X- _ O
GNN -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
mention– -X- _ O
document -X- _ O
graph, -X- _ O
enhanced -X- _ O
with -X- _ O
path -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
entity -X- _ O
graph, -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3. -X- _ O

connected -X- _ O
if -X- _ O
they -X- _ O
are -X- _ O
mentioned -X- _ O
in -X- _ O
one -X- _ O
sentence. -X- _ O

The -X- _ O
mentions -X- _ O
are -X- _ O
connected -X- _ O
to -X- _ O
its -X- _ O
document, -X- _ O
and -X- _ O
two -X- _ O
mentions -X- _ O
are -X- _ O
connected -X- _ O
if -X- _ O
they -X- _ O
co-occur -X- _ O
in -X- _ O
one -X- _ O
In -X- _ O
the -X- _ O
entity -X- _ O
graph, -X- _ O
two -X- _ O
entities -X- _ O
are -X- _ O
sentence. -X- _ O

Essentially, -X- _ O
a -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
mention–document -X- _ O
graph -X- _ O
is -X- _ O
either -X- _ O
a -X- _ O
mention -X- _ O
or -X- _ O
a -X- _ O
document. -X- _ O

Thus, -X- _ O
we -X- _ O
will -X- _ O
explain -X- _ O
this -X- _ O
model -X- _ O
in -X- _ O
more -X- _ O
detail. -X- _ O

When -X- _ O
combining -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
with -X- _ O
GAIN, -X- _ B-MethodName
we -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
among -X- _ O
all -X- _ O
the -X- _ O
base -X- _ O
models -X- _ O
with -X- _ O
SIEF -X- _ B-MethodName
on -X- _ B-DatasetName
DocRED. -X- _ I-DatasetName

GAIN -X- _ B-MethodName
constructs -X- _ O
two -X- _ O
graphs: -X- _ O
mention–document -X- _ O
graphs -X- _ O
and -X- _ O
entity -X- _ O
graphs, -X- _ O
and -X- _ O
performs -X- _ O
graph -X- _ O
and -X- _ O
path -X- _ O
reasoning -X- _ O
over -X- _ O
the -X- _ O
two -X- _ O
graphs -X- _ O
separately. -X- _ O

GAIN -X- _ B-MethodName
(Zeng -X- _ O
et -X- _ O
al., -X- _ O
2020)3. -X- _ O

The -X- _ O
corresponding -X- _ O
nodes -X- _ O
and -X- _ O
edges -X- _ O
are -X- _ O
removed -X- _ O
from -X- _ O
the -X- _ O
mention–document -X- _ O
graph -X- _ O
and -X- _ O
the -X- _ O
entity -X- _ O
graph. -X- _ O

A -X- _ O
sentence -X- _ O
is -X- _ O
randomly -X- _ O
removed -X- _ O
from -X- _ O
the -X- _ O
document. -X- _ O

Figure -X- _ O
3: -X- _ O
The -X- _ O
model -X- _ O
architecture -X- _ O
of -X- _ O
GAIN -X- _ B-MethodName
with -X- _ O
SIEF. -X- _ B-MethodName

5https://github.com/nlpdata/dialogre -X- _ O

For -X- _ O
DialogRE, -X- _ B-DatasetName
we -X- _ O
followed -X- _ O
Yu -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
and -X- _ O
considered -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
BERTs -X- _ B-MethodName
for -X- _ O
comparison,5 -X- _ O
where -X- _ O
BERTs -X- _ B-MethodName
prevents -X- _ O
a -X- _ O
model -X- _ O
from -X- _ O
overfitting -X- _ O
by -X- _ O
replacing -X- _ O
of -X- _ O
the -X- _ O
interpersonal -X- _ O
augment -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
token. -X- _ O

For -X- _ O
DocRED, -X- _ B-DatasetName
we -X- _ O
consider -X- _ O
additional -X- _ O
competing -X- _ O
methods: -X- _ O
Two -X- _ O
Phase -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
which -X- _ O
first -X- _ O
predicts -X- _ O
whether -X- _ O
the -X- _ O
entity -X- _ O
pair -X- _ O
has -X- _ O
a -X- _ O
relation -X- _ O
and -X- _ O
then -X- _ O
predicts -X- _ O
the -X- _ O
relation -X- _ O
type; -X- _ O
LSR -X- _ B-MethodName
(Nan -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
which -X- _ O
constructs -X- _ O
the -X- _ O
graph -X- _ O
by -X- _ O
inducing -X- _ O
a -X- _ O
latent -X- _ O
document-level -X- _ O
graph; -X- _ O
Reconstructor -X- _ B-MethodName
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021b), -X- _ O
which -X- _ O
encourages -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
reconstruct -X- _ O
a -X- _ O
reasoning -X- _ O
path -X- _ O
during -X- _ O
training; -X- _ O
DRN -X- _ B-MethodName
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
which -X- _ O
considers -X- _ O
different -X- _ O
reasoning -X- _ O
skills -X- _ O
explicitly -X- _ O
and -X- _ O
uses -X- _ O
graph -X- _ O
representation -X- _ O
and -X- _ O
context -X- _ O
representation -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
reasoning -X- _ O
skills; -X- _ O
ATLOP -X- _ B-MethodName
(Zhou -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
which -X- _ O
aggregates -X- _ O
contextual -X- _ O
information -X- _ O
by -X- _ O
the -X- _ O
Transformer -X- _ O
attentions -X- _ O
and -X- _ O
adopts -X- _ O
an -X- _ O
adaptive -X- _ O
threshold -X- _ O
for -X- _ O
different -X- _ O
entity -X- _ O
pairs; -X- _ O
and -X- _ O
DocuNet -X- _ B-MethodName
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
which -X- _ O
models -X- _ O
DocRE -X- _ B-TaskName
as -X- _ O
a -X- _ O
semantic -X- _ O
segmentation -X- _ O
task. -X- _ O

These -X- _ O
base -X- _ O
models -X- _ O
are -X- _ O
all -X- _ O
considered -X- _ O
for -X- _ O
comparison. -X- _ O

We -X- _ O
experimented -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
on -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
base -X- _ O
models, -X- _ O
namely, -X- _ O
BiLSTM, -X- _ B-MethodName
BERTbase, -X- _ B-MethodName
HeterGSAN, -X- _ B-MethodName
and -X- _ O
GAIN -X- _ B-MethodName
(Section -X- _ O
4.4). -X- _ O

Competing -X- _ O
Methods. -X- _ O

(2020), -X- _ O
we -X- _ O
report -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
scores -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
standard -X- _ O
and -X- _ O
conversational -X- _ O
settings; -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
F1c. -X- _ B-MetricName

Following -X- _ O
Yu -X- _ O
et -X- _ O
al. -X- _ O

We -X- _ O
followed -X- _ O
the -X- _ O
standard -X- _ O
split -X- _ O
with -X- _ O
1073 -X- _ O
training -X- _ O
dialogues, -X- _ O
358 -X- _ O
validation, -X- _ O
and -X- _ O
357 -X- _ O
test. -X- _ O

We -X- _ O
also -X- _ O
evaluated -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
DialogRE -X- _ B-DatasetName
(V2, -X- _ O
Yu -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
which -X- _ O
contains -X- _ O
36 -X- _ O
relation -X- _ O
types, -X- _ O
17 -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
interpersonal. -X- _ O

The -X- _ O
standard -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
Ign -X- _ B-MetricName
F1 -X- _ I-MetricName
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zeng -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
where -X- _ O
Ign -X- _ B-MetricName
F1 -X- _ I-MetricName
refers -X- _ O
to -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
excluding -X- _ O
the -X- _ O
relational -X- _ O
facts -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set. -X- _ O

More -X- _ O
than -X- _ O
40% -X- _ O
of -X- _ O
the -X- _ O
relational -X- _ O
facts -X- _ O
require -X- _ O
reasoning -X- _ O
over -X- _ O
multiple -X- _ O
sentences. -X- _ O

In -X- _ O
total, -X- _ O
it -X- _ O
has -X- _ O
132,375 -X- _ O
entities -X- _ O
and -X- _ O
56,354 -X- _ O
relational -X- _ O
facts -X- _ O
in -X- _ O
96 -X- _ O
relation -X- _ O
types. -X- _ O

The -X- _ O
dataset -X- _ O
is -X- _ O
constructed -X- _ O
from -X- _ O
Wikipedia -X- _ O
and -X- _ O
Wikidata, -X- _ O
containing -X- _ O
3053 -X- _ O
documents -X- _ O
for -X- _ O
training, -X- _ O
1000 -X- _ O
for -X- _ O
development, -X- _ O
and -X- _ O
1000 -X- _ O
for -X- _ O
test. -X- _ O

DocRED -X- _ B-DatasetName
is -X- _ O
a -X- _ O
large-scale -X- _ O
humanannotated -X- _ O
dataset -X- _ O
for -X- _ O
document-level -X- _ O
relation -X- _ O
extraction -X- _ O
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Datasets. -X- _ O

5.1 -X- _ O
Setup -X- _ O

5 -X- _ O
Experiments -X- _ O

2https://github.com/thunlp/DocRED -X- _ O
3https://github.com/DreamInvoker/GAIN -X- _ O
4https://github.com/xwjim/DocRE-Rec -X- _ O

HeterGSAN -X- _ B-MethodName
is -X- _ O
a -X- _ O
recent -X- _ O
graph-based -X- _ O
DocRED -X- _ B-DatasetName
model, -X- _ O
which -X- _ O
constructs -X- _ O
a -X- _ O
heterogeneous -X- _ O
graph -X- _ O
of -X- _ O
sentence, -X- _ O
mention, -X- _ O
and -X- _ O
entity -X- _ O
nodes; -X- _ O
it -X- _ O
uses -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
for -X- _ O
relation -X- _ O
extraction. -X- _ O

HeterGSAN -X- _ O
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021b)4. -X- _ O

language -X- _ O
model -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
document -X- _ O
encoding. -X- _ O

A -X- _ O
pre-trained -X- _ O

BERTbase -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019)3. -X- _ O

The -X- _ O
head -X- _ O
and -X- _ O
tail -X- _ O
entity -X- _ O
representations -X- _ O
are -X- _ O
fed -X- _ O
to -X- _ O
a -X- _ O
multi-layer -X- _ O
perceptron -X- _ O
(MLP) -X- _ O
for -X- _ O
relation -X- _ O
extraction. -X- _ O

A -X- _ O
bi-directional -X- _ O
long -X- _ O
short -X- _ O
term -X- _ O
memory -X- _ O
(BiLSTM) -X- _ O
encodes -X- _ O
the -X- _ O
document, -X- _ O
and -X- _ O
an -X- _ O
entity -X- _ O
is -X- _ O
representated -X- _ O
by -X- _ O
BiLSTM’s -X- _ O
hidden -X- _ O
states, -X- _ O
averaged -X- _ O
over -X- _ O
entity -X- _ O
mentions. -X- _ O

BiLSTM -X- _ O
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2019)2. -X- _ O

To -X- _ O
evaluate -X- _ O
its -X- _ O
generality, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
recent -X- _ O
models. -X- _ O

Our -X- _ O
SIEF -X- _ B-MethodName
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
various -X- _ O
base -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

4.4 -X- _ O
DocRE -X- _ B-TaskName
Model -X- _ O
Architectures -X- _ O

Our -X- _ O
approach -X- _ O
is -X- _ O
a -X- _ O
generic -X- _ O
framework -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
various -X- _ O
DocRE -X- _ B-TaskName
model -X- _ O
easily, -X- _ O
without -X- _ O
introducing -X- _ O
extra -X- _ O
parameters -X- _ O
into -X- _ O
the -X- _ O
model. -X- _ O

the -X- _ O
proposed -X- _ O
SIEF -X- _ B-MethodName
framework -X- _ O
identifies -X- _ O
non-evidence -X- _ O
sentences -X- _ O
and -X- _ O
penalizes -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
predicted -X- _ O
probabilities -X- _ O
when -X- _ O
a -X- _ O
nonevidence -X- _ O
sentence -X- _ O
is -X- _ O
removed. -X- _ O

To -X- _ O
sum -X- _ O
up, -X- _ O

Their -X- _ O
approach -X- _ O
is -X- _ O
much -X- _ O
slower -X- _ O
than -X- _ O
ours. -X- _ O

Huang -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
propose -X- _ O
a -X- _ O
similar -X- _ O
idea -X- _ O
but -X- _ O
train -X- _ O
different -X- _ O
entity -X- _ O
pairs -X- _ O
in -X- _ O
a -X- _ O
document -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
sets -X- _ O
of -X- _ O
sentences; -X- _ O
all -X- _ O
sentence -X- _ O
are -X- _ O
processed -X- _ O
repeatedly -X- _ O
among -X- _ O
entity -X- _ O
pairs -X- _ O
in -X- _ O
a -X- _ O
document. -X- _ O

} -X- _ O
(6) -X- _ O
As -X- _ O
seen, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
forward -X- _ O
the -X- _ O
base -X- _ O
models -X- _ O
twice -X- _ O
in -X- _ O
each -X- _ O
update, -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
sentence -X- _ O
n. -X- _ O

Lsf -X- _ O
= -X- _ O

The -X- _ O
loss -X- _ O
is -X- _ O
reformulated -X- _ O
as -X- _ O
follows: -X- _ O

In -X- _ O
implementation, -X- _ O
we -X- _ O
further -X- _ O
simply -X- _ O
the -X- _ O
summation -X- _ O
over -X- _ O
n -X- _ O
by -X- _ O
Monte -X- _ O
Carlo -X- _ O
sampling -X- _ O
of -X- _ O
a -X- _ O
randomly -X- _ O
selected -X- _ O
sentence -X- _ O
n -X- _ O
in -X- _ O
each -X- _ O
gradient -X- _ O
update. -X- _ O

N -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
terms -X- _ O
does -X- _ O
not -X- _ O
grow -X- _ O
combinatorially, -X- _ O
but -X- _ O
linearly -X- _ O
w.r.t. -X- _ O

Essentially, -X- _ O
we -X- _ O
linearly -X- _ O
approximate -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
multiple -X- _ O
non-evidence -X- _ O
sentences -X- _ O
in -X- _ O
(4) -X- _ O
by -X- _ O
an -X- _ O
outer -X- _ O
summation. -X- _ O

where -X- _ O
I -X- _ O
is -X- _ O
the -X- _ O
indicator -X- _ O
function. -X- _ O

the -X- _ O
effect -X- _ O
of -X- _ O
different -X- _ O
non-evidence -X- _ O
sentences -X- _ O
by: -X- _ O

Concretely, -X- _ O
we -X- _ O
only -X- _ O
remove -X- _ O
one -X- _ O
non-evidence -X- _ O
sentence -X- _ O
in -X- _ O
Kij -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
Kij, -X- _ O
and -X- _ O
we -X- _ O
aggregate -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
Jij -X- _ O
⊆ -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
strategy -X- _ O
to -X- _ O
simplify -X- _ O
the -X- _ O
calculation -X- _ O
and -X- _ O
the -X- _ O
training -X- _ O
procedure. -X- _ O

4.3 -X- _ O
Training -X- _ O
Strategy -X- _ O

To -X- _ O
this -X- _ O
end, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
simplified -X- _ O
training -X- _ O
strategy -X- _ O
to -X- _ O
approximate -X- _ O
Eqn. -X- _ O
(4) -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
subsection. -X- _ O

Moreover -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
calculated -X- _ O
repeatedly -X- _ O
once -X- _ O
the -X- _ O
parameter -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
updated. -X- _ O

The -X- _ O
calculation -X- _ O
of -X- _ O
Eqn. -X- _ O
(4) -X- _ O
is -X- _ O
time- -X- _ O
and -X- _ O
resourceconsuming, -X- _ O
because -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
the -X- _ O
subsets -X- _ O
Jij -X- _ O
grows -X- _ O
combinatorially -X- _ O
with -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
non-evidence -X- _ O
sentences. -X- _ O

for -X- _ O
training. -X- _ O

However, -X- _ O
compared -X- _ O
with -X- _ O
one-hot -X- _ O
groundtruth -X- _ O
labels, -X- _ O
our -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
works -X- _ O
with -X- _ O
soft -X- _ O
labels -X- _ O
Pij -X- _ O
and -X- _ O
ˆP -X- _ O
( -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
believed -X- _ O
to -X- _ O
contain -X- _ O
more -X- _ O
− -X- _ O
ij -X- _ O
information -X- _ O
(Hinton -X- _ O
et -X- _ O
al., -X- _ O
2015), -X- _ O
and -X- _ O
our -X- _ O
gradient -X- _ O
propagates -X- _ O
to -X- _ O
both -X- _ O
Pij -X- _ O
and -X- _ O
ˆP -X- _ O
( -X- _ O
− -X- _ O
ij -X- _ O

Our -X- _ O
approach -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
thought -X- _ O
of -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
of -X- _ O
data -X- _ O
augmentation. -X- _ O

( -X- _ O
Essentially, -X- _ O
our -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
ensures -X- _ O
Pij -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
ˆP -X- _ O
( -X- _ O
, -X- _ O
which -X- _ O
intuitively -X- _ O
makes -X- _ O
− -X- _ O
ij -X- _ O
sense -X- _ O
because -X- _ O
non-evidence -X- _ O
sentences -X- _ O
should -X- _ O
not -X- _ O
affect -X- _ O
the -X- _ O
prediction. -X- _ O

Jij -X- _ O
removed -X- _ O
from -X- _ O
D, -X- _ O
and -X- _ O
the -X- _ O
total -X- _ O
loss -X- _ O
is -X- _ O
Lrel -X- _ O
+ -X- _ O
Lsf)/2. -X- _ O

) -X- _ O
} -X- _ O
− -X- _ O
(4) -X- _ O
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
Kij -X- _ O
and -X- _ O
ˆP -X- _ O
( -X- _ O
= -X- _ O
where -X- _ O
Jij -X- _ O
Jij, -X- _ O
eih, -X- _ O
eit) -X- _ O
is -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
with -X- _ O
Fj(D -X- _ O
\ -X- _ O
= -X- _ O

Lsf -X- _ O
= -X- _ O

We -X- _ O
propose -X- _ O
the -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
as: -X- _ O

Therefore, -X- _ O
we -X- _ O
penalize -X- _ O
the -X- _ O
extent -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
is -X- _ O
changed. -X- _ O

Ideally, -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
should -X- _ O
remain -X- _ O
the -X- _ O
same -X- _ O
if -X- _ O
we -X- _ O
remove -X- _ O
any -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
Kij. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
same -X- _ O
output -X- _ O
distribution -X- _ O
when -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
is -X- _ O
fed -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
when -X- _ O
non-evidence -X- _ O
sentences -X- _ O
are -X- _ O
removed. -X- _ O

4.2 -X- _ O
Sentence -X- _ O
Focusing -X- _ O
Loss -X- _ O

Input -X- _ O
Document -X- _ O

Original -X- _ O
Document -X- _ O

The -X- _ O
Bee -X- _ O
is -X- _ O
the -X- _ O
flagship -X- _ O
of -X- _ O
the -X- _ O
American -X- _ O
McClatchy -X- _ O
Company. -X- _ O

[3] -X- _ O

[2] -X- _ O
Since -X- _ O
its -X- _ O
founding -X- _ O
in -X- _ O
1857, -X- _ O
The -X- _ O
Bee -X- _ O
has -X- _ O
become -X- _ O
the -X- _ O
largest -X- _ O
newspaper -X- _ O
in -X- _ O
Sacramento, -X- _ O
the -X- _ O
fifth -X- _ O
largest -X- _ O
newspaper -X- _ O
in -X- _ O
California, -X- _ O
and -X- _ O
the -X- _ O
27th -X- _ O
largest -X- _ O
paper -X- _ O
in -X- _ O
the -X- _ O
U.S. -X- _ O

[1] -X- _ O
The -X- _ O
Sacramento -X- _ O
Bee -X- _ O
is -X- _ O
a -X- _ O
daily -X- _ O
newspaper -X- _ O
published -X- _ O
in -X- _ O
Sacramento, -X- _ O
California, -X- _ O
in -X- _ O
the -X- _ O
United -X- _ O
States. -X- _ O

The -X- _ O
resulting -X- _ O
set -X- _ O
of -X- _ O
non-evidence -X- _ O
sentences -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
Kij -X- _ O
for -X- _ O
the -X- _ O
an -X- _ O
entity -X- _ O
pair -X- _ O
(eih, -X- _ O
eit) -X- _ O
and -X- _ O
relation -X- _ O
j. -X- _ O

We -X- _ O
treat -X- _ O
a -X- _ O
sentence -X- _ O
n -X- _ O
as -X- _ O
non-evidence -X- _ O
if -X- _ O
g( -X- _ O
n) -X- _ O
ij -X- _ O
< -X- _ O
− -X- _ O
β -X- _ O
for -X- _ O
a -X- _ O
thresholding -X- _ O
hyperparameter -X- _ O
β. -X- _ B-HyperparameterName

is -X- _ O
monotonically -X- _ O
decreasing -X- _ O
with -X- _ O
ˆP -X- _ O
( -X- _ O
− -X- _ O
ij -X- _ O

− -X- _ O
ij -X- _ O
Compared -X- _ O
with -X- _ O
a -X- _ O
naive -X- _ O
difference -X- _ O
or -X- _ O
ratio -X- _ O
between -X- _ O
Pij -X- _ O
and -X- _ O
ˆP -X- _ O
( -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
our -X- _ O
KL-like -X- _ O
score -X- _ O
is -X- _ O
ij -X- _ O
more -X- _ O
robust -X- _ O
in -X- _ O
the -X- _ O
scale -X- _ O
of -X- _ O
Pij -X- _ O
when -X- _ O
determining -X- _ O
non-evidence -X- _ O
sentences. -X- _ O

However, -X- _ O
we -X- _ O
only -X- _ O
take -X- _ O
one -X- _ O
term -X- _ O
in -X- _ O
the -X- _ O
KL -X- _ O
summation, -X- _ O
because -X- _ O
the -X- _ O
KL -X- _ O
divergence, -X- _ O
albeit -X- _ O
asymmetric -X- _ O
in -X- _ O
its -X- _ O
two -X- _ O
arguments, -X- _ O
cannot -X- _ O
model -X- _ O
the -X- _ O
increase -X- _ O
or -X- _ O
decrease -X- _ O
of -X- _ O
ˆP -X- _ O
( -X- _ O
, -X- _ O
whereas -X- _ O
ij -X- _ O
our -X- _ O
g( -X- _ O
n) -X- _ O
. -X- _ O

The -X- _ O
formula -X- _ O
appears -X- _ O
similar -X- _ O
to -X- _ O
Kullback–Leibler -X- _ O
(KL) -X- _ O
divergence. -X- _ O

We -X- _ O
propose -X- _ O
the -X- _ O
importance -X- _ O
score -X- _ O
as -X- _ O

1, -X- _ O
sn+1, -X- _ O

, -X- _ O
sN -X- _ O
} -X- _ O

Fj( -X- _ O
ˆD( -X- _ O
− -X- _ O

Fj(D, -X- _ O
eih, -X- _ O
eit) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
document, -X- _ O
and -X- _ O
ˆP -X- _ O
( -X- _ O
n), -X- _ O
eih, -X- _ O
eit) -X- _ O
with -X- _ O
− -X- _ O
ij -X- _ O
sentence -X- _ O
n -X- _ O
removed. -X- _ O

− -X- _ O
s1, -X- _ O
For -X- _ O
a -X- _ O
DocRE -X- _ B-TaskName
{ -X- _ O
model -X- _ O
F -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
classification -X- _ O
probabilities -X- _ O
Pij -X- _ O
= -X- _ O

Formally, -X- _ O
we -X- _ O
consider -X- _ O
removing -X- _ O
one -X- _ O
sentence -X- _ O
at -X- _ O
a -X- _ O
time, -X- _ O
and -X- _ O
the -X- _ O
document -X- _ O
with -X- _ O
the -X- _ O
nth -X- _ O
sentence -X- _ O
removed -X- _ O
is -X- _ O
denoted -X- _ O
by -X- _ O
ˆD( -X- _ O
n) -X- _ O
= -X- _ O

Moreover, -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
may -X- _ O
sometimes -X- _ O
increase -X- _ O
when -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
removed, -X- _ O
in -X- _ O
which -X- _ O
case -X- _ O
the -X- _ O
DocRE -X- _ B-TaskName
model -X- _ O
is -X- _ O
not -X- _ O
robust, -X- _ O
as -X- _ O
this -X- _ O
violates -X- _ O
monotonicity. -X- _ O

If -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
does -X- _ O
not -X- _ O
change, -X- _ O
then -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
nonevidence. -X- _ O

If -X- _ O
we -X- _ O
remove -X- _ O
a -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
relation -X- _ O
decreases, -X- _ O
then -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
evidence. -X- _ O

be -X- _ O
predicted -X- _ O
with -X- _ O
more -X- _ O
sentences. -X- _ O

Our -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
relation -X- _ O
extraction -X- _ O
task -X- _ O
is -X- _ O
usually -X- _ O
monotonic -X- _ O
to -X- _ O
evidence, -X- _ O
i.e., -X- _ O
(non-strictly) -X- _ O
more -X- _ O
relations -X- _ O
will -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
sentence -X- _ O
importance -X- _ O
score -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
DocRE -X- _ B-TaskName
predictions -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
sentence -X- _ O
in -X- _ O
question. -X- _ O

Low-scored -X- _ O
sentences -X- _ O
will -X- _ O
be -X- _ O
treated -X- _ O
as -X- _ O
non-evidence, -X- _ O
and -X- _ O
in -X- _ O
principle, -X- _ O
can -X- _ O
be -X- _ O
removed -X- _ O
without -X- _ O
changing -X- _ O
DocRE -X- _ B-TaskName
predictions. -X- _ O

We -X- _ O
estimate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
sentence -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
entity -X- _ O
pair. -X- _ O

4.1 -X- _ O
Sentence -X- _ O
Importance -X- _ O
Estimation -X- _ O

Section -X- _ O
4.4 -X- _ O
further -X- _ O
presents -X- _ O
the -X- _ O
architectures -X- _ O
of -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

Then, -X- _ O
Sections -X- _ O
4.2 -X- _ O
and -X- _ O
4.3 -X- _ O
present -X- _ O
our -X- _ O
approach -X- _ O
that -X- _ O
encourages -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
same -X- _ O
output -X- _ O
distribution, -X- _ O
when -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
is -X- _ O
fed -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
when -X- _ O
non-evidence -X- _ O
sentences -X- _ O
are -X- _ O
removed. -X- _ O

Sentences -X- _ O
with -X- _ O
low -X- _ O
importance -X- _ O
scores -X- _ O
are -X- _ O
treated -X- _ O
as -X- _ O
non-evidence. -X- _ O

First, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
estimation -X- _ O
of -X- _ O
sentence -X- _ O
importance -X- _ O
in -X- _ O
Section -X- _ O
4.1. -X- _ O

The -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
will -X- _ O
describe -X- _ O
our -X- _ O
approach -X- _ O
in -X- _ O
detail. -X- _ O

4 -X- _ O
Methodology -X- _ O

During -X- _ O
inference, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
relation(s) -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
entity -X- _ O
pair -X- _ O
by -X- _ O
thresholding -X- _ O
the -X- _ O
predicted -X- _ O
probabilities, -X- _ O
following -X- _ O
most -X- _ O
previous -X- _ O
work -X- _ O
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zhou -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

where -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
relation -X- _ O
types. -X- _ O

To -X- _ O
train -X- _ O
the -X- _ O
model, -X- _ O
the -X- _ O
binary -X- _ O
cross-entropy -X- _ O
loss -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
objective -X- _ O
for -X- _ O
parameter -X- _ O
estimation: -X- _ O

Then, -X- _ O
we -X- _ O
encourage -X- _ O
the -X- _ O
DocRE -X- _ B-TaskName
model -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
same -X- _ O
probability -X- _ O
when -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
is -X- _ O
fed -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
when -X- _ O
a -X- _ O
non-evidence -X- _ O
sentence -X- _ O
is -X- _ O
removed. -X- _ O

We -X- _ O
estimate -X- _ O
the -X- _ O
sentence -X- _ O
importance -X- _ O
(for -X- _ O
a -X- _ O
specific -X- _ O
entity -X- _ O
pair -X- _ O
and -X- _ O
relation) -X- _ O
by -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
the -X- _ O
classification -X- _ O
probabilities -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
sentence. -X- _ O

(1) -X- _ O
where -X- _ O
eih -X- _ O
is -X- _ O
the -X- _ O
head -X- _ O
entity -X- _ O
and -X- _ O
eit -X- _ O
is -X- _ O
the -X- _ O
tail -X- _ O
entity; -X- _ O
0, -X- _ O
1 -X- _ O
rij -X- _ O
∈ -X- _ O
{ -X- _ O
is -X- _ O
the -X- _ O
groundtruth -X- _ O
label -X- _ O
regarding -X- _ O
} -X- _ O
entity -X- _ O
pair -X- _ O
i -X- _ O
and -X- _ O
relation -X- _ O
j. -X- _ O

Fj -X- _ O
predicts -X- _ O
whether -X- _ O
the -X- _ O
jth -X- _ O
relation -X- _ O
holds -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
marked -X- _ O
entity -X- _ O
pair -X- _ O
in -X- _ O
a -X- _ O
document, -X- _ O
given -X- _ O
by -X- _ O

A -X- _ O
DocRE -X- _ B-TaskName
model -X- _ O
F -X- _ O
is -X- _ O
usually -X- _ O
formulated -X- _ O
as -X- _ O
multi-label -X- _ O
classification -X- _ O
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

In -X- _ O
a -X- _ O
DocRE -X- _ B-TaskName
dataset, -X- _ O
the -X- _ O
document -X- _ O
D -X- _ O
is -X- _ O
typically -X- _ O
annotated -X- _ O
with -X- _ O
entity -X- _ O
mentions, -X- _ O
each -X- _ O
mention -X- _ O
(e.g., -X- _ O
U.S. -X- _ O
and -X- _ O
USA) -X- _ O
labeled -X- _ O
by -X- _ O
its -X- _ O
conceptual -X- _ O
entity -X- _ O
e -X- _ O
and -X- _ O
its -X- _ O
entity -X- _ O
type -X- _ O
(e.g., -X- _ O
location). -X- _ O

Consider -X- _ O
an -X- _ O
unstructured -X- _ O
document -X- _ O
comprising -X- _ O
N -X- _ O
sentences, -X- _ O
D -X- _ O
= -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
sentence -X- _ O
sn -X- _ O
is -X- _ O
a -X- _ O
sequence -X- _ O
words. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
formulation -X- _ O
of -X- _ O
document -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
(DocRE). -X- _ B-TaskName

3 -X- _ O
Problem -X- _ O
Definition -X- _ O

In -X- _ O
our -X- _ O
approach, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
sentence -X- _ O
importance -X- _ O
score -X- _ O
and -X- _ O
a -X- _ O
sentence -X- _ O
focusing -X- _ O
loss -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
evidence -X- _ O
sentences, -X- _ O
improving -X- _ O
the -X- _ O
robustness -X- _ O
and -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
of -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

from -X- _ O
previous -X- _ O
work, -X- _ O
our -X- _ O
paper -X- _ O
proposes -X- _ O
SIEF -X- _ B-MethodName
as -X- _ O
a -X- _ O
general -X- _ O
framework -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
various -X- _ O
sequence-based -X- _ O
and -X- _ O
graph-based -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

(2021a) -X- _ O
explicitly -X- _ O
incorporate -X- _ O
logical -X- _ O
reasoning, -X- _ O
commonsense -X- _ O
reasoning, -X- _ O
and -X- _ O
coreference -X- _ O
reasoning -X- _ O
into -X- _ O
DocRE, -X- _ B-TaskName
based -X- _ O
on -X- _ O
both -X- _ O
sequence -X- _ O
and -X- _ O
graph -X- _ O
features. -X- _ O

Xu -X- _ O
et -X- _ O
al. -X- _ O

double -X- _ O
graphs, -X- _ O
applying -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
to -X- _ O
mention–document -X- _ O
graphs -X- _ O
and -X- _ O
performing -X- _ O
path -X- _ O
reasoning -X- _ O
over -X- _ O
entity -X- _ O
graphs. -X- _ O

Then -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
are -X- _ O
applied -X- _ O
to -X- _ O
aggregate -X- _ O
inter-sentence -X- _ O
information -X- _ O
(Quirk -X- _ O
and -X- _ O
Poon, -X- _ O
2017; -X- _ O
Christopoulou -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zeng -X- _ O
Zeng -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
construct -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

For -X- _ O
example, -X- _ O
a -X- _ O
node -X- _ O
can -X- _ O
be -X- _ O
a -X- _ O
sentence, -X- _ O
a -X- _ O
mention, -X- _ O
and/or -X- _ O
an -X- _ O
their -X- _ O
co-occurrence -X- _ O
is -X- _ O
modeled -X- _ O
by -X- _ O
an -X- _ O
entity; -X- _ O
edge. -X- _ O

Graph-based -X- _ O
DocRE -X- _ B-TaskName
models -X- _ O
abstract -X- _ O
a -X- _ O
document -X- _ O
by -X- _ O
graphical -X- _ O
structures. -X- _ O

Zhang -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
model -X- _ O
DocRE -X- _ B-TaskName
as -X- _ O
a -X- _ O
semantic -X- _ O
segmentation -X- _ O
task -X- _ O
and -X- _ O
predict -X- _ O
an -X- _ O
entity-level -X- _ O
relation -X- _ O
matrix -X- _ O
to -X- _ O
capture -X- _ O
local -X- _ O
and -X- _ O
global -X- _ O
information. -X- _ O

Zhou -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
Transformer -X- _ O
attentions -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
extract -X- _ O
useful -X- _ O
contextual -X- _ O
features -X- _ O
across -X- _ O
sentences -X- _ O
for -X- _ O
DocRE, -X- _ B-TaskName
and -X- _ O
they -X- _ O
adopt -X- _ O
an -X- _ O
adaptive -X- _ O
threshold -X- _ O
for -X- _ O
each -X- _ O
entity -X- _ O
pair. -X- _ O

architecture -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Sequence-based -X- _ O
DocRE -X- _ B-TaskName
models -X- _ O
encode -X- _ O
a -X- _ O
document -X- _ O
by -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
and/or -X- _ O
sentences, -X- _ O
for -X- _ O
example, -X- _ O
using -X- _ O
the -X- _ O
Transformer -X- _ O

Recent -X- _ O
efforts -X- _ O
design -X- _ O
sequence-based -X- _ O
and -X- _ O
graphbased -X- _ O
models -X- _ O
to -X- _ O
address -X- _ O
such -X- _ O
a -X- _ O
problem. -X- _ O

Compared -X- _ O
with -X- _ O
the -X- _ O
sentence -X- _ O
level, -X- _ O
DocRE -X- _ B-TaskName
requires -X- _ O
the -X- _ O
model -X- _ O
collecting -X- _ O
and -X- _ O
integrating -X- _ O
inter-sentence -X- _ O
information -X- _ O
effectively. -X- _ O

Document-level -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
(DocRE) -X- _ B-TaskName
is -X- _ O
attracting -X- _ O
increasing -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
community, -X- _ O
as -X- _ O
it -X- _ O
considers -X- _ O
the -X- _ O
interactions -X- _ O
of -X- _ O
entity -X- _ O
mentions -X- _ O
expressed -X- _ O
in -X- _ O
different -X- _ O
sentences -X- _ O
(Li -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Yao -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

In -X- _ O
the -X- _ O
past -X- _ O
several -X- _ O
years, -X- _ O
neural -X- _ O
networks -X- _ O
have -X- _ O
become -X- _ O
a -X- _ O
prevailing -X- _ O
approach -X- _ O
for -X- _ O
relation -X- _ O
extraction -X- _ O
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Song -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

(2009) -X- _ O
manually -X- _ O
design -X- _ O
features -X- _ O
for -X- _ O
classifying -X- _ O
relations. -X- _ O

and -X- _ O
Pennacchiotti -X- _ O
(2006) -X- _ O
propose -X- _ O
a -X- _ O
rule-based -X- _ O
approach, -X- _ O
and -X- _ O
Mintz -X- _ O
et -X- _ O
al. -X- _ O

Pantel -X- _ O
on -X- _ O
sentence-level -X- _ O
relation -X- _ O
extraction. -X- _ O

Relation -X- _ B-TaskName
extraction -X- _ I-TaskName
(RE) -X- _ B-TaskName
can -X- _ O
be -X- _ O
categorized -X- _ O
by -X- _ O
its -X- _ O
granularity, -X- _ O
such -X- _ O
as -X- _ O
sentence-level -X- _ O
(Doddington -X- _ O
et -X- _ O
al., -X- _ O
2004; -X- _ O
Xu -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Wei -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
document-level -X- _ O
(Gupta -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zhu -X- _ O
Early -X- _ O
work -X- _ O
mainly -X- _ O
focuses -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

We -X- _ O
further -X- _ O
evaluated -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
a -X- _ O
dialogue -X- _ O
relation -X- _ O
extraction -X- _ O
dataset, -X- _ O
DialogRE -X- _ B-DatasetName
(Yu -X- _ O
et -X- _ O
al., -X- _ O
2020); -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
yields -X- _ O
consistent -X- _ O
improvement, -X- _ O
showing -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
in -X- _ O
different -X- _ O
domains. -X- _ O

Experimental -X- _ O
results -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
combines -X- _ O
show -X- _ O
that -X- _ O
well -X- _ O
with -X- _ O
various -X- _ O
recent -X- _ O
DocRE -X- _ B-TaskName
models -X- _ O
and -X- _ O
significantly -X- _ O
improves -X- _ O
the -X- _ O
performance. -X- _ O

We -X- _ O
evaluated -X- _ O
the -X- _ O
generality -X- _ O
and -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
the -X- _ O
large-scale -X- _ O
DocRED -X- _ B-DatasetName
dataset -X- _ O
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Our -X- _ O
SIEF -X- _ B-MethodName
method -X- _ O
is -X- _ O
a -X- _ O
general -X- _ O
framework -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
combined -X- _ O
with -X- _ O
different -X- _ O
underlying -X- _ O
DocRE -X- _ B-TaskName
models. -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
the -X- _ O
model -X- _ O
pays -X- _ O
more -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
evidence -X- _ O
sentences -X- _ O
for -X- _ O
the -X- _ O
classification. -X- _ O

Then, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
auxiliary -X- _ O
loss -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
same -X- _ O
output -X- _ O
distribution, -X- _ O
when -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
is -X- _ O
fed -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
when -X- _ O
a -X- _ O
non-evidence -X- _ O
sentence -X- _ O
is -X- _ O
removed. -X- _ O

If -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
relation -X- _ O
does -X- _ O
not -X- _ O
change, -X- _ O
or -X- _ O
even -X- _ O
increases, -X- _ O
when -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
removed, -X- _ O
it -X- _ O
typically -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
non-evidence. -X- _ O

Specifically, -X- _ O
we -X- _ O
first -X- _ O
evaluate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
sentence -X- _ O
by -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
output -X- _ O
probabilities -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
this -X- _ O
sentence. -X- _ O

Relation: -X- _ O
MemberOf -X- _ O

[3] -X- _ O
After -X- _ O
a -X- _ O
self-issued -X- _ O
demo, -X- _ O
the -X- _ O
band -X- _ O
signed -X- _ O
with -X- _ O
Epic -X- _ O
Records -X- _ O
and -X- _ O
released -X- _ O
its -X- _ O
debut -X- _ O
album -X- _ O
Rage -X- _ O
Against -X- _ O
the -X- _ O
Machine -X- _ O
in -X- _ O
1992. -X- _ O

[2] -X- _ O
Formed -X- _ O
in -X- _ O
1991, -X- _ O
the -X- _ O
group -X- _ O
consists -X- _ O
of -X- _ O
vocalist -X- _ O
Zack -X- _ O
de -X- _ O
la -X- _ O
Rocha, -X- _ O
guitarist -X- _ O
Tom -X- _ O
Morello, -X- _ O
bassist -X- _ O
Tim -X- _ O
Commerford -X- _ O
and -X- _ O
drummer -X- _ O
Brad -X- _ O
Wilk. -X- _ O

[1] -X- _ O
Rage -X- _ O
Against -X- _ O
the -X- _ O
Machine -X- _ O
is -X- _ O
an -X- _ O
American -X- _ O
rap -X- _ O
metal -X- _ O
band -X- _ O
from -X- _ O
Los -X- _ O
Angeles, -X- _ O
California. -X- _ O

To -X- _ O
this -X- _ O
end, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Sentence -X- _ B-MethodName
Importance -X- _ I-MethodName
Estimation -X- _ I-MethodName
and -X- _ I-MethodName
Focusing -X- _ I-MethodName
(SIEF) -X- _ B-MethodName
framework -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
evidence -X- _ O
sentences -X- _ O
for -X- _ O
predicting -X- _ O
the -X- _ O
relation -X- _ O
of -X- _ O

Such -X- _ O
model -X- _ O
behaviors -X- _ O
are -X- _ O
undesired, -X- _ O
because -X- _ O
it -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
robust -X- _ O
and -X- _ O
lacks -X- _ O
interpretability. -X- _ O

Intuitively, -X- _ O
removing -X- _ O
sentence -X- _ O
{3} -X- _ O
should -X- _ O
not -X- _ O
change -X- _ O
the -X- _ O
result, -X- _ O
as -X- _ O
this -X- _ O
sentence -X- _ O
does -X- _ O
not -X- _ O
provide -X- _ O
information -X- _ O
regarding -X- _ O
whether -X- _ O
“MemberOf” -X- _ O
holds -X- _ O
or -X- _ O
not -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
entities. -X- _ O

However, -X- _ O
the -X- _ O
recent -X- _ O
DocRE -X- _ B-TaskName
model -X- _ O
GAIN -X- _ B-MethodName
(Zeng -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
identifies -X- _ O
the -X- _ O
relation -X- _ O
“MemberOf” -X- _ O
correctly -X- _ O
from -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
{1,2,3}, -X- _ O
but -X- _ O
predicts -X- _ O
“not -X- _ O
MemberOf” -X- _ O
from -X- _ O
sentences -X- _ O
{1,2}. -X- _ O

The -X- _ O
evidence -X- _ O
sentences -X- _ O
are -X- _ O
{1,2}, -X- _ O
and -X- _ O
humans -X- _ O
can -X- _ O
easily -X- _ O
identify -X- _ O
such -X- _ O
a -X- _ O
relation -X- _ O
when -X- _ O
reading -X- _ O
sentences -X- _ O
{1,2} -X- _ O
only. -X- _ O

In -X- _ O
Figure -X- _ O
1, -X- _ O
for -X- _ O
example, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
relation -X- _ O
“MemberOf” -X- _ O
between -X- _ O
the -X- _ O
entities -X- _ O
Brad -X- _ O
Wilk -X- _ O
and -X- _ O
Rage -X- _ O
Against -X- _ O
the -X- _ O
Machine. -X- _ O

Moreover, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
a -X- _ O
DocRE -X- _ B-TaskName
model, -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
document, -X- _ O
may -X- _ O
err -X- _ O
when -X- _ O
non-evidence -X- _ O
sentences -X- _ O
are -X- _ O
removed. -X- _ O

Huang -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
show -X- _ O
that -X- _ O
irrelevant -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
would -X- _ O
hinder -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model. -X- _ O

However, -X- _ O
one -X- _ O
can -X- _ O
identify -X- _ O
the -X- _ O
relation -X- _ O
of -X- _ O
a -X- _ O
specific -X- _ O
entity -X- _ O
pair -X- _ O
from -X- _ O
a -X- _ O
few -X- _ O
sentences. -X- _ O

all -X- _ O
entity -X- _ O
pairs -X- _ O
without -X- _ O
concerning -X- _ O
where -X- _ O
the -X- _ O
evidence -X- _ O
is -X- _ O
located -X- _ O
(Nan -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Zeng -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Xu -X- _ O
et -X- _ O
al., -X- _ O
2021a,b). -X- _ O

Figure -X- _ O
1: -X- _ O
A -X- _ O
DocRE -X- _ B-TaskName
model -X- _ O
predicts -X- _ O
correctly -X- _ O
for -X- _ O
an -X- _ O
entire -X- _ O
document, -X- _ O
but -X- _ O
errs -X- _ O
when -X- _ O
a -X- _ O
non-evidence -X- _ O
sentence -X- _ O
is -X- _ O
removed. -X- _ O

com/xwjim/SIEF -X- _ O

1The -X- _ O
code -X- _ O
is -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
https://github. -X- _ O

Most -X- _ O
recent -X- _ O
DocRE -X- _ B-TaskName
studies -X- _ O
use -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
as -X- _ O
a -X- _ O
clue -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
relations -X- _ O
of -X- _ O

Thus, -X- _ O
DocRE -X- _ B-TaskName
is -X- _ O
more -X- _ O
a -X- _ O
realistic -X- _ O
setting, -X- _ O
attracting -X- _ O
increasing -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
field -X- _ O
of -X- _ O
information -X- _ O
extraction. -X- _ O

Different -X- _ O
from -X- _ O
sentence-level -X- _ O
relation -X- _ O
extraction -X- _ O
(Zeng -X- _ O
et -X- _ O
al., -X- _ O
2014; -X- _ O
Xiao -X- _ O
and -X- _ O
Liu, -X- _ O
2016; -X- _ O
Song -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
the -X- _ O
supporting -X- _ O
evidence -X- _ O
in -X- _ O
the -X- _ O
DocRE -X- _ B-TaskName
setting -X- _ O
may -X- _ O
involve -X- _ O
multiple -X- _ O
sentences -X- _ O
scattering -X- _ O
in -X- _ O
the -X- _ O
document. -X- _ O

It -X- _ O
plays -X- _ O
a -X- _ O
crucial -X- _ O
role -X- _ O
in -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
knowledgebased -X- _ O
applications, -X- _ O
such -X- _ O
as -X- _ O
question -X- _ O
answering -X- _ O
(Sorokin -X- _ O
and -X- _ O
Gurevych, -X- _ O
2017) -X- _ O
and -X- _ O
large-scale -X- _ O
knowledge -X- _ O
graph -X- _ O
construction -X- _ O
(Baldini -X- _ O
Soares -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Document-level -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
(DocRE) -X- _ B-TaskName
aims -X- _ O
to -X- _ O
predict -X- _ O
entity -X- _ O
relations -X- _ O
across -X- _ O
multiple -X- _ O
sentences. -X- _ O

Introduction -X- _ O

Moreover, -X- _ O
SIEF -X- _ B-MethodName
is -X- _ O
a -X- _ O
general -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
when -X- _ O
framework, -X- _ O
combined -X- _ O
with -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
base -X- _ O
DocRE -X- _ B-TaskName
models.1 -X- _ O

Experimental -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
domains -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
SIEF -X- _ B-MethodName
not -X- _ O
only -X- _ O
improves -X- _ O
overall -X- _ O
performance, -X- _ O
but -X- _ O
also -X- _ O
makes -X- _ O
DocRE -X- _ B-TaskName
models -X- _ O
more -X- _ O
robust. -X- _ O

To -X- _ O
this -X- _ O
end, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Sentence -X- _ B-MethodName
Importance -X- _ I-MethodName
Estimation -X- _ I-MethodName
and -X- _ I-MethodName
Focusing -X- _ I-MethodName
(SIEF) -X- _ B-MethodName
framework -X- _ O
for -X- _ O
DocRE, -X- _ B-TaskName
where -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
sentence -X- _ O
importance -X- _ O
score -X- _ O
and -X- _ O
a -X- _ O
sentence -X- _ O
focusing -X- _ O
loss, -X- _ O
encouraging -X- _ O
DocRE -X- _ B-TaskName
models -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
evidence -X- _ O
sentences. -X- _ O

However, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
such -X- _ O
a -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
it -X- _ O
robust -X- _ O
and -X- _ O
exhibits -X- _ O
bizarre -X- _ O
behaviors: -X- _ O
predicts -X- _ O
correctly -X- _ O
when -X- _ O
an -X- _ O
entire -X- _ O
test -X- _ O
document -X- _ O
is -X- _ O
fed -X- _ O
as -X- _ O
input, -X- _ O
but -X- _ O
errs -X- _ O
when -X- _ O
non-evidence -X- _ O
sentences -X- _ O
are -X- _ O
removed. -X- _ O

Recent -X- _ O
studies -X- _ O
typically -X- _ O
represent -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
by -X- _ O
sequence- -X- _ O
or -X- _ O
graph-based -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
relations -X- _ O
of -X- _ O
all -X- _ O
entity -X- _ O
pairs. -X- _ O

Document-level -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
(DocRE) -X- _ B-TaskName
aims -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
two -X- _ O
entities -X- _ O
from -X- _ O
a -X- _ O
document -X- _ O
of -X- _ O
multiple -X- _ O
sentences. -X- _ O

Abstract -X- _ O

Document-Level -X- _ B-TaskName
Relation -X- _ I-TaskName
Extraction -X- _ I-TaskName
with -X- _ O
Sentences -X- _ B-MethodName
Importance -X- _ I-MethodName
Estimation -X- _ I-MethodName
and -X- _ I-MethodName
Focusing -X- _ I-MethodName


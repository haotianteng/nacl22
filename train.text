-DOCSTART- -X- O
References -X- _ O

Acknowledgments -X- _ O

We -X- _ O
hope -X- _ O
this -X- _ O
work -X- _ O
will -X- _ O
spur -X- _ O
more -X- _ O
research -X- _ O
in -X- _ O
how -X- _ O
to -X- _ O
better -X- _ O
use -X- _ O
pre-trained -X- _ O
encoder-decoders -X- _ O
for -X- _ O
not -X- _ O
only -X- _ O
MCQA, -X- _ B-TaskName
but -X- _ O
also -X- _ O
beyond; -X- _ O
for -X- _ O
tasks -X- _ O
with -X- _ O
divergent -X- _ O
structures -X- _ O
from -X- _ O
the -X- _ O
pre-training, -X- _ O
a -X- _ O
smarter -X- _ O
use -X- _ O
of -X- _ O
PLMs -X- _ O
can -X- _ O
boost -X- _ O
the -X- _ O
performance -X- _ O
significantly. -X- _ O

In -X- _ O
the -X- _ O
future, -X- _ O
we -X- _ O
will -X- _ O
focus -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
clue -X- _ O
generation -X- _ O
quality, -X- _ O
which -X- _ O
remains -X- _ O
a -X- _ O
bottleneck -X- _ O
of -X- _ O
GenMC. -X- _ B-MethodName

Table -X- _ O
7: -X- _ O
Inference -X- _ O
time -X- _ O
for -X- _ O
answering -X- _ O
a -X- _ O
question -X- _ O
(seconds). -X- _ O

In -X- _ O
our -X- _ O
future -X- _ O
research, -X- _ O
we -X- _ O
will -X- _ O
focus -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
generate -X- _ O
more -X- _ O
helpful -X- _ O
clues -X- _ O
from -X- _ O
questions. -X- _ O

This -X- _ O
suggests -X- _ O
a -X- _ O
great -X- _ O
room -X- _ O
for -X- _ O
improvement. -X- _ O

Though -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
our -X- _ O
clues -X- _ O
are -X- _ O
relevant -X- _ O
(i.e., -X- _ O
76.4% -X- _ O
of -X- _ O
them -X- _ O
are -X- _ O
relevant -X- _ O
across -X- _ O
all -X- _ O
datasets), -X- _ O
which -X- _ O
seems -X- _ O
positive, -X- _ O
only -X- _ O
24% -X- _ O
of -X- _ O
the -X- _ O
clues -X- _ O
are -X- _ O
deemed -X- _ O
as -X- _ O
helpful. -X- _ O

Figure -X- _ O
4 -X- _ O
breaks -X- _ O
down -X- _ O
by -X- _ O
dataset. -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
percent -X- _ O
of -X- _ O
each -X- _ O
clue -X- _ O
type -X- _ O
across -X- _ O
all -X- _ O
datasets -X- _ O
with -X- _ O
an -X- _ O
example -X- _ O
for -X- _ O
each -X- _ O
type. -X- _ O

If -X- _ O
all -X- _ O
three -X- _ O
students -X- _ O
annotate -X- _ O
differently -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
for -X- _ O
an -X- _ O
instance, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
fourth -X- _ O
student -X- _ O
to -X- _ O
arbitrate. -X- _ O

To -X- _ O
ensure -X- _ O
the -X- _ O
annotation -X- _ O
quality, -X- _ O
we -X- _ O
aggregate -X- _ O
annotated -X- _ O
results -X- _ O
from -X- _ O
three -X- _ O
students -X- _ O
for -X- _ O
every -X- _ O
dataset -X- _ O
using -X- _ O
majority -X- _ O
vote. -X- _ O

to -X- _ O
answer -X- _ O
the -X- _ O
question. -X- _ O

The -X- _ O
clue -X- _ O
adds -X- _ O
helpful -X- _ O
information -X- _ O

• -X- _ O
Helpful: -X- _ O

• -X- _ O
Relevant -X- _ O
but -X- _ O
unhelpful: -X- _ O
Though -X- _ O
relevant, -X- _ O
the -X- _ O
clue -X- _ O
makes -X- _ O
a -X- _ O
factually -X- _ O
incorrect -X- _ O
statement, -X- _ O
often -X- _ O
on -X- _ O
the -X- _ O
contrary -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
question, -X- _ O
or -X- _ O
the -X- _ O
clue -X- _ O
contributes -X- _ O
relevant -X- _ O
but -X- _ O
insufficient -X- _ O
knowledge -X- _ O
for -X- _ O
prediction, -X- _ O
such -X- _ O
as -X- _ O
repetition -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
or -X- _ O
other -X- _ O
distractors. -X- _ O

understandable. -X- _ O

5We -X- _ O
follow -X- _ O
a -X- _ O
similar -X- _ O
definition -X- _ O
by -X- _ O
Shwartz -X- _ O
et -X- _ O
al. -X- _ O
(2020). -X- _ O

They -X- _ O
know -X- _ O
and -X- _ O
agree -X- _ O
that -X- _ O
their -X- _ O
annotations -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
error -X- _ O
analysis -X- _ O
in -X- _ O
a -X- _ O
research -X- _ O
paper. -X- _ O

4They -X- _ O
are -X- _ O
volunteers -X- _ O
recruited -X- _ O
from -X- _ O
the -X- _ O
contact -X- _ O
author’s -X- _ O
research -X- _ O
group. -X- _ O

• -X- _ O
Irrelevant: -X- _ O
The -X- _ O
clue -X- _ O
is -X- _ O
off -X- _ O
topic -X- _ O
or -X- _ O
is -X- _ O
not -X- _ O

We -X- _ O
then -X- _ O
ask -X- _ O
them -X- _ O
to -X- _ O
categorize -X- _ O
clues -X- _ O
into -X- _ O
the -X- _ O
following -X- _ O
families:5 -X- _ O

We -X- _ O
show -X- _ O
six -X- _ O
graduate -X- _ O
students -X- _ O
of -X- _ O
computer -X- _ O
science4 -X- _ O
an -X- _ O
instance -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
generated -X- _ O
clue, -X- _ O
correct -X- _ O
answer, -X- _ O
and -X- _ O
predicted -X- _ O
answer. -X- _ O

Specifically, -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
50 -X- _ O
negative -X- _ O
cases -X- _ O
from -X- _ O
T5LARGE -X- _ B-MethodName
+ -X- _ I-MethodName
GenMC -X- _ I-MethodName
for -X- _ O
each -X- _ O
dataset. -X- _ O

By -X- _ O
studying -X- _ O
these -X- _ O
potentially -X- _ O
negative -X- _ O
clues, -X- _ O
we -X- _ O
can -X- _ O
gain -X- _ O
more -X- _ O
insights -X- _ O
into -X- _ O
how -X- _ O
GenMC -X- _ B-MethodName
fails -X- _ O
and -X- _ O
discuss -X- _ O
venues -X- _ O
for -X- _ O
future -X- _ O
improvement. -X- _ O

The -X- _ O
intuition -X- _ O
is -X- _ O
that -X- _ O
in -X- _ O
these -X- _ O
negative -X- _ O
cases, -X- _ O
the -X- _ O
clues -X- _ O
generated -X- _ O
by -X- _ O
GenMC -X- _ B-MethodName
may -X- _ O
play -X- _ O
a -X- _ O
negative -X- _ O
role. -X- _ O

We -X- _ O
analyze -X- _ O
the -X- _ O
clues -X- _ O
generated -X- _ O
by -X- _ O
GenMC -X- _ B-MethodName
using -X- _ O
T5LARGE -X- _ O
with -X- _ O
a -X- _ O
focus -X- _ O
on -X- _ O
instances -X- _ O
that -X- _ O
are -X- _ O
correctly -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
our -X- _ O
main -X- _ O
experiments -X- _ O
(i.e., -X- _ O
T5LARGE -X- _ B-MethodName
+ -X- _ I-MethodName
Text2Textvanilla), -X- _ I-MethodName
while -X- _ O
our -X- _ O
GenMC -X- _ B-MethodName
fails. -X- _ O

5.4 -X- _ O
Error -X- _ O
Analysis -X- _ O

demonstrates -X- _ O
that -X- _ O
naively -X- _ O
using -X- _ O
explicit -X- _ O
knowledge -X- _ O
in -X- _ O
plain -X- _ O
text, -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
implicit -X- _ O
clues -X- _ O
from -X- _ O
the -X- _ O
decoder’s -X- _ O
hidden -X- _ O
state, -X- _ O
is -X- _ O
inferior -X- _ O
as -X- _ O
it -X- _ O
may -X- _ O
unnecessarily -X- _ O
bring -X- _ O
information -X- _ O
loss -X- _ O
and -X- _ O
noise. -X- _ O

Instance -X- _ O
Which -X- _ O
would -X- _ O
you -X- _ O
likely -X- _ O
find -X- _ O
inside -X- _ O
a -X- _ O
beach -X- _ O
ball? -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
using -X- _ O
token-level -X- _ O
clues -X- _ O
lags -X- _ O
much -X- _ O
behind -X- _ O
GenMC. -X- _ B-MethodName

5.3.2 -X- _ O
Results -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
that -X- _ O
masking -X- _ O
out -X- _ O
generation -X- _ O
loss -X- _ O
leads -X- _ O
to -X- _ O
substantial -X- _ O
performance -X- _ O
drops -X- _ O
across -X- _ O
all -X- _ O
datasets, -X- _ O
demonstrating -X- _ O
that -X- _ O
fine-tuning -X- _ O
the -X- _ O
decoder -X- _ O
GEN -X- _ O
helps -X- _ O
to -X- _ O
derive -X- _ O
useful -X- _ O
with -X- _ O
generation -X- _ O
loss -X- _ O
clues -X- _ O
from -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
models. -X- _ O

(2020c), -X- _ O
which -X- _ O
also -X- _ O
adopts -X- _ O
a -X- _ O
pipeline -X- _ O
framework -X- _ O
to -X- _ O
first -X- _ O
generate -X- _ O
a -X- _ O
token-level -X- _ O
evidence -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
the -X- _ O
evidence -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
question. -X- _ O

This -X- _ O
variant -X- _ O
is -X- _ O
indeed -X- _ O
very -X- _ O
similar -X- _ O
to -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O

We -X- _ O
then -X- _ O
directly -X- _ O
concatenate -X- _ O
C -X- _ O
with -X- _ O
Q -X- _ O
and -X- _ O
Oi -X- _ O
to -X- _ O
compute -X- _ O
a -X- _ O
score -X- _ O
for -X- _ O
Oi -X- _ O
using -X- _ O
the -X- _ O
model’s -X- _ O
encoder -X- _ O
part -X- _ O
stacked -X- _ O
with -X- _ O
an -X- _ O
MLP -X- _ O
layer. -X- _ O

We -X- _ O
first -X- _ O
collect -X- _ O
the -X- _ O
generated -X- _ O
clue -X- _ O
text -X- _ O
C -X- _ O
(instead -X- _ O
of -X- _ O
its -X- _ O
representation) -X- _ O
from -X- _ O
the -X- _ O
decoder. -X- _ O

In -X- _ O
this -X- _ O
setting, -X- _ O
we -X- _ O
separately -X- _ O
train -X- _ O
Token -X- _ O
Clue -X- _ O
a -X- _ O
clue -X- _ O
generator -X- _ O
and -X- _ O
a -X- _ O
reader. -X- _ O

Intuitively, -X- _ O
under -X- _ O
this -X- _ O
setting, -X- _ O
the -X- _ O
generated -X- _ O
clue -X- _ O
is -X- _ O
weaker -X- _ O
than -X- _ O
GenMC -X- _ B-MethodName
which -X- _ O
learns -X- _ O
how -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
clue -X- _ O
with -X- _ O
supervision. -X- _ O

We -X- _ O
train -X- _ O
this -X- _ O
variant -X- _ O
only -X- _ O
using -X- _ O
the -X- _ O
READ, -X- _ O
so -X- _ O
only -X- _ O
the -X- _ O
encoder -X- _ O
part -X- _ O
classification -X- _ O
loss -X- _ O
is -X- _ O
updated, -X- _ O
while -X- _ O
the -X- _ O
decoder -X- _ O
part -X- _ O
is -X- _ O
left -X- _ O
untouched -X- _ O
from -X- _ O
pre-training. -X- _ O

5.3.1 -X- _ O
Variants -X- _ O
of -X- _ O
GenMC -X- _ B-MethodName
Weak -X- _ O
Clue -X- _ O

To -X- _ O
better -X- _ O
understand -X- _ O
its -X- _ O
superior -X- _ O
results -X- _ O
and -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
our -X- _ O
clue -X- _ O
generation, -X- _ O
we -X- _ O
compare -X- _ O
with -X- _ O
two -X- _ O
variants. -X- _ O

Our -X- _ O
main -X- _ O
results -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
have -X- _ O
demonstrated -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
model. -X- _ O

As -X- _ O
a -X- _ O
fairer -X- _ O
comparison -X- _ O
in -X- _ O
Table -X- _ O
4, -X- _ O
by -X- _ O
unifying -X- _ O
the -X- _ O
training -X- _ O
sets -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
five -X- _ O
datasets, -X- _ O
our -X- _ O
GenMCT5-U -X- _ B-MethodName
outperforms -X- _ O
UnifiedQAT5-FT -X- _ B-MethodName
on -X- _ O
all -X- _ O
datasets -X- _ O
except -X- _ O
for -X- _ O
CSQA -X- _ B-DatasetName
with -X- _ O
large -X- _ O
models. -X- _ O

The -X- _ O
promising -X- _ O
results -X- _ O
of -X- _ O
GenMC -X- _ B-MethodName
further -X- _ O
reveals -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
learn -X- _ O
to -X- _ O
effectively -X- _ O
extract -X- _ O
knowledge -X- _ O
from -X- _ O
pre-trained -X- _ O
encoder-decoders -X- _ O
with -X- _ O
limited -X- _ O
training -X- _ O
data. -X- _ O

These -X- _ O
results -X- _ O
are -X- _ O
impressive -X- _ O
because -X- _ O
UnifiedQA -X- _ B-MethodName
uses -X- _ O
more -X- _ O
datasets -X- _ O
(i.e., -X- _ O
eight -X- _ O
different -X- _ O
QA -X- _ O
datasets) -X- _ O
for -X- _ O
training. -X- _ O

It -X- _ O
also -X- _ O
achieves -X- _ O
comparable -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
remaining -X- _ O
datasets. -X- _ O

Moreover, -X- _ O
for -X- _ O
UnifiedQAT5-FT, -X- _ B-MethodName
which -X- _ O
further -X- _ O
finetunes -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
dataset, -X- _ O
GenMCT5 -X- _ B-MethodName
outperforms -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
CSQA, -X- _ B-DatasetName
OBQA, -X- _ B-DatasetName
and -X- _ O
ARC-Easy -X- _ B-DatasetName
for -X- _ O
the -X- _ O
base -X- _ O
models -X- _ O
and -X- _ O
ARC-Easy -X- _ B-DatasetName
for -X- _ O
the -X- _ O
large -X- _ O
models. -X- _ O

More -X- _ O
interestingly, -X- _ O
GenMCT5 -X- _ B-MethodName
also -X- _ O
performs -X- _ O
better -X- _ O
than -X- _ O
UnifiedQAT5 -X- _ B-MethodName
on -X- _ O
most -X- _ O
datasets. -X- _ O

The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
show -X- _ O
that -X- _ O
GenMCT5 -X- _ B-MethodName

significantly -X- _ O
(with -X- _ O
p-value -X- _ O
< -X- _ O
0.01) -X- _ O
outperforms -X- _ O
the -X- _ O
two -X- _ O
encoder-only -X- _ O
strong -X- _ O
baselines -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
ALBERT. -X- _ B-MethodName

5.2.2 -X- _ O
Results -X- _ O

All -X- _ O
models -X- _ O
are -X- _ O
of -X- _ O
comparable -X- _ O
model -X- _ O
size -X- _ O
to -X- _ O
ours. -X- _ O

In -X- _ O
addition, -X- _ O
we -X- _ O
compare -X- _ O
with -X- _ O
two -X- _ O
encoder-only -X- _ O
models, -X- _ O
RoBERTa -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
ALBERT -X- _ B-MethodName
(Lan -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
which -X- _ O
have -X- _ O
served -X- _ O
as -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
many -X- _ B-TaskName
MCQA -X- _ I-TaskName
models. -X- _ O

5.3 -X- _ O
Ablation -X- _ O
Study: -X- _ O
Influence -X- _ O
of -X- _ O
Clues -X- _ O

Note -X- _ O
that -X- _ O
instead -X- _ O
of -X- _ O
training -X- _ O
on -X- _ O
each -X- _ O
dataset -X- _ O
separately, -X- _ O
UnifiedQA -X- _ B-MethodName
converts -X- _ O
a -X- _ O
line -X- _ O
of -X- _ O
popular -X- _ O
QA -X- _ O
datasets -X- _ O
with -X- _ O
four -X- _ O
formats -X- _ O
(e.g., -X- _ O
retrieval-based -X- _ O
QA, -X- _ O
MCQA) -X- _ O
into -X- _ O
a -X- _ O
unified -X- _ O
format, -X- _ O
and -X- _ O
trains -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
over -X- _ O
all -X- _ O
training -X- _ O
data, -X- _ O
while -X- _ O
GenMC -X- _ O
only -X- _ O
uses -X- _ O
each -X- _ O

While -X- _ O
UnifiedQA -X- _ B-MethodName
reports -X- _ O
the -X- _ O
best -X- _ O
score -X- _ O
using -X- _ O
its -X- _ O
T5-11B -X- _ O
version, -X- _ O
since -X- _ O
for -X- _ O
T5 -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
its -X- _ O
BASE -X- _ O
and -X- _ O
LARGE -X- _ O
versions, -X- _ O
we -X- _ O
only -X- _ O
report -X- _ O
and -X- _ O
compare -X- _ O
under -X- _ O
T5BASE -X- _ O
and -X- _ O
T5LARGE. -X- _ O

Among -X- _ O
these -X- _ O
models, -X- _ O
UnifiedQA -X- _ B-MethodName
(Khashabi -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
is -X- _ O
the -X- _ O
current -X- _ O
best -X- _ O
model. -X- _ O

However, -X- _ O
to -X- _ O
enable -X- _ O
a -X- _ O
fair -X- _ O
comparison, -X- _ O
we -X- _ O
only -X- _ O
compare -X- _ O
with -X- _ O
models -X- _ O
that -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
setting -X- _ O
as -X- _ O
ours, -X- _ O
where -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
its -X- _ O
options -X- _ O
are -X- _ O
the -X- _ O
only -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
model. -X- _ O

Existing -X- _ O
methods -X- _ O
that -X- _ O
rely -X- _ O
on -X- _ O
external -X- _ O
documents -X- _ O
or -X- _ O
corpora -X- _ O
have -X- _ O
achieved -X- _ O
state-ofthe-art -X- _ O
performance -X- _ O
on -X- _ O
several -X- _ O
MCQA -X- _ B-TaskName
datasets. -X- _ O

5.2.1 -X- _ O
Baselines -X- _ O
UnifiedQA -X- _ B-MethodName

5.2 -X- _ O
Comparison -X- _ O
with -X- _ O
Other -X- _ O
Models -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
embedded -X- _ O
knowledge -X- _ O
gained -X- _ O
from -X- _ O
pre-training -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
MCQA -X- _ B-TaskName
tasks, -X- _ O
strengthening -X- _ O
our -X- _ O
point -X- _ O
to -X- _ O
make -X- _ O
full -X- _ O
use -X- _ O
of -X- _ O
pre-trained -X- _ O
encoders -X- _ O
and -X- _ O
decoders. -X- _ O

In -X- _ O
addition, -X- _ O
all -X- _ O
LARGE -X- _ O
models -X- _ O
significantly -X- _ O
outperform -X- _ O
their -X- _ O
BASE -X- _ O
counterparts. -X- _ O

This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
decoder’s -X- _ O
general -X- _ O
language -X- _ O
knowledge -X- _ O
gained -X- _ O
from -X- _ O
pre-training -X- _ O
is -X- _ O
largely -X- _ O
wasted -X- _ O
by -X- _ O
only -X- _ O
using -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
classifier, -X- _ O
which -X- _ O
may -X- _ O
further -X- _ O
explain -X- _ O
the -X- _ O
superior -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
because -X- _ O
GenMC -X- _ B-MethodName
can -X- _ O
exploit -X- _ O
the -X- _ O
pre-trained -X- _ O
decoder -X- _ O
more -X- _ O
effectively. -X- _ O

Moreover, -X- _ O
we -X- _ O
interestingly -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
decoder-free -X- _ O
baseline -X- _ O
Text2Textenc -X- _ B-MethodName
outperforms -X- _ O
Text2Textvanilla -X- _ B-MethodName
on -X- _ O
over -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
experiments. -X- _ O

These -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
GenMC -X- _ B-MethodName
is -X- _ O
a -X- _ O
more -X- _ O
effective -X- _ O
usage -X- _ O
of -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
models -X- _ O
than -X- _ O
existing -X- _ O
ones. -X- _ O

racy -X- _ O
of -X- _ O
23.69% -X- _ B-MetricValue
to -X- _ O
39.00%, -X- _ B-MetricValue
suggesting -X- _ O
a -X- _ O
relative -X- _ O
gain -X- _ O
of -X- _ O
around -X- _ O
65%. -X- _ B-MetricValue

For -X- _ O
example, -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
challenging -X- _ O
scientific -X- _ O
MCQA -X- _ B-TaskName
dataset -X- _ O
ARC-Challenge, -X- _ B-DatasetName
T5BASE -X- _ B-MethodName
+ -X- _ I-MethodName
GenMC -X- _ I-MethodName
improves -X- _ O
T5BASE -X- _ B-MethodName
+ -X- _ I-MethodName
Text2Textvanilla -X- _ I-MethodName
from -X- _ O
an -X- _ O
accu -X- _ O

For -X- _ O
several -X- _ O
settings, -X- _ O
GenMC -X- _ B-MethodName
even -X- _ O
obtains -X- _ O
an -X- _ O
absolute -X- _ O
gain -X- _ O
of -X- _ O
over -X- _ O
10%. -X- _ B-MetricValue

The -X- _ O
main -X- _ O
results -X- _ O
(see -X- _ O
Table -X- _ O
2) -X- _ O
show -X- _ O
that -X- _ O
GenMC -X- _ B-MethodName
consistently -X- _ O
and -X- _ O
significantly -X- _ O
(with -X- _ O
p-value -X- _ O
< -X- _ O
0.01) -X- _ O
outperforms -X- _ O
Text2Textvanilla -X- _ B-MethodName
and -X- _ O
Text2Textenc -X- _ B-MethodName
on -X- _ O
all -X- _ O
datasets. -X- _ O

5.1.2 -X- _ O
Results -X- _ O

Though -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
find -X- _ O
that -X- _ O
their -X- _ O
encoder-only -X- _ O
model -X- _ O
performs -X- _ O
comparably -X- _ O
to -X- _ O
using -X- _ O
the -X- _ O
decoder -X- _ O
as -X- _ O
a -X- _ O
classifier, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
decoder -X- _ O
part -X- _ O
can -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
performance, -X- _ O
if -X- _ O
being -X- _ O
properly -X- _ O
used. -X- _ O

In -X- _ O
this -X- _ O
setting, -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
totally -X- _ O
unused. -X- _ O

The -X- _ O
model -X- _ O
then -X- _ O
predicts -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score. -X- _ O

Then -X- _ O
the -X- _ O
representation -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
scorer -X- _ O
(i.e., -X- _ O
an -X- _ O
MLP) -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
matching -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
question-option -X- _ O
pair. -X- _ O

Each -X- _ O
option -X- _ O
is -X- _ O
independently -X- _ O
paired -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
joint -X- _ O
representation -X- _ O
using -X- _ O
the -X- _ O
encoder. -X- _ O

Text2Textenc -X- _ B-MethodName
Similar -X- _ O
to -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
we -X- _ O
use -X- _ O
only -X- _ O
the -X- _ O
encoder -X- _ O
part -X- _ O
of -X- _ O
a -X- _ O
pre-trained -X- _ O
encoderdecoder -X- _ O
model. -X- _ O

In -X- _ O
this -X- _ O
setting, -X- _ O
the -X- _ O
decoder -X- _ O
is -X- _ O
basically -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
classifier. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
joint -X- _ O
representation, -X- _ O
the -X- _ O
decoder -X- _ O
finally -X- _ O
outputs -X- _ O
an -X- _ O
option -X- _ O
ID. -X- _ O

The -X- _ O
concatenated -X- _ O
sequence -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
encoder -X- _ O
part -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
joint -X- _ O
representation -X- _ O
for -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
all -X- _ O
options. -X- _ O

Specifically, -X- _ O
following -X- _ O
Raffel -X- _ O
et -X- _ O
al. -X- _ O
(2020), -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
input -X- _ O
question -X- _ O
with -X- _ O
all -X- _ O
candidate -X- _ O
options, -X- _ O
where -X- _ O
each -X- _ O
option -X- _ O
is -X- _ O
also -X- _ O
preceded -X- _ O
by -X- _ O
its -X- _ O
option -X- _ O
ID, -X- _ O
and -X- _ O
then -X- _ O
prepend -X- _ O
the -X- _ O
sequence -X- _ O
with -X- _ O
a -X- _ O
dataset -X- _ O
name. -X- _ O

The -X- _ O
vanilla -X- _ O
usage -X- _ O
of -X- _ O
pre-trained -X- _ O
encoder-decoders -X- _ O
for -X- _ O
MCQA -X- _ B-TaskName
is -X- _ O
to -X- _ O
reform -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
directly -X- _ O
processed -X- _ O
by -X- _ O
a -X- _ O
encoder-decoder -X- _ O
model. -X- _ O

5.1.1 -X- _ O
Baselines -X- _ O
Text2Textvanilla -X- _ B-MethodName

Table -X- _ O
2: -X- _ O
Comparison -X- _ O
with -X- _ O
text-to-text -X- _ O
models. -X- _ O

To -X- _ O
empirically -X- _ O
evaluate -X- _ O
GenMC -X- _ B-MethodName
in -X- _ O
terms -X- _ O
of -X- _ O
whether -X- _ O
it -X- _ O
better -X- _ O
exploits -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
pretrained -X- _ O
encoder-decoder -X- _ O
models -X- _ O
for -X- _ O
MCQA, -X- _ B-TaskName
we -X- _ O
compare -X- _ O
GenMC -X- _ B-MethodName
with -X- _ O
a -X- _ O
standard -X- _ O
text-to-text -X- _ O
implementation -X- _ O
and -X- _ O
with -X- _ O
a -X- _ O
variant -X- _ O
thereof -X- _ O
for -X- _ O
analysis. -X- _ O

Text-to-Text -X- _ O
Models -X- _ O

5.1 -X- _ O
Main -X- _ O
Results: -X- _ O
Comparison -X- _ O
with -X- _ O

5 -X- _ O
Experimental -X- _ O
Results -X- _ O

For -X- _ O
each -X- _ O
model, -X- _ O
we -X- _ O
reported -X- _ O
its -X- _ O
proportion -X- _ B-MetricName
of -X- _ I-MetricName
correctly -X- _ I-MetricName
answered -X- _ I-MetricName
questions -X- _ I-MetricName
in -X- _ O
each -X- _ O
dataset. -X- _ O

4.3 -X- _ O
Evaluation -X- _ O
Metric -X- _ O

All -X- _ O

the -X- _ O
experiments -X- _ O
were -X- _ O
performed -X- _ O
on -X- _ O
a -X- _ O

For -X- _ O
the -X- _ O
smallest -X- _ O
three -X- _ O
random -X- _ O
seeds -X- _ O
} -X- _ O
dataset -X- _ O
ARC-Challenge, -X- _ B-DatasetName
we -X- _ O
used -X- _ O
five -X- _ O
random -X- _ O
seeds -X- _ O
1, -X- _ O
10, -X- _ O
20, -X- _ O
30, -X- _ O
40 -X- _ O
} -X- _ O
{ -X- _ O

For -X- _ O
CSQA, -X- _ B-DatasetName
OBQA, -X- _ B-DatasetName
ARC-Easy, -X- _ B-DatasetName
and -X- _ O
QASC, -X- _ B-DatasetName
we -X- _ O
used -X- _ O
1, -X- _ B-HyperparameterValue
10, -X- _ B-HyperparameterValue
20 -X- _ B-HyperparameterValue
. -X- _ O

Because -X- _ O
neural -X- _ O
models -X- _ O
are -X- _ O
known -X- _ O
to -X- _ O
be -X- _ O
sensitive -X- _ O
to -X- _ O
different -X- _ O
random -X- _ O
seeds, -X- _ O
especially -X- _ O
when -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
is -X- _ O
small, -X- _ O
we -X- _ O
performed -X- _ O
multiple -X- _ O
experiments -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds, -X- _ O
and -X- _ O
reported -X- _ O
the -X- _ O
mean -X- _ O
and -X- _ O
standard -X- _ O
deviation. -X- _ O

5 -X- _ O

− -X- _ O

4, -X- _ B-HyperparameterValue
5e -X- _ B-HyperparameterValue

For -X- _ O
each -X- _ O
model, -X- _ O
we -X- _ O
searched -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
from -X- _ O
1e -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
{ -X- _ O
} -X- _ O
− -X- _ O
out -X- _ O
of -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
and -X- _ O
set -X- _ O
warmup -X- _ B-HyperparameterName
fraction -X- _ I-HyperparameterName
= -X- _ O
0.1, -X- _ B-HyperparameterValue
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
= -X- _ O
0.01, -X- _ B-HyperparameterValue
maximum -X- _ B-HyperparameterName
source -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
= -X- _ O
64, -X- _ B-HyperparameterValue
maximum -X- _ B-HyperparameterName
target -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
= -X- _ O
32, -X- _ B-HyperparameterValue
epoch -X- _ B-HyperparameterName
= -X- _ O
30, -X- _ B-HyperparameterValue
and -X- _ O
early -X- _ O
stop -X- _ O
training -X- _ O
when -X- _ O
there -X- _ O
was -X- _ O
no -X- _ O
better -X- _ O
result -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
after -X- _ O
5 -X- _ O
epochs. -X- _ O

We -X- _ O
used -X- _ O
PyTorch -X- _ O
1.7. -X- _ O

External -X- _ O
Knowledge -X- _ O
For -X- _ O
all -X- _ O
these -X- _ O
datasets, -X- _ O
our -X- _ O
experiments -X- _ O
did -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
any -X- _ O
provided -X- _ O
documents -X- _ O
or -X- _ O
external -X- _ O
corpora; -X- _ O
a -X- _ O
question -X- _ O
was -X- _ O
solely -X- _ O

The -X- _ O
dataset -X- _ O
statistics -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

For -X- _ O
CSQA -X- _ B-DatasetName
and -X- _ O
QASC, -X- _ B-DatasetName
since -X- _ O
the -X- _ O
correct -X- _ O
answers -X- _ O
in -X- _ O
the -X- _ O
official -X- _ O
test -X- _ O
set -X- _ O
are -X- _ O
not -X- _ O
public, -X- _ O
we -X- _ O
took -X- _ O
their -X- _ O
official -X- _ O
dev -X- _ O
set -X- _ O
as -X- _ O
our -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
experiments -X- _ O
and -X- _ O
randomly -X- _ O
held -X- _ O
out -X- _ O
an -X- _ O
in-house -X- _ O
dev -X- _ O
set -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set. -X- _ O

Train-Dev-Test -X- _ B-HyperparameterValue
Split -X- _ I-HyperparameterValue
For -X- _ O
OBQA, -X- _ B-DatasetName
ARC-Easy, -X- _ B-DatasetName
and -X- _ O
ARC-Challenge -X- _ B-DatasetName
we -X- _ O
used -X- _ O
their -X- _ O
official -X- _ O
train, -X- _ O
dev, -X- _ O
and -X- _ O
test -X- _ O
sets. -X- _ O

QASC -X- _ B-DatasetName
(Khot -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
elementary -X- _ O
and -X- _ O
middle -X- _ O
school -X- _ O
level -X- _ O
science -X- _ O
with -X- _ O
8 -X- _ O
options -X- _ O
for -X- _ O
each -X- _ O
question. -X- _ O

ARC-Easy -X- _ B-DatasetName
and -X- _ O
ARC-Challenge, -X- _ B-DatasetName
denoting -X- _ O
two -X- _ O
disjointed -X- _ O
subsets -X- _ O
of -X- _ O
ARC -X- _ B-DatasetName
(Clark -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
contain -X- _ O
natural -X- _ O
grade-school -X- _ O
science -X- _ O
questions -X- _ O
with -X- _ O
4 -X- _ O
options, -X- _ O
where -X- _ O
ARC-Challenge -X- _ B-DatasetName
comprises -X- _ O
difficult -X- _ O
questions -X- _ O
which -X- _ O
require -X- _ O
more -X- _ O
advanced -X- _ O
reasoning. -X- _ O

Each -X- _ O
question -X- _ O
is -X- _ O
given -X- _ O
with -X- _ O
5 -X- _ O
options -X- _ O
in -X- _ O
CSQA -X- _ B-DatasetName
and -X- _ O
4 -X- _ O
options -X- _ O
in -X- _ O
OBQA. -X- _ B-DatasetName

Datasets -X- _ O
CSQA -X- _ B-DatasetName
(Talmor -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
OBQA -X- _ B-DatasetName
(Mihaylov -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
are -X- _ O
two -X- _ O
commonsense -X- _ O
MCQA -X- _ B-TaskName
datasets -X- _ O
created -X- _ O
by -X- _ O
crowd -X- _ O
workers -X- _ O
based -X- _ O
on -X- _ O
commonsense -X- _ O
facts. -X- _ O

The -X- _ O
former -X- _ O
requires -X- _ O
commonsense -X- _ O
knowledge -X- _ O
and -X- _ O
reasoning, -X- _ O
and -X- _ O
the -X- _ O
latter -X- _ O
requires -X- _ O
inference -X- _ O
over -X- _ O
scientific -X- _ O
facts. -X- _ O

We -X- _ O
conducted -X- _ O
experiments -X- _ O
on -X- _ O
five -X- _ O
popular -X- _ O
MCQA -X- _ B-TaskName
datasets -X- _ O
spanning -X- _ O
from -X- _ O
commonsense -X- _ O
questions -X- _ O
to -X- _ O
scientific -X- _ O
questions. -X- _ O

4.1 -X- _ O
Data -X- _ O

4 -X- _ O
Experimental -X- _ O
Setup -X- _ O

For -X- _ O
each -X- _ O
model, -X- _ O
we -X- _ O
experimented -X- _ O
with -X- _ O
its -X- _ O
BASE -X- _ O
and -X- _ O
LARGE -X- _ O
versions. -X- _ O

We -X- _ O
used -X- _ O
two -X- _ O
popular -X- _ O
encoder-decoder -X- _ O
models -X- _ O
as -X- _ O
a -X- _ O
basis, -X- _ O
BART -X- _ O
(Lewis -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
T5 -X- _ O
(Raffel -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

4.2 -X- _ O
Implementation -X- _ O
Details -X- _ O

It -X- _ O
means -X- _ O
that -X- _ O
pre-trained -X- _ O
models -X- _ O
were -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
primary -X- _ O
source -X- _ O
of -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
experiments. -X- _ O

provided -X- _ O
with -X- _ O
its -X- _ O
options -X- _ O
to -X- _ O
form -X- _ O
the -X- _ O
input. -X- _ O

Such -X- _ O
usage -X- _ O
is -X- _ O
more -X- _ O
natural -X- _ O
than -X- _ O
the -X- _ O
text-totext -X- _ O
paradigm -X- _ O
(Khashabi -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Zhou -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
thus -X- _ O
having -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
outperform. -X- _ O

We -X- _ O
use -X- _ O
Ot -X- _ O
as -X- _ O
a -X- _ O
text -X- _ O
to -X- _ O
supervise -X- _ O
our -X- _ O
clue -X- _ O
generator, -X- _ O
and -X- _ O
as -X- _ O
an -X- _ O
index -X- _ O
(i.e., -X- _ O
classification -X- _ O
label) -X- _ O
to -X- _ O
supervise -X- _ O
our -X- _ O
enhanced -X- _ O
reader. -X- _ O

The -X- _ O
above -X- _ O
training -X- _ O
objective -X- _ O
exploits -X- _ O
the -X- _ O
double -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
Ot -X- _ O
in -X- _ O
MCQA: -X- _ B-TaskName
as -X- _ O
a -X- _ O
text -X- _ O
and -X- _ O
as -X- _ O
an -X- _ O
index. -X- _ O

For -X- _ O
CSQA -X- _ B-DatasetName
and -X- _ O
QASC, -X- _ B-DatasetName
their -X- _ O
official -X- _ O
dev -X- _ O
sets -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
our -X- _ O
test -X- _ O
sets, -X- _ O
and -X- _ O
our -X- _ O
dev -X- _ O
sets -X- _ O
are -X- _ O
in-house -X- _ O
split -X- _ O
from -X- _ O
their -X- _ O
official -X- _ O
training -X- _ O
sets. -X- _ O

L -X- _ O

Note -X- _ O
that -X- _ O
we -X- _ O
update -X- _ O
the -X- _ O
encoder -X- _ O
using -X- _ O
the -X- _ O
joint -X- _ O
loss -X- _ O
READ -X- _ O
to -X- _ O
be -X- _ O
backpropL -X- _ O
agated -X- _ O
to -X- _ O
the -X- _ O
decoder -X- _ O
part -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
memory -X- _ O
consumption. -X- _ O

READ, -X- _ O
we -X- _ O
simply -X- _ O
calculate -X- _ O
a -X- _ O
O -X- _ O

Reader -X- _ O
Loss -X- _ O
For -X- _ O
cross-entropy -X- _ O
loss -X- _ O
given -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
Ot -X- _ O
∈ -X- _ O
as -X- _ O
follows: -X- _ O

where -X- _ O
pOt -X- _ O
denotes -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
j -X- _ O
over -X- _ O
the -X- _ O
decoding -X- _ O
vocabulary -X- _ O
at -X- _ O
the -X- _ O
j-th -X- _ O
step, -X- _ O
and -X- _ O
pOt -X- _ O
j,aj -X- _ O
is -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
token -X- _ O
aj. -X- _ O

We -X- _ O
jointly -X- _ O
train -X- _ O
the -X- _ O
clue -X- _ O
generator -X- _ O
and -X- _ O
the -X- _ O
enhanced -X- _ O
reader -X- _ O
in -X- _ O
an -X- _ O
end-to-end -X- _ O
fashion -X- _ O
with -X- _ O
a -X- _ O
combined -X- _ O
loss: -X- _ O

3.3 -X- _ O
Training -X- _ O
Objective -X- _ O

We -X- _ O
select -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
as -X- _ O
the -X- _ O
predicted -X- _ O
answer, -X- _ O
denoted -X- _ O
as -X- _ O
Op. -X- _ O

3A -X- _ O
delimiter -X- _ O
" -X- _ O
n" -X- _ O
is -X- _ O
inserted -X- _ O
between -X- _ O
Q -X- _ O
and -X- _ O
each -X- _ O
Oi. -X- _ O

forming -X- _ O
beam -X- _ O
search. -X- _ O

2For -X- _ O
efficiency, -X- _ O
we -X- _ O
decode -X- _ O
the -X- _ O
clue -X- _ O
greedily -X- _ O
without -X- _ O
per -X- _ O

Specifically, -X- _ O
we -X- _ O
first -X- _ O
concatenate -X- _ O
Q -X- _ O
and -X- _ O
each -X- _ O
Oi -X- _ O
independently3 -X- _ O
and -X- _ O
feed -X- _ O
the -X- _ O
concatenated -X- _ O
input -X- _ O
into -X- _ O
the -X- _ O
pre-trained -X- _ O
encoder -X- _ O
(which -X- _ O
is -X- _ O
shared -X- _ O
with -X- _ O
our -X- _ O
clue -X- _ O
generator) -X- _ O
to -X- _ O
obtain -X- _ O
Oi’s -X- _ O
contextualized -X- _ O

By -X- _ O
contrast, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
previously -X- _ O
generated -X- _ O
clue -X- _ O
representation -X- _ O
to -X- _ O
enhance -X- _ O
our -X- _ O
reader -X- _ O
for -X- _ O
a -X- _ O
deeper -X- _ O
understanding -X- _ O
of -X- _ O
each -X- _ O
question-option -X- _ O
pair. -X- _ O

Previous -X- _ O
works -X- _ O
often -X- _ O
directly -X- _ O
model -X- _ O
the -X- _ O
relevance -X- _ O
O -X- _ O
to -X- _ O
Q -X- _ O
via -X- _ O
joint -X- _ O
encoding -X- _ O
using -X- _ O
a -X- _ O
preof -X- _ O
each -X- _ O
Oi -X- _ O
∈ -X- _ O
trained -X- _ O
encoder, -X- _ O
which -X- _ O
largely -X- _ O
performs -X- _ O
superficial -X- _ O
lexical -X- _ O
reasoning -X- _ O
(Zellers -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

HQC -X- _ O
carries -X- _ O
the -X- _ O
where -X- _ O
[ -X- _ O
information -X- _ O
of -X- _ O
C -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
helpful -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
and -X- _ O
answer -X- _ O
Q. -X- _ O

To -X- _ O
encourage -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
C -X- _ O
to -X- _ O
thoroughly -X- _ O
interact -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
and -X- _ O
with -X- _ O
Q, -X- _ O
we -X- _ O
strengthen -X- _ O
the -X- _ O
clue -X- _ O
representation -X- _ O
by -X- _ O
passing -X- _ O
it -X- _ O
to -X- _ O
a -X- _ O
transformer -X- _ O
layer -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
and -X- _ O
obtain -X- _ O
HQC: -X- _ O

where -X- _ O
Decoder -X- _ O
( -X- _ O
1, -X- _ O
· -X- _ O
− -X- _ O
the -X- _ O
representation -X- _ O
for -X- _ O
the -X- _ O
decoding -X- _ O
history -X- _ O
HC -X- _ O
<j, -X- _ O
and -X- _ O
HQ -X- _ O
as -X- _ O
input, -X- _ O
and -X- _ O
outputs -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
HC -X- _ O
j -X- _ O
together -X- _ O
with -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
pC -X- _ O
j -X- _ O
over -X- _ O
the -X- _ O
decoding -X- _ O
vocabulary -X- _ O
at -X- _ O
the -X- _ O
j-th -X- _ O
step. -X- _ O

i -X- _ O

To -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
score -X- _ O
si -X- _ O
for -X- _ O
each -X- _ O
Oi, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
dual -X- _ O
matching -X- _ O
features -X- _ O
f -X- _ O
QO -X- _ O
and -X- _ O
f -X- _ O
QC -X- _ O
i -X- _ O
and -X- _ O
feed -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
two-layer -X- _ O
multi-layer -X- _ O
perceptron -X- _ O
(MLP): -X- _ O

i -X- _ O

Then -X- _ O
we -X- _ O
perform -X- _ O
max-pooling -X- _ O
to -X- _ O
aggregate -X- _ O
the -X- _ O
matching -X- _ O
features: -X- _ O

Specifically, -X- _ O
inspired -X- _ O
by -X- _ O
Huang -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
dual-attention -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2020a) -X- _ O
to -X- _ O
fuse -X- _ O
information -X- _ O
from -X- _ O
HQO -X- _ O
to -X- _ O
HQC -X- _ O
and -X- _ O
i -X- _ O
from -X- _ O
HQC -X- _ O
to -X- _ O
HQO -X- _ O
. -X- _ O

Next, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
clue -X- _ O
representation -X- _ O
HQC, -X- _ O
our -X- _ O
model -X- _ O
intensively -X- _ O
reads -X- _ O
each -X- _ O
question-option -X- _ O
pair -X- _ O
and -X- _ O
obtains -X- _ O
the -X- _ O
matching -X- _ O
signal -X- _ O
between -X- _ O
the -X- _ O
clue -X- _ O
and -X- _ O
the -X- _ O
option. -X- _ O

HC -X- _ O
j -X- _ O
, -X- _ O
denoting -X- _ O
the -X- _ O
C, -X- _ O
is -X- _ O
comrepresentation -X- _ O
of -X- _ O
the -X- _ O
j-th -X- _ O
token -X- _ O
cj -X- _ O
∈ -X- _ O
puted -X- _ O
as -X- _ O
follows: -X- _ O

Specifically, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
question -X- _ O
represenRd -X- _ O
tation -X- _ O
HQ -X- _ O
| -X- _ O
and -X- _ O
the -X- _ O
clue -X- _ O
representation -X- _ O
HC -X- _ O
Rd -X- _ O
| -X- _ O
from -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
of -X- _ O
the -X- _ O
decoder, -X- _ O
respectively, -X- _ O
where -X- _ O
d -X- _ O
denotes -X- _ O
the -X- _ O
representation -X- _ O
dimension. -X- _ O

, -X- _ O
c -X- _ O
using -X- _ O
a -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
model.2 -X- _ O
Note -X- _ O
that -X- _ O
not -X- _ O
the -X- _ O
clue -X- _ O
text -X- _ O
C -X- _ O
but -X- _ O
its -X- _ O
representation -X- _ O
HC -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
model, -X- _ O
although -X- _ O
one -X- _ O
could -X- _ O
output -X- _ O
C -X- _ O
as -X- _ O
evidence -X- _ O
for -X- _ O
explainability. -X- _ O

3.1 -X- _ O
Clue -X- _ O
Generator -X- _ O
The -X- _ O
clue -X- _ O
generator -X- _ O
takes -X- _ O
the -X- _ O
question -X- _ O
Q -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
autoregressively -X- _ O
outputs -X- _ O
a -X- _ O
clue -X- _ O
C -X- _ O
= -X- _ O
c1, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

Then -X- _ O
the -X- _ O
enhanced -X- _ O
reader -X- _ O
(Section -X- _ O
3.2) -X- _ O
uses -X- _ O
the -X- _ O
generated -X- _ O
clue -X- _ O
to -X- _ O
augment -X- _ O
question-option -X- _ O
understanding. -X- _ O

The -X- _ O
clue -X- _ O
generator -X- _ O
(Section -X- _ O
3.1) -X- _ O
first -X- _ O
generates -X- _ O
a -X- _ O
clue -X- _ O
representation -X- _ O
only -X- _ O
given -X- _ O
Q. -X- _ O

The -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
GenMC -X- _ B-MethodName
is -X- _ O
shown -X- _ O
in -X- _ O

Our -X- _ O
model -X- _ O
design -X- _ O
mimics -X- _ O
how -X- _ O
humans -X- _ O
solve -X- _ O
an -X- _ O
MCQA -X- _ B-TaskName
task, -X- _ O
i.e., -X- _ O
after -X- _ O
reading -X- _ O
a -X- _ O
question, -X- _ O
humans -X- _ O
may -X- _ O
firstly -X- _ O
associate -X- _ O
it -X- _ O
with -X- _ O
some -X- _ O
of -X- _ O
their -X- _ O
background -X- _ O
knowledge -X- _ O
(i.e., -X- _ O
looking -X- _ O
for -X- _ O
clues) -X- _ O
that -X- _ O
helps -X- _ O
them -X- _ O
to -X- _ O
later -X- _ O
identify -X- _ O
the -X- _ O
correct -X- _ O
answer. -X- _ O

Then -X- _ O
GenMC -X- _ B-MethodName
employs -X- _ O
the -X- _ O
generated -X- _ O
clue -X- _ O
representation -X- _ O
as -X- _ O
intermediate -X- _ O
knowledge -X- _ O
connecting -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
and -X- _ O
enhance -X- _ O
a -X- _ O
reader -X- _ O
for -X- _ O
solving -X- _ O
MCQA. -X- _ B-TaskName

Building -X- _ O
on -X- _ O
a -X- _ O
pre-trained -X- _ O
encoderdecoder -X- _ O
model, -X- _ O
GenMC -X- _ B-MethodName
firstly -X- _ O
generates -X- _ O
a -X- _ O
clue -X- _ O
which -X- _ O
is -X- _ O
indicative -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
answer, -X- _ O
thereby -X- _ O
exploiting -X- _ O
the -X- _ O
NLG -X- _ O
capability -X- _ O
and -X- _ O
underlying -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
model. -X- _ O

Our -X- _ O
proposed -X- _ O
model -X- _ O
GenMC -X- _ B-MethodName
overcomes -X- _ O
these -X- _ O
limitations. -X- _ O

Moreover, -X- _ O
a -X- _ O
simple -X- _ O
joint -X- _ O
encoding -X- _ O
of -X- _ O
Q -X- _ O
and -X- _ O
each -X- _ O
Oi -X- _ O
can -X- _ O
only -X- _ O
enable -X- _ O
lexical-level -X- _ O
reasoning -X- _ O
(Zellers -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
which -X- _ O
is -X- _ O
insufficient -X- _ O
for -X- _ O
MCQA -X- _ B-TaskName
tasks. -X- _ O

However, -X- _ O
previous -X- _ O
works -X- _ O
directly -X- _ O
use -X- _ O
the -X- _ O
decoder -X- _ O
to -X- _ O
generate -X- _ O
an -X- _ O
option -X- _ O
in -X- _ O
O, -X- _ O
i.e., -X- _ O
using -X- _ O
the -X- _ O
decoder -X- _ O
as -X- _ O
a -X- _ O
classifier, -X- _ O
which -X- _ O
may -X- _ O
have -X- _ O
under-exploited -X- _ O
the -X- _ O
model’s -X- _ O
NLG -X- _ O
capability -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
trend -X- _ O
of -X- _ O
building -X- _ O
on -X- _ O
a -X- _ O
pretrained -X- _ O
encoder-decoder -X- _ O
model -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
encoder -X- _ O
to -X- _ O
jointly -X- _ O
encode -X- _ O
Q -X- _ O
and -X- _ O
each -X- _ O
Oi. -X- _ O

The -X- _ O
key -X- _ O
to -X- _ O
finding -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
is -X- _ O
to -X- _ O
capture -X- _ O
and -X- _ O
deeply -X- _ O
understand -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
Q -X- _ O
and -X- _ O
each -X- _ O
Oi -X- _ O
∈ -X- _ O
O, -X- _ O
which -X- _ O
oftentimes -X- _ O
is -X- _ O
beyond -X- _ O
the -X- _ O
lexical -X- _ O
level -X- _ O
and -X- _ O
requires -X- _ O
a -X- _ O
non-trivial -X- _ O
entailment -X- _ O
process. -X- _ O

In -X- _ O
MCQA, -X- _ B-TaskName
a -X- _ O
question -X- _ O
Q -X- _ O
is -X- _ O
given -X- _ O
together -X- _ O
with -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
n -X- _ O
options -X- _ O
O -X- _ O
= -X- _ O
with -X- _ O
exactly -X- _ O
one -X- _ O
option -X- _ O
being -X- _ O
the -X- _ O
correct -X- _ O
answer. -X- _ O

Such -X- _ O
token-level -X- _ O
interaction -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
significant -X- _ O
losses -X- _ O
in -X- _ O
accuracy -X- _ O
as -X- _ O
we -X- _ O
will -X- _ O
see -X- _ O
in -X- _ O
our -X- _ O
experiments, -X- _ O
where -X- _ O
our -X- _ O
representation-level -X- _ O
interaction -X- _ O
exhibits -X- _ O
better -X- _ O
performance. -X- _ O

However, -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
reading -X- _ O
model -X- _ O
are -X- _ O
separate -X- _ O
steps -X- _ O
in -X- _ O
a -X- _ O
pipeline -X- _ O
and -X- _ O
are -X- _ O
connected -X- _ O
only -X- _ O
via -X- _ O
the -X- _ O
evidence -X- _ O
text. -X- _ O

It -X- _ O
first -X- _ O
uses -X- _ O
a -X- _ O
generative -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
evidence, -X- _ O
and -X- _ O
then -X- _ O
uses -X- _ O
a -X- _ O
reading -X- _ O
model -X- _ O
to -X- _ O
incorporate -X- _ O
the -X- _ O
evidence -X- _ O
and -X- _ O
predict -X- _ O
the -X- _ O
answer, -X- _ O
both -X- _ O
using -X- _ O
answer -X- _ O
supervision. -X- _ O

CEGI -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2020c) -X- _ O
is -X- _ O
probably -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
work -X- _ O
to -X- _ O
ours. -X- _ O

Although -X- _ O
it -X- _ O
somewhat -X- _ O
improves -X- _ O
the -X- _ O
explainability -X- _ O
of -X- _ O
MCQA, -X- _ B-TaskName
in -X- _ O
terms -X- _ O
of -X- _ O
accuracy -X- _ O
of -X- _ O
MCQA -X- _ B-TaskName
there -X- _ O
is -X- _ O
little -X- _ O
advancement. -X- _ O

Latcinnik -X- _ O
and -X- _ O
Berant -X- _ O
(2020) -X- _ O
propose -X- _ O
a -X- _ O
joint -X- _ O
generator-classifier -X- _ O
model -X- _ O
where -X- _ O
the -X- _ O
generator -X- _ O
produces -X- _ O
a -X- _ O
human-readable -X- _ O
textual -X- _ O
hypothesis. -X- _ O

However, -X- _ O
CAGE -X- _ O
relies -X- _ O
on -X- _ O
explanations -X- _ O
annotated -X- _ O
by -X- _ O
humans, -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
in -X- _ O
many -X- _ O
real -X- _ O
scenarios -X- _ O
and -X- _ O
datasets. -X- _ O

Rajani -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
propose -X- _ O
CAGE -X- _ O
as -X- _ O
a -X- _ O
framework -X- _ O
for -X- _ O
generating -X- _ O
explanations -X- _ O
for -X- _ O
commonsense -X- _ O
QA. -X- _ O

There -X- _ O
is -X- _ O
also -X- _ O
research -X- _ O
on -X- _ O
MCQA -X- _ B-TaskName
trying -X- _ O
to -X- _ O
exporting -X- _ O
knowledge -X- _ O
from -X- _ O
PLMs -X- _ O
before -X- _ O
answering. -X- _ O

Exploiting -X- _ O
the -X- _ O
knowledge -X- _ O
in -X- _ O
PLMs -X- _ O
for -X- _ O
QA -X- _ O
tasks -X- _ O
has -X- _ O
come -X- _ O
into -X- _ O
play -X- _ O
in -X- _ O
many -X- _ O
forms -X- _ O
including -X- _ O
question -X- _ O
expansion -X- _ O
(Mao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
(Shwartz -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Recently, -X- _ O
PLMs -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
as -X- _ O
knowledge -X- _ O
bases -X- _ O
(Petroni -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
and -X- _ O
the -X- _ O
knowledge -X- _ O
in -X- _ O
parameters -X- _ O
can -X- _ O
be -X- _ O
exported -X- _ O
via -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
Prompt -X- _ O
(Jiang -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Shin -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

3 -X- _ O
GenMC -X- _ B-MethodName
Model -X- _ O

2.3 -X- _ O
Knowledge -X- _ O
in -X- _ O
PLMs -X- _ O

READ. -X- _ O

GEN -X- _ O
and -X- _ O
the -X- _ O
classification -X- _ O
loss -X- _ O

The -X- _ O
whole -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
end-to-end -X- _ O
manner -X- _ O
with -X- _ O
both -X- _ O
the -X- _ O
generation -X- _ O
loss -X- _ O

The -X- _ O
enhanced -X- _ O
reader -X- _ O
then -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
generated -X- _ O
clue -X- _ O
representation -X- _ O
to -X- _ O
better -X- _ O
attend -X- _ O
to -X- _ O
options -X- _ O
from -X- _ O
O -X- _ O
and -X- _ O
makes -X- _ O
the -X- _ O
final -X- _ O
prediction. -X- _ O

To -X- _ O
make -X- _ O
the -X- _ O
prediction -X- _ O
Op -X- _ O
∈ -X- _ O
O, -X- _ O
the -X- _ O
clue -X- _ O
generator -X- _ O
first -X- _ O
takes -X- _ O
Q -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
outputs -X- _ O
a -X- _ O
clue -X- _ O
representation -X- _ O
HQC -X- _ O
which -X- _ O
is -X- _ O
indicative -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
answer. -X- _ O

A -X- _ O

Question: -X- _ O

By -X- _ O
contrast, -X- _ O
we -X- _ O
aim -X- _ O
at -X- _ O
exporting -X- _ O
clues -X- _ O
from -X- _ O
pre-trained -X- _ O
models -X- _ O
without -X- _ O
resorting -X- _ O
to -X- _ O
extra -X- _ O
sources. -X- _ O

There, -X- _ O
evidence -X- _ O
is -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
given -X- _ O
passage -X- _ O
or -X- _ O
retrieved -X- _ O
from -X- _ O
external -X- _ O
corpora. -X- _ O

Other -X- _ O
efforts -X- _ O
mimic -X- _ O
human -X- _ O
behavior -X- _ O
of -X- _ O
reading -X- _ O
evidence -X- _ O
and -X- _ O
answering -X- _ O
questions -X- _ O
(Ran -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Tang -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Sun -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Building -X- _ O
on -X- _ O
this, -X- _ O
some -X- _ O
works -X- _ O
study -X- _ O
how -X- _ O
to -X- _ O
design -X- _ O
better -X- _ O
attention-based -X- _ O
models -X- _ O
to -X- _ O
identify -X- _ O
evidence -X- _ O
(Chen -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zhang -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Zhu -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2b, -X- _ O
in -X- _ O
this -X- _ O
paradigm, -X- _ O
the -X- _ O
question -X- _ O
Q -X- _ O
and -X- _ O
each -X- _ O
option -X- _ O
in -X- _ O
are -X- _ O
interacted -X- _ O
to -X- _ O
calculate -X- _ O
a -X- _ O
score, -X- _ O
and -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
score -X- _ O
is -X- _ O
chosen -X- _ O
as -X- _ O
the -X- _ O
answer. -X- _ O

Liu -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Lan -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
the -X- _ O
encoder-only -X- _ O
paradigm -X- _ O
has -X- _ O
been -X- _ O
popular -X- _ O
for -X- _ O
MCQA. -X- _ B-TaskName

Benefiting -X- _ O
from -X- _ O
the -X- _ O
powerful -X- _ O
NLU -X- _ B-TaskName
capabilities -X- _ O
of -X- _ O
BERT-style -X- _ O
PLMs -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

O1, -X- _ O
O2, -X- _ O
O3, -X- _ O
O4} -X- _ O
{ -X- _ O

2.2 -X- _ O
Encoder-Only -X- _ O
Paradigm -X- _ O
for -X- _ O
MCQA -X- _ B-TaskName

They -X- _ O
are -X- _ O
orthogonal -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
as -X- _ O
we -X- _ O
leverage -X- _ O
existing -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
models -X- _ O
instead -X- _ O
of -X- _ O
pre-training -X- _ O
new -X- _ O
models -X- _ O
at -X- _ O
an -X- _ O
additional -X- _ O
cost. -X- _ O

Some -X- _ O
other -X- _ O
works -X- _ O
propose -X- _ O
new -X- _ O
pre-trained -X- _ O
models -X- _ O
for -X- _ O
unified -X- _ O
generation -X- _ O
and -X- _ O
classification -X- _ O
tasks -X- _ O
by -X- _ O
designing -X- _ O
universal -X- _ O
encoders -X- _ O
and -X- _ O
task-specific -X- _ O
decoders -X- _ O
(Shao -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Sun -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

By -X- _ O
contrast, -X- _ O
we -X- _ O
address -X- _ O
this -X- _ O
issue -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
perspective -X- _ O
of -X- _ O
how -X- _ O
to -X- _ O
exploit -X- _ O
the -X- _ O
NLG -X- _ O
capability -X- _ O
of -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
models -X- _ O
for -X- _ O
MCQA -X- _ B-TaskName
to -X- _ O
improve -X- _ O
accuracy. -X- _ O

Therefore, -X- _ O
they -X- _ O
propose -X- _ O
a -X- _ O
method -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
T5 -X- _ O
parameters -X- _ O
to -X- _ O
improve -X- _ O
efficiency -X- _ O
without -X- _ O
reducing -X- _ O
accuracy. -X- _ O

Liu -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
point -X- _ O
out -X- _ O
that -X- _ O
the -X- _ O
decoder -X- _ O
layers -X- _ O
of -X- _ O
T5 -X- _ O
are -X- _ O
under-utilized -X- _ O
when -X- _ O
finetuning -X- _ O
on -X- _ O
classification -X- _ O
and -X- _ O
regression -X- _ O
tasks. -X- _ O

However, -X- _ O
it -X- _ O
might -X- _ O
be -X- _ O
debatable -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
appropriate -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
classification -X- _ O
task -X- _ O
via -X- _ O
a -X- _ O
generation -X- _ O
target. -X- _ O

learns -X- _ O
concept-centric -X- _ O
knowledge -X- _ O
from -X- _ O
text -X- _ O
for -X- _ O
commonsense -X- _ O
QA. -X- _ O

1https://github.com/nju-websoft/GenMC -X- _ O

{ -X- _ O

Similarly, -X- _ O
CALM -X- _ O
(Zhou -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O

Using -X- _ O
such -X- _ O
a -X- _ O
framework, -X- _ O
UnifiedQA -X- _ B-MethodName
(Khashabi -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
integrates -X- _ O
20 -X- _ O
QA -X- _ O
datasets -X- _ O
into -X- _ O
a -X- _ O
unified -X- _ O
format -X- _ O
for -X- _ O
training, -X- _ O
and -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
multiple -X- _ O
MCQA -X- _ B-TaskName
datasets. -X- _ O

One -X- _ O
benefit -X- _ O
is -X- _ O
that -X- _ O
extensive -X- _ O
training -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
shared -X- _ O
across -X- _ O
different -X- _ O
tasks. -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2a, -X- _ O
adopting -X- _ O
this -X- _ O
paradigm -X- _ O
for -X- _ O
MCQA, -X- _ B-TaskName
the -X- _ O
question -X- _ O
Q -X- _ O
and -X- _ O
all -X- _ O
the -X- _ O
options -X- _ O
O1, -X- _ O
O2, -X- _ O
O3, -X- _ O
O4} -X- _ O
are -X- _ O
spliced -X- _ O
into -X- _ O
a -X- _ O
text -X- _ O
as -X- _ O
input, -X- _ O
and -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
O1 -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
generation -X- _ O
target. -X- _ O

Recently, -X- _ O
the -X- _ O
text-to-text -X- _ O
paradigm -X- _ O
has -X- _ O
achieved -X- _ O
breakthrough -X- _ O
results -X- _ O
on -X- _ O
many -X- _ O
NLP -X- _ O
tasks -X- _ O
(Raffel -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Lewis -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

2.1 -X- _ O
Text-to-Text -X- _ O
Paradigm -X- _ O
for -X- _ O
MCQA -X- _ B-TaskName

2 -X- _ O
Related -X- _ O
Work -X- _ O

Code -X- _ O
Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
on -X- _ O
GitHub1 -X- _ O
under -X- _ O
the -X- _ O
Apache -X- _ O
Licence -X- _ O
2.0. -X- _ O

Outline -X- _ O
We -X- _ O
discuss -X- _ O
related -X- _ O
work -X- _ O
in -X- _ O
Section -X- _ O
2, -X- _ O
introduce -X- _ O
GenMC -X- _ B-MethodName
in -X- _ O
Section -X- _ O
3, -X- _ O
describe -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
in -X- _ O
Section -X- _ O
4, -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Section -X- _ O
5, -X- _ O
and -X- _ O
conclude -X- _ O
in -X- _ O
Section -X- _ O
6. -X- _ O

It -X- _ O
significantly -X- _ O
outperforms -X- _ O
comparable -X- _ O
models, -X- _ O
in -X- _ O
particular, -X- _ O
text-to-text -X- _ O
models, -X- _ O
on -X- _ O
five -X- _ O
MCQA -X- _ B-TaskName
datasets. -X- _ O

We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
generation-enhanced -X- _ O
MCQA -X- _ B-TaskName
model -X- _ O
as -X- _ O
GenMC. -X- _ B-MethodName

The -X- _ O
clue -X- _ O
representation -X- _ O
is -X- _ O
then -X- _ O
leveraged -X- _ O
by -X- _ O
an -X- _ O
encoder-based -X- _ O
model -X- _ O
to -X- _ O
read -X- _ O
the -X- _ O
options -X- _ O
and -X- _ O
make -X- _ O
prediction. -X- _ O

With -X- _ O
this -X- _ O
idea, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
employ -X- _ O
a -X- _ O
pretrained -X- _ O
encoder-decoder -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
clue -X- _ O
from -X- _ O
the -X- _ O
question -X- _ O
by -X- _ O
exploiting -X- _ O
its -X- _ O
underlying -X- _ O
knowledge, -X- _ O
without -X- _ O
seeing -X- _ O
and -X- _ O
being -X- _ O
strictly -X- _ O
confined -X- _ O
to -X- _ O
the -X- _ O
options -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
text-to-text -X- _ O
framework. -X- _ O

Our -X- _ O
Contribution -X- _ O

One -X- _ O
research -X- _ O
question -X- _ O
is -X- _ O
how -X- _ O
to -X- _ O
apply -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
more -X- _ O
natural -X- _ O
way -X- _ O
to -X- _ O
MCQA, -X- _ B-TaskName
in -X- _ O
particular, -X- _ O
to -X- _ O
exploit -X- _ O
their -X- _ O
NLG -X- _ O
capabilities. -X- _ O

Indeed, -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
have -X- _ O
found -X- _ O
that -X- _ O
in -X- _ O
classification -X- _ O
and -X- _ O
regression -X- _ O
tasks, -X- _ O
the -X- _ O
decoder -X- _ O
layer -X- _ O
is -X- _ O
often -X- _ O
under-utilized. -X- _ O

However, -X- _ O
this -X- _ O
is -X- _ O
inconsistent -X- _ O
with -X- _ O
how -X- _ O
encoder-decoder -X- _ O
models -X- _ O
are -X- _ O
pre-trained -X- _ O
so -X- _ O
that -X- _ O
their -X- _ O
underlying -X- _ O
knowledge -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
sufficiently -X- _ O
exploited. -X- _ O

Research -X- _ O
Question -X- _ O
To -X- _ O
fit -X- _ O
MCQA, -X- _ B-TaskName
existing -X- _ O
implementations -X- _ O
of -X- _ O
the -X- _ O
text-to-text -X- _ O
framework -X- _ O
take -X- _ O
all -X- _ O
the -X- _ O
options -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
are -X- _ O
trained -X- _ O
to -X- _ O
generate -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
options, -X- _ O
i.e., -X- _ O
to -X- _ O
copy -X- _ O
some -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
input. -X- _ O

This -X- _ O
is -X- _ O
enabled -X- _ O
by -X- _ O
the -X- _ O
text-to-text -X- _ O
framework, -X- _ O
which -X- _ O
transforms -X- _ O
data -X- _ O
in -X- _ O
different -X- _ O
tasks -X- _ O
into -X- _ O
a -X- _ O
unified -X- _ O
text-to-text -X- _ O
format -X- _ O
so -X- _ O
that -X- _ O
knowledge -X- _ O
spanning -X- _ O
many -X- _ O
and -X- _ O
various -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
learned, -X- _ O
aggregated, -X- _ O
and -X- _ O
used -X- _ O
by -X- _ O
a -X- _ O
single -X- _ O
model. -X- _ O

However, -X- _ O
encoder-decoder -X- _ O
models -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
MCQA -X- _ B-TaskName
(Khashabi -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Zhou -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

T5 -X- _ O
(Raffel -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
BART -X- _ O
(Lewis -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
are -X- _ O
encoder-decoder -X- _ O
models, -X- _ O
being -X- _ O
more -X- _ O
suitable -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
generation -X- _ O
(NLG) -X- _ O
tasks. -X- _ O

and -X- _ O
its -X- _ O
variants -X- _ O
such -X- _ O
as -X- _ O
RoBERTa -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
ALBERT -X- _ O
(Lan -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
are -X- _ O
encoder-only -X- _ O
models, -X- _ O
being -X- _ O
more -X- _ O
suitable -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
(NLU) -X- _ B-TaskName
tasks -X- _ O
including -X- _ O
MCQA -X- _ B-TaskName
and -X- _ O
other -X- _ O
classification -X- _ O
and -X- _ O
regression -X- _ O
tasks. -X- _ O

BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O

Basically -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
PLMs -X- _ O
that -X- _ O
are -X- _ O
suitable -X- _ O
for -X- _ O
different -X- _ O
tasks. -X- _ O

MCQA -X- _ B-TaskName
has -X- _ O
made -X- _ O
great -X- _ O
progress -X- _ O
with -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
(PLMs). -X- _ O

Mihaylov -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
and -X- _ O
scientific -X- _ O
knowledge -X- _ O
(Clark -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Khot -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Huang -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Li -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
and -X- _ O
have -X- _ O
reasoning -X- _ O
skills -X- _ O
such -X- _ O
as -X- _ O
multi-hop -X- _ O
reasoning -X- _ O
(Khot -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
logical -X- _ O
reasoning -X- _ O
(Yu -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2020b; -X- _ O
Li -X- _ O
et -X- _ O
al., -X- _ O
2022). -X- _ O

This -X- _ O
long-standing -X- _ O
challenge -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
(NLP) -X- _ O
requires -X- _ O
machines -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
wealth -X- _ O
of -X- _ O
knowledge, -X- _ O
such -X- _ O
as -X- _ O
commonsense -X- _ O
knowledge -X- _ O
(Talmor -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

Multiple-choice -X- _ O
question -X- _ O
answering -X- _ O
(MCQA) -X- _ B-TaskName
aims -X- _ O
at -X- _ O
selecting -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
from -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
options -X- _ O
given -X- _ O
a -X- _ O
question. -X- _ O

Introduction -X- _ O

It -X- _ O
outperforms -X- _ O
textto-text -X- _ O
models -X- _ O
on -X- _ O
multiple -X- _ O
MCQA -X- _ B-TaskName
datasets. -X- _ O

It -X- _ O
generates -X- _ O
a -X- _ O
clue -X- _ O
from -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
then -X- _ O
leverages -X- _ O
the -X- _ O
clue -X- _ O
to -X- _ O
enhance -X- _ O
a -X- _ O
reader -X- _ O
for -X- _ O
MCQA. -X- _ B-TaskName

To -X- _ O
exploit -X- _ O
the -X- _ O
generation -X- _ O
capability -X- _ O
and -X- _ O
underlying -X- _ O
knowledge -X- _ O
of -X- _ O
a -X- _ O
pre-trained -X- _ O
encoder-decoder -X- _ O
model, -X- _ O
in -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
generation-enhanced -X- _ O
MCQA -X- _ B-TaskName
model -X- _ O
named -X- _ O
GenMC. -X- _ B-MethodName

However, -X- _ O
a -X- _ O
side -X- _ O
effect -X- _ O
of -X- _ O
twisting -X- _ O
a -X- _ O
generation -X- _ O
target -X- _ O
to -X- _ O
fit -X- _ O
the -X- _ O
classification -X- _ O
nature -X- _ O
of -X- _ O
MCQA -X- _ B-TaskName
is -X- _ O
the -X- _ O
underutilization -X- _ O
of -X- _ O
the -X- _ O
decoder -X- _ O
and -X- _ O
the -X- _ O
knowledge -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
decoded. -X- _ O

By -X- _ O
unifying -X- _ O
data -X- _ O
in -X- _ O
different -X- _ O
tasks -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
text-to-text -X- _ O
format, -X- _ O
it -X- _ O
trains -X- _ O
a -X- _ O
generative -X- _ O
encoder-decoder -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
both -X- _ O
powerful -X- _ O
and -X- _ O
universal. -X- _ O

A -X- _ O
trending -X- _ O
paradigm -X- _ O
for -X- _ O
multiple-choice -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
(MCQA) -X- _ B-TaskName
is -X- _ O
using -X- _ O
a -X- _ O
text-to-text -X- _ O
framework. -X- _ O

Abstract -X- _ O

Clues -X- _ O
Before -X- _ O
Answers: -X- _ O
Generation-Enhanced -X- _ O
Multiple-Choice -X- _ O
QA -X- _ O

-DOCSTART- -X- O
Figure -X- _ O
6 -X- _ O
and -X- _ O
Figure -X- _ O
7 -X- _ O
display -X- _ O
the -X- _ O
10 -X- _ O
first -X- _ O
dialog -X- _ O
samples -X- _ O
produced -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
on -X- _ O
CLEVR, -X- _ B-DatasetName
while -X- _ O
figures -X- _ O
8, -X- _ O
9, -X- _ O
and -X- _ O
10 -X- _ O
display -X- _ O
the -X- _ O
15 -X- _ O
first -X- _ O
dialog -X- _ O
samples -X- _ O
produced -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
on -X- _ O
VQAv2. -X- _ B-DatasetName

D -X- _ O
Additional -X- _ O
VQG -X- _ B-TaskName
Samples -X- _ O

(b) -X- _ O
Language -X- _ O
Grounding -X- _ O
pairwise -X- _ O
comparison -X- _ O

(a) -X- _ O
Language -X- _ O
Quality -X- _ O
pairwise -X- _ O
comparison -X- _ O

Figure -X- _ O
5 -X- _ O
displays -X- _ O
one -X- _ O
pairwise -X- _ O
comparison -X- _ O
example -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
sections, -X- _ O
and -X- _ O
a -X- _ O
full -X- _ O
form -X- _ O
example -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
the -X- _ O
following -X- _ O
url: -X- _ O
https://forms.gle/kkL38x31wF7A9YKx5. -X- _ O

The -X- _ O
evaluation -X- _ O
of -X- _ O
syntax -X- _ O
errors -X- _ O
was -X- _ O
made -X- _ O
within -X- _ O
the -X- _ O
diversity -X- _ O
section: -X- _ O
for -X- _ O
each -X- _ O
questions -X- _ O
pair, -X- _ O
we -X- _ O
asked -X- _ O
participants -X- _ O
to -X- _ O
tick -X- _ O
the -X- _ O
questions -X- _ O
if -X- _ O
they -X- _ O
are -X- _ O
grammatically -X- _ O
incorrect. -X- _ O

Each -X- _ O
pairwise -X- _ O
comparison -X- _ O
is -X- _ O
sampled -X- _ O
uniformly -X- _ O
over -X- _ O
the -X- _ O
50 -X- _ O
first -X- _ O
question -X- _ O
samples -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
algorithms -X- _ O
at -X- _ O
test -X- _ O
time. -X- _ O

Given -X- _ O
the -X- _ O
five -X- _ O
evaluated -X- _ O
models, -X- _ O
there -X- _ O
are -X- _ O
ten -X- _ O
different -X- _ O
model -X- _ O
pairs: -X- _ O
each -X- _ O
section -X- _ O
of -X- _ O
the -X- _ O
form -X- _ O
contains -X- _ O
10 -X- _ O
pairwise -X- _ O
comparison -X- _ O
covering -X- _ O
all -X- _ O
the -X- _ O
possible -X- _ O
model -X- _ O
pairs -X- _ O
for -X- _ O
the -X- _ O
criteria. -X- _ O

For -X- _ O
the -X- _ O
Human -X- _ O
Evaluation -X- _ O
study, -X- _ O
we -X- _ O
designed -X- _ O
one -X- _ O
form -X- _ O
per -X- _ O
participant, -X- _ O
with -X- _ O
three -X- _ O
sections -X- _ O
evaluating -X- _ O
respectively -X- _ O
the -X- _ O
language -X- _ O
quality, -X- _ O
language -X- _ O
grounding -X- _ O
and -X- _ O
diversity -X- _ O
criteria. -X- _ O

C -X- _ O
Human -X- _ O
Evaluation -X- _ O
details -X- _ O

Additionally, -X- _ O
on-policy -X- _ O
versus -X- _ O
off-policy -X- _ O
scores -X- _ O
split -X- _ O
per -X- _ O
sampling -X- _ O
procedure -X- _ O
are -X- _ O
displayed -X- _ O
in -X- _ O
table -X- _ O
12: -X- _ O
unsurprisingly, -X- _ O
greedy -X- _ O
decoding -X- _ O
for -X- _ O
TrufLLoff -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
two -X- _ O
sampling-based -X- _ O
methods, -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
penalized -X- _ O
by -X- _ O
the -X- _ O
imperfect -X- _ O
generalization -X- _ O
of -X- _ O
the -X- _ O
optimized -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary. -X- _ O

Note -X- _ O
that -X- _ O
for -X- _ O
VQAv2, -X- _ B-DatasetName
the -X- _ O
poor -X- _ O
performances -X- _ O
of -X- _ O
TrufLLoff,KL -X- _ B-MethodName
on -X- _ O
the -X- _ O
external -X- _ O
LM -X- _ O
is -X- _ O
mainly -X- _ O
due -X- _ O
to -X- _ O
numerical -X- _ O
instability -X- _ O
challenges -X- _ O
when -X- _ O
using -X- _ O
GPT-2 -X- _ B-MethodName
as -X- _ O
the -X- _ O
target -X- _ O
policy -X- _ O
of -X- _ O
the -X- _ O
KL -X- _ O
regularization -X- _ O
term. -X- _ O

Yet, -X- _ O
keeping -X- _ O
truncation -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
remains -X- _ O
crucial -X- _ O
with -X- _ O
large -X- _ O
vocabulary. -X- _ O

In -X- _ O
such -X- _ O
a -X- _ O
setting, -X- _ O
it -X- _ O
hence -X- _ O
improves -X- _ O
the -X- _ O
global -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
off-policy -X- _ O
version -X- _ O
of -X- _ O
TrufLL, -X- _ B-MethodName
and -X- _ O
enables -X- _ O
a -X- _ O
much -X- _ O
better -X- _ O
generalization -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
of -X- _ O
the -X- _ O
global -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary. -X- _ O

Interestingly, -X- _ O
while -X- _ O
on -X- _ O
CLEVR, -X- _ B-DatasetName
TrufLLoff,KL -X- _ B-MethodName
trades -X- _ O
off -X- _ O
task -X- _ O
performance -X- _ O
for -X- _ O
language -X- _ O
quality -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
TrufLLoff, -X- _ B-MethodName
on -X- _ O
VQAv2, -X- _ B-DatasetName
it -X- _ O
mainly -X- _ O
provides -X- _ O
a -X- _ O
better -X- _ O
learning -X- _ O
signal -X- _ O
for -X- _ O
the -X- _ O
complete -X- _ O
(large) -X- _ O
vocabulary. -X- _ O

Indeed, -X- _ O
on -X- _ O
the -X- _ O
off-policy -X- _ O
setting -X- _ O
for -X- _ O
such -X- _ O
a -X- _ O
task, -X- _ O
the -X- _ O
exploding -X- _ O
values -X- _ O
for -X- _ O
e-ppl -X- _ B-MetricName
suggest -X- _ O
that -X- _ O
the -X- _ O
optimized -X- _ O
language -X- _ O
agent -X- _ O
samples -X- _ O
incoherent -X- _ O
words -X- _ O
taken -X- _ O
outside -X- _ O
the -X- _ O
truncated -X- _ O
action -X- _ O
space, -X- _ O
as -X- _ O
corroborated -X- _ O
by -X- _ O
the -X- _ O
low -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
sumVA -X- _ B-MetricName
ratio. -X- _ O

The -X- _ O
full -X- _ O
results -X- _ O
emphasize -X- _ O
the -X- _ O
challenges -X- _ O
of -X- _ O
the -X- _ O
approach -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
vocabulary -X- _ O
of -X- _ O
VQAv2. -X- _ B-DatasetName

Table -X- _ O
11 -X- _ O
displays -X- _ O
the -X- _ O
full -X- _ O
results -X- _ O
of -X- _ O
on-policy -X- _ O
versus -X- _ O
off-policy -X- _ O
scores -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
(Task-LM) -X- _ I-MethodName
and -X- _ O
TrufLL -X- _ B-MethodName
(Ext-LM) -X- _ I-MethodName
on -X- _ O
the -X- _ O
two -X- _ O
tasks. -X- _ O

Intuitively, -X- _ O
it -X- _ O
encourages -X- _ O
the -X- _ O
policy -X- _ O
to -X- _ O
stay -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model’s -X- _ O
distribution, -X- _ O
with -X- _ O
a -X- _ O
distribution -X- _ O
support -X- _ O
attributing -X- _ O
negligible -X- _ O
probabilities -X- _ O
to -X- _ O
words -X- _ O
outside -X- _ O
the -X- _ O
truncated -X- _ O
action -X- _ O
space. -X- _ O

Wu -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
TrufLLoff,KL. -X- _ B-MethodName

To -X- _ O
ease -X- _ O
off-policy -X- _ O
learning, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
add -X- _ O
a -X- _ O
KLregularization -X- _ O
term -X- _ O
in -X- _ O
the -X- _ O
RL -X- _ O
loss -X- _ O
(Jaques -X- _ O
et -X- _ O
al., -X- _ O
2017, -X- _ O
2019; -X- _ O

On-policy -X- _ B-MethodName
TrufLL -X- _ I-MethodName
versus -X- _ O
off-policy -X- _ B-MethodName
TrufLL. -X- _ I-MethodName

This -X- _ O
suggests -X- _ O
that -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
vocabulary -X- _ O
task, -X- _ O
the -X- _ O
language -X- _ O
distribution -X- _ O
learned -X- _ O
by -X- _ O
the -X- _ O
SL -X- _ O
pretrained -X- _ O
policy -X- _ O
is -X- _ O
significantly -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
one -X- _ O
learned -X- _ O
with -X- _ O
TrufLL. -X- _ B-MethodName

In -X- _ O
table -X- _ O
10, -X- _ O
while -X- _ O
on -X- _ O
CLEVR, -X- _ B-DatasetName
TrufLLpretrain -X- _ B-MethodName
marginally -X- _ O
improves -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
pretrain+RL -X- _ B-MethodName
fine-tune -X- _ I-MethodName
baseline, -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
pre-training -X- _ O
phase -X- _ O
leads -X- _ O
to -X- _ O
performance -X- _ O
degradation -X- _ O
on -X- _ O
VQAv2. -X- _ B-DatasetName

Therefore, -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
task-related -X- _ O
dataset, -X- _ O
we -X- _ O
evaluate -X- _ O
TrufLL -X- _ B-MethodName
from -X- _ O
a -X- _ O
pretrained -X- _ O
policy, -X- _ O
and -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
TrufLLpretrain. -X- _ B-MethodName

Although -X- _ O
TrufLL -X- _ B-MethodName
aims -X- _ O
at -X- _ O
providing -X- _ O
a -X- _ O
robust -X- _ O
method -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
(almost) -X- _ O
from -X- _ O
scratch, -X- _ O
we -X- _ O
investigate -X- _ O
whether -X- _ O
such -X- _ O
algorithm -X- _ O
can -X- _ O
be -X- _ O
complementary -X- _ O
to -X- _ O
RL -X- _ O
algorithms -X- _ O
with -X- _ O
a -X- _ O
pre-training -X- _ O
phase. -X- _ O

TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
pre-training -X- _ O
phase. -X- _ O

B.3 -X- _ O
Additional -X- _ O
discussion -X- _ O

This -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
KL -X- _ O
regularization -X- _ O
term, -X- _ O
while -X- _ O
encouraging -X- _ O
the -X- _ O
policy -X- _ O
distribution -X- _ O
to -X- _ O
resemble -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
distribution, -X- _ O
fails -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
task -X- _ O
pragmatics, -X- _ O
which -X- _ O
requires -X- _ O
generating -X- _ O
a -X- _ O
language -X- _ O
that -X- _ O
is -X- _ O
visually -X- _ O
grounded. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
the -X- _ O
scratch+KL -X- _ B-MethodName
baselines -X- _ O
stay -X- _ O
stuck -X- _ O
to -X- _ O
a -X- _ O
low -X- _ O
training -X- _ O
return. -X- _ O

The -X- _ O
training -X- _ O
curves -X- _ O
of -X- _ O
TrufLL -X- _ B-MethodName
present -X- _ O
a -X- _ O
steady -X- _ O
increase -X- _ O
in -X- _ O
the -X- _ O
return -X- _ O
until -X- _ O
reaching -X- _ O
convergence, -X- _ O
confirming -X- _ O
that -X- _ O
our -X- _ O
approach, -X- _ O
by -X- _ O
guiding -X- _ O
the -X- _ O
exploration -X- _ O
of -X- _ O
the -X- _ O
action -X- _ O
space, -X- _ O
provides -X- _ O
a -X- _ O
sufficient -X- _ O
learning -X- _ O
signal. -X- _ O

As -X- _ O
expected, -X- _ O
the -X- _ O
pretrain+RL -X- _ B-MethodName
fine-tune -X- _ I-MethodName
baseline -X- _ O
return -X- _ O
does -X- _ O
not -X- _ O
evolve -X- _ O
much, -X- _ O
confirming -X- _ O
that -X- _ O
the -X- _ O
policy -X- _ O
distribution -X- _ O
almost -X- _ O
does -X- _ O
not -X- _ O
shift -X- _ O
through -X- _ O
the -X- _ O
fine-tuning -X- _ O
phase. -X- _ O

Finally, -X- _ O
Figure -X- _ O
4 -X- _ O
displays -X- _ O
the -X- _ O
evolution -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
return -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
baselines. -X- _ O

The -X- _ O
former -X- _ O
displays -X- _ O
the -X- _ O
best -X- _ O
performance/language -X- _ O
scores -X- _ O
trade-off -X- _ O
for -X- _ O
the -X- _ O
schedule -X- _ O
"τ: -X- _ B-HyperparameterName
3 -X- _ B-HyperparameterValue
> -X- _ I-HyperparameterValue
1. -X- _ I-HyperparameterValue
& -X- _ O
Tu=5,000", -X- _ B-HyperparameterName
while -X- _ O
the -X- _ O
latter -X- _ O
has -X- _ O
the -X- _ O
best -X- _ O
metrics -X- _ O
trade-off -X- _ O
for -X- _ O
"τ: -X- _ B-HyperparameterName
1.5 -X- _ B-HyperparameterValue
> -X- _ I-HyperparameterValue
1. -X- _ I-HyperparameterValue
& -X- _ O
Tu=5,000". -X- _ B-HyperparameterName

(Ext-LM) -X- _ O
benefit -X- _ O
slightly -X- _ O
from -X- _ O
truncation -X- _ O
with -X- _ O
a -X- _ O
temperature -X- _ O
schedule -X- _ O
compared -X- _ O
to -X- _ O
a -X- _ O
vanilla -X- _ O
truncation. -X- _ O

In -X- _ O
Table -X- _ O
9, -X- _ O
both -X- _ O
TrufLL -X- _ B-MethodName
(Task-LM) -X- _ I-MethodName
and -X- _ O
TrufLL -X- _ B-MethodName

While -X- _ O
temperature -X- _ O
scaling -X- _ O
(Bahdanau -X- _ O
et -X- _ O
al., -X- _ O
2015) -X- _ O
is -X- _ O
usually -X- _ O
used -X- _ O
at -X- _ O
test -X- _ O
time -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
smoothness -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
distribution, -X- _ O
temperature -X- _ O
schedules -X- _ O
during -X- _ O
training -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
w<t) -X- _ O
distribution -X- _ O
is -X- _ O
several -X- _ O
settings -X- _ O
(Jang -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O

When -X- _ O
scaling -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
15k -X- _ O
words -X- _ O
of -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
task, -X- _ O
we -X- _ O
also -X- _ O
dynamically -X- _ O
decrease -X- _ O
the -X- _ O
truncation -X- _ O
size -X- _ O
through -X- _ O
training, -X- _ O
by -X- _ O
applying -X- _ O
a -X- _ O
decreasing -X- _ O
temperature -X- _ O
schedule -X- _ O
on -X- _ O
the -X- _ O
language -X- _ O
model. -X- _ O

Temperature -X- _ O
scheduling: -X- _ O
On -X- _ O
the -X- _ O
CLEVR -X- _ B-DatasetName
task, -X- _ O
we -X- _ O
observed -X- _ O
that -X- _ O
dynamic -X- _ O
truncations -X- _ O
outperform -X- _ O
static -X- _ O
ones -X- _ O
such -X- _ O
as -X- _ O
top(k): -X- _ O
indeed, -X- _ O
they -X- _ O
better -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
inherent -X- _ O
variability -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
structure -X- _ O
at -X- _ O
the -X- _ O
sentence-level. -X- _ O

Table -X- _ O
6: -X- _ O
CLEVR -X- _ B-DatasetName
task: -X- _ O
Ablation -X- _ O
on -X- _ O
the -X- _ O
truncation -X- _ O
functions -X- _ O
with -X- _ O
parameters -X- _ O
sweep. -X- _ O

This -X- _ O
illustrates -X- _ O
that -X- _ O
using -X- _ O
a -X- _ O
language -X- _ O
similarity -X- _ O
score -X- _ O
as -X- _ O
a -X- _ O
reward -X- _ O
signal -X- _ O
is -X- _ O
much -X- _ O
less -X- _ O
interesting -X- _ O
than -X- _ O
a -X- _ O
reward -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
task -X- _ O
completion -X- _ O
score. -X- _ O

While -X- _ O
on -X- _ O
such -X- _ O
a -X- _ O
task -X- _ O
TrufLL -X- _ B-MethodName
still -X- _ O
exhibits -X- _ O
promising -X- _ O
language -X- _ O
scores, -X- _ O
the -X- _ O
n-grams -X- _ O
metrics -X- _ O
remain -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
pretrained -X- _ O
baselines. -X- _ O

Finally, -X- _ O
Table -X- _ O
8 -X- _ O
reports -X- _ O
CLEVR -X- _ B-DatasetName
metrics -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
as -X- _ O
the -X- _ O
reward. -X- _ O

Such -X- _ O
an -X- _ O
ablation -X- _ O
presents -X- _ O
a -X- _ O
similar -X- _ O
pattern -X- _ O
than -X- _ O
VQAv2 -X- _ B-DatasetName
results -X- _ O
described -X- _ O
in -X- _ O
section -X- _ O
5.2. -X- _ O

Table -X- _ O
6 -X- _ O
displays -X- _ O
the -X- _ O
complete -X- _ O
ablation -X- _ O
on -X- _ O
the -X- _ O
truncation -X- _ O
functions -X- _ O
with -X- _ O
parameters -X- _ O
sweep. -X- _ O

B.1 -X- _ O
CLEVR -X- _ B-DatasetName

B -X- _ O
Additional -X- _ O
experiments -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
detail -X- _ O
the -X- _ O
reward -X- _ O
function -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
task. -X- _ O

A.5 -X- _ O
Reward -X- _ O
formula -X- _ O
for -X- _ O
VQAv2 -X- _ B-DatasetName

None,1,5,10,100 -X- _ B-HyperparameterValue
, -X- _ O
bs -X- _ B-HyperparameterName
} -X- _ O

0.01, -X- _ B-HyperparameterValue
0.02, -X- _ B-HyperparameterValue
0.05, -X- _ B-HyperparameterValue
0.1 -X- _ B-HyperparameterValue
, -X- _ O
ϵ -X- _ B-HyperparameterName
} -X- _ O
3,10− -X- _ O
, -X- _ O
gradclip -X- _ B-HyperparameterName
} -X- _ O

following -X- _ O
values -X- _ O
were -X- _ O
tested: -X- _ O
β -X- _ B-HyperparameterName
3,5 -X- _ B-HyperparameterValue

We -X- _ O
kept -X- _ O
the -X- _ O
network -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
giving -X- _ O
the -X- _ O
best -X- _ O
performances, -X- _ O
i.e. -X- _ O
policy -X- _ O
network -X- _ O
of -X- _ O
256 -X- _ B-HyperparameterValue
units -X- _ B-HyperparameterName
and -X- _ O
128 -X- _ B-HyperparameterValue
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension. -X- _ I-HyperparameterName

} -X- _ O
Additionally, -X- _ O
we -X- _ O
also -X- _ O
tested -X- _ O
for -X- _ O
VQAv2 -X- _ B-DatasetName
policy -X- _ O
networks -X- _ O
with -X- _ O
64, -X- _ B-HyperparameterValue
256 -X- _ B-HyperparameterValue
and -X- _ O
1024 -X- _ B-HyperparameterValue
units, -X- _ B-HyperparameterName
with -X- _ O
respectively -X- _ O
32, -X- _ B-HyperparameterValue
128 -X- _ B-HyperparameterValue
and -X- _ O
512 -X- _ B-HyperparameterValue
word -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimensions. -X- _ I-HyperparameterName

The -X- _ O
0.01, -X- _ B-HyperparameterValue
0.02, -X- _ B-HyperparameterValue
0.05, -X- _ B-HyperparameterValue
0.1, -X- _ B-HyperparameterValue
0.5, -X- _ B-HyperparameterValue
0.9 -X- _ B-HyperparameterValue
lr -X- _ B-HyperparameterName
, -X- _ O
} -X- _ O
10− -X- _ O
32,64,128 -X- _ B-HyperparameterValue
. -X- _ O

Such -X- _ O
hyper-parameters -X- _ O
were -X- _ O
selected, -X- _ O
after -X- _ O
conducting -X- _ O
an -X- _ O
extensive -X- _ O
hyper-parameter -X- _ O
search. -X- _ O

5) -X- _ B-HyperparameterValue
for -X- _ O
CLEVR -X- _ B-DatasetName
and -X- _ O
VQAv2. -X- _ B-DatasetName

Finally, -X- _ O
for -X- _ O
the -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
baselines, -X- _ O
we -X- _ O
perform -X- _ O
gradient -X- _ B-HyperparameterName
clipping -X- _ I-HyperparameterName
(gladclip) -X- _ B-HyperparameterName
of -X- _ O
1 -X- _ B-HyperparameterValue
(resp. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
(bs) -X- _ B-HyperparameterName
on -X- _ O
CLEVR -X- _ B-DatasetName
(resp. -X- _ O
VQAv2), -X- _ B-DatasetName
and -X- _ O
5 -X- _ O
of -X- _ O
128 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
models -X- _ O
except -X- _ O
the -X- _ O
ones -X- _ O
with -X- _ O
KL -X- _ O
regularization, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64. -X- _ B-HyperparameterValue

We -X- _ O
use -X- _ O
Adam -X- _ O
optimizer -X- _ O
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2014) -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
6) -X- _ O
for -X- _ O
RL -X- _ O
algorithms -X- _ O
with -X- _ O
a -X- _ O
pre-training -X- _ O
phase -X- _ O
(lr) -X- _ B-HyperparameterName
of -X- _ O
10− -X- _ B-HyperparameterValue
4 -X- _ I-HyperparameterValue
for -X- _ O
models -X- _ O
including -X- _ O
a -X- _ O
KL -X- _ O
regularization -X- _ O
term. -X- _ O

VQAv2). -X- _ B-DatasetName

We -X- _ O
optimize -X- _ O
the -X- _ O
full -X- _ O
loss -X- _ O
L=LP -X- _ O
P -X- _ O
O -X- _ O
+αLV -X- _ O
F -X- _ O
+βLE -X- _ O
with -X- _ O
α=0.5, -X- _ B-HyperparameterName
β -X- _ B-HyperparameterName
=0.01 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
PPO -X- _ O
clipping -X- _ O
ratio -X- _ O
ϵ=0.02 -X- _ B-HyperparameterName
(resp. -X- _ O
0.01) -X- _ B-HyperparameterValue
for -X- _ O
CLEVR -X- _ B-DatasetName
(resp. -X- _ O

3 -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
scratch -X- _ O
baseline, -X- _ O
10− -X- _ O

For -X- _ O
VQAv2, -X- _ B-DatasetName
the -X- _ O
image -X- _ O
representation -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
200 -X- _ B-HyperparameterValue
bounding -X- _ B-HyperparameterName
box -X- _ I-HyperparameterName
features -X- _ I-HyperparameterName
of -X- _ O
dimension -X- _ B-HyperparameterName
1048, -X- _ B-HyperparameterValue
extracted -X- _ O
from -X- _ O
a -X- _ O
faster -X- _ O
R-CNN -X- _ O
(Ren -X- _ O
et -X- _ O
al., -X- _ O
2015). -X- _ O

For -X- _ O
CLEVR, -X- _ B-DatasetName
the -X- _ O
image -X- _ O
representation -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
pretrained -X- _ O
ResNet50 -X- _ O
and -X- _ O
projected -X- _ O
into -X- _ O
a -X- _ O
tensor -X- _ O
of -X- _ O
size -X- _ B-HyperparameterName
(32,7,7) -X- _ B-HyperparameterValue
before -X- _ O
being -X- _ O
flattened. -X- _ O

the -X- _ O
answer -X- _ O
embedding -X- _ O
of -X- _ O
dimension -X- _ B-HyperparameterName
32 -X- _ B-HyperparameterValue
(resp. -X- _ O
128), -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
image -X- _ O
representation. -X- _ O

At -X- _ O
every -X- _ O
time -X- _ O
step, -X- _ O
the -X- _ O
LSTM -X- _ O
input -X- _ O
is -X- _ O
then -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
of -X- _ O
dimension -X- _ B-HyperparameterName
32 -X- _ B-HyperparameterValue
(resp. -X- _ O

256) -X- _ B-HyperparameterValue
units -X- _ B-HyperparameterName
for -X- _ O
the -X- _ O
policy -X- _ O
network. -X- _ O

VQAv2), -X- _ B-DatasetName
we -X- _ O
used -X- _ O
a -X- _ O
single-layer -X- _ O
LSTM -X- _ O
with -X- _ O
64 -X- _ B-HyperparameterValue
(resp. -X- _ O

For -X- _ O
CLEVR -X- _ B-DatasetName
(resp. -X- _ O

A.4 -X- _ O
Language -X- _ O
Agent -X- _ O
Networks -X- _ O
and -X- _ O
Training -X- _ O

10) -X- _ B-HyperparameterValue
words. -X- _ B-HyperparameterName

Finally, -X- _ O
questions -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
20 -X- _ B-HyperparameterValue
(resp. -X- _ O

Besides, -X- _ O
we -X- _ O
uniformly -X- _ O
sample -X- _ O
the -X- _ O
answer -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
reference -X- _ O
answers -X- _ O
for -X- _ O
each -X- _ O
image -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
answers. -X- _ O

20k) -X- _ O
images -X- _ O
of -X- _ O
the -X- _ O
validation -X- _ O
set. -X- _ O

all -X- _ O
the -X- _ O
images) -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
dataset, -X- _ O
and -X- _ O
is -X- _ O
then -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
5k -X- _ O
(resp. -X- _ O

100k) -X- _ B-HyperparameterValue
episodes -X- _ B-HyperparameterName
over -X- _ O
the -X- _ O
first -X- _ O
20k -X- _ O
images -X- _ O
(resp. -X- _ O

VQAv2), -X- _ B-DatasetName
the -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
50k -X- _ B-HyperparameterValue
(resp. -X- _ O

For -X- _ O
CLEVR -X- _ B-DatasetName
(resp. -X- _ O

A.3 -X- _ O
Dataset -X- _ O
split -X- _ O

A.2 -X- _ O
Answer -X- _ O
filtering -X- _ O
For -X- _ O
each -X- _ O
dataset, -X- _ O
we -X- _ O
remove -X- _ O
yes -X- _ O
and -X- _ O
no -X- _ O
question-answer -X- _ O
pairs -X- _ O
which -X- _ O
frequency -X- _ O
largely -X- _ O
exceeds -X- _ O
other -X- _ O
answers, -X- _ O
to -X- _ O
avoid -X- _ O
any -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
generation -X- _ O
process, -X- _ O
as -X- _ O
usually -X- _ O
done -X- _ O
in -X- _ O
the -X- _ O
VQG -X- _ B-TaskName
litterature -X- _ O
(Mostafazadeh -X- _ O
et -X- _ O
al., -X- _ O
2016). -X- _ O

For -X- _ O
the -X- _ O
CIDEr -X- _ B-MetricName
score, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
nlg-eval -X- _ O
implementation6. -X- _ O

A.1 -X- _ O
Evaluation -X- _ O
Metrics -X- _ O
For -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
and -X- _ O
METEOR -X- _ B-MetricName
scores, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
NLTK5 -X- _ O
implementations -X- _ O
with -X- _ O
the -X- _ O
smoothing -X- _ O
function -X- _ O
number -X- _ O
2 -X- _ O
for -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
score. -X- _ O

A -X- _ O
Dataset -X- _ O
and -X- _ O
training -X- _ O
details -X- _ O

References -X- _ O

Acknowledgements -X- _ O

Although -X- _ O
it -X- _ O
comes -X- _ O
with -X- _ O
its -X- _ O
limitations, -X- _ O
the -X- _ O
truncated -X- _ O
RL -X- _ O
algorithm -X- _ O
provided -X- _ O
by -X- _ O
TrufLL -X- _ B-MethodName
gets -X- _ O
free -X- _ O
from -X- _ O
labelled -X- _ O
data -X- _ O
in -X- _ O
task-oriented -X- _ O
language -X- _ O
models, -X- _ O
presents -X- _ O
interesting -X- _ O
language -X- _ O
generation -X- _ O
properties, -X- _ O
and -X- _ O
provides -X- _ O
a -X- _ O
generic -X- _ O
and -X- _ O
transferable -X- _ O
method -X- _ O
to -X- _ O
learn -X- _ O
any -X- _ O
NLG -X- _ B-TaskName
problem. -X- _ O

To -X- _ O
our -X- _ O
knowledge, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
RL-based -X- _ O
algorithm -X- _ O
dedicated -X- _ O
to -X- _ O
learning -X- _ O
a -X- _ O
word-based -X- _ B-TaskName
text-generation -X- _ I-TaskName
task, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
pre-training -X- _ O
phase -X- _ O
while -X- _ O
scaling -X- _ O
to -X- _ O
large -X- _ O
vocabularies. -X- _ O

We -X- _ O
proposed -X- _ O
TrufLL, -X- _ B-MethodName
an -X- _ O
original -X- _ O
approach -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
(NLG) -X- _ B-TaskName
task -X- _ O
using -X- _ O
RL, -X- _ O
without -X- _ O
the -X- _ O
usual -X- _ O
pre-training -X- _ O
phase -X- _ O
requiring -X- _ O
supervised -X- _ O
datasets. -X- _ O

Yet, -X- _ O
they -X- _ O
still -X- _ O
face -X- _ O
optimization -X- _ O
and -X- _ O
computational -X- _ O
challenges -X- _ O
(Parisotto -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Garg -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
finetune -X- _ O
pretrained -X- _ O
GPT-2 -X- _ O
models -X- _ O
with -X- _ O
RL -X- _ O
for -X- _ O
language -X- _ O
generation -X- _ O
tasks -X- _ O
without -X- _ O
task-related -X- _ O
data, -X- _ O
only -X- _ O
using -X- _ O
reward -X- _ O
signals. -X- _ O

Learning -X- _ O
Language -X- _ O
Models -X- _ O
from -X- _ O
scratch. -X- _ O

Besides, -X- _ O
CALM -X- _ O
is -X- _ O
only -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
697 -X- _ O
tokens, -X- _ O
and -X- _ O
on -X- _ O
4-words -X- _ O
action -X- _ O
sequences. -X- _ O

Yet, -X- _ O
its -X- _ O
truncation -X- _ O
language -X- _ O
model -X- _ O
remains -X- _ O
fine-tuned -X- _ O
on -X- _ O
the -X- _ O
RL -X- _ O
dataset. -X- _ O

Similarly -X- _ O
to -X- _ O
TrufLL, -X- _ B-MethodName
CALM -X- _ O
(Yao -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
combines -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
prune -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
with -X- _ O
a -X- _ O
DeepQ -X- _ O
network, -X- _ O
aka -X- _ O
DRNN -X- _ O
(He -X- _ O
et -X- _ O
al., -X- _ O
2016). -X- _ O

Closer -X- _ O
to -X- _ O
our -X- _ O
work, -X- _ O
a -X- _ O
few -X- _ O
algorithms -X- _ O
(Ammanabrolu -X- _ O
and -X- _ O
Riedl, -X- _ O
2018) -X- _ O
use -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
language -X- _ O
to -X- _ O
prune -X- _ O
the -X- _ O
action -X- _ O
space -X- _ O
of -X- _ O
text-based -X- _ O
games, -X- _ O
but -X- _ O
within -X- _ O
value-based -X- _ O
algorithms, -X- _ O
which -X- _ O
are -X- _ O
less -X- _ O
scalable -X- _ O
to -X- _ O
large -X- _ O
vocabularies. -X- _ O

(2020) -X- _ O
proposes -X- _ O
Q-learning -X- _ O
algorithms -X- _ O
with -X- _ O
an -X- _ O
elimination -X- _ O
signal -X- _ O
to -X- _ O
eliminate -X- _ O
forbidden -X- _ O
actions. -X- _ O

RL -X- _ O
methods -X- _ O
for -X- _ O
Language -X- _ O
Action -X- _ O
Spaces. -X- _ O

Several -X- _ O
RL -X- _ O
algorithms -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
to -X- _ O
tackle -X- _ O
large -X- _ O
discrete -X- _ O
action -X- _ O
spaces. -X- _ O

Hence, -X- _ O
Dulac-Arnold -X- _ O
et -X- _ O
al. -X- _ O
(2015); -X- _ O
Tennenholtz -X- _ O
and -X- _ O
Mannor -X- _ O
(2019); -X- _ O
Chandak -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
embed -X- _ O
the -X- _ O
actions -X- _ O
into -X- _ O
a -X- _ O
continuous -X- _ O
action -X- _ O
space, -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
classic -X- _ O
RL -X- _ O
algorithms -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
policy -X- _ O
over -X- _ O
this -X- _ O
continuous -X- _ O
space. -X- _ O

Bahdanau -X- _ O
et -X- _ O
al. -X- _ O
(2016); -X- _ O
Rennie -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
use -X- _ O
RL -X- _ O
to -X- _ O
train -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
an -X- _ O
alternative -X- _ O
to -X- _ O
SL -X- _ O
to -X- _ O
prevent -X- _ O
typical -X- _ O
text -X- _ O
degeneration -X- _ O
issues, -X- _ O
but -X- _ O
within -X- _ O
training -X- _ O
algorithms -X- _ O
relying -X- _ O
on -X- _ O
ground-truth -X- _ O
examples -X- _ O
from -X- _ O
labelled -X- _ O
datasets. -X- _ O

Yet, -X- _ O
the -X- _ O
former -X- _ O
uses -X- _ O
slot -X- _ O
filling -X- _ O
with -X- _ O
template -X- _ O
questions, -X- _ O
while -X- _ O
the -X- _ O
later -X- _ O
computes -X- _ O
a -X- _ O
mixed -X- _ O
objective -X- _ O
with -X- _ O
a -X- _ O
MLE -X- _ O
loss -X- _ O
using -X- _ O
ground-truth -X- _ O
sentences. -X- _ O

fine-tuning. -X- _ O

Following -X- _ O
(Singh -X- _ O
et -X- _ O
al., -X- _ O
2002; -X- _ O
Lemon -X- _ O
and -X- _ O
Pietquin, -X- _ O
2007), -X- _ O
recent -X- _ O
RL-based -X- _ O
taskoriented -X- _ O
dialogues -X- _ O
(De -X- _ O
Vries -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Das -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Lewis -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Narasimhan -X- _ O
et -X- _ O
al., -X- _ O
2015) -X- _ O
have -X- _ O
been -X- _ O
developed, -X- _ O
where -X- _ O
the -X- _ O
policy -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
generally -X- _ O
pretrained -X- _ O
with -X- _ O
SL -X- _ O
followed -X- _ O
RL -X- _ O

RL -X- _ O
and -X- _ O
NLP -X- _ O
Tasks. -X- _ O

6 -X- _ O
Related -X- _ O
work -X- _ O

The -X- _ O
context -X- _ O
can -X- _ O
be -X- _ O
any -X- _ O
kind -X- _ O
of -X- _ O
data -X- _ O
structure -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
(natural -X- _ O
language, -X- _ O
database, -X- _ O
video, -X- _ O
etc): -X- _ O
linguistic -X- _ O
input, -X- _ O
TrufLL -X- _ B-MethodName
can -X- _ O
be -X- _ O
applied -X- _ O
for -X- _ O
instance -X- _ O
to -X- _ O
text -X- _ O
summarization, -X- _ O
paraphrase -X- _ O
generation -X- _ O
(with -X- _ O
reward -X- _ O
functions -X- _ O
based -X- _ O
on -X- _ O
similarity -X- _ O
scores -X- _ O
between -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
language) -X- _ O
or -X- _ O
text-based -X- _ O
games -X- _ O
(Ammanabrolu -X- _ O
and -X- _ O
Riedl, -X- _ O
2018). -X- _ O

Reward -X- _ O
functions -X- _ O
for -X- _ O
such -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
based -X- _ O
on -X- _ O
similarity -X- _ O
scores -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
language -X- _ O
and -X- _ O
the -X- _ O
associated -X- _ O
image -X- _ O
or -X- _ O
image -X- _ O
region, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
using -X- _ O
pretrained -X- _ O
language -X- _ O
representations -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
or -X- _ O
multi-modal -X- _ O
pretrained -X- _ O
systems -X- _ O
such -X- _ O
as -X- _ O
ViLBERT -X- _ O
(Lu -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Other -X- _ O
interesting -X- _ O
tasks -X- _ O
for -X- _ O
TrufLL -X- _ B-MethodName
include -X- _ O
the -X- _ O
ones -X- _ O
typically -X- _ O
found -X- _ O
in -X- _ O
Vision -X- _ O
and -X- _ O
Language -X- _ O
Representation -X- _ O
Learning -X- _ O
(Lu -X- _ O
et -X- _ O
al., -X- _ O
2020a), -X- _ O
such -X- _ O
as -X- _ O
Image -X- _ O
Captioning, -X- _ O
Grounding -X- _ O
Referring -X- _ O
Expressions -X- _ O
(generation -X- _ O
of -X- _ O
a -X- _ O
referring -X- _ O
expression -X- _ O
over -X- _ O
a -X- _ O
specific -X- _ O
bounding -X- _ O
box -X- _ O
of -X- _ O
an -X- _ O
image), -X- _ O
Captionbased -X- _ O
Image -X- _ O
Retrieval -X- _ O
(generation -X- _ O
of -X- _ O
a -X- _ O
caption -X- _ O
that -X- _ O
discriminates -X- _ O
an -X- _ O
image -X- _ O
between -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
images). -X- _ O

Additionally, -X- _ O
the -X- _ O
RL -X- _ O
framework -X- _ O
allows -X- _ O
to -X- _ O
optimize -X- _ O
non-differentiable -X- _ O
objectives, -X- _ O
making -X- _ O
TrufLL -X- _ B-MethodName
a -X- _ O
natural -X- _ O
choice -X- _ O
to -X- _ O
learn -X- _ O
end-to-end -X- _ O
task-oriented -X- _ O
dialogs, -X- _ O
such -X- _ O
as -X- _ O
(De -X- _ O
Vries -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Das -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

Hence, -X- _ O
the -X- _ O
method -X- _ O
is -X- _ O
transferable -X- _ O
to -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
NLG -X- _ B-TaskName
tasks, -X- _ O
without -X- _ O
requiring -X- _ O
upfront -X- _ O
large-scale -X- _ O
labelled -X- _ O
datasets. -X- _ O

TrufLL -X- _ B-MethodName
learns -X- _ O
conditional -X- _ O
language -X- _ O
models -X- _ O
able -X- _ O
to -X- _ O
solve -X- _ O
specific -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Generation -X- _ I-TaskName
tasks -X- _ O
given -X- _ O
a -X- _ O
context -X- _ O
c. -X- _ O
For -X- _ O
solving -X- _ O
such -X- _ O
tasks, -X- _ O
it -X- _ O
only -X- _ O
requires -X- _ O
the -X- _ O
context, -X- _ O
a -X- _ O
reward -X- _ O
function -X- _ O
that -X- _ O
scores -X- _ O
the -X- _ O
language -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
RL -X- _ O
agent -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
task, -X- _ O
and -X- _ O
eventually -X- _ O
a -X- _ O
few -X- _ O
natural -X- _ O
language -X- _ O
demonstrations -X- _ O
fed -X- _ O
as -X- _ O
input -X- _ O
prompt -X- _ O
to -X- _ O
the -X- _ O
generic -X- _ O
language -X- _ O
model -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
truncation -X- _ O
algorithm. -X- _ O

Generalization -X- _ O
of -X- _ O
the -X- _ O
approach. -X- _ O

Finally, -X- _ O
we -X- _ O
explore -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
pre-training -X- _ O
phase -X- _ O
in -X- _ O
Table -X- _ O
10. -X- _ O

In -X- _ O
VQA, -X- _ B-TaskName
we -X- _ O
apply -X- _ O
temperature -X- _ O
scheduling -X- _ O
on -X- _ O
the -X- _ O
LM -X- _ O
to -X- _ O
perform -X- _ O
fine-grained -X- _ O
truncations -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
of -X- _ O
B.2. -X- _ O

In -X- _ O
Table -X- _ O
8, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
rewarding -X- _ O
an -X- _ O
agent -X- _ O
with -X- _ O
a -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
is -X- _ O
sub-optimal -X- _ O
in -X- _ O
both -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
scores -X- _ O
on -X- _ O
CLEVR. -X- _ B-DatasetName

We -X- _ O
sweep -X- _ O
over -X- _ O
truncation -X- _ O
hyper-parameters -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
of -X- _ O
Appendix -X- _ O
B. -X- _ O

Additional -X- _ O
experiments. -X- _ O

We -X- _ O
leave -X- _ O
such -X- _ O
possibilities -X- _ O
to -X- _ O
future -X- _ O
works. -X- _ O

It -X- _ O
could -X- _ O
be -X- _ O
improved -X- _ O
with -X- _ O
regularisation -X- _ O
techniques -X- _ O
and -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
TruFLL -X- _ B-MethodName
within -X- _ O
state-of-the-art -X- _ O
off-policy -X- _ O
RL -X- _ O
algorithms. -X- _ O

However, -X- _ O
the -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
manage -X- _ O
to -X- _ O
sufficiently -X- _ O
scale -X- _ O
to -X- _ O
VQAv2. -X- _ B-DatasetName

As -X- _ O
its -X- _ O
sumVA -X- _ B-MetricName
ratios -X- _ O
are -X- _ O
very -X- _ O
close -X- _ O
to -X- _ O
1, -X- _ O
the -X- _ O
agent -X- _ O
has -X- _ O
learned -X- _ O
to -X- _ O
generalize -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary. -X- _ O

On -X- _ O
CLEVR, -X- _ B-DatasetName
the -X- _ O
TrufLLoff -X- _ B-MethodName
has -X- _ O
lower -X- _ O
- -X- _ O
yet -X- _ O
close -X- _ O
- -X- _ O
performance -X- _ O
on -X- _ O
language -X- _ O
and -X- _ O
task -X- _ O
scores -X- _ O
than -X- _ O
TrufLL. -X- _ B-MethodName

Method -X- _ O

Thus, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
unbiased -X- _ O
the -X- _ O
PG -X- _ O
by -X- _ O
using -X- _ O
an -X- _ O
importance -X- _ O
sampling -X- _ O
term -X- _ O
between -X- _ O
the -X- _ O
exploratory -X- _ O
policy -X- _ O
π−θ -X- _ O
and -X- _ O
the -X- _ O
behavior -X- _ O
policy -X- _ O
πθ -X- _ O
(Degris -X- _ O
et -X- _ O
al., -X- _ O

In -X- _ O
such -X- _ O
a -X- _ O
setting, -X- _ O
we -X- _ O
adopt -X- _ O
an -X- _ O
off-policy -X- _ O
training -X- _ O
scheme, -X- _ O
where -X- _ O
the -X- _ O
trajectories -X- _ O
used -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
behavior -X- _ O
πθ -X- _ O
at -X- _ O
training -X- _ O
time -X- _ O
are -X- _ O
sampled -X- _ O
under -X- _ O
a -X- _ O
different -X- _ O
policy, -X- _ O
the -X- _ O
truncated -X- _ O
policy -X- _ O
π−θ -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
investigate -X- _ O
if -X- _ O
we -X- _ O
can -X- _ O
directly -X- _ O
learn -X- _ O
a -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
vocabulary, -X- _ O
and -X- _ O
thus -X- _ O
removing -X- _ O
the -X- _ O
truncation -X- _ O
at -X- _ O
test -X- _ O
time. -X- _ O

Hence, -X- _ O
the -X- _ O
algorithm -X- _ O
requires -X- _ O
the -X- _ O
truncation, -X- _ O
and -X- _ O
a -X- _ O
fortiori -X- _ O
the -X- _ O
language -X- _ O
model, -X- _ O
at -X- _ O
test -X- _ O
time. -X- _ O

So -X- _ O
far, -X- _ O
TrufLL -X- _ B-MethodName
directly -X- _ O
learns -X- _ O
the -X- _ O
truncated -X- _ O
policy -X- _ O
over -X- _ O
the -X- _ O
truncated -X- _ O
vocabulary -X- _ O
in -X- _ O
an -X- _ O
on-policy -X- _ O
scheme. -X- _ O

Removing -X- _ O
the -X- _ O
truncation -X- _ O
at -X- _ O
evaluation -X- _ O
with -X- _ O
offpolicy -X- _ O
RL. -X- _ O

5.3 -X- _ O
Discussion -X- _ O

As -X- _ O
PG -X- _ O
solely -X- _ O
optimizes -X- _ O
the -X- _ O
task -X- _ O
success -X- _ O
ratio, -X- _ O
this -X- _ O
may -X- _ O
reduce -X- _ O
overall -X- _ O
language -X- _ O
quality, -X- _ O
the -X- _ O
re-ranking -X- _ O
thus -X- _ O
retrieves -X- _ O
the -X- _ O
best -X- _ O
syntactically -X- _ O
sentences -X- _ O
a -X- _ O
posteriori. -X- _ O

While -X- _ O
greedy -X- _ B-MethodName
decoding -X- _ O
produces -X- _ O
the -X- _ O
best -X- _ O
outcome -X- _ O
for -X- _ O
pretrained -X- _ O
models, -X- _ O
lm-ranking -X- _ B-MethodName
provides -X- _ O
an -X- _ O
excellent -X- _ O
trade-off -X- _ O
between -X- _ O
task -X- _ O
performance -X- _ O
and -X- _ O
language -X- _ O
quality -X- _ O
with -X- _ O
RL-based -X- _ O
methods. -X- _ O

In -X- _ O
Table -X- _ O
4, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
Decoding -X- _ O
procedure: -X- _ O
text -X- _ O
sampling -X- _ O
procedures -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.5. -X- _ O

It -X- _ O
confirms -X- _ O
that -X- _ O
TrufLL -X- _ B-MethodName
(Ext-LM) -X- _ I-MethodName
could -X- _ O
be -X- _ O
an -X- _ O
alternative -X- _ O
approach -X- _ O
as -X- _ O
it -X- _ O
has -X- _ O
an -X- _ O
excellent -X- _ O
trade-off -X- _ O
between -X- _ O
language -X- _ O
quality, -X- _ O
diversity, -X- _ O
and -X- _ O
grounding. -X- _ O

Although -X- _ O
its -X- _ O
questions -X- _ O
are -X- _ O
less -X- _ O
grounded, -X- _ O
they -X- _ O
are -X- _ O
diverse, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
they -X- _ O
follow -X- _ O
a -X- _ O
different -X- _ O
distribution -X- _ O
from -X- _ O
the -X- _ O
initial -X- _ O
VQA -X- _ B-DatasetName
dataset. -X- _ O

Finally, -X- _ O
unlike -X- _ O
TrufLL -X- _ B-MethodName
(Task-LM) -X- _ I-MethodName
which -X- _ O
suffers -X- _ O
from -X- _ O
syntactic -X- _ O
errors, -X- _ O
TrufLL -X- _ B-MethodName
(Ext-LM) -X- _ I-MethodName
produces -X- _ O
language -X- _ O
that -X- _ O
qualitatively -X- _ O
competes -X- _ O
with -X- _ O
pretrain -X- _ O
models -X- _ O
(53%), -X- _ B-MetricValue
with -X- _ O
a -X- _ O
similar -X- _ O
ratio -X- _ O
of -X- _ O
syntactic -X- _ O
uncorrect -X- _ O
samples. -X- _ O

Yet, -X- _ O
they -X- _ O
exhibit -X- _ O
significantly -X- _ O
less -X- _ O
diversity -X- _ O
with -X- _ O
the -X- _ O
reference -X- _ O
language; -X- _ O
this -X- _ O
suggests -X- _ O
in -X- _ O
particular -X- _ O
that -X- _ O
pretrain+RL -X- _ B-MethodName
fails -X- _ O
to -X- _ O
go -X- _ O
beyond -X- _ O
the -X- _ O
initial -X- _ O
task-data -X- _ O
distribution. -X- _ O

supervised -X- _ O
baselines -X- _ O
produce -X- _ O
the -X- _ O
best -X- _ O
language, -X- _ O
while -X- _ O
being -X- _ O
accurately -X- _ O
grounded. -X- _ O

Yet, -X- _ O
it -X- _ O
fails -X- _ O
to -X- _ O
generate -X- _ O
correct -X- _ O
and -X- _ O
grounded -X- _ O
language; -X- _ O
it -X- _ O
is -X- _ O
thus -X- _ O
not -X- _ O
a -X- _ O
viable -X- _ O
approach -X- _ O
despite -X- _ O
its -X- _ O
diverse -X- _ O
In -X- _ O
line -X- _ O
with -X- _ O
the -X- _ O
automatic -X- _ O
metrics, -X- _ O
the -X- _ O
output. -X- _ O

Among -X- _ O
the -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
baselines, -X- _ O
we -X- _ O
selected -X- _ O
scratch+KL-task -X- _ B-MethodName
as -X- _ O
the -X- _ O
only -X- _ O
model -X- _ O
producing -X- _ O
sometimes -X- _ O
meaningful -X- _ O
questions. -X- _ O

Human -X- _ O
Evaluation: -X- _ O
Figure -X- _ O
3 -X- _ O
details -X- _ O
the -X- _ O
Human -X- _ O
Evaluation -X- _ O
results. -X- _ O

questions -X- _ O
which -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
VQA -X- _ B-TaskName
distribution, -X- _ O
yet -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
context. -X- _ O

Pretrained -X- _ O
baselines -X- _ O
tend -X- _ O
to -X- _ O
output -X- _ O
a -X- _ O
question -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
reference -X- _ O
question -X- _ O
whereas -X- _ O
TrufLL -X- _ B-MethodName
outputs -X- _ O
original -X- _ O

TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
successfully -X- _ O
generate -X- _ O
a -X- _ O
question -X- _ O
giving -X- _ O
the -X- _ O
expected -X- _ O
answer -X- _ O
("Black"), -X- _ O
while -X- _ O
the -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
baselines -X- _ O
fail, -X- _ O
and -X- _ O
even -X- _ O
showcase -X- _ O
degenerated -X- _ O
language. -X- _ O

the -X- _ O
poor -X- _ O
diversity -X- _ O
behavior -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
observed -X- _ O
on -X- _ O
CLEVR -X- _ B-DatasetName
is -X- _ O
likely -X- _ O
attributable -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
vocabulary -X- _ O
and -X- _ O
synthetic -X- _ O
language -X- _ O
distribution. -X- _ O

Interestingly, -X- _ O
TrufLL -X- _ B-MethodName
displays -X- _ O
a -X- _ O
self-BLEU -X- _ B-MetricName
score -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
pretrained -X- _ O
baselines. -X- _ O

The -X- _ O
similarity -X- _ O
between -X- _ O
TrufLL -X- _ B-MethodName
(Task-LM) -X- _ I-MethodName
and -X- _ O
TrufLL -X- _ B-MethodName
(Ext-LM) -X- _ I-MethodName
results -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
truncation -X- _ O
approach -X- _ O
is -X- _ O
viable -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
generic -X- _ O
LM -X- _ O
whose -X- _ O
original -X- _ O
vocabulary -X- _ O
distribution -X- _ O
differs -X- _ O
from -X- _ O
the -X- _ O
task. -X- _ O

Although -X- _ O
TrufLL -X- _ B-MethodName
does -X- _ O
not -X- _ O
outperform -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
anymore, -X- _ O
it -X- _ O
still -X- _ O
leads -X- _ O
to -X- _ O
similar -X- _ O
performances, -X- _ O
and -X- _ O
satisfactory -X- _ O
language -X- _ O
scores. -X- _ O

First, -X- _ O
the -X- _ O
scratch -X- _ O
baselines -X- _ O
keep -X- _ O
failing -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
valuable -X- _ O
policy, -X- _ O
with -X- _ O
performance -X- _ O
scores -X- _ O
and -X- _ O
n-grams -X- _ O
metrics -X- _ O
close -X- _ O
to -X- _ O
zero. -X- _ O

Quantitative -X- _ O
performance: -X- _ O
Table -X- _ O
3 -X- _ O
reports -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
results, -X- _ O
for -X- _ O
which -X- _ O
TrufLL -X- _ B-MethodName
and -X- _ O
the -X- _ O
baselines -X- _ O
present -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
than -X- _ O
on -X- _ O
CLEVR. -X- _ B-DatasetName

We -X- _ O
scale -X- _ O
our -X- _ O
approach -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
with -X- _ O
large -X- _ O
vocabulary -X- _ O
(15k -X- _ O
tokens) -X- _ O
through -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
dataset. -X- _ O

In -X- _ O
CLEVR, -X- _ B-DatasetName
we -X- _ O
observe -X- _ O
that -X- _ O
TrufLL -X- _ B-MethodName
seems -X- _ O
a -X- _ O
promising -X- _ O
approach -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
language -X- _ O
policy -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
training -X- _ O
phase, -X- _ O
by -X- _ O
solely -X- _ O
interacting -X- _ O
with -X- _ O
another -X- _ O
language -X- _ O
system. -X- _ O

As -X- _ O
for -X- _ O
the -X- _ O
scratch+KL -X- _ B-MethodName
samples, -X- _ O
they -X- _ O
are -X- _ O
either -X- _ O
not -X- _ O
grounded, -X- _ O
or -X- _ O
showcase -X- _ O
degenerated -X- _ O
language. -X- _ O

Despite -X- _ O
a -X- _ O
peaky -X- _ O
distribution, -X- _ O
TrufLL -X- _ B-MethodName
has -X- _ O
moderate -X- _ O
repetitions -X- _ O
across -X- _ O
images, -X- _ O
and -X- _ O
is -X- _ O
mostly -X- _ O
overconfident. -X- _ O

It -X- _ O
is -X- _ O
remarkable -X- _ O
that -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
a -X- _ O
generic -X- _ O
LM -X- _ O
still -X- _ O
manages -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
necessary -X- _ O
subtleties -X- _ O
of -X- _ O
VQG, -X- _ B-TaskName
without -X- _ O
any -X- _ O
prior -X- _ O
task -X- _ O
knowledge. -X- _ O

Interestingly, -X- _ O
they -X- _ O
are -X- _ O
often -X- _ O
grounded -X- _ O
with -X- _ O
different -X- _ O
objects -X- _ O
of -X- _ O
the -X- _ O
image. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
TrufLL -X- _ B-MethodName
generate -X- _ O
adequate -X- _ O
questions, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
expected -X- _ O
answer. -X- _ O

They -X- _ O
inaccurately -X- _ O
capture -X- _ O
the -X- _ O
pragmatics -X- _ O
of -X- _ O
the -X- _ O
task. -X- _ O

Qualitative -X- _ O
performance: -X- _ O
We -X- _ O
display -X- _ O
qualitative -X- _ O
samples -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
and -X- _ O
Appendix -X- _ O
D. -X- _ O
On -X- _ O
the -X- _ O
one -X- _ O
hand, -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
generate -X- _ O
either -X- _ O
a -X- _ O
question -X- _ O
inconsistent -X- _ O
with -X- _ O
the -X- _ O
visual -X- _ O
context, -X- _ O
or -X- _ O
which -X- _ O
fails -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
expected -X- _ O
answer. -X- _ O

Less -X- _ O
positively, -X- _ O
TrufLL -X- _ B-MethodName
diversity -X- _ O
metrics -X- _ O
suggest -X- _ O
potential -X- _ O
mode -X- _ O
collapse, -X- _ O
with -X- _ O
a -X- _ O
high -X- _ O
peakiness -X- _ B-MetricName
and -X- _ O
self-BLEU -X- _ B-MetricName
score. -X- _ O

Therefore, -X- _ O
TrufLL -X- _ B-MethodName
seems -X- _ O
to -X- _ O
correctly -X- _ O
capture -X- _ O
the -X- _ O
language -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
initial -X- _ O
LM. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
the -X- _ O
external -X- _ O
LM -X- _ O
reports -X- _ O
poor -X- _ O
dataset-based -X- _ O
language -X- _ O
scores, -X- _ O
while -X- _ O
maintaining -X- _ O
a -X- _ O
low -X- _ O
external -X- _ B-MetricName
perplexity. -X- _ I-MetricName

Noticeably, -X- _ O
TrufLL -X- _ B-MethodName
with -X- _ O
the -X- _ O
task-specific -X- _ O
LM -X- _ O
follows -X- _ O
the -X- _ O
same -X- _ O
pattern. -X- _ O

Yet, -X- _ O
they -X- _ O
also -X- _ O
remain -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
distribution -X- _ O
with -X- _ O
a -X- _ O
medium -X- _ O
external -X- _ B-MetricValue
perplexity. -X- _ I-MetricValue

Pretrained -X- _ O
baselines -X- _ O
have -X- _ O
high -X- _ O
language -X- _ O
scores -X- _ O
when -X- _ O
assessed -X- _ O
with -X- _ O
datasetbased -X- _ O
metrics, -X- _ O
e.g -X- _ O
BLEU -X- _ B-MetricName
or -X- _ B-MetricName
task-perplexity. -X- _ I-MetricName

In -X- _ O
this -X- _ O
synthetic -X- _ O
VQG -X- _ B-TaskName
setting, -X- _ O
TrufLL -X- _ B-MethodName
seems -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
viable -X- _ O
and -X- _ O
promising -X- _ O
procedure -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
training -X- _ O
phase. -X- _ O

Yet, -X- _ O
as -X- _ O
soon -X- _ O
as -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
dynamic -X- _ O
truncation, -X- _ O
TrufLL -X- _ B-MethodName
matches -X- _ O
the -X- _ O
pretrained -X- _ O
baselines -X- _ O
performance -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
external -X- _ O
LM, -X- _ O
and -X- _ O
even -X- _ O
outperforms -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
task-specific -X- _ O
LM. -X- _ O

Besides, -X- _ O
adding -X- _ O
a -X- _ O
KL -X- _ O
regularisation -X- _ O
term -X- _ O
does -X- _ O
kick-start -X- _ O
the -X- _ O
learning -X- _ O
process. -X- _ O

In -X- _ O
Table -X- _ O
1, -X- _ O
vanilla -X- _ O
Quantitative -X- _ O
performance: -X- _ O
RL -X- _ O
from -X- _ O
scratch -X- _ O
fails -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
decent -X- _ O
performance -X- _ O
even -X- _ O
with -X- _ O
synthetic -X- _ O
language. -X- _ O

We -X- _ O
here -X- _ O
report -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
task-success:, -X- _ O
i.e. -X- _ O
the -X- _ O
scratch+KL -X- _ O
baselines -X- _ O
with -X- _ O
λKL -X- _ O
= -X- _ O
0.1, -X- _ O
and -X- _ O
the -X- _ O
truncation -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
probability -X- _ O
threshold, -X- _ O
pth(α=0.05). -X- _ O

Scores -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
the -X- _ O
three -X- _ O
decoding -X- _ O
procedures -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
4.5 -X- _ O
and -X- _ O
over -X- _ O
5 -X- _ O
seeds; -X- _ O
standard -X- _ O
deviations -X- _ O
are -X- _ O
displayed -X- _ O
when -X- _ O
greater -X- _ O
than -X- _ O
0.01 -X- _ O
for -X- _ O
accuracy -X- _ O
metrics. -X- _ O

This -X- _ O
process -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
recently -X- _ O
in -X- _ O
Text-to-Image -X- _ O
Generation -X- _ O
tasks -X- _ O
(Ramesh -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Finally, -X- _ O
we -X- _ O
sampled -X- _ O
ten -X- _ O
text -X- _ O
sequences -X- _ O
from -X- _ O
the -X- _ O
policy, -X- _ O
and -X- _ O
selected -X- _ O
the -X- _ O
one -X- _ O
with -X- _ O
the -X- _ O
lowest -X- _ O
perplexity -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
external -X- _ O
language -X- _ O
model, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
lm-ranking. -X- _ B-MetricValue

greedy -X- _ B-MetricValue
uses -X- _ O
the -X- _ O
argmax -X- _ O
of -X- _ O
the -X- _ O
policy, -X- _ O
while -X- _ O
sampling -X- _ O
uses -X- _ O
the -X- _ O
multinomial -X- _ O
distribution. -X- _ O

We -X- _ O
consider -X- _ O
three -X- _ O
text -X- _ O
generation -X- _ O
methods. -X- _ O

When -X- _ O
generating -X- _ O
text -X- _ O
from -X- _ O
a -X- _ O
trained -X- _ O
language -X- _ O
model, -X- _ O
the -X- _ O
quality -X- _ O
and -X- _ O
diversity -X- _ O
of -X- _ O
samples -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
decoding -X- _ O
algorithm -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

4.5 -X- _ O
Sampling -X- _ O
methods -X- _ O
for -X- _ O
text -X- _ O
generation -X- _ O

Examples -X- _ O
of -X- _ O
questions -X- _ O
asked -X- _ O
during -X- _ O
the -X- _ O
study -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
C. -X- _ O

Finally, -X- _ O
we -X- _ O
evaluated -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
syntax -X- _ O
errors -X- _ O
by -X- _ O
asking -X- _ O
participants -X- _ O
to -X- _ O
tick -X- _ O
the -X- _ O
question -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
grammatically -X- _ O
incorrect. -X- _ O

Thirdly, -X- _ O
we -X- _ O
evaluated -X- _ O
the -X- _ O
language -X- _ O
originality -X- _ O
and -X- _ O
diversity, -X- _ O
by -X- _ O
asking -X- _ O
participants -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
question -X- _ O
the -X- _ O
most -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
reference -X- _ O
question. -X- _ O

Secondly, -X- _ O
we -X- _ O
evaluated -X- _ O
language -X- _ O
grounding, -X- _ O
i.e -X- _ O
adequacy -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
to -X- _ O
the -X- _ O
image-answer -X- _ O
pair, -X- _ O
by -X- _ O
asking -X- _ O
the -X- _ O
participants -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
question -X- _ O
most -X- _ O
suitable -X- _ O
given -X- _ O
the -X- _ O
two -X- _ O
elements. -X- _ O

First, -X- _ O
we -X- _ O
evaluated -X- _ O
the -X- _ O
language -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
samples, -X- _ O
by -X- _ O
asking -X- _ O
the -X- _ O
participants -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
most -X- _ O
syntactically -X- _ O
and -X- _ O
semantically -X- _ O
correct -X- _ O
question -X- _ O
among -X- _ O
the -X- _ O
two -X- _ O
samples -X- _ O
of -X- _ O
the -X- _ O
questions -X- _ O
pair. -X- _ O

The -X- _ O
study -X- _ O
(further -X- _ O
detailed -X- _ O
in -X- _ O
Appendix -X- _ O
C) -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
pairwise -X- _ O
comparison -X- _ O
of -X- _ O
question -X- _ O
samples -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
concurrent -X- _ O
algorithms -X- _ O
according -X- _ O
to -X- _ O
four -X- _ O
criteria. -X- _ O

On -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
task, -X- _ O
we -X- _ O
also -X- _ O
performed -X- _ O
human -X- _ O
evaluation -X- _ O
by -X- _ O
surveying -X- _ O
53 -X- _ O
participants -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
50 -X- _ O
questions -X- _ O
produced -X- _ O
by -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
at -X- _ O
test -X- _ O
time. -X- _ O

Human -X- _ O
Evaluation. -X- _ O

We -X- _ O
thus -X- _ O
also -X- _ O
measure -X- _ O
the -X- _ O
probability -X- _ B-MetricName
mass -X- _ I-MetricName
of -X- _ I-MetricName
the -X- _ I-MetricName
ten -X- _ I-MetricName
most -X- _ I-MetricName
frequent -X- _ I-MetricName
words -X- _ I-MetricName
(Choshen -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
peakiness -X- _ B-MetricName
(peak). -X- _ B-MetricName

Although -X- _ O
such -X- _ O
score -X- _ O
detects -X- _ O
potential -X- _ O
mode -X- _ O
collapse, -X- _ O
i.e., -X- _ O
when -X- _ O
the -X- _ O
language -X- _ O
utters -X- _ O
identical -X- _ O
sequences -X- _ O
of -X- _ O
words, -X- _ O
it -X- _ O
also -X- _ O
values -X- _ O
babbling, -X- _ O
i.e., -X- _ O
outputting -X- _ O
random -X- _ O
words. -X- _ O

We -X- _ O
here -X- _ O
estimate -X- _ O
a -X- _ O
self-BLEU -X- _ B-MetricName
(sBLEU) -X- _ B-MetricName
score -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
over -X- _ O
10 -X- _ O
questions -X- _ O
generated -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
image-answer -X- _ O
pair. -X- _ O

Diversity -X- _ O
Metrics. -X- _ O

Thus, -X- _ O
we -X- _ O
also -X- _ O
compute -X- _ O
two -X- _ O
metrics -X- _ O
assessing -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
independently -X- _ O
of -X- _ O
reference -X- _ O
questions, -X- _ O
the -X- _ O
perplexity -X- _ B-MetricName
of -X- _ I-MetricName
the -X- _ I-MetricName
question -X- _ I-MetricName
given -X- _ I-MetricName
an -X- _ I-MetricName
external -X- _ I-MetricName
LM -X- _ I-MetricName
(ppl-e), -X- _ B-MetricName
and -X- _ O
its -X- _ O
perplexity -X- _ B-MetricName
given -X- _ I-MetricName
the -X- _ I-MetricName
task-related -X- _ I-MetricName
LM -X- _ I-MetricName
(ppl-t). -X- _ B-MetricName

identical -X- _ O
answer -X- _ O
may -X- _ O
arise -X- _ O
from -X- _ O
two -X- _ O
non-overlapping -X- _ O
but -X- _ O
syntactically -X- _ O
correct -X- _ O
questions. -X- _ O

While -X- _ O
those -X- _ O
scores -X- _ O
can -X- _ O
capture -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
properties -X- _ O
of -X- _ O
language, -X- _ O
they -X- _ O
also -X- _ O
fall -X- _ O
short -X- _ O
an -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
open-form -X- _ O
language, -X- _ O
e.g. -X- _ O

First, -X- _ O
we -X- _ O
used -X- _ O
n-grams -X- _ O
metrics, -X- _ O
BLEU -X- _ B-MetricName
(Papineni -X- _ O
et -X- _ O
al., -X- _ O
2002), -X- _ O
METEOR -X- _ B-MetricName
(Banerjee -X- _ O
and -X- _ O
Lavie, -X- _ O
2005) -X- _ O
and -X- _ O
CIDEr -X- _ B-MetricName
(Vedantam -X- _ O
et -X- _ O
al., -X- _ O
2015), -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
generated -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
questions -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
set. -X- _ O

Language -X- _ O
Metrics. -X- _ O

These -X- _ O
scores -X- _ O
whether -X- _ O
measure -X- _ O
the -X- _ O
task-solving -X- _ O
abilities -X- _ O
of -X- _ O
the -X- _ O
agent, -X- _ O
but -X- _ O
they -X- _ O
are -X- _ O
also -X- _ O
conditioned -X- _ O
by -X- _ O
the -X- _ O
VQA -X- _ B-TaskName
model -X- _ O
abilities. -X- _ O

We -X- _ O
measure -X- _ O
the -X- _ O
taskcompletion -X- _ B-MetricName
score -X- _ I-MetricName
or -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
1 -X- _ I-MetricName
which -X- _ O
states -X- _ O
whether -X- _ O
the -X- _ O
target -X- _ O
answer -X- _ O
is -X- _ O
the -X- _ O
top -X- _ O
answer -X- _ O
of -X- _ O
the -X- _ O
VQA -X- _ O
models, -X- _ O
and -X- _ O
the -X- _ O
recall -X- _ B-MetricName
@ -X- _ I-MetricName
5 -X- _ I-MetricName
(R@5), -X- _ B-MetricName
which -X- _ O
assesses -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
5 -X- _ O
top -X- _ O
answers. -X- _ O

We -X- _ O
decompose -X- _ O
automatic -X- _ O
language -X- _ O
evaluation -X- _ O
into -X- _ O
three -X- _ O
categories -X- _ O
to -X- _ O
assess -X- _ O
different -X- _ O
facets -X- _ O
of -X- _ O
language, -X- _ O
and -X- _ O
perform -X- _ O
as -X- _ O
well -X- _ O
a -X- _ O
human -X- _ O
evaluation -X- _ O
study. -X- _ O

Evaluating -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
is -X- _ O
an -X- _ O
open-research -X- _ O
problem -X- _ O
in -X- _ O
language -X- _ O
literature. -X- _ O

4.4 -X- _ O
Metrics -X- _ O
and -X- _ O
Evaluation -X- _ O
Methods -X- _ O

These -X- _ O
two -X- _ O
baselines -X- _ O
should -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
gold -X- _ O
standards -X- _ O
as -X- _ O
they -X- _ O
rely -X- _ O
on -X- _ O
task-related -X- _ O
data; -X- _ O
additionally, -X- _ O
pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName
fine-tune -X- _ I-MethodName
is -X- _ O
today -X- _ O
the -X- _ O
state-of-the-art -X- _ O
method -X- _ O
for -X- _ O
learning -X- _ O
RL-based -X- _ O
LM. -X- _ O

Then, -X- _ O
we -X- _ O
fine-tune -X- _ O
the -X- _ O
pretrained -X- _ O
language -X- _ O
agent -X- _ O
with -X- _ O
PPO -X- _ O
without -X- _ O
truncation, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
pretrain -X- _ B-MethodName
+ -X- _ I-MethodName
RL -X- _ I-MethodName
fine-tune. -X- _ I-MethodName

We -X- _ O
trained -X- _ O
a -X- _ O
language -X- _ O
agent -X- _ O
on -X- _ O
the -X- _ O
task-dataset -X- _ O
with -X- _ O
a -X- _ O
log-likelihood -X- _ O
objective, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
pretrain. -X- _ B-MethodName

Finally, -X- _ O
we -X- _ O
include -X- _ O
two -X- _ O
baselines -X- _ O
with -X- _ O
a -X- _ O
pre-training -X- _ O
phase. -X- _ O

We -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
scratch -X- _ B-MethodName
+ -X- _ I-MethodName
KL-task -X- _ I-MethodName
when -X- _ O
distilling -X- _ O
the -X- _ O
task-specific -X- _ O
language -X- _ O
model, -X- _ O
and -X- _ O
scratch -X- _ B-MethodName
+ -X- _ I-MethodName
KL-ext -X- _ I-MethodName
with -X- _ O
the -X- _ O
external -X- _ O
language -X- _ O
model. -X- _ O

Then, -X- _ O
we -X- _ O
added -X- _ O
a -X- _ O
Kullback-Leibler -X- _ O
(KL) -X- _ O
fLM -X- _ O
), -X- _ O
regularization -X- _ O
term -X- _ O
to -X- _ O
the -X- _ O
loss, -X- _ O
λKLKL(πθ|| -X- _ O
with -X- _ O
λKL -X- _ O
> -X- _ O
0, -X- _ O
to -X- _ O
incorporate -X- _ O
language -X- _ O
prior -X- _ O
to -X- _ O
the -X- _ O
agent -X- _ O
as -X- _ O
in -X- _ O
(Jaques -X- _ O
et -X- _ O
al., -X- _ O
2017, -X- _ O
2019). -X- _ O

We -X- _ O
trained -X- _ O
a -X- _ O
simple -X- _ O
on-policy -X- _ B-MethodName
PPO -X- _ I-MethodName
algorithm -X- _ I-MethodName
without -X- _ O
any -X- _ O
action -X- _ O
space -X- _ O
pruning, -X- _ O
and -X- _ O
refer -X- _ O
to -X- _ O
it -X- _ O
as -X- _ O
scratch. -X- _ B-MethodName

The -X- _ O
truncation -X- _ O
with -X- _ O
the -X- _ O
task-related -X- _ O
LM -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
TrufLL -X- _ B-MethodName
(Task-LM), -X- _ I-MethodName
while -X- _ O
the -X- _ O
one -X- _ O
with -X- _ O
the -X- _ O
External -X- _ O
LM -X- _ O
is -X- _ O
referred -X- _ O
as -X- _ O
TrufLL -X- _ B-MethodName
(Ext-LM). -X- _ I-MethodName

We -X- _ O
first -X- _ O
emphasize -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
training -X- _ O
an -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
pre-training -X- _ O
phase -X- _ O
through -X- _ O
two -X- _ O
baselines. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
from -X- _ O
scratch, -X- _ O
i.e. -X- _ O
without -X- _ O
the -X- _ O
usual -X- _ O
pre-training -X- _ O
phase -X- _ O
by -X- _ O
solely -X- _ O
interacting -X- _ O
with -X- _ O
another -X- _ O
language -X- _ O
system, -X- _ O
the -X- _ O
VQA -X- _ B-TaskName
model, -X- _ O
when -X- _ O
supported -X- _ O
by -X- _ O
truncation -X- _ O
methods. -X- _ O

Other -X- _ O
language -X- _ O
generation -X- _ O
applications -X- _ O
are -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
5.3. -X- _ O

Here, -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
VQG -X- _ B-TaskName
framework -X- _ O
as -X- _ O
a -X- _ O
proof -X- _ O
of -X- _ O
concept -X- _ O
that -X- _ O
natural -X- _ O
language -X- _ O
can -X- _ O
be -X- _ O
learned -X- _ O
through -X- _ O
pure -X- _ O
interaction -X- _ O
given -X- _ O
any -X- _ O
task -X- _ O
reward. -X- _ O

Please -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
VQA -X- _ B-TaskName
modules -X- _ O
are -X- _ O
only -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
environment, -X- _ O
i.e. -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
positive/negative -X- _ O
In -X- _ O
other -X- _ O
settings, -X- _ O
TrufLL -X- _ B-MethodName
feedback -X- _ O
to -X- _ O
the -X- _ O
agent. -X- _ O

In -X- _ O
these -X- _ O
two -X- _ O
settings, -X- _ O
we -X- _ O
acknowledge -X- _ O
that -X- _ O
the -X- _ O
task -X- _ O
dataset -X- _ O
is -X- _ O
still -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
VQA -X- _ B-TaskName
models. -X- _ O

Given -X- _ O
the -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
answers, -X- _ O
we -X- _ O
use -X- _ O
as -X- _ O
reward -X- _ O
a -X- _ O
decreasing -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
rank -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
answer -X- _ O
)/2, -X- _ O
as -X- _ O
rk( -X- _ O
further -X- _ O
explained -X- _ O
in -X- _ O
Appendix -X- _ O
A.5. -X- _ O

Finally, -X- _ O
we -X- _ O
used -X- _ O
a -X- _ O
pretrained -X- _ O
Vil| -X- _ O
BERT -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
reward -X- _ O
(Lu -X- _ O
et -X- _ O
al., -X- _ O
2020a). -X- _ O

Instead, -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
few-shot -X- _ O
generalization -X- _ O
capabilities -X- _ O
of -X- _ O
GPT-2, -X- _ B-MethodName
by -X- _ O
feeding -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
prompt -X- _ O
"Here -X- _ O
are -X- _ O
a -X- _ O
few -X- _ O
examples:" -X- _ O
followed -X- _ O
by -X- _ O
100 -X- _ O
random -X- _ O
questions -X- _ O
q<100 -X- _ O
from -X- _ O
the -X- _ O
dataset. -X- _ O

Unlike -X- _ O
most -X- _ O
NLP -X- _ O
tasks -X- _ O
relying -X- _ O
on -X- _ O
pretrained -X- _ O
generic -X- _ O
language -X- _ O
models, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
fine-tune -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
dataset. -X- _ O

The -X- _ O
original -X- _ O
language -X- _ O
model -X- _ O
outputs -X- _ O
a -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
50,257 -X- _ O
tokens, -X- _ O
but -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
masked -X- _ O
softmax -X- _ O
function -X- _ O
to -X- _ O
restrict -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
to -X- _ O
the -X- _ O
14,810 -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
VQAv2 -X- _ B-DatasetName
dataset. -X- _ O

The -X- _ O
External -X- _ O
Language -X- _ O
Model -X- _ O
is -X- _ O
Open-AI’s -X- _ O
GPT-2 -X- _ B-MethodName
(Radford -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

The -X- _ O
task-specific -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
a -X- _ O
one-layer -X- _ O
LSTM -X- _ O
with -X- _ O
512 -X- _ O
units -X- _ O
and -X- _ O
a -X- _ O
512 -X- _ O
word -X- _ O
embedding -X- _ O
dimension, -X- _ O
pretrained -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
training -X- _ O
dataset -X- _ O
of -X- _ O
VQAv2 -X- _ B-DatasetName
questions. -X- _ O

It -X- _ O
has -X- _ O
a -X- _ O
vocabulary -X- _ O
of -X- _ O
14,810 -X- _ O
words -X- _ O
and -X- _ O
3,149 -X- _ O
answers. -X- _ O

The -X- _ O
VQAv2 -X- _ B-DatasetName
dataset -X- _ O
(Goyal -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
is -X- _ O
made -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
and -X- _ O
open-formed -X- _ O
questions -X- _ O
on -X- _ O
images -X- _ O
from -X- _ O
the -X- _ O
MS-Coco -X- _ B-DatasetName
Dataset -X- _ O
(Lin -X- _ O
et -X- _ O
al., -X- _ O
2014). -X- _ O

Although -X- _ O
those -X- _ O
two -X- _ O
datasets -X- _ O
share -X- _ O
the -X- _ O
CLEVR -X- _ B-DatasetName
vocabulary, -X- _ O
their -X- _ O
language -X- _ O
distribution -X- _ O
differs -X- _ O
from -X- _ O
vanilla -X- _ O
CLEVR. -X- _ B-DatasetName

The -X- _ O
external -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
mixture -X- _ O
of -X- _ O
CLOSURE -X- _ B-DatasetName
(Bahdanau -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
CLEVR-Dialog -X- _ B-DatasetName
(Kottur -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
datasets. -X- _ O

The -X- _ O
task-specific -X- _ O
LM -X- _ O
is -X- _ O
trained -X- _ O
over -X- _ O
the -X- _ O
full -X- _ O
train -X- _ O
dataset -X- _ O
of -X- _ O
CLEVR -X- _ B-DatasetName
questions. -X- _ O

Both -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
single-layer -X- _ O
LSTMs -X- _ O
(Hochreiter -X- _ O
and -X- _ O
Schmidhuber, -X- _ O
1997) -X- _ O
with -X- _ O
512 -X- _ O
units, -X- _ O
and -X- _ O
512 -X- _ O
word -X- _ O
embedding -X- _ O
dimension. -X- _ O

The -X- _ O
vocabulary -X- _ O
contains -X- _ O
86 -X- _ O
words -X- _ O
and -X- _ O
28 -X- _ O
potential -X- _ O
answers, -X- _ O
making -X- _ O
it -X- _ O
a -X- _ O
valuable -X- _ O
proof -X- _ O
of -X- _ O
concept -X- _ O
for -X- _ O
assessing -X- _ O

CLEVR -X- _ B-DatasetName
The -X- _ O
CLEVR -X- _ B-DatasetName
VQA -X- _ O
dataset -X- _ O
(Johnson -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
is -X- _ O
made -X- _ O
of -X- _ O
template -X- _ O
questions -X- _ O
on -X- _ O
synthetic -X- _ O
images, -X- _ O
which -X- _ O
contain -X- _ O
simple -X- _ O
objects -X- _ O
with -X- _ O
four -X- _ O
distinct -X- _ O
properties -X- _ O
(shape, -X- _ O
material, -X- _ O
color, -X- _ O
size). -X- _ O

The -X- _ O
two -X- _ O
datasets -X- _ O
have -X- _ O
been -X- _ O
originally -X- _ O
created -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
(VQA), -X- _ B-TaskName
i.e. -X- _ O
for -X- _ O
multi-modal -X- _ O
classification -X- _ O
algorithms -X- _ O
predicting -X- _ O
an -X- _ O
answer -X- _ O
given -X- _ O
an -X- _ O
image-question -X- _ O
pair. -X- _ O

We -X- _ O
evaluate -X- _ O
TrufLL -X- _ B-MethodName
on -X- _ O
the -X- _ O
CLEVR -X- _ B-DatasetName
and -X- _ O
VQAv2 -X- _ B-DatasetName
datasets -X- _ O
to -X- _ O
simulate -X- _ O
large-scale -X- _ O
VQG -X- _ B-TaskName
datasets. -X- _ O

This -X- _ O
model -X- _ O
takes -X- _ O
as -X- _ O
inputs -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
question -X- _ O
w<t -X- _ O
and -X- _ O
outputs -X- _ O
the -X- _ O
image -X- _ O
I -X- _ O
a -X- _ O
predicted -X- _ O
answer -X- _ O
ˆ -X- _ O
. -X- _ O

We -X- _ O
then -X- _ O
provide -X- _ O
the -X- _ O
generated -X- _ O
question -X- _ O
to -X- _ O
a -X- _ O
pretrained -X- _ O
VQA -X- _ B-TaskName
model. -X- _ O

The -X- _ O
RL -X- _ O
agent -X- _ O
then -X- _ O
, -X- _ O
I -X- _ O
generates -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
w<t -X- _ O
of -X- _ O
maximum -X- _ O
length -X- _ O
T -X- _ O
. -X- _ O

Formally, -X- _ O
the -X- _ O
initial -X- _ O
context -X- _ O
c -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
the -X- _ O
image-answer -X- _ O
pair -X- _ O
( -X- _ O
). -X- _ O

Such -X- _ O
a -X- _ O
criterion, -X- _ O
unlike -X- _ O
metrics -X- _ O
based -X- _ O
on -X- _ O
ground-truth -X- _ O
sentences, -X- _ O
allows -X- _ O
generating -X- _ O
diverse -X- _ O
grounded -X- _ O
questions -X- _ O
given -X- _ O
an -X- _ O
image-answer -X- _ O
pair. -X- _ O

Secondly, -X- _ O
the -X- _ O
success -X- _ O
criterion -X- _ O
is -X- _ O
naturally -X- _ O
non-differentiable, -X- _ O
hence -X- _ O
a -X- _ O
natural -X- _ O
fit -X- _ O
for -X- _ O
RL -X- _ O
methods. -X- _ O

First, -X- _ O
by -X- _ O
combining -X- _ O
vision, -X- _ O
scene -X- _ O
understanding -X- _ O
and -X- _ O
language -X- _ O
generation, -X- _ O
it -X- _ O
requires -X- _ O
high-level -X- _ O
reasoning -X- _ O
and -X- _ O
exhibits -X- _ O
a -X- _ O
large -X- _ O
spectrum -X- _ O
of -X- _ O
language -X- _ O
difficulties. -X- _ O

Such -X- _ O
a -X- _ O
task -X- _ O
presents -X- _ O
multiple -X- _ O
advantages. -X- _ O

There, -X- _ O
the -X- _ O
language -X- _ O
agent -X- _ O
observes -X- _ O
an -X- _ O
image-answer -X- _ O
pair -X- _ O
and -X- _ O
has -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
question -X- _ O
that -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
answer, -X- _ O
as -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

We -X- _ O
showcase -X- _ O
TrufLL -X- _ B-MethodName
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Generation -X- _ I-TaskName
(VQG) -X- _ B-TaskName
(Mostafazadeh -X- _ O
et -X- _ O
al., -X- _ O
2016), -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
Visual -X- _ O
Jeopardy! -X- _ O

We -X- _ O
here -X- _ O
list -X- _ O
the -X- _ O
experimental -X- _ O
setting -X- _ O
and -X- _ O
detail -X- _ O
the -X- _ O
network -X- _ O
and -X- _ O
hyperparameters -X- _ O
in -X- _ O
Appendix -X- _ O
A.4. -X- _ O

For -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
completeness, -X- _ O
we -X- _ O
also -X- _ O
study -X- _ O
the -X- _ O
truncation -X- _ B-MethodName
with -X- _ I-MethodName
the -X- _ I-MethodName
task-related -X- _ I-MethodName
LM -X- _ I-MethodName
as -X- _ O
an -X- _ O
additional -X- _ O
benchmark -X- _ O
to -X- _ O
assess -X- _ O
our -X- _ O
approach. -X- _ O

We -X- _ O
emphasize -X- _ O
that -X- _ O
this -X- _ O
paper -X- _ O
aims -X- _ O
at -X- _ O
leveraging -X- _ O
taskagnostic -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
they -X- _ O
discard -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
task-specific -X- _ O
data. -X- _ O

Such -X- _ O
a -X- _ O
model -X- _ O
provides -X- _ O
a -X- _ O
task-specific -X- _ O
linguistic -X- _ O
prior -X- _ O
to -X- _ O
the -X- _ O
RL -X- _ O
language -X- _ O
agent, -X- _ O
and -X- _ O
captures -X- _ O
language -X- _ O
pragmatics. -X- _ O

we -X- _ O
use -X- _ O
a -X- _ O
task-related -X- _ O
language -X- _ O
model -X- _ O
pretrained -X- _ O
on -X- _ O
the -X- _ O
supervised -X- _ O
dataset -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
task. -X- _ O

Such -X- _ O
a -X- _ O
model -X- _ O
provides -X- _ O
a -X- _ O
generic -X- _ O
linguistic -X- _ O
prior -X- _ O
to -X- _ O
the -X- _ O
RL -X- _ O
agent -X- _ O
exploration -X- _ O
process, -X- _ O
solely -X- _ O
encoding -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
information. -X- _ O

On -X- _ O
the -X- _ O
one -X- _ O
hand, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
external -X- _ O
language -X- _ O
model -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
task-agnostic -X- _ O
language -X- _ O
corpora. -X- _ O

We -X- _ O
benchmark -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
truncation. -X- _ O

This -X- _ O
function -X- _ O
randomly -X- _ O
samples -X- _ O
k -X- _ B-HyperparameterName
words -X- _ O
from -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
replacement -X- _ O
to -X- _ O
directly -X- _ O
build -X- _ O
the -X- _ O
truncated -X- _ O
vocabulary: -X- _ O

Probability -X- _ O
threshold -X- _ O
(α): -X- _ B-HyperparameterName
This -X- _ O
function -X- _ O
only -X- _ O
keeps -X- _ O
words -X- _ O
having -X- _ O
a -X- _ O
probability -X- _ O
fLM -X- _ O
(. -X- _ O

This -X- _ O
function -X- _ O
selects -X- _ O
the -X- _ O
k -X- _ B-HyperparameterName
words -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
probability -X- _ O
given -X- _ O
by -X- _ O
fLM -X- _ O
(. -X- _ O

At -X- _ O
each -X- _ O
timestep -X- _ O
t, -X- _ O
TrufLL -X- _ B-MethodName
restricts -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
of -X- _ O
the -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
with: -X- _ O

TrufLL -X- _ B-MethodName
combines -X- _ O
two -X- _ O
distinct -X- _ O
language -X- _ O
models, -X- _ O
: -X- _ O
a -X- _ O
RL -X- _ O
language -X- _ O
which -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
vocabulary -X- _ O
agent -X- _ O
πθ -X- _ O
and -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
fLM -X- _ O
. -X- _ O

We -X- _ O
detail -X- _ O
below -X- _ O
the -X- _ O
action -X- _ O
space’s -X- _ O
truncation -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
associated -X- _ O
RL -X- _ O
algorithm -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
language -X- _ O
agent. -X- _ O

We -X- _ O
here -X- _ O
aim -X- _ O
at -X- _ O
making -X- _ O
RL -X- _ O
methods -X- _ O
feasible -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
setting -X- _ O
by -X- _ O
dynamically -X- _ O
reducing -X- _ O
the -X- _ O
action -X- _ O
space, -X- _ O
i.e., -X- _ O
by -X- _ O
restricting -X- _ O
the -X- _ O
language -X- _ O
agent -X- _ O
to -X- _ O
select -X- _ O
a -X- _ O
word -X- _ O
within -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
at -X- _ O
each -X- _ O
time -X- _ O
step. -X- _ O

The -X- _ O
expectation -X- _ O
is -X- _ O
estimated -X- _ O
in -X- _ O
practice -X- _ O
using -X- _ O
a -X- _ O
Monte -X- _ O
Carlo -X- _ O
approach, -X- _ O
with -X- _ O
an -X- _ O
empirical -X- _ O
average -X- _ O
over -X- _ O
a -X- _ O
finite -X- _ O
batch -X- _ O
of -X- _ O
episodes, -X- _ O
i.e -X- _ O
a -X- _ O
succession -X- _ O
of -X- _ O
transitions -X- _ O
from -X- _ O
an -X- _ O
initial -X- _ O
state -X- _ O
s0 -X- _ O
to -X- _ O
a -X- _ O
terst,at -X- _ O
∼ -X- _ O
minal -X- _ O
state -X- _ O
sT -X- _ O
. -X- _ O

b -X- _ O
= -X- _ O
min(a,b), -X- _ O
where -X- _ O
for -X- _ O
all -X- _ O
real -X- _ O
numbers -X- _ O
a, -X- _ O
b, -X- _ O
a -X- _ O
ρθ -X- _ O
st), -X- _ O
ϵ -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
hyper-parameter -X- _ O
st)/πθold(at| -X- _ O
t -X- _ O
= -X- _ O
πθ(at| -X- _ O
controlling -X- _ O
the -X- _ O
magnitude -X- _ O
of -X- _ O
the -X- _ O
policy -X- _ O
updates, -X- _ O
and -X- _ O
clip(a,x,b) -X- _ O
is -X- _ O
the -X- _ O
function -X- _ O
that -X- _ O
clips -X- _ O
x -X- _ O
in -X- _ O
interval -X- _ O
[a,b]. -X- _ O

This -X- _ O
process -X- _ O
may -X- _ O
be -X- _ O
performed -X- _ O
through -X- _ O
Policy -X- _ O
Gradient -X- _ O
(PG) -X- _ O
algorithms -X- _ O
(Sutton -X- _ O
et -X- _ O
al., -X- _ O
1999). -X- _ O

The -X- _ O
RL -X- _ O
language -X- _ O
agent -X- _ O
aims -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
policy -X- _ O
that -X- _ O
maximizes -X- _ O
T -X- _ O
t=0 -X- _ O
rt],2 -X- _ O
while -X- _ O
generating -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
Eπθ[ -X- _ O
words -X- _ O
w<T -X- _ O
, -X- _ O
where -X- _ O
Eπθ -X- _ O
is -X- _ O
the -X- _ O
expectation -X- _ O
under -X- _ O
πθ, -X- _ O
and -X- _ O
T -X- _ O
the -X- _ O
maximal -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
sequence. -X- _ O

It -X- _ O
moves -X- _ O
to -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
(w<t+1, -X- _ O
c) -X- _ O
πθ(wt| -X- _ O
and -X- _ O
receives -X- _ O
a -X- _ O
reward -X- _ O
rt -X- _ O
=r(w<t,c,wt), -X- _ O
where -X- _ O
r -X- _ O
is -X- _ O
a -X- _ O
reward -X- _ O
function -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
task. -X- _ O

Formally, -X- _ O
a -X- _ O
language -X- _ O
generation -X- _ O
agent -X- _ O
is -X- _ O
defined -X- _ O
by -X- _ O
a -X- _ O
policy -X- _ O
πθ -X- _ O
(a -X- _ O
distribution -X- _ O
over -X- _ O
) -X- _ O
parametrized -X- _ O
by -X- _ O
θ, -X- _ O
first -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
c. -X- _ O
At -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
t, -X- _ O
the -X- _ O
agent -X- _ O
samples -X- _ O
a -X- _ O
new -X- _ O
word -X- _ O
wt -X- _ O
from -X- _ O
its -X- _ O
policy -X- _ O
w<t, -X- _ O
c). -X- _ O

During -X- _ O
this -X- _ O
process, -X- _ O
the -X- _ O
agent -X- _ O
may -X- _ O
be -X- _ O
rewarded -X- _ O
with -X- _ O
language -X- _ O
scores -X- _ O
(Ranzato -X- _ O
et -X- _ O
al., -X- _ O
2016), -X- _ O
human -X- _ O
preferences -X- _ O
(Stiennon -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
or -X- _ O
task -X- _ O
completion -X- _ O
scores -X- _ O
(Strub -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

Translation, -X- _ O
text -X- _ O
summarization -X- _ O
or -X- _ O
image -X- _ O
captioning -X- _ O
are -X- _ O
examples -X- _ O
of -X- _ O
such -X- _ O
tasks -X- _ O
respectively -X- _ O
using -X- _ O
a -X- _ O
source -X- _ O
sentence, -X- _ O
a -X- _ O
text -X- _ O
article, -X- _ O
or -X- _ O
an -X- _ O
image -X- _ O
as -X- _ O
a -X- _ O
context -X- _ O
(c). -X- _ O

We -X- _ O
cast -X- _ O
the -X- _ O
word-based -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
task -X- _ O
as -X- _ O
a -X- _ O
Markov -X- _ O
Decision -X- _ O
Process -X- _ O
to -X- _ O
apply -X- _ O
RL -X- _ O
methods -X- _ O
(Sutton -X- _ O
et -X- _ O
al., -X- _ O
1998). -X- _ O

Unlike -X- _ O
alternative -X- _ O
RL -X- _ O
without -X- _ O
pre-training -X- _ O
approaches, -X- _ O
TrufLL -X- _ B-TaskName
manages -X- _ O
to -X- _ O
ask -X- _ O
meaningful -X- _ O
and -X- _ O
valid -X- _ O
questions -X- _ O
on -X- _ O
large -X- _ O
vocabularies, -X- _ O
exhibiting -X- _ O
success -X- _ O
rate -X- _ O
and -X- _ O
language -X- _ O
metrics -X- _ O
close -X- _ O
to -X- _ O
pretrain -X- _ O
models -X- _ O
with -X- _ O
labeled -X- _ O
data, -X- _ O
while -X- _ O
producing -X- _ O
more -X- _ O
original -X- _ O
language. -X- _ O

We -X- _ O
here -X- _ O
evaluate -X- _ O
it -X- _ O
on -X- _ O
two -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Generation -X- _ I-TaskName
(VQG) -X- _ B-TaskName
tasks, -X- _ O
the -X- _ O
synthetic -X- _ O
CLEVR -X- _ B-DatasetName
dataset -X- _ O
(Johnson -X- _ O
et -X- _ O
al., -X- _ O
2017), -X- _ O
and -X- _ O
the -X- _ O
natural -X- _ O
language -X- _ O
VQAv2 -X- _ B-DatasetName
dataset -X- _ O
(Goyal -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

Such -X- _ O
an -X- _ O
approach -X- _ O
injects -X- _ O
a -X- _ O
generic -X- _ O
prior -X- _ O
linguistic -X- _ O
knowledge -X- _ O
into -X- _ O
the -X- _ O
RL -X- _ O
algorithm, -X- _ O
is -X- _ O
usable -X- _ O
on -X- _ O
tasks -X- _ O
lacking -X- _ O
in-domain -X- _ O
labeled -X- _ O
data, -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
transferred -X- _ O
to -X- _ O
new -X- _ O
RL-based -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
tasks. -X- _ O

At -X- _ O
each -X- _ O
time -X- _ O
step -X- _ O
of -X- _ O
the -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
process, -X- _ O
TrufLL -X- _ B-MethodName
truncates -X- _ O
its -X- _ O
effective -X- _ O
action -X- _ O
space -X- _ O
to -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
words -X- _ O
provided -X- _ O
by -X- _ O
a -X- _ O
pretrained -X- _ O
task-agnostic -X- _ O
language -X- _ O
model. -X- _ O

TrufLL -X- _ B-MethodName
leverages -X- _ O
such -X- _ O
structure -X- _ O
to -X- _ O
drive -X- _ O
the -X- _ O
exploration -X- _ O
of -X- _ O
the -X- _ O
RL-based -X- _ O
language -X- _ O
agent -X- _ O
during -X- _ O
training. -X- _ O

Yet, -X- _ O
while -X- _ O
large -X- _ O
and -X- _ O
discrete, -X- _ O
a -X- _ O
language -X- _ O
action -X- _ O
space -X- _ O
contains -X- _ O
a -X- _ O
specific -X- _ O
structure, -X- _ O
made -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
syntactical -X- _ O
and -X- _ O
semantics -X- _ O
rules -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
language. -X- _ O

While -X- _ O
appealing, -X- _ O
such -X- _ O
an -X- _ O
approach -X- _ O
requires -X- _ O
overcoming -X- _ O
the -X- _ O
hurdle -X- _ O
of -X- _ O
the -X- _ O
combinatorial -X- _ O
language -X- _ O
action -X- _ O
space, -X- _ O
a -X- _ O
vocabulary -X- _ O
usually -X- _ O
containing -X- _ O
more -X- _ O
than -X- _ O
10,000 -X- _ O
words. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
aim -X- _ O
at -X- _ O
learning -X- _ O
a -X- _ O
conditional -X- _ O
language -X- _ O
model -X- _ O
using -X- _ O
RL -X- _ O
without -X- _ O
a -X- _ O
pre-training -X- _ O
phase, -X- _ O
so -X- _ O
that -X- _ O
(i) -X- _ O
we -X- _ O
get -X- _ O
free -X- _ O
from -X- _ O
datasets -X- _ O
with -X- _ O
human -X- _ O
annotations, -X- _ O
and -X- _ O
(ii) -X- _ O
we -X- _ O
avoid -X- _ O
the -X- _ O
text -X- _ O
generation -X- _ O
flaws -X- _ O
induced -X- _ O
by -X- _ O
the -X- _ O
common -X- _ O
methods. -X- _ O

Besides, -X- _ O
combining -X- _ O
pre-training -X- _ O
and -X- _ O
fine-tuning -X- _ O
phases -X- _ O
either -X- _ O
barely -X- _ O
change -X- _ O
the -X- _ O
policy -X- _ O
distribution, -X- _ O
or -X- _ O
induces -X- _ O
language -X- _ O
drift -X- _ O
(Lazaridou -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Lu -X- _ O
et -X- _ O
al., -X- _ O
2020b), -X- _ O
i.e -X- _ O
the -X- _ O
generated -X- _ O
language -X- _ O
drifts -X- _ O
semantically -X- _ O
or -X- _ O
syntactically -X- _ O
from -X- _ O
natural -X- _ O
language. -X- _ O

So -X- _ O
far, -X- _ O
RL-based -X- _ O
text-generation -X- _ B-TaskName
tasks -X- _ O
have -X- _ O
relied -X- _ O
on -X- _ O
a -X- _ O
pre-training -X- _ O
phase -X- _ O
to -X- _ O
ease -X- _ O
learning: -X- _ O
the -X- _ O
policy -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
SL -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
dataset, -X- _ O
before -X- _ O
being -X- _ O
fine-tuned -X- _ O
with -X- _ O
policy -X- _ O
gradient -X- _ O
methods -X- _ O
(Sutton -X- _ O
et -X- _ O
al., -X- _ O
1999) -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
at -X- _ O
hand. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
text -X- _ B-TaskName
generation -X- _ I-TaskName
can -X- _ O
be -X- _ O
naturally -X- _ O
framed -X- _ O
as -X- _ O
a -X- _ O
sequential -X- _ O
decision -X- _ O
making -X- _ O
problem, -X- _ O
with -X- _ O
the -X- _ O
sequence -X- _ O
of -X- _ O
words -X- _ O
seen -X- _ O
as -X- _ O
successive -X- _ O
actions -X- _ O
over -X- _ O
a -X- _ O
vocabulary. -X- _ O

If -X- _ O
both -X- _ O
answers -X- _ O
match, -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
rewarded. -X- _ O

In -X- _ O
a -X- _ O
VQG -X- _ B-TaskName
training -X- _ O
loop, -X- _ O
the -X- _ O
agent -X- _ O
generates -X- _ O
a -X- _ O
question -X- _ O
given -X- _ O
an -X- _ O
image-answer -X- _ O
pair, -X- _ O
which -X- _ O
is -X- _ O
then -X- _ O
fed -X- _ O
to -X- _ O
a -X- _ O
VQA -X- _ O
model -X- _ O
predicting -X- _ O
an -X- _ O
expected -X- _ O
answer. -X- _ O

In -X- _ O
a -X- _ O
conditional -X- _ B-TaskName
language -X- _ I-TaskName
generation -X- _ I-TaskName
task -X- _ O
as -X- _ O
VQG, -X- _ B-TaskName
TrufLL -X- _ B-MethodName
truncates -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
language -X- _ O
model. -X- _ O

1Code -X- _ O

The -X- _ O
pretrained -X- _ O
Language -X- _ O
Model -X- _ O
(LM) -X- _ O
is -X- _ O
fine-tuned -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
supervised -X- _ O
learning -X- _ O
(SL) -X- _ O

Brown -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
state-of-the -X- _ O
art -X- _ O
language -X- _ O
processing -X- _ O
systems -X- _ O
rely -X- _ O
on -X- _ O
sequential -X- _ O
transfer -X- _ O
learning -X- _ O
(Ruder, -X- _ O
2019). -X- _ O

Since -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
generic -X- _ O
language -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
massive -X- _ O
unlabelled -X- _ O
text -X- _ O
corpora -X- _ O
(Radford -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

1 -X- _ O
Introduction -X- _ O

1 -X- _ O

To -X- _ O
our -X- _ O
knowledge, -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
approach -X- _ O
that -X- _ O
successfully -X- _ O
learns -X- _ O
a -X- _ O
language -X- _ B-TaskName
generation -X- _ I-TaskName
policy -X- _ O
without -X- _ O
pre-training, -X- _ O
using -X- _ O
only -X- _ O
reinforcement -X- _ O
learning. -X- _ O

We -X- _ O
evaluate -X- _ O
TrufLL -X- _ B-MethodName
on -X- _ O
two -X- _ O
visual -X- _ B-TaskName
question -X- _ I-TaskName
generation -X- _ I-TaskName
tasks, -X- _ O
for -X- _ O
which -X- _ O
we -X- _ O
report -X- _ O
positive -X- _ O
results -X- _ O
over -X- _ O
performance -X- _ O
and -X- _ O
language -X- _ O
metrics, -X- _ O
which -X- _ O
we -X- _ O
then -X- _ O
corroborate -X- _ O
with -X- _ O
a -X- _ O
human -X- _ O
evaluation. -X- _ O

Interestingly, -X- _ O
this -X- _ O
approach -X- _ O
avoids -X- _ O
the -X- _ O
dependency -X- _ O
to -X- _ O
labelled -X- _ O
datasets -X- _ O
and -X- _ O
inherently -X- _ O
reduces -X- _ O
pretrained -X- _ O
policy -X- _ O
flaws -X- _ O
such -X- _ O
as -X- _ O
language -X- _ O
or -X- _ O
exposure -X- _ O
biases. -X- _ O

TrufLL -X- _ B-MethodName
thus -X- _ O
enables -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
language -X- _ O
agent -X- _ O
by -X- _ O
solely -X- _ O
interacting -X- _ O
with -X- _ O
its -X- _ O
environment -X- _ O
without -X- _ O
any -X- _ O
task-specific -X- _ O
prior -X- _ O
knowledge; -X- _ O
it -X- _ O
is -X- _ O
only -X- _ O
guided -X- _ O
with -X- _ O
a -X- _ O
task-agnostic -X- _ O
language -X- _ O
model. -X- _ O

As -X- _ O
RL -X- _ O
methods -X- _ O
unsuccessfully -X- _ O
scale -X- _ O
to -X- _ O
large -X- _ O
action -X- _ O
spaces, -X- _ O
we -X- _ O
dynamically -X- _ O
truncate -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
using -X- _ O
a -X- _ O
generic -X- _ O
language -X- _ O
model. -X- _ O

This -X- _ O
paper -X- _ O
introduces -X- _ O
TRUncated -X- _ B-MethodName
ReinForcement -X- _ I-MethodName
Learning -X- _ I-MethodName
for -X- _ I-MethodName
Language -X- _ I-MethodName
(TrufLL), -X- _ B-MethodName
an -X- _ O
original -X- _ O
approach -X- _ O
to -X- _ O
train -X- _ O
conditional -X- _ O
language -X- _ O
models -X- _ O
without -X- _ O
a -X- _ O
supervised -X- _ O
learning -X- _ O
phase, -X- _ O
by -X- _ O
only -X- _ O
using -X- _ O
reinforcement -X- _ O
learning -X- _ O
(RL). -X- _ O

Abstract -X- _ O

Florian -X- _ O
Strub -X- _ O
Deep -X- _ O
Mind -X- _ O

Sylvain -X- _ O
Le -X- _ O
Corff -X- _ O
Samovar, -X- _ O
Télécom -X- _ O
SudParis, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris, -X- _ O
Palaiseau -X- _ O

Guillaume -X- _ O
Quispe -X- _ O
and -X- _ O
Charles -X- _ O
Ollion -X- _ O
CMAP, -X- _ O
École -X- _ O
Polytechnique, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris, -X- _ O
Palaiseau -X- _ O

Alice -X- _ O
Martin -X- _ O
Samovar, -X- _ O
Télécom -X- _ O
SudParis, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris, -X- _ O
Palaiseau -X- _ O
CMAP, -X- _ O
École -X- _ O
Polytechnique, -X- _ O
Institut -X- _ O
Polytechnique -X- _ O
de -X- _ O
Paris, -X- _ O
Palaiseau -X- _ O

Learning -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Generation -X- _ I-TaskName
with -X- _ O
Truncated -X- _ B-MethodName
Reinforcement -X- _ I-MethodName
Learning -X- _ I-MethodName

12 -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2022 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies, -X- _ O
pages -X- _ O
12 -X- _ O
- -X- _ O
37 -X- _ O
July -X- _ O
10-15, -X- _ O
2022 -X- _ O
©2022 -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O

-DOCSTART- -X- O
References -X- _ O

This -X- _ O
work -X- _ O
was -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
Shandong -X- _ O
Provincial -X- _ O
Natural -X- _ O
Science -X- _ O
Foundation -X- _ O
(No.ZR2020MF149), -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
Science -X- _ O
and -X- _ O
Technology -X- _ O
Commission -X- _ O
of -X- _ O
Shanghai -X- _ O
Municipality -X- _ O
(21511100302). -X- _ O

Acknowledgements -X- _ O

Experimental -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
three -X- _ O
public -X- _ O
datasets. -X- _ O

Consequently, -X- _ O
we -X- _ O
combine -X- _ O
attention -X- _ O
score -X- _ O
matrices -X- _ O
with -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
semantic -X- _ O
and -X- _ O
syntactic -X- _ O
information. -X- _ O

Furthermore, -X- _ O
we -X- _ O
construct -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
syntactic -X- _ O
distances -X- _ O
that -X- _ O
learn -X- _ O
local -X- _ O
to -X- _ O
global -X- _ O
structure -X- _ O
information. -X- _ O

Then, -X- _ O
we -X- _ O
combine -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
self-attention -X- _ O
to -X- _ O
compose -X- _ O
the -X- _ O
attention -X- _ O
layer. -X- _ O

Specifically, -X- _ O
we -X- _ O
first -X- _ O
design -X- _ O
an -X- _ O
aspect-aware -X- _ O
attention -X- _ O
mechanism, -X- _ O
which -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
learning -X- _ O
aspectrelated -X- _ O
semantic -X- _ O
information. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
SSEGCN -X- _ B-MethodName
architecture -X- _ O
which -X- _ O
integrates -X- _ O
semantic -X- _ O
information -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
syntactic -X- _ O
structure -X- _ O
for -X- _ O
ABSA -X- _ B-TaskName
task. -X- _ O

5 -X- _ O
Conclusion -X- _ O

the -X- _ O
introduction -X- _ O
of -X- _ O
noise -X- _ O
and -X- _ O
decline -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
performance. -X- _ O

When -X- _ O
the -X- _ O
syntactic -X- _ O
distance -X- _ O
is -X- _ O
greater -X- _ O
than -X- _ O
five, -X- _ O
multiple -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O
are -X- _ O
fully -X- _ O
connected -X- _ O
matrices, -X- _ O
and -X- _ O
leads -X- _ O
to -X- _ O

mask -X- _ O
matrices -X- _ O
from -X- _ O
5 -X- _ B-HyperparameterValue
to -X- _ O
7 -X- _ B-HyperparameterValue
leads -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
degradation -X- _ O
of -X- _ O
SSEGCN. -X- _ B-MethodName

If -X- _ O
you -X- _ O
are -X- _ O
a -X- _ O
Tequila -X- _ O
fan -X- _ O
you -X- _ O
will -X- _ O
not -X- _ O
be -X- _ O
disappointed. -X- _ O

Not -X- _ O
as -X- _ O
fact -X- _ O
as -X- _ O
I -X- _ O
would -X- _ O
have -X- _ O
expect -X- _ O
for -X- _ O
an -X- _ O
i5 -X- _ O

The -X- _ O
settings -X- _ O
are -X- _ O
not -X- _ O
user-friendly -X- _ O
either. -X- _ O

Biggest -X- _ O
complaint -X- _ O
is -X- _ O
Windows -X- _ O
8. -X- _ O

However, -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
syntactic -X- _ O

One -X- _ O
main -X- _ O
reason -X- _ O
may -X- _ O
be -X- _ O
that -X- _ O
SSEGCN -X- _ B-MethodName
can -X- _ O
learn -X- _ O
structure -X- _ O
information -X- _ O
from -X- _ O
local -X- _ O
to -X- _ O
global -X- _ O
when -X- _ O
the -X- _ O
syntactic -X- _ O
distance -X- _ O
becomes -X- _ O
larger -X- _ O
and -X- _ O
SSEGCN -X- _ B-MethodName
achieves -X- _ O
remarkable -X- _ O
results -X- _ O
on -X- _ O
five -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
SSEGCN -X- _ B-MethodName
shows -X- _ O
an -X- _ O
upward -X- _ O
trend -X- _ O
with -X- _ O
the -X- _ O
increase -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
when -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
syntactic -X- _ I-HyperparameterName
mask -X- _ I-HyperparameterName
matrices -X- _ I-HyperparameterName
is -X- _ O
less -X- _ O
than -X- _ B-HyperparameterValue
5. -X- _ I-HyperparameterValue

We -X- _ O
conduct -X- _ O
different -X- _ O
numbers -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
syntactic -X- _ I-HyperparameterName
mask -X- _ I-HyperparameterName
matrices -X- _ I-HyperparameterName
from -X- _ O
1 -X- _ B-HyperparameterValue
to -X- _ O
7 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
demonstrated -X- _ O
in -X- _ O
Figure -X- _ O
5. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
multiple -X- _ O
different -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O
on -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
SSEGCN -X- _ B-MethodName
in -X- _ O
Restaurant -X- _ B-DatasetName
and -X- _ O
Laptop -X- _ B-DatasetName
datasets. -X- _ O

4.9 -X- _ O
Effect -X- _ O
of -X- _ O
Syntax-Mask -X- _ O

Second, -X- _ O
node -X- _ O
representation -X- _ O
will -X- _ O
be -X- _ O
over-smooth -X- _ O
and -X- _ O
obtain -X- _ O
more -X- _ O
redundancy -X- _ O
information -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
GCN -X- _ O
layers -X- _ O
is -X- _ O
large, -X- _ O
thus -X- _ O
making -X- _ O
model -X- _ O
in -X- _ O
poor -X- _ O
performance. -X- _ O

of -X- _ O
GCN -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
1, -X- _ B-HyperparameterValue
SSEGCN -X- _ B-MethodName
can -X- _ O
only -X- _ O
learn -X- _ O
local -X- _ O
node -X- _ O
information -X- _ O
with -X- _ O
syntactic -X- _ O
distance -X- _ O
of -X- _ O
1. -X- _ O

First, -X- _ O
if -X- _ O
the -X- _ O
number -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4, -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
with -X- _ O
2 -X- _ B-HyperparameterValue
layers. -X- _ B-HyperparameterName

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
investigate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
layer -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
ranging -X- _ O
from -X- _ O
1 -X- _ B-HyperparameterValue
to -X- _ O
5 -X- _ B-HyperparameterValue
on -X- _ O
the -X- _ O
Restaurant -X- _ B-DatasetName
and -X- _ O
Laptop -X- _ B-DatasetName
datasets. -X- _ O

4.8 -X- _ O
Effect -X- _ O
of -X- _ O
SSEGCN -X- _ B-MethodName
Layers -X- _ O

Thus, -X- _ O
SSEGCN -X- _ B-MethodName
can -X- _ O
accurately -X- _ O
find -X- _ O
the -X- _ O
opinion -X- _ O
words -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
aspect -X- _ O
term. -X- _ O

For -X- _ O
sentence -X- _ O
“great -X- _ O
food -X- _ O
but -X- _ O
the -X- _ O
service -X- _ O
was -X- _ O
dreadful!”, -X- _ O
our -X- _ O
model -X- _ O
considers -X- _ O
the -X- _ O
aspect-related -X- _ O
semantic -X- _ O
correlations -X- _ O
by -X- _ O
introducing -X- _ O
aspect-aware -X- _ O
attention -X- _ O
and -X- _ O
combining -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices. -X- _ O

For -X- _ O
the -X- _ O
harder -X- _ O
example -X- _ O
of -X- _ O
multiple -X- _ O
aspects -X- _ O
with -X- _ O
different -X- _ O
sentiment -X- _ O
polarities, -X- _ O
our -X- _ O
model -X- _ O
also -X- _ O
performs -X- _ O
well. -X- _ O

Our -X- _ O
SSEGCN -X- _ B-MethodName
model -X- _ O
considers -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
reduce -X- _ O
the -X- _ O
attention -X- _ O
weight -X- _ O
on -X- _ O
the -X- _ O
word -X- _ O
“friendly” -X- _ O
through -X- _ O
syntactic -X- _ O
distance -X- _ O
mask -X- _ O
and -X- _ O
aspect-aware -X- _ O
attention. -X- _ O

“The -X- _ O
staff -X- _ O
should -X- _ O
be -X- _ O
a -X- _ O
bit -X- _ O
more -X- _ O
friendly.”, -X- _ O
our -X- _ O
model -X- _ O
correctly -X- _ O
identifies -X- _ O
the -X- _ O
sentiment -X- _ O
of -X- _ O
aspect -X- _ O
term -X- _ O
“staff” -X- _ O
as -X- _ O
negative. -X- _ O

For -X- _ O
the -X- _ O
sentence -X- _ O

To -X- _ O
further -X- _ O
demonstrate -X- _ O
how -X- _ O
our -X- _ O
SSEGCN -X- _ B-MethodName
improves -X- _ O
ABSA -X- _ B-TaskName
task, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
two -X- _ O
test -X- _ O
examples -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
to -X- _ O
visualize -X- _ O
attention -X- _ O
scores. -X- _ O

4.7 -X- _ O
Visualization -X- _ O

Additionally, -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
complex -X- _ O
sentences -X- _ O
with -X- _ O
implicit -X- _ O
sentiment -X- _ O
expressions, -X- _ O
our -X- _ O
SSEGCN -X- _ B-MethodName
can -X- _ O
achieve -X- _ O
better -X- _ O
performance. -X- _ O

Our -X- _ O
SSEGCN -X- _ B-MethodName
correctly -X- _ O
predicts -X- _ O
all -X- _ O
the -X- _ O
samples, -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
SSEGCN -X- _ B-MethodName
effectively -X- _ O
combines -X- _ O
syntactic -X- _ O
structure -X- _ O
and -X- _ O
semantic -X- _ O
information. -X- _ O

Thus, -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
learn -X- _ O
integral -X- _ O
semantics -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
a -X- _ O
significant -X- _ O
factor -X- _ O
for -X- _ O
ABSA -X- _ B-TaskName
task. -X- _ O

For -X- _ O
the -X- _ O
sentence -X- _ O
“Not -X- _ O
as -X- _ O
fact -X- _ O
as -X- _ O
I -X- _ O
would -X- _ O
have -X- _ O
expect -X- _ O
for -X- _ O
an -X- _ O
i5”, -X- _ O
CDT -X- _ O
does -X- _ O
not -X- _ O
obtain -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
keyword -X- _ O
“not” -X- _ O
from -X- _ O
a -X- _ O
syntactic -X- _ O
point -X- _ O
of -X- _ O
view -X- _ O
and -X- _ O
thus -X- _ O
produces -X- _ O
wrong -X- _ O
prediction. -X- _ O

The -X- _ O
last -X- _ O
two -X- _ O
examples -X- _ O
have -X- _ O
no -X- _ O
explicit -X- _ O
sentiment -X- _ O
expression. -X- _ O

In -X- _ O
the -X- _ O
third -X- _ O
sample, -X- _ O
the -X- _ O
key -X- _ O
point -X- _ O
is -X- _ O
capturing -X- _ O
the -X- _ O
negated -X- _ O
semantics -X- _ O
which -X- _ O
is -X- _ O
most -X- _ O
methods -X- _ O
tend -X- _ O
to -X- _ O
ignore -X- _ O
and -X- _ O
easily -X- _ O
make -X- _ O
wrong -X- _ O
predictions. -X- _ O

has -X- _ O
the -X- _ O
interfering -X- _ O
word -X- _ O
“Biggest”, -X- _ O
which -X- _ O
may -X- _ O
neutralize -X- _ O
the -X- _ O
polarity -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
“complaint”. -X- _ O

The -X- _ O
second -X- _ O
sample -X- _ O
“Biggest -X- _ O
complaint -X- _ O
is -X- _ O
Windows -X- _ O
8.” -X- _ O

has -X- _ O
two -X- _ O
aspects -X- _ O
(“food” -X- _ O
and -X- _ O
“service”) -X- _ O
with -X- _ O
contrast -X- _ O
sentiment -X- _ O
polarities, -X- _ O
which -X- _ O
may -X- _ O
interfere -X- _ O
with -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
models. -X- _ O

The -X- _ O
first -X- _ O
sample -X- _ O
“great -X- _ O
food -X- _ O
but -X- _ O
the -X- _ O
service -X- _ O
was -X- _ O
dreadful!” -X- _ O

The -X- _ O
notations -X- _ O
P, -X- _ O
N -X- _ O
and -X- _ O
O -X- _ O
in -X- _ O
the -X- _ O
table -X- _ O
represent -X- _ O
positive, -X- _ O
negative -X- _ O
and -X- _ O
neutral -X- _ O
sentiment, -X- _ O
respectively. -X- _ O

Particularly, -X- _ O
we -X- _ O
compare -X- _ O
SSEGCN -X- _ B-MethodName
with -X- _ O
ATAE-LSTM, -X- _ B-MethodName
IAN -X- _ B-MethodName
and -X- _ O
CDT -X- _ B-MethodName
in -X- _ O
Table -X- _ O
4 -X- _ O
which -X- _ O
contain -X- _ O
their -X- _ O
predictions -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
truth -X- _ O
labels -X- _ O
on -X- _ O
these -X- _ O
sentences. -X- _ O

To -X- _ O
examine -X- _ O
whether -X- _ O
SSEGCN -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
syntax -X- _ O
and -X- _ O
semantic -X- _ O
information -X- _ O
for -X- _ O
improving -X- _ B-TaskName
ABSA, -X- _ I-TaskName
we -X- _ O
conduct -X- _ O
case -X- _ O
study -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
of -X- _ O
sample -X- _ O
sentences. -X- _ O

4.6 -X- _ O
Case -X- _ O
Study -X- _ O

In -X- _ O
summary, -X- _ O
the -X- _ O
ablation -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
each -X- _ O
component -X- _ O
contributes -X- _ O
to -X- _ O
our -X- _ O
entire -X- _ O
model. -X- _ O

In -X- _ O
addition, -X- _ O
the -X- _ O
removal -X- _ O
of -X- _ O
syntactic -X- _ O
mask -X- _ O
matrix -X- _ O
and -X- _ O
aspect-aware -X- _ O
attention -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
significant -X- _ O
performance -X- _ O
drop, -X- _ O
which -X- _ O
further -X- _ O
indicates -X- _ O
that -X- _ O
these -X- _ O
two -X- _ O
components -X- _ O
play -X- _ O
crucial -X- _ O
roles -X- _ O
in -X- _ O
SSEGCN -X- _ B-MethodName
for -X- _ O
ABSA -X- _ B-TaskName
task. -X- _ O

Second, -X- _ O
removing -X- _ O
syntactic -X- _ O
mask -X- _ O
matrix -X- _ O
leads -X- _ O
to -X- _ O
dropping -X- _ O
0.90%, -X- _ B-MetricValue
1.42% -X- _ B-MetricValue
and -X- _ O
0.88% -X- _ B-MetricValue
in -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
Restaurant, -X- _ B-DatasetName
Laptop -X- _ B-DatasetName
and -X- _ O
Twitter -X- _ B-DatasetName
respectively, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
syntactic -X- _ O
mask -X- _ O
matrix -X- _ O
can -X- _ O
assist -X- _ O
GCNs -X- _ O
to -X- _ O
learn -X- _ O
better -X- _ O
syntactic -X- _ O
structure -X- _ O
information -X- _ O
in -X- _ O
original -X- _ O
dependency -X- _ O
trees. -X- _ O

tion -X- _ O
between -X- _ O
aspect -X- _ O
and -X- _ O
contextual -X- _ O
words. -X- _ O

It -X- _ O
indicates -X- _ O
that -X- _ O
aspect-aware -X- _ O
attention -X- _ O
is -X- _ O
essential -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
correlated -X- _ O
semantic -X- _ O
informa -X- _ O

We -X- _ O
can -X- _ O
also -X- _ O
notice -X- _ O
that -X- _ O
model -X- _ O
without -X- _ O
aspect-aware -X- _ O
attention -X- _ O
performs -X- _ O
unsatisfactory, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
lacks -X- _ O
of -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
capture -X- _ O
aspect-related -X- _ O
semantics, -X- _ O
resulting -X- _ O
in -X- _ O
1.70%, -X- _ B-MetricValue
1.58% -X- _ B-MetricValue
and -X- _ O
1.47% -X- _ B-MetricValue
reductions -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
Restaurant, -X- _ B-DatasetName
Laptop -X- _ B-DatasetName
and -X- _ O
Twitter, -X- _ B-DatasetName
respectively. -X- _ O

First, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
removal -X- _ O
of -X- _ O
self-attention -X- _ O
degrades -X- _ O
the -X- _ O
performance, -X- _ O
verifying -X- _ O
that -X- _ O
global -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
necessary -X- _ O
for -X- _ O
ABSA. -X- _ B-TaskName

The -X- _ O
basic -X- _ O
SSEGCN -X- _ B-MethodName
is -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
model. -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
conduct -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
examine -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
different -X- _ O
modules -X- _ O
in -X- _ O
SSEGCN. -X- _ B-MethodName

4.5 -X- _ O
Ablation -X- _ O
Study -X- _ O

Combining -X- _ O
our -X- _ O
SSEGCN -X- _ B-MethodName
with -X- _ O
BERT, -X- _ B-MethodName
the -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
this -X- _ O
powerful -X- _ O
model -X- _ O
is -X- _ O
further -X- _ O
improved, -X- _ O
justifying -X- _ O
that -X- _ O
SSEGCN -X- _ B-MethodName
learns -X- _ O
more -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
knowledge -X- _ O
can -X- _ O
empower -X- _ O
ABSA. -X- _ B-TaskName

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
basic -X- _ O
BERT -X- _ B-MethodName
has -X- _ O
been -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
most -X- _ O
ABSA -X- _ B-TaskName
models. -X- _ O

In -X- _ O
GCN-based -X- _ O
models, -X- _ O
our -X- _ O
SSEGCN -X- _ B-MethodName
learns -X- _ O
structure -X- _ O
information -X- _ O
from -X- _ O
local -X- _ O
to -X- _ O
global -X- _ O
and -X- _ O
considers -X- _ O
aspect-related -X- _ O
semantic -X- _ O
information, -X- _ O
and -X- _ O
performs -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
previous -X- _ O
GCN-based -X- _ O
models -X- _ O
(i.e., -X- _ O
CDT, -X- _ B-MethodName
TD-GAT, -X- _ B-MethodName
BiGCN, -X- _ B-MethodName
KuamGCN, -X- _ B-MethodName
R-GAT, -X- _ B-MethodName
DGEDT -X- _ I-MethodName
and -X- _ O
DualGCN) -X- _ B-MethodName
that -X- _ O
verifies -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
fusing -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
information. -X- _ O

In -X- _ O
particular, -X- _ O
GCN-based -X- _ O
models -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
syntactic -X- _ O
structure -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
and -X- _ O
capture -X- _ O
longterm -X- _ O
syntactic -X- _ O
dependencies -X- _ O
between -X- _ O
the -X- _ O
aspect -X- _ O
word -X- _ O
and -X- _ O
the -X- _ O
opinion -X- _ O
word, -X- _ O
hence -X- _ O
outperform -X- _ O
all -X- _ O
attention-based -X- _ O
methods. -X- _ O

Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
SSEGCN -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
datasets. -X- _ O

To -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
SSEGCN, -X- _ B-MethodName
we -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
previous -X- _ O
works -X- _ O
using -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
macro-averaged -X- _ B-MetricName
F1 -X- _ I-MetricName
as -X- _ O
evaluation -X- _ O
metrics, -X- _ O
and -X- _ O
report -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
2. -X- _ O

4.4 -X- _ O
Main -X- _ O
Results -X- _ O

16) -X- _ O
T-GCN -X- _ B-MethodName
(Tian -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
utilizes -X- _ O
dependency -X- _ O
types -X- _ O
to -X- _ O
distinguish -X- _ O
different -X- _ O
relations -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
and -X- _ O
uses -X- _ O
attentive -X- _ O
layer -X- _ O
ensemble -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
contextual -X- _ O
information -X- _ O
from -X- _ O
different -X- _ O
GCN -X- _ O
layers. -X- _ O

15) -X- _ O
BERT4GCN -X- _ B-MethodName
(Zhang -X- _ O
and -X- _ O
Qian, -X- _ O
2020) -X- _ O
integrates -X- _ O
the -X- _ O
grammatical -X- _ O
sequential -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
PLM -X- _ O
of -X- _ O
BERT -X- _ O
and -X- _ O
the -X- _ O
syntactic -X- _ O
knowledge -X- _ O
from -X- _ O
dependency -X- _ O
graphs. -X- _ O

model -X- _ O
based -X- _ O
on -X- _ O
pre-trained -X- _ O
BERT. -X- _ O

14) -X- _ O
DGEDT+BERT -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
is -X- _ O
the -X- _ O
DGEDT -X- _ O

13) -X- _ O
R-GAT+BERT -X- _ B-MethodName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
is -X- _ O
the -X- _ O
RGAT -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
pre-trained -X- _ O
BERT. -X- _ O

12) -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
is -X- _ O
the -X- _ O
vanilla -X- _ O
BERT -X- _ O
model, -X- _ O
which -X- _ O
adopts -X- _ O
“[CLS] -X- _ O
sentence -X- _ O
[SEP] -X- _ O
aspect -X- _ O
[SEP]” -X- _ O
as -X- _ O
input. -X- _ O

11) -X- _ O
DualGCN -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
designs -X- _ O
a -X- _ O
SynGCN -X- _ O
module -X- _ O
and -X- _ O
a -X- _ O
SemGCN -X- _ O
module -X- _ O
with -X- _ O
orthogonal -X- _ O
and -X- _ O
differential -X- _ O
regularizers. -X- _ O

10) -X- _ O
DGEDT -X- _ B-MethodName
(Tang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
proposes -X- _ O
a -X- _ O
dependency -X- _ O
graph -X- _ O
enhanced -X- _ O
dual-transformer -X- _ O
network -X- _ O
by -X- _ O
jointly -X- _ O
considering -X- _ O
the -X- _ O
flat -X- _ O
representations -X- _ O
from -X- _ O
Transformer -X- _ O
and -X- _ O
graph-based -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
dependency -X- _ O
graph. -X- _ O

9) -X- _ O
R-GAT -X- _ B-MethodName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
proposes -X- _ O
a -X- _ O
relational -X- _ O
graph -X- _ O
attention -X- _ O
network -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
new -X- _ O
tree -X- _ O
reshaped -X- _ O
by -X- _ O
an -X- _ O
ordinary -X- _ O
dependency -X- _ O
parse -X- _ O
tree. -X- _ O

8) -X- _ O
kumaGCN -X- _ B-MethodName
(Chen -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
combines -X- _ O
information -X- _ O
from -X- _ O
a -X- _ O
dependency -X- _ O
graph -X- _ O
and -X- _ O
a -X- _ O
latent -X- _ O
graph -X- _ O
to -X- _ O
learn -X- _ O
syntactic -X- _ O
features. -X- _ O

7) -X- _ O
BiGCN -X- _ B-MethodName
(Zhang -X- _ O
and -X- _ O
Qian, -X- _ O
2020) -X- _ O
builds -X- _ O
a -X- _ O
concept -X- _ O
hierarchy -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
syntactic -X- _ O
and -X- _ O
lexical -X- _ O
graphs -X- _ O
for -X- _ O
sentiment -X- _ O
prediction. -X- _ O

6) -X- _ O
TD-GAT -X- _ B-MethodName
(Huang -X- _ O
and -X- _ O
Carley, -X- _ O
2019) -X- _ O
proposes -X- _ O
a -X- _ O
target-dependent -X- _ O
graph -X- _ O
attention -X- _ O
network -X- _ O
for -X- _ O
aspect -X- _ O
level -X- _ O
sentiment -X- _ O
classification, -X- _ O
which -X- _ O
explicitly -X- _ O
utilizes -X- _ O
the -X- _ O
dependency -X- _ O
relationship -X- _ O
among -X- _ O
words. -X- _ O

5) -X- _ O
CDT -X- _ B-MethodName
(Sun -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
utilizes -X- _ O
a -X- _ O
convolution -X- _ O
over -X- _ O
a -X- _ O
dependency -X- _ O
tree -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
sentence -X- _ O
features. -X- _ O

4) -X- _ O
ASGCN -X- _ B-MethodName
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
proposes -X- _ O
to -X- _ O
build -X- _ O
GCN -X- _ O
to -X- _ O
learn -X- _ O
syntactical -X- _ O
information -X- _ O
and -X- _ O
word -X- _ O
dependencies -X- _ O
for -X- _ O
ABSA. -X- _ B-TaskName

3) -X- _ O
TNet -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
employs -X- _ O
a -X- _ O
CNN -X- _ O
model -X- _ O
to -X- _ O
extract -X- _ O
salient -X- _ O
features -X- _ O
from -X- _ O
target-specific -X- _ O
embeddings -X- _ O
by -X- _ O
transformed -X- _ O
BiLSTM -X- _ O
embeddings. -X- _ O

2) -X- _ O
RAM -X- _ B-MethodName
(Chen -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
proposes -X- _ O
a -X- _ O
recurrent -X- _ O
attention -X- _ O
memory -X- _ O
network -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
sentence -X- _ O
representation. -X- _ O

1) -X- _ O
IAN -X- _ B-MethodName
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
interactively -X- _ O
learns -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
aspect -X- _ O
and -X- _ O
their -X- _ O
context. -X- _ O

To -X- _ O
comprehensively -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model, -X- _ O
we -X- _ O
compare -X- _ O
with -X- _ O
state-of-the-art -X- _ O
baselines: -X- _ O

4.3 -X- _ O
Baseline -X- _ O
Comparisons -X- _ O

For -X- _ O
SSEGCN+BERT, -X- _ B-MethodName
we -X- _ O
employ -X- _ O
the -X- _ O
bert-base-uncased3 -X- _ O
English -X- _ O
version. -X- _ O

Our -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.002 -X- _ B-HyperparameterValue
to -X- _ O
optimize -X- _ O
the -X- _ O
parameters. -X- _ O

Besides, -X- _ O
dropout -X- _ O
function -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
word -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
BiLSTM -X- _ O
and -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
as -X- _ O
0.3. -X- _ B-HyperparameterValue

The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
all -X- _ O
model -X- _ O
is -X- _ O
set -X- _ O
as -X- _ O
16 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
GCN -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
is -X- _ O
2. -X- _ B-HyperparameterValue

All -X- _ O
sentences -X- _ O
are -X- _ O
parsed -X- _ O
by -X- _ O
the -X- _ O
Stanford -X- _ O
parser2. -X- _ O

Then, -X- _ O
word -X- _ O
embeddings, -X- _ O
POS -X- _ O
embeddings -X- _ O
and -X- _ O
position -X- _ O
embeddings -X- _ O
are -X- _ O
concatenated -X- _ O
as -X- _ O
input -X- _ O
word -X- _ O
representations. -X- _ O

Additionally, -X- _ O
we -X- _ O
use -X- _ O
30-dimensional -X- _ B-HyperparameterValue
Part-of-Speech -X- _ B-MethodName
(POS) -X- _ I-MethodName
embeddings -X- _ I-MethodName
and -X- _ O
30-dimensional -X- _ B-HyperparameterValue
position -X- _ B-HyperparameterName
embeddings -X- _ I-HyperparameterName
which -X- _ O
is -X- _ O
the -X- _ O
relative -X- _ O
position -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
aspect -X- _ O
term -X- _ O
in -X- _ O
the -X- _ O
sentence. -X- _ O

For -X- _ O
our -X- _ O
experiments, -X- _ O
we -X- _ O
initialize -X- _ O
word -X- _ O
embeddings -X- _ O
with -X- _ O
300-dimensional -X- _ B-HyperparameterValue
Glove -X- _ O
vectors -X- _ O
provided -X- _ O
by -X- _ O
Pennington -X- _ O
et -X- _ O
al. -X- _ O
(2014). -X- _ O

Implementation -X- _ O
Details -X- _ O

4.2 -X- _ O

The -X- _ O
statistics -X- _ O
for -X- _ O
three -X- _ O
datasets -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

Each -X- _ O
aspect -X- _ O
is -X- _ O
labeled -X- _ O
by -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
sentiment -X- _ O
polarities: -X- _ O
positive, -X- _ O
neutral -X- _ O
and -X- _ O
negative. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets -X- _ O
for -X- _ O
aspect-based -X- _ O
sentiment -X- _ O
analysis, -X- _ O
including -X- _ O
Restaurant -X- _ O
and -X- _ O
Laptop -X- _ O
reviews -X- _ O
from -X- _ O
SemEval -X- _ B-DatasetName
2014 -X- _ I-DatasetName
Task -X- _ I-DatasetName
4 -X- _ I-DatasetName
(Pontiki -X- _ O
et -X- _ O
al., -X- _ O
2014) -X- _ O
and -X- _ O
Twitter -X- _ B-DatasetName
(twitter -X- _ O
posts) -X- _ O
from -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O
(2014). -X- _ O

4.1 -X- _ O
Datasets -X- _ O

4 -X- _ O
Experiments -X- _ O

contains -X- _ O
all -X- _ O
the -X- _ O
sentence-aspect -X- _ O
pairs -X- _ O
and -X- _ O
where -X- _ O
a -X- _ O
represents -X- _ O
the -X- _ O
aspect -X- _ O
appearing -X- _ O
in -X- _ O
sentence -X- _ O
s. -X- _ O
θ -X- _ O
represents -X- _ O
all -X- _ O
the -X- _ O
trainable -X- _ O
parameters -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
collection -X- _ O
of -X- _ O
sentiment -X- _ O
polarities. -X- _ O

Finally, -X- _ O
the -X- _ O
standard -X- _ O
cross-entropy -X- _ O
loss -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
our -X- _ O
objective -X- _ O
function: -X- _ O

3.5 -X- _ O
Training -X- _ O

where -X- _ O
Wp -X- _ O
and -X- _ O
bp -X- _ O
are -X- _ O
the -X- _ O
learnable -X- _ O
weight -X- _ O
and -X- _ O
bias. -X- _ O

Moreover, -X- _ O
an -X- _ O
average -X- _ O
pooling -X- _ O
to -X- _ O
retain -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
aspect -X- _ O
term -X- _ O
representation -X- _ O
hl -X- _ O
a. -X- _ O

We -X- _ O
mask -X- _ O
the -X- _ O
non-aspect -X- _ O
words -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
representation -X- _ O
learned -X- _ O
by -X- _ O
the -X- _ O
GCN -X- _ O
layer -X- _ O
to -X- _ O
obtain -X- _ O
aspect -X- _ O
term -X- _ O
representation. -X- _ O

After -X- _ O
aggregating -X- _ O
node -X- _ O
representation -X- _ O
from -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
SSEGCN, -X- _ B-MethodName
we -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
feature -X- _ O
representation. -X- _ O

The -X- _ O
final -X- _ O
output -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
l-layer -X- _ O
GCN -X- _ O
is -X- _ O
H -X- _ O
l -X- _ O
= -X- _ O

where -X- _ O
W -X- _ O
l -X- _ O
is -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
weight, -X- _ O
bl -X- _ O
is -X- _ O
a -X- _ O
bias -X- _ O
term, -X- _ O
and -X- _ O
σ -X- _ O
is -X- _ O
a -X- _ O
nonlinear -X- _ O
function. -X- _ O

Each -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
l-th -X- _ O
GCN -X- _ O
layer -X- _ O
is -X- _ O
updated -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
hidden -X- _ O
representations -X- _ O
of -X- _ O
its -X- _ O
neighborhoods: -X- _ O

Since -X- _ O
we -X- _ O
have -X- _ O
p -X- _ O
different -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices, -X- _ O
p -X- _ O
graph -X- _ O
convolution -X- _ O
operations -X- _ O
over -X- _ O
Amask -X- _ O
∈ -X- _ O
1 -X- _ O
as -X- _ O
the -X- _ O
inRp -X- _ O
× -X- _ O
put -X- _ O
state -X- _ O
and -X- _ O
hl -X- _ O
as -X- _ O
the -X- _ O
output -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
l-th -X- _ O
layer, -X- _ O
h0 -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
sentence -X- _ O
encoding -X- _ O
layer. -X- _ O

3.4 -X- _ O
GCN -X- _ O
Layer -X- _ O

To -X- _ O
obtain -X- _ O
global -X- _ O
information -X- _ O
and -X- _ O
local -X- _ O
feature, -X- _ O
attention -X- _ O
scopes -X- _ O
are -X- _ O
restricted -X- _ O
by -X- _ O
different -X- _ O
syntactic -X- _ O
distances. -X- _ O

The -X- _ O
calculation -X- _ O
of -X- _ O
syntactic -X- _ O
mask -X- _ O
matrix -X- _ O
M -X- _ O
k -X- _ B-HyperparameterName
with -X- _ O
threshold -X- _ B-HyperparameterName
k -X- _ B-HyperparameterName
can -X- _ O
be -X- _ O
formulated -X- _ O
as: -X- _ O

When -X- _ O
syntactic -X- _ O
distance -X- _ O
is -X- _ O
relatively -X- _ O
small, -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
learn -X- _ O
local -X- _ O
information; -X- _ O
on -X- _ O
the -X- _ O
contrary, -X- _ O
if -X- _ O
syntactic -X- _ O
distance -X- _ O
is -X- _ O
relatively -X- _ O
large, -X- _ O
global -X- _ O
structure -X- _ O
information -X- _ O
will -X- _ O
be -X- _ O
considered. -X- _ O

Therefore, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
syntactic -X- _ I-HyperparameterName
mask -X- _ I-HyperparameterName
matrices -X- _ I-HyperparameterName
based -X- _ O
on -X- _ O
different -X- _ O
syntactic -X- _ O
distances -X- _ O
as -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
heads. -X- _ I-HyperparameterName

In -X- _ O
the -X- _ O
previous -X- _ O
part, -X- _ O
the -X- _ O
p-head -X- _ O
attention -X- _ O
mechanism -X- _ O
can -X- _ O
obtain -X- _ O
p -X- _ O
adjacency -X- _ O
matrices. -X- _ O

(4) -X- _ O

D(i, -X- _ O
j) -X- _ O
= -X- _ O
min -X- _ O
d(vi, -X- _ O
vj) -X- _ O

Since -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
paths -X- _ O
between -X- _ O
nodes -X- _ O
on -X- _ O
the -X- _ O
syntactic -X- _ O
dependency -X- _ O
tree, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
distance -X- _ O
of -X- _ O
the -X- _ O
shortest -X- _ O
path -X- _ O
as -X- _ O
D: -X- _ O

Then, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
node -X- _ O
vi -X- _ O
and -X- _ O
vj -X- _ O
as -X- _ O
d(vi, -X- _ O
vj). -X- _ O

We -X- _ O
treat -X- _ O
the -X- _ O
syntactic -X- _ O
dependency -X- _ O
tree -X- _ O
as -X- _ O
an -X- _ O
undirected -X- _ O
graph, -X- _ O
and -X- _ O
each -X- _ O
token -X- _ O
as -X- _ O
a -X- _ O
node. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
first -X- _ O
introduce -X- _ O
the -X- _ O
syntactic -X- _ O
mask -X- _ O
matrix, -X- _ O
and -X- _ O
then -X- _ O
mask -X- _ O
each -X- _ O
fully -X- _ O
connected -X- _ O
graph -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
different -X- _ O
syntactic -X- _ O
distances. -X- _ O

3.3 -X- _ O
Syntax-Mask -X- _ O
Layer -X- _ O

For -X- _ O
each -X- _ O
Ai, -X- _ O
it -X- _ O
represents -X- _ O
a -X- _ O
fully -X- _ O
connected -X- _ O
graph. -X- _ O

n -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
for -X- _ O
the -X- _ O
comwhere -X- _ O
Ai -X- _ O
putation -X- _ O
of -X- _ O
the -X- _ O
later -X- _ O
Syntax-Mask -X- _ O
Layer. -X- _ O

d -X- _ O
and -X- _ O
W -X- _ O
K -X- _ O

Then, -X- _ O
we -X- _ O
integrate -X- _ O
aspect-aware -X- _ O
attention -X- _ O
score -X- _ O
with -X- _ O
self-attention -X- _ O
score: -X- _ O

W -X- _ O
Q -X- _ O
d -X- _ O
are -X- _ O
Rd -X- _ O
× -X- _ O
learnable -X- _ O
weights. -X- _ O

where -X- _ O
Q -X- _ O
and -X- _ O
K -X- _ O
are -X- _ O
both -X- _ O
equal -X- _ O
to -X- _ O
H -X- _ O
produced -X- _ O
by -X- _ O
encoding -X- _ O
layer. -X- _ O

The -X- _ O
calculation -X- _ O
involves -X- _ O
a -X- _ O
query -X- _ O
and -X- _ O
a -X- _ O
key: -X- _ O

3.2.2 -X- _ O
Self-Attention -X- _ O
Similarly, -X- _ O
here -X- _ O
Aself -X- _ O
can -X- _ O
be -X- _ O
constructed -X- _ O
by -X- _ O
utilizing -X- _ O
p-head -X- _ O
self-attention -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
that -X- _ O
captures -X- _ O
the -X- _ O
interaction -X- _ O
between -X- _ O
two -X- _ O
arbitrary -X- _ O
words -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
sentence. -X- _ O

We -X- _ O
propose -X- _ O
the -X- _ O
aspect-aware -X- _ O
attention -X- _ O
mechanism, -X- _ O
which -X- _ O
regards -X- _ O
aspect -X- _ O
term -X- _ O
as -X- _ O
query -X- _ O
to -X- _ O
attention -X- _ O
calculation -X- _ O
for -X- _ O
learning -X- _ O
aspect-related -X- _ O
features: -X- _ O

3.2.1 -X- _ O
Aspect-aware -X- _ O
Attention -X- _ O
Unlike -X- _ O
sentence -X- _ O
level -X- _ O
sentiment -X- _ O
classification -X- _ O
task, -X- _ O
aspect-based -X- _ O
sentiment -X- _ O
classification -X- _ O
aims -X- _ O
at -X- _ O
judging -X- _ O
sentiments -X- _ O
of -X- _ O
one -X- _ O
specific -X- _ O
aspect -X- _ O
term -X- _ O
in -X- _ O
its -X- _ O
context -X- _ O
sentence, -X- _ O
and -X- _ O
thus -X- _ O
calls -X- _ O
for -X- _ O
modeling -X- _ O
particular -X- _ O
semantic -X- _ O
correlation -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
aspect -X- _ O
terms. -X- _ O

Here, -X- _ O
we -X- _ O
construct -X- _ O
p -X- _ B-HyperparameterName
matrices -X- _ O
and -X- _ O
the -X- _ O
p -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
hyper-parameter. -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
multiple -X- _ O
attention -X- _ O
adjacency -X- _ O
matrices. -X- _ O

In -X- _ O
this -X- _ O
subsection, -X- _ O
we -X- _ O
combine -X- _ O
aspect-aware -X- _ O
attention -X- _ O
and -X- _ O
self-attention -X- _ O
for -X- _ O
better -X- _ O
semantic -X- _ O
features. -X- _ O

Attention -X- _ O
mechanism -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
way -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
the -X- _ O
aspect -X- _ O
and -X- _ O
context -X- _ O
words -X- _ O
(Fan -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

3.2 -X- _ O
Attention -X- _ O
Layer -X- _ O

For -X- _ O
the -X- _ O
BERT -X- _ O
encoder, -X- _ O
we -X- _ O
adopt -X- _ O
“[CLS] -X- _ O
sentence -X- _ O
[SEP] -X- _ O
aspect -X- _ O
[SEP]” -X- _ O
as -X- _ O
input. -X- _ O

Take -X- _ O
H -X- _ O
as -X- _ O
initial -X- _ O
nodes -X- _ O
representation -X- _ O
in -X- _ O
SSEGCN. -X- _ B-MethodName

With -X- _ O
the -X- _ O
word -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
sentence, -X- _ O
BiLSTM -X- _ O
is -X- _ O
leveraged -X- _ O
to -X- _ O
produce -X- _ O
hidden -X- _ O
state -X- _ O
vectors -X- _ O
R2d. -X- _ O

Thus, -X- _ O
the -X- _ O
sentence -X- _ O
s -X- _ O
has -X- _ O
corresponding -X- _ O
word -X- _ O
embeddings -X- _ O
x -X- _ O
= -X- _ O
x1, -X- _ O
x2, -X- _ O
..., -X- _ O
xn} -X- _ O
. -X- _ O

We -X- _ O
first -X- _ O
map -X- _ O
each -X- _ O
word -X- _ O
into -X- _ O
a -X- _ O
low-dimensional -X- _ O
real-value -X- _ O
vector -X- _ O
with -X- _ O
embedding -X- _ O
de, -X- _ O
where -X- _ O
matrix -X- _ O
E -X- _ O
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
vocabulary -X- _ O
and -X- _ O
de -X- _ O
denotes -X- _ O
the -X- _ O
dimensionality -X- _ O
of -X- _ O
word -X- _ O
embeddings. -X- _ O

We -X- _ O
utilize -X- _ O
BiLSTM -X- _ O
or -X- _ O
BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
as -X- _ O
sentence -X- _ O
encoder -X- _ O
to -X- _ O
extract -X- _ O
hidden -X- _ O
contextual -X- _ O
representations. -X- _ O

Given -X- _ O
a -X- _ O
sentence-aspect -X- _ O
pair -X- _ O
(s, -X- _ O
a), -X- _ O
where -X- _ O
s -X- _ O
= -X- _ O
a1, -X- _ O
a2, -X- _ O
..., -X- _ O
am} -X- _ O
w1, -X- _ O
w2, -X- _ O
..., -X- _ O
wn} -X- _ O
is -X- _ O
an -X- _ O
as{ -X- _ O
{ -X- _ O
pect -X- _ O
and -X- _ O
also -X- _ O
a -X- _ O
sub-sequence -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
s. -X- _ O

3.1 -X- _ O

Next, -X- _ O
components -X- _ O
of -X- _ O
SSEGCN -X- _ B-MethodName
will -X- _ O
be -X- _ O
introduced -X- _ O
separately -X- _ O
in -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
sections. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
SSEGCN -X- _ B-MethodName
model -X- _ O
which -X- _ O
is -X- _ O
mainly -X- _ O
composed -X- _ O
of -X- _ O
three -X- _ O
components: -X- _ O
the -X- _ O
Input -X- _ O
and -X- _ O
Encoding -X- _ O
Layer, -X- _ O
the -X- _ O
Attention -X- _ O
Layer, -X- _ O
the -X- _ O
Syntax-Mask -X- _ O
Layer -X- _ O
and -X- _ O
the -X- _ O
GCN -X- _ O
Layer. -X- _ O

Figure -X- _ O
2 -X- _ O
gives -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
SSEGCN. -X- _ B-MethodName

3 -X- _ O
Proposed -X- _ O
SSEGCN -X- _ B-MethodName

However, -X- _ O
these -X- _ O
approaches -X- _ O
generally -X- _ O
ignore -X- _ O
the -X- _ O
effective -X- _ O
fusion -X- _ O
of -X- _ O
syntactic -X- _ O
structure -X- _ O
and -X- _ O
semantic -X- _ O
correlation -X- _ O
to -X- _ O
obtain -X- _ O
richer -X- _ O
information. -X- _ O

Tian -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
utilized -X- _ O
dependency -X- _ O
types -X- _ O
and -X- _ O
distinguished -X- _ O
different -X- _ O
relations -X- _ O
in -X- _ O
the -X- _ O
dependency -X- _ O
tree. -X- _ O

Liang -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
constructed -X- _ O
a -X- _ O
sentiment -X- _ O
enhancement -X- _ O
graph -X- _ O
by -X- _ O
integrating -X- _ O
the -X- _ O
sentiment -X- _ O
knowledge -X- _ O
from -X- _ O
SenticNet -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
affective -X- _ O
information -X- _ O
between -X- _ O
opinion -X- _ O
words -X- _ O
and -X- _ O
aspect -X- _ O
term. -X- _ O

Zhang -X- _ O
and -X- _ O
Qian -X- _ O
(2020) -X- _ O
constructed -X- _ O
a -X- _ O
global -X- _ O
lexical -X- _ O
graph -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
word -X- _ O
co-occurrence -X- _ O
relation -X- _ O
and -X- _ O
combined -X- _ O
a -X- _ O
global -X- _ O
lexical -X- _ O
graph -X- _ O
and -X- _ O
a -X- _ O
syntactic -X- _ O
graph. -X- _ O

(2020) -X- _ O
build -X- _ O
aspectfocused -X- _ O
and -X- _ O
inter-aspect -X- _ O
graphs -X- _ O
to -X- _ O
learn -X- _ O
aspectspecific -X- _ O
sentiment -X- _ O
features. -X- _ O

Liang -X- _ O
et -X- _ O
al. -X- _ O

(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Sun -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
stacked -X- _ O
a -X- _ O
GCN -X- _ O
layer -X- _ O
to -X- _ O
extract -X- _ O
rich -X- _ O
representations -X- _ O
over -X- _ O
dependency -X- _ O
tree. -X- _ O

Syntactical -X- _ O
information -X- _ O
can -X- _ O
establish -X- _ O
relation -X- _ O
connections -X- _ O
between -X- _ O
aspect -X- _ O
and -X- _ O
corresponding -X- _ O
opinion -X- _ O
words, -X- _ O
GCN -X- _ O
based -X- _ O
on -X- _ O
dependency -X- _ O
tree -X- _ O
have -X- _ O
achieved -X- _ O
impressive -X- _ O
performance -X- _ O
in -X- _ O
ABSA. -X- _ B-TaskName

Another -X- _ O
trend -X- _ O
explicitly -X- _ O
leverages -X- _ O
dependency -X- _ O
tree. -X- _ O

with -X- _ O
both -X- _ O
orthogonal -X- _ O
regularization -X- _ O
and -X- _ O
sparse -X- _ O
regularization. -X- _ O

1https://github.com/zhangzheng1997/ -X- _ O

(2018) -X- _ O
employed -X- _ O
a -X- _ O
constrained -X- _ O
attention -X- _ O
network -X- _ O

Hu -X- _ O
et -X- _ O
al. -X- _ O

(2018) -X- _ O
designed -X- _ O
a -X- _ O
hierarchical -X- _ O
aspect-specific -X- _ O
attention -X- _ O
model -X- _ O
for -X- _ O
aspect -X- _ O
sentiment -X- _ O
classification. -X- _ O

Wang -X- _ O
et -X- _ O
al. -X- _ O

Ma -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
introduced -X- _ O
an -X- _ O
interactive -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
representations -X- _ O
for -X- _ O
aspects -X- _ O
and -X- _ O
contexts -X- _ O
separately. -X- _ O

Chen -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
proposed -X- _ O
a -X- _ O
multi-layer -X- _ O
attention -X- _ O
network -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
for -X- _ O
the -X- _ O
aspect. -X- _ O

Among -X- _ O
them, -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
utilized -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
concentrate -X- _ O
on -X- _ O
different -X- _ O
parts -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
to -X- _ O
generate -X- _ O
an -X- _ O
attention -X- _ O
vector -X- _ O
for -X- _ O
aspect -X- _ O
sentiment -X- _ O
classification. -X- _ O

Most -X- _ O
recent -X- _ O
researches -X- _ O
solve -X- _ O
aspect-based -X- _ O
sentiment -X- _ O
analysis -X- _ O
by -X- _ O
utilizing -X- _ O
attention-based -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
semantic -X- _ O
correlation -X- _ O
between -X- _ O
context -X- _ O
and -X- _ O
aspect -X- _ O
term -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Chen -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Ma -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Hu -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Huang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Fan -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

Earlier -X- _ O
methods -X- _ O
(Jiang -X- _ O
et -X- _ O
al., -X- _ O
2011; -X- _ O
Kiritchenko -X- _ O
et -X- _ O
al., -X- _ O
2014) -X- _ O
manually -X- _ O
defined -X- _ O
some -X- _ O
syntactic -X- _ O
rules -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
of -X- _ O
aspect -X- _ O
term. -X- _ O

Aspect-based -X- _ B-TaskName
sentiment -X- _ I-TaskName
analysis -X- _ I-TaskName
is -X- _ O
a -X- _ O
fine-grained -X- _ O
sentiment -X- _ O
analysis -X- _ O
task -X- _ O
and -X- _ O
generally -X- _ O
treated -X- _ O
as -X- _ O
a -X- _ O
classification -X- _ O
problem. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

The -X- _ O
code -X- _ O
and -X- _ O
datasets -X- _ O
involved -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
provided -X- _ O
on -X- _ O
Github1. -X- _ O

• -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
SSEGCN -X- _ B-MethodName
model -X- _ O
achieves -X- _ O
the -X- _ O
stateof-the-art -X- _ O
performance. -X- _ O

Meanwhile, -X- _ O
we -X- _ O
construct -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O
to -X- _ O
complement -X- _ O
with -X- _ O
semantic -X- _ O
information. -X- _ O

We -X- _ O
propose -X- _ O
an -X- _ O
aspect-aware -X- _ O
attention -X- _ O
mechanism -X- _ O
combined -X- _ O
with -X- _ O
self-attention -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
aspect-related -X- _ O
semantic -X- _ O
correlations -X- _ O
and -X- _ O
the -X- _ O
global -X- _ O
semantic -X- _ O
of -X- _ O
the -X- _ O
sentence. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
SSEGCN -X- _ B-MethodName
model -X- _ O
that -X- _ O
effectively -X- _ O
integrates -X- _ O
syntactic -X- _ O
structure -X- _ O
and -X- _ O
semantic -X- _ O
correlation -X- _ O
for -X- _ O
ABSA -X- _ B-TaskName
task. -X- _ O

• -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
summarized -X- _ O
as -X- _ O
follows: -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
baselines -X- _ O
and -X- _ O
achieves -X- _ O
new -X- _ O
state-of-the-art -X- _ O
performance. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
approach -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets. -X- _ O

Finally, -X- _ O
a -X- _ O
multilayer -X- _ O
graph -X- _ O
convolution -X- _ O
operation -X- _ O
is -X- _ O
implemented -X- _ O
to -X- _ O
obtain -X- _ O
aspect-specific -X- _ O
features -X- _ O
for -X- _ O
aspect -X- _ O
term -X- _ O
sentiment -X- _ O
classification. -X- _ O

to -X- _ O
enhance -X- _ O
the -X- _ O
conventional -X- _ O
GCN. -X- _ O

Then, -X- _ O
we -X- _ O
combine -X- _ O
adjacency -X- _ O
matrices -X- _ O
with -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O

Besides, -X- _ O
to -X- _ O
fully -X- _ O
utilize -X- _ O
syntactic -X- _ O
structure -X- _ O
to -X- _ O
complement -X- _ O
semantic -X- _ O
information, -X- _ O
rather -X- _ O
than -X- _ O
just -X- _ O
syntactic -X- _ O
first-order -X- _ O
neighbor -X- _ O
node -X- _ O
information, -X- _ O
we -X- _ O
construct -X- _ O
the -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O
calculated -X- _ O
by -X- _ O
the -X- _ O
different -X- _ O
distances -X- _ O
between -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
syntactic -X- _ O
dependency -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
learn -X- _ O
structure -X- _ O
information -X- _ O
from -X- _ O
local -X- _ O
to -X- _ O
global. -X- _ O

We -X- _ O
take -X- _ O
the -X- _ O
obtained -X- _ O
attention -X- _ O
scores -X- _ O
as -X- _ O
the -X- _ O
initial -X- _ O
adjacency -X- _ O
matrices -X- _ O
for -X- _ O
GCN. -X- _ O

The -X- _ O
aspect-aware -X- _ O
attention -X- _ O
learns -X- _ O
aspect-related -X- _ O
semantic -X- _ O
information, -X- _ O
while -X- _ O
selfattention -X- _ O
learns -X- _ O
global -X- _ O
semantic -X- _ O
of -X- _ O
the -X- _ O
sentence. -X- _ O

Secondly, -X- _ O
to -X- _ O
model -X- _ O
particular -X- _ O
semantic -X- _ O
correlations -X- _ O
for -X- _ O
different -X- _ O
aspect -X- _ O
terms, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
aspect-aware -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
combine -X- _ O
with -X- _ O
self-attention. -X- _ O

Firstly, -X- _ O
SSEGCN -X- _ B-MethodName
captures -X- _ O
the -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
with -X- _ O
sentence -X- _ O
encoder. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Syntactic -X- _ B-MethodName
and -X- _ I-MethodName
Semantic -X- _ I-MethodName
Enhanced -X- _ I-MethodName
Graph -X- _ I-MethodName
Convolutional -X- _ I-MethodName
Network -X- _ I-MethodName
(SSEGCN) -X- _ B-MethodName
model -X- _ O
for -X- _ O
integrating -X- _ O
the -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
information -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
above -X- _ O
issues. -X- _ O

It -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
harness -X- _ O
the -X- _ O
aspect-related -X- _ O
semantic -X- _ O
information -X- _ O
for -X- _ O
different -X- _ O
aspect -X- _ O
terms. -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
simply -X- _ O
considering -X- _ O
the -X- _ O
syntactic -X- _ O
structure -X- _ O
of -X- _ O
dependency -X- _ O
tree -X- _ O
might -X- _ O
be -X- _ O
unsatisfactory. -X- _ O

At -X- _ O
the -X- _ O
same -X- _ O
time, -X- _ O
noisy -X- _ O
word -X- _ O
“not” -X- _ O
is -X- _ O
also -X- _ O
obtained -X- _ O
for -X- _ O
aspect -X- _ O
term -X- _ O
“service”. -X- _ O

For -X- _ O
aspect -X- _ O
term -X- _ O
“food”, -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
word -X- _ O
“not” -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
utilizing -X- _ O
two-layer -X- _ O
GCN. -X- _ O

However, -X- _ O
the -X- _ O
“good” -X- _ O
refers -X- _ O
to -X- _ O
another -X- _ O
aspect -X- _ O
“service”. -X- _ O

For -X- _ O
instance, -X- _ O
consider -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
as -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
a -X- _ O
dependency -X- _ O
connection -X- _ O
exists -X- _ O
between -X- _ O
the -X- _ O
aspect -X- _ O
“food” -X- _ O
and -X- _ O
the -X- _ O
opinion -X- _ O
word -X- _ O
“good”. -X- _ O

Recently, -X- _ O
most -X- _ O
methods -X- _ O
apply -X- _ O
multi-layer -X- _ O
GCNs -X- _ O
to -X- _ O
derive -X- _ O
the -X- _ O
expression -X- _ O
of -X- _ O
opinion -X- _ O
words -X- _ O
which -X- _ O
brings -X- _ O
potential -X- _ O
noise. -X- _ O

How -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
secondorder -X- _ O
nodes, -X- _ O
third-order -X- _ O
nodes -X- _ O
and -X- _ O
even -X- _ O
the -X- _ O
global -X- _ O
syntactic -X- _ O
structure -X- _ O
in -X- _ O
one -X- _ O
shot -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
challenge. -X- _ O

Moreover, -X- _ O
some -X- _ O
hard -X- _ O
cases -X- _ O
obscurely -X- _ O
express -X- _ O
sentiment -X- _ O
of -X- _ O
aspect -X- _ O
term, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
direct -X- _ O
syntactic -X- _ O
relationship -X- _ O
between -X- _ O
aspect -X- _ O
term -X- _ O
and -X- _ O
opinion -X- _ O
words. -X- _ O

Notablely, -X- _ O
existing -X- _ O
GCN-based -X- _ O
approaches -X- _ O
do -X- _ O
not -X- _ O
fully -X- _ O
leverage -X- _ O
syntactic -X- _ O
structure, -X- _ O
where -X- _ O
only -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
neighbor -X- _ O
nodes -X- _ O
is -X- _ O
considered. -X- _ O

Following -X- _ O
this -X- _ O
line, -X- _ O
Chen -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
and -X- _ O
Li -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
combine -X- _ O
a -X- _ O
syntactic -X- _ O
structure -X- _ O
graph -X- _ O
with -X- _ O
a -X- _ O
latent -X- _ O
semantic -X- _ O
graph -X- _ O
but -X- _ O
the -X- _ O
two -X- _ O
graphs -X- _ O
are -X- _ O
constructed -X- _ O
independently. -X- _ O

cal -X- _ O
attention -X- _ O
by -X- _ O
only -X- _ O
calculating -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
neighboring -X- _ O
nodes -X- _ O
and -X- _ O
neglects -X- _ O
the -X- _ O
global -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
sentence. -X- _ O

The -X- _ O
attention -X- _ O
mechanism -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
consider -X- _ O
semantic -X- _ O
correlation -X- _ O
of -X- _ O
each -X- _ O
neighbor -X- _ O
node, -X- _ O
but -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
lo -X- _ O

To -X- _ O
tackle -X- _ O
this -X- _ O
problem, -X- _ O
Huang -X- _ O
and -X- _ O
Carley -X- _ O
(2019) -X- _ O
design -X- _ O
a -X- _ O
target-dependent -X- _ O
graph -X- _ O
attention -X- _ O
network -X- _ O
that -X- _ O
updates -X- _ O
each -X- _ O
node -X- _ O
representation -X- _ O
by -X- _ O
utilizing -X- _ O
multi-head -X- _ O
attention. -X- _ O

Accordingly, -X- _ O
noisy -X- _ O
nodes -X- _ O
may -X- _ O
cause -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
misjudge -X- _ O
the -X- _ O
sentiment -X- _ O
polarity. -X- _ O

However, -X- _ O
these -X- _ O
two -X- _ O
studies -X- _ O
treat -X- _ O
all -X- _ O
the -X- _ O
neighbor -X- _ O
nodes -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
equally, -X- _ O
and -X- _ O
are -X- _ O
limited -X- _ O
in -X- _ O
lacking -X- _ O
of -X- _ O
efficient -X- _ O
mechanisms -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
neighbor -X- _ O
nodes. -X- _ O

Sun -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
propose -X- _ O
a -X- _ O
GCN -X- _ O
model -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
feature -X- _ O
representations -X- _ O
of -X- _ O
aspects -X- _ O
learned -X- _ O
by -X- _ O
a -X- _ O
Bi-directional -X- _ O
Long -X- _ O
Short -X- _ O
Term -X- _ O
Memory -X- _ O
(Bi-LSTM). -X- _ O

(2019) -X- _ O
employ -X- _ O
Graph -X- _ O
Convolutional -X- _ O
Network -X- _ O
(GCN) -X- _ O
to -X- _ O
integrate -X- _ O
the -X- _ O
syntactic -X- _ O
information. -X- _ O

In -X- _ O
these -X- _ O
works, -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O

Recent -X- _ O
works -X- _ O
on -X- _ O
ABSA -X- _ B-TaskName
leverage -X- _ O
Graph -X- _ O
Neural -X- _ O
Networks -X- _ O
(GNNs) -X- _ O
over -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
to -X- _ O
exploit -X- _ O
syntactic -X- _ O
structure -X- _ O
(Sun -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zhang -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Liang -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Zhao -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Li -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Tian -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

However, -X- _ O
attention -X- _ O
mechanism -X- _ O
is -X- _ O
vulnerable -X- _ O
to -X- _ O
noise -X- _ O
in -X- _ O
sentences, -X- _ O
i.e., -X- _ O
the -X- _ O
irrelevant -X- _ O
words. -X- _ O

Prior -X- _ O
studies -X- _ O
exploit -X- _ O
attention -X- _ O
mechanism -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Chen -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Ma -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Hu -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Huang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Fan -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
correlations -X- _ O
between -X- _ O
aspect -X- _ O
term -X- _ O
and -X- _ O
the -X- _ O
context. -X- _ O

The -X- _ O
main -X- _ O
idea -X- _ O
of -X- _ O
most -X- _ O
works -X- _ O
is -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
dependency -X- _ O
relation -X- _ O
between -X- _ O
aspects -X- _ O
and -X- _ O
their -X- _ O
associated -X- _ O
opinion -X- _ O
words. -X- _ O

different -X- _ O
aspects. -X- _ O

That -X- _ O
is, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
discriminate -X- _ O
sentiment -X- _ O
polarities -X- _ O
according -X- _ O
to -X- _ O

For -X- _ O
aspect -X- _ O
term -X- _ O
“food”, -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
is -X- _ O
negative, -X- _ O
but -X- _ O
“service” -X- _ O
is -X- _ O
positive. -X- _ O

For -X- _ O
example, -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
ABSA -X- _ B-TaskName
determines -X- _ O
the -X- _ O
sentiment -X- _ O
towards -X- _ O
the -X- _ O
aspects -X- _ O
“food” -X- _ O
and -X- _ O
“service”. -X- _ O

Aspect-based -X- _ B-TaskName
Sentiment -X- _ I-TaskName
Analysis -X- _ I-TaskName
(ABSA) -X- _ B-TaskName
aims -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
aspect -X- _ O
term -X- _ O
in -X- _ O
a -X- _ O
sentence, -X- _ O
where -X- _ O
sentiment -X- _ O
polarity -X- _ O
includes -X- _ O
positive, -X- _ O
negative -X- _ O
and -X- _ O
neutral. -X- _ O

Introduction -X- _ O

Experimental -X- _ O
results -X- _ O
on -X- _ O
benchmark -X- _ O
datasets -X- _ O
illustrate -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
outperforms -X- _ O
state-of-the-art -X- _ O
methods. -X- _ O

Finally, -X- _ O
we -X- _ O
enhance -X- _ O
the -X- _ O
node -X- _ O
representations -X- _ O
with -X- _ O
graph -X- _ O
convolutional -X- _ O
network -X- _ O
over -X- _ O
attention -X- _ O
score -X- _ O
matrices -X- _ O
for -X- _ O
ABSA. -X- _ B-TaskName

Furthermore, -X- _ O
to -X- _ O
combine -X- _ O
syntactic -X- _ O
structure -X- _ O
and -X- _ O
semantic -X- _ O
information, -X- _ O
we -X- _ O
equip -X- _ O
the -X- _ O
attention -X- _ O
score -X- _ O
matrices -X- _ O
by -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
comprehensive -X- _ O
syntactic -X- _ O
structure -X- _ O
information, -X- _ O
we -X- _ O
construct -X- _ O
syntactic -X- _ O
mask -X- _ O
matrices -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
different -X- _ O
syntactic -X- _ O
distances -X- _ O
between -X- _ O
words. -X- _ O

Specifically, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
aspect-aware -X- _ O
attention -X- _ O
mechanism -X- _ O
combined -X- _ O
with -X- _ O
self-attention -X- _ O
to -X- _ O
obtain -X- _ O
attention -X- _ O
score -X- _ O
matrices -X- _ O
of -X- _ O
a -X- _ O
sentence, -X- _ O
which -X- _ O
can -X- _ O
not -X- _ O
only -X- _ O
learn -X- _ O
the -X- _ O
aspect-related -X- _ O
semantic -X- _ O
correlations, -X- _ O
but -X- _ O
also -X- _ O
learn -X- _ O
the -X- _ O
global -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
sentence. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
Syntactic -X- _ B-MethodName
and -X- _ I-MethodName
Semantic -X- _ I-MethodName
Enhanced -X- _ I-MethodName
Graph -X- _ I-MethodName
Convolutional -X- _ I-MethodName
Network -X- _ I-MethodName
(SSEGCN) -X- _ B-MethodName
model -X- _ O
for -X- _ O
ABSA -X- _ B-TaskName
task. -X- _ O

However, -X- _ O
how -X- _ O
to -X- _ O
effectively -X- _ O
harness -X- _ O
the -X- _ O
semantic -X- _ O
and -X- _ O
syntactic -X- _ O
structure -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
remains -X- _ O
a -X- _ O
challenging -X- _ O
research -X- _ O
question. -X- _ O

Recently, -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
based -X- _ O
on -X- _ O
dependency -X- _ O
tree -X- _ O
convey -X- _ O
rich -X- _ O
structural -X- _ O
information -X- _ O
which -X- _ O
is -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
utility -X- _ O
for -X- _ O
ABSA. -X- _ B-TaskName

Aspect-based -X- _ B-TaskName
Sentiment -X- _ I-TaskName
Analysis -X- _ I-TaskName
(ABSA) -X- _ B-TaskName
aims -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
sentiment -X- _ O
polarity -X- _ O
towards -X- _ O
a -X- _ O
particular -X- _ O
aspect -X- _ O
in -X- _ O
a -X- _ O
sentence. -X- _ O

Abstract -X- _ O

SSEGCN: -X- _ B-MethodName
Syntactic -X- _ B-MethodName
and -X- _ I-MethodName
Semantic -X- _ I-MethodName
Enhanced -X- _ I-MethodName
Graph -X- _ I-MethodName
Convolutional -X- _ I-MethodName
Network -X- _ I-MethodName
for -X- _ O
Aspect-based -X- _ B-TaskName
Sentiment -X- _ I-TaskName
Analysis -X- _ I-TaskName

-DOCSTART- -X- O
io/en/latest/. -X- _ O

16https://pytorch-geometric.readthedocs. -X- _ O

nese -X- _ O

15https://huggingface.co/bert-base-chi -X- _ O

ed -X- _ O

13https://github.com/huggingface -X- _ O

Our -X- _ O
models -X- _ O
are -X- _ O
implemented -X- _ O
in -X- _ O
PyTorch -X- _ O
using -X- _ O
the -X- _ O
HuggingFace -X- _ O
library13 -X- _ O
and -X- _ O
their -X- _ O
pretrained -X- _ O

A -X- _ O
Implementation -X- _ O
Details -X- _ O

All -X- _ O
models -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ O
optimiser -X- _ O
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2015), -X- _ O
and -X- _ O
our -X- _ O
experiments -X- _ O
are -X- _ O
run -X- _ O
using -X- _ O
4 -X- _ O
A100 -X- _ O
GPU -X- _ O
with -X- _ O
40GB -X- _ O
Memory. -X- _ O

For -X- _ O
the -X- _ O
user -X- _ O
tree, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
each -X- _ I-HyperparameterName
node -X- _ I-HyperparameterName
hidden -X- _ I-HyperparameterName
features -X- _ I-HyperparameterName
as -X- _ O
256. -X- _ B-HyperparameterValue

[2e− -X- _ B-HyperparameterValue
of -X- _ O
40. -X- _ B-HyperparameterValue

[1e− -X- _ B-HyperparameterValue
For -X- _ O
the -X- _ O
comment -X- _ O
chain, -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
for -X- _ O
twotier -X- _ O
transformer -X- _ O
(comment -X- _ O
chain) -X- _ O
is -X- _ O
tuned -X- _ O
in -X- _ O
the -X- _ O
5] -X- _ B-HyperparameterValue
with -X- _ O
the -X- _ O
maximum -X- _ O
token -X- _ O
length -X- _ O
range -X- _ O

Learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
5] -X- _ B-HyperparameterValue
for -X- _ O
BERT -X- _ O
and -X- _ O
5, -X- _ B-HyperparameterValue
5e− -X- _ B-HyperparameterValue
is -X- _ O
tuned -X- _ O
in -X- _ O
the -X- _ O
range -X- _ O
[1e− -X- _ B-HyperparameterValue
4] -X- _ I-HyperparameterValue
for -X- _ O
GAT -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set. -X- _ O

[0.5, -X- _ B-HyperparameterValue
0.6] -X- _ B-HyperparameterValue
for -X- _ O
GAT -X- _ O
and -X- _ O
0.2 -X- _ B-HyperparameterValue
for -X- _ O
BERT -X- _ O
embeddings. -X- _ O

Graph -X- _ O
neural -X- _ O
networks -X- _ O
are -X- _ O
implemented -X- _ O
with -X- _ O
the -X- _ O
Geometric16 -X- _ O
package. -X- _ O

References -X- _ O

Lin -X- _ O
Tian -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
RMIT -X- _ O
University -X- _ O
Vice-Chancellor -X- _ O
PhD -X- _ O
Scholarship -X- _ O
(VCPS). -X- _ O

This -X- _ O
research -X- _ O
is -X- _ O
supported -X- _ O
partially -X- _ O
by -X- _ O
the -X- _ O
Australian -X- _ O
Research -X- _ O
Council -X- _ O
Discovery -X- _ O
Project -X- _ O
DP200101441. -X- _ O

Acknowledgements -X- _ O

As -X- _ O
such, -X- _ O
we -X- _ O
recommend -X- _ O
these -X- _ O
tools -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
aid, -X- _ O
e.g. -X- _ O
by -X- _ O
ﬁltering -X- _ O
the -X- _ O
enormous -X- _ O
volume -X- _ O
of -X- _ O
data -X- _ O
and -X- _ O
help -X- _ O
human -X- _ O
analysts -X- _ O
to -X- _ O
narrow -X- _ O
down -X- _ O
and -X- _ O
detect -X- _ O
harmful -X- _ O
stories -X- _ O
on -X- _ O
social -X- _ O
media. -X- _ O

If -X- _ O
these -X- _ O
systems -X- _ O
are -X- _ O
deployed -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
to -X- _ O
monitor -X- _ O
user -X- _ O
posts -X- _ O
without -X- _ O
human -X- _ O
oversight, -X- _ O
there -X- _ O
are -X- _ O
implications -X- _ O
when -X- _ O
these -X- _ O
systems -X- _ O
misclassify -X- _ O
(particularly -X- _ O
in -X- _ O
the -X- _ O
false -X- _ O
positive -X- _ O
cases) -X- _ O
and -X- _ O
users -X- _ O
are -X- _ O
wrongfully -X- _ O
accused -X- _ O
for -X- _ O
posting -X- _ O
misinformation. -X- _ O

We -X- _ O
contend -X- _ O
that -X- _ O
while -X- _ O
automatic -X- _ O
rumour -X- _ O
detection -X- _ O
systems -X- _ O
can -X- _ O
beneﬁt -X- _ O
combating -X- _ O
the -X- _ O
spread -X- _ O
of -X- _ O
misinformation, -X- _ O
there -X- _ O
are -X- _ O
potential -X- _ O
risks -X- _ O
to -X- _ O
them. -X- _ O

Ethical -X- _ O
Considerations -X- _ O

DUCK -X- _ B-MethodName
substantially -X- _ O
outperforms -X- _ O
all -X- _ O
benchmark -X- _ O
methods -X- _ O
consistently, -X- _ O
creating -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art. -X- _ O

We -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
comment -X- _ O
network -X- _ O
contains -X- _ O
the -X- _ O
strongest -X- _ O
signal -X- _ O
for -X- _ O
predicting -X- _ O
rumours, -X- _ O
and -X- _ O
social -X- _ O
relations -X- _ O
are -X- _ O
important -X- _ O
for -X- _ O
modelling -X- _ O
the -X- _ O
user -X- _ O
network. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
over -X- _ O
four -X- _ O
popular -X- _ O
rumour -X- _ O
benchmark -X- _ O
datasets -X- _ O
to -X- _ O
evaluate -X- _ O
DUCK. -X- _ B-MethodName

Our -X- _ O
approach -X- _ O
is -X- _ O
unique -X- _ O
in -X- _ O
how -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
comment -X- _ O
as -X- _ O
a -X- _ O
graph -X- _ O
(with -X- _ O
BERT -X- _ O
and -X- _ O
GAT) -X- _ O
and -X- _ O
also -X- _ O
as -X- _ O
a -X- _ O
stream -X- _ O
(with -X- _ O
transformers) -X- _ O
and -X- _ O
the -X- _ O
user -X- _ O
networks -X- _ O
together -X- _ O
with -X- _ O
their -X- _ O
peer -X- _ O
relations -X- _ O
(with -X- _ O
GAT -X- _ O
and -X- _ O
GAE). -X- _ O

We -X- _ O
presented -X- _ O
DUCK, -X- _ B-MethodName
a -X- _ O
social -X- _ O
media -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
approach -X- _ O
that -X- _ O
models -X- _ O
both -X- _ O
the -X- _ O
network -X- _ O
of -X- _ O
users -X- _ O
who -X- _ O
interact -X- _ O
with -X- _ O
a -X- _ O
story -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
their -X- _ O
comments/opinions. -X- _ O

6 -X- _ O
Conclusion -X- _ O

This -X- _ O
ﬁnding -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
what -X- _ O
we -X- _ O
saw -X- _ O
earlier, -X- _ O
where -X- _ O
systems -X- _ O
like -X- _ O
stance-BERT -X- _ B-MethodName
and -X- _ O
BiGCN -X- _ B-MethodName
that -X- _ O
use -X- _ O
comments -X- _ O
tend -X- _ O
to -X- _ O
perform -X- _ O
better. -X- _ O

Results -X- _ O
suggest -X- _ O
that -X- _ O
comment -X- _ O
tree -X- _ O
has -X- _ O
the -X- _ O
largest -X- _ O
impact, -X- _ O
followed -X- _ O
by -X- _ O
comment -X- _ O
chain -X- _ O
as -X- _ O
they -X- _ O
produce -X- _ O
the -X- _ O
largest -X- _ O
performance -X- _ O
drop -X- _ O
when -X- _ O
removed. -X- _ O

To -X- _ O
understand -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
each -X- _ O
module -X- _ O
in -X- _ O
DUCK, -X- _ B-MethodName
we -X- _ O
present -X- _ O
variants -X- _ O
where -X- _ O
we -X- _ O
remove -X- _ O
one -X- _ O
CT -X- _ O
means -X- _ O
comment -X- _ O
tree -X- _ O
remodule, -X- _ O
e.g. -X- _ O
DUCK -X- _ O
moved. -X- _ O

¬ -X- _ O

Here -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
most -X- _ O
systems -X- _ O
struggle -X- _ O
with -X- _ O
the -X- _ O
minority -X- _ O
class -X- _ O
(“F”), -X- _ O
but -X- _ O
our -X- _ O
combined -X- _ O
approach -X- _ O
appears -X- _ O
to -X- _ O
handle -X- _ O
this -X- _ O
well. -X- _ O

Another -X- _ O
thing -X- _ O
of -X- _ O
note -X- _ O
is -X- _ O
CoAID, -X- _ B-DatasetName
the -X- _ O
only -X- _ O
dataset -X- _ O
where -X- _ O
the -X- _ O
class -X- _ O
distribution -X- _ O
is -X- _ O
heavily -X- _ O
imbalanced. -X- _ O

use -X- _ O
the -X- _ O
user -X- _ O
network -X- _ O
(RNN+CNN -X- _ O
and -X- _ O
GCAN), -X- _ O
although -X- _ O
the -X- _ O
strong -X- _ O
performance -X- _ O
of -X- _ O
DUCK -X- _ B-MethodName
indicates -X- _ O
that -X- _ O
combining -X- _ O
both -X- _ O
types -X- _ O
of -X- _ O
information -X- _ O
works -X- _ O
best, -X- _ O
suggesting -X- _ O
that -X- _ O
they -X- _ O
complement -X- _ O
each -X- _ O
other. -X- _ O

“CT”, -X- _ O
“CC” -X- _ O
and -X- _ O
“UT” -X- _ O
denote -X- _ O
comment -X- _ O
tree, -X- _ O
comment -X- _ O
chain -X- _ O
and -X- _ O
user -X- _ O
tree -X- _ O
respectively, -X- _ O
and -X- _ O
“R” -X- _ O
and -X- _ O
“NR” -X- _ O
in -X- _ O
WEIBO -X- _ B-DatasetName
denote -X- _ O
rumour -X- _ O
and -X- _ O
non-rumour. -X- _ O

10https://github.com/majingCUHK/Rumor_R -X- _ O

followers, -X- _ O
and -X- _ O
so -X- _ O
it -X- _ O
uses -X- _ O
GATprf. -X- _ O

9With -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
WEIBO -X- _ B-DatasetName
where -X- _ O
we -X- _ O
can’t -X- _ O
crawl -X- _ O
users’ -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
models -X- _ O
that -X- _ O
use -X- _ O
the -X- _ O
comment -X- _ O
texts -X- _ O
(stance-BERT -X- _ B-MethodName
and -X- _ O
Bi-GCN) -X- _ B-MethodName
tend -X- _ O
to -X- _ O
do -X- _ O
better -X- _ O
than -X- _ O
those -X- _ O
that -X- _ O
only -X- _ O

In -X- _ O
terms -X- _ O
of -X- _ O
datasets, -X- _ O
WEIBO -X- _ B-DatasetName
appears -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
“easier” -X- _ O
dataset, -X- _ O
where -X- _ O
most -X- _ O
systems -X- _ O
produce -X- _ O
a -X- _ O
macro-F1 -X- _ B-MetricName
over -X- _ O
90%. -X- _ B-MetricValue

DUCK -X- _ B-MethodName
(our -X- _ O
model) -X- _ O
performs -X- _ O
very -X- _ O
strongly, -X- _ O
outperforming -X- _ O
all -X- _ O
benchmark -X- _ O
systems -X- _ O
consistently -X- _ O
over -X- _ O
all -X- _ O
datasets, -X- _ O
creating -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

We -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5. -X- _ O

Note -X- _ O
that -X- _ O
we -X- _ O
only -X- _ O
have -X- _ O
English -X- _ O
results -X- _ O
(Twitter15, -X- _ B-DatasetName
Twitter16 -X- _ B-DatasetName
and -X- _ O
CoAID) -X- _ B-DatasetName
for -X- _ O
stanceBERT -X- _ B-MethodName
as -X- _ O
it -X- _ O
uses -X- _ O
stance -X- _ O
annotations -X- _ O
from -X- _ O
SemEval2016 -X- _ O
(Mohammad -X- _ O
et -X- _ O
al., -X- _ O
2016), -X- _ O
and -X- _ O
GCAN -X- _ B-MethodName
and -X- _ O
RNN+CNN -X- _ B-MethodName
do -X- _ O
not -X- _ O
have -X- _ O
results -X- _ O
for -X- _ O
CoAID -X- _ B-DatasetName
as -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
contain -X- _ O
retweets. -X- _ O

All -X- _ O
benchmark -X- _ O
results -X- _ O
are -X- _ O
produced -X- _ O
using -X- _ O
the -X- _ O
author-provided -X- _ O
code, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
RNN+CNN -X- _ B-MethodName
and -X- _ O
stance-BERT -X- _ B-MethodName
where -X- _ O
we -X- _ O
implement -X- _ O
ourselves. -X- _ O

For -X- _ O
a -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
features -X- _ O
used -X- _ O
by -X- _ O
these -X- _ O
benchmark -X- _ O
systems -X- _ O
and -X- _ O
our -X- _ O
model, -X- _ O
see -X- _ O
Table -X- _ O
1. -X- _ O

We -X- _ O
next -X- _ O
compare -X- _ O
the -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
performance -X- _ O
of -X- _ O
DUCK -X- _ B-MethodName
that -X- _ O
combines -X- _ O
comment -X- _ O
tree, -X- _ O
comment -X- _ O
chain -X- _ O
and -X- _ O
user -X- _ O
tree -X- _ O
models -X- _ O
(Figure -X- _ O
1) -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
state-of-the-art -X- _ O
methods: -X- _ O
(1) -X- _ O
RvNN -X- _ B-MethodName
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2018)10: -X- _ O
uses -X- _ O
a -X- _ O
GRU -X- _ O
to -X- _ O
process -X- _ O
text -X- _ O
content -X- _ O
and -X- _ O
recursive -X- _ O
networks -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
comment -X- _ O
network; -X- _ O
(2) -X- _ O
RNN+CNN -X- _ B-MethodName
(Liu -X- _ O
and -X- _ O
Wu, -X- _ O
2018): -X- _ O
uses -X- _ O
CNN -X- _ O
and -X- _ O
RNN -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
retweet -X- _ O
user -X- _ O
network -X- _ O
where -X- _ O
user -X- _ O
representations -X- _ O
are -X- _ O
initialised -X- _ O
with -X- _ O
user -X- _ O
proﬁle -X- _ O
features; -X- _ O
(3) -X- _ O
stance-BERT -X- _ B-MethodName
(Tian -X- _ O
et -X- _ O
al., -X- _ O
2020): -X- _ O
ﬁne-tunes -X- _ O
a -X- _ O
BERT -X- _ O
pretrained -X- _ O
with -X- _ O
stance -X- _ O
annotations -X- _ O
for -X- _ O
rumour -X- _ O
detection -X- _ O
and -X- _ O
comments -X- _ O
are -X- _ O
modelled -X- _ O
as -X- _ O
a -X- _ O
chain -X- _ O
(similar -X- _ O
to -X- _ O
our -X- _ O
one-tier -X- _ O
transformer -X- _ O
model); -X- _ O
(4) -X- _ O
Bi-GCN -X- _ B-MethodName
(Bian -X- _ O
et -X- _ O
al., -X- _ O
2020)11: -X- _ O
uses -X- _ O
a -X- _ O
bidirectional -X- _ O
graph -X- _ O
convolutional -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
comment -X- _ O
network -X- _ O
in -X- _ O
a -X- _ O
top-down -X- _ O
(i.e. -X- _ O
nodes -X- _ O
are -X- _ O
combined -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
leaf -X- _ O
comments) -X- _ O
and -X- _ O
bottom-up -X- _ O
manner -X- _ O
(i.e. -X- _ O
nodes -X- _ O
are -X- _ O
combined -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
root); -X- _ O
and -X- _ O
(5) -X- _ O
GCAN -X- _ B-MethodName
(Lu -X- _ O
and -X- _ O
Li, -X- _ O
2020)12: -X- _ O
uses -X- _ O
graph -X- _ O
networks -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
retweet -X- _ O
user -X- _ O
network -X- _ O
and -X- _ O
a -X- _ O
CNN -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
source -X- _ O
post -X- _ O
with -X- _ O
co-attention -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
networks. -X- _ O

5.2.4 -X- _ O
Overall -X- _ O
Rumour -X- _ B-TaskName
Detection -X- _ I-TaskName

reply -X- _ O
and -X- _ O
retweet -X- _ O
user -X- _ O
network.9 -X- _ O

8For -X- _ O
one-tier -X- _ O
and -X- _ O
two-tier -X- _ O
transformers, -X- _ O
if -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
comments -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
10, -X- _ B-HyperparameterValue
that -X- _ O
means -X- _ O
we -X- _ O
will -X- _ O
concatenate -X- _ O
10 -X- _ O
comments -X- _ O
(with -X- _ O
the -X- _ O
source -X- _ O
post) -X- _ O
into -X- _ O
a -X- _ O
long -X- _ O
string, -X- _ O
and -X- _ O
any -X- _ O
text -X- _ O
that -X- _ O
exceeds -X- _ O
BERT’s -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
will -X- _ O
be -X- _ O
truncated -X- _ O
(and -X- _ O
so -X- _ O
for -X- _ O
some -X- _ O
stories -X- _ O
the -X- _ O
models -X- _ O
may -X- _ O
use -X- _ O
less -X- _ O
than -X- _ O
10 -X- _ O
comments, -X- _ O
if -X- _ O
earlier -X- _ O
comments -X- _ O
are -X- _ O
very -X- _ O
long). -X- _ O

Our -X- _ O
results -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
incorporating -X- _ O
social -X- _ O
relations, -X- _ O
and -X- _ O
DUCK -X- _ B-MethodName
therefore -X- _ O
uses -X- _ O
GATprf+rel -X- _ O
for -X- _ O
modelling -X- _ O
the -X- _ O

Unsurprisingly, -X- _ O
random -X- _ O
initialisation -X- _ O
performs -X- _ O
the -X- _ O
worst, -X- _ O
and -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
substantial -X- _ O
improvement -X- _ O
when -X- _ O
user -X- _ O
proﬁle -X- _ O
information -X- _ O
is -X- _ O
incorporated, -X- _ O
and -X- _ O
again -X- _ O
an -X- _ O
improvement -X- _ O
when -X- _ O
we -X- _ O
incorporate -X- _ O
user -X- _ O
social -X- _ O
relations -X- _ O
(6% -X- _ B-MetricValue
and -X- _ O
5% -X- _ B-MetricValue
increase -X- _ O
in -X- _ B-MetricName
macro-F1 -X- _ I-MetricName
for -X- _ O
Twitter16 -X- _ B-DatasetName
and -X- _ O
CoAID). -X- _ B-DatasetName

Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4. -X- _ O

Recall -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
GAT -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
reply -X- _ O
and -X- _ O
repost -X- _ O
user -X- _ O
network, -X- _ O
and -X- _ O
we -X- _ O
investigate -X- _ O
different -X- _ O
node -X- _ O
encodings -X- _ O
to -X- _ O
initialise -X- _ O
GAT: -X- _ O
(1) -X- _ O
random -X- _ O
initialisation -X- _ O
(GATrnd); -X- _ O
(2) -X- _ O
user -X- _ O
proﬁle -X- _ O
metadata -X- _ O
(GATprf); -X- _ O
and -X- _ O
(3) -X- _ O
user -X- _ O
proﬁle -X- _ O
metadata -X- _ O
and -X- _ O
social -X- _ O
relations -X- _ O
(GATprf+rel). -X- _ O

5.2.3 -X- _ O
User -X- _ O
Tree -X- _ O

With -X- _ O
these -X- _ O
results, -X- _ O
we -X- _ O
will -X- _ O
use -X- _ O
the -X- _ O
two-tier -X- _ O
transformer -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
comment -X- _ O
chain -X- _ O
in -X- _ O
DUCK. -X- _ B-MethodName

Interestingly, -X- _ O
even -X- _ O
though -X- _ O
longformer -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
include -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
comments, -X- _ O
it -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
both -X- _ O
one-tier -X- _ O
and -X- _ O
two-tier -X- _ O
transformer, -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
sparser -X- _ O
attention -X- _ O
pattern -X- _ O
that -X- _ O
longformer -X- _ O
introduces -X- _ O
has -X- _ O
a -X- _ O
negative -X- _ O
impact. -X- _ O

Two-tier -X- _ O
transformer -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
process -X- _ O
more -X- _ O
comments, -X- _ O
and -X- _ O
produces -X- _ O
the -X- _ O
best -X- _ O
performance. -X- _ O

However, -X- _ O
due -X- _ O
to -X- _ O
one-tier -X- _ O
transformer’s -X- _ O
sequence -X- _ O
length -X- _ O
limit, -X- _ O
it -X- _ O
can -X- _ O
take -X- _ O
no -X- _ O
more -X- _ O
than -X- _ O
60 -X- _ O
comments -X- _ O
on -X- _ O
average. -X- _ O

Both -X- _ O
one-tier -X- _ O
and -X- _ O
two-tier -X- _ O
transformers -X- _ O
see -X- _ O
a -X- _ O
performance -X- _ O
gain -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
comments -X- _ O
increases -X- _ O
and -X- _ O
a -X- _ O
drop -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
too -X- _ O
many -X- _ O
comments -X- _ O
(noting -X- _ O
that -X- _ O
the -X- _ O
trend -X- _ O
is -X- _ O
ﬂatter -X- _ O
in -X- _ O
CoAID). -X- _ B-DatasetName

7The -X- _ O
“unpaired” -X- _ O
approach -X- _ O
uses -X- _ O
“all” -X- _ O
as -X- _ O
the -X- _ O
aggregation -X- _ O

5.2.2 -X- _ O
Comment -X- _ O
Chain -X- _ O
Recall -X- _ O
that -X- _ O
we -X- _ O
explore -X- _ O
using -X- _ O
transformer -X- _ O
models -X- _ O
– -X- _ O
one-tier -X- _ O
transformer, -X- _ O
longformer -X- _ O
and -X- _ O
two-tier -X- _ O
trans -X- _ O

Given -X- _ O
these -X- _ O
results, -X- _ O
our -X- _ O
full -X- _ O
model -X- _ O
(DUCK) -X- _ B-MethodName
will -X- _ O
be -X- _ O
using -X- _ O
“all” -X- _ O
as -X- _ O
the -X- _ O
aggregation -X- _ O
method -X- _ O
for -X- _ O
computing -X- _ O
the -X- _ O
comment -X- _ O
graph -X- _ O
representation. -X- _ O

The -X- _ O
answer -X- _ O
is -X- _ O
evidently -X- _ O
yes, -X- _ O
as -X- _ O
we -X- _ O
see -X- _ O
a -X- _ O
substantial -X- _ O
drop -X- _ O
in -X- _ O
performance -X- _ O
when -X- _ O
we -X- _ O
process -X- _ O
the -X- _ O
posts -X- _ O
independently: -X- _ O
“unpaired” -X- _ O
produces -X- _ O
a -X- _ O
macro-F1 -X- _ B-MetricName
of -X- _ O
only -X- _ O
0.83 -X- _ B-MetricValue
in -X- _ O
both -X- _ O
Twitter16 -X- _ B-DatasetName
and -X- _ O
CoAID. -X- _ B-DatasetName

Does -X- _ O
processing -X- _ O
CoAID -X- _ B-DatasetName
drops -X- _ O
to -X- _ O
0.80 -X- _ B-MetricValue
with -X- _ O
the -X- _ O
parent-child -X- _ O
posts -X- _ O
together -X- _ O
with -X- _ O
BERT -X- _ O
help? -X- _ O

We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
root -X- _ O
and -X- _ O
its -X- _ O
immediate -X- _ O
neighbours -X- _ O
contain -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
information, -X- _ O
and -X- _ O
not -X- _ O
including -X- _ O
the -X- _ O
root -X- _ O
node -X- _ O
impacts -X- _ O
the -X- _ O
performance -X- _ O
severely -X- _ O
(both -X- _ O
Twitter16 -X- _ B-DatasetName
and -X- _ O
root). -X- _ O

Comparing -X- _ O
the -X- _ O
aggregation -X- _ O
methods, -X- _ O
“all” -X- _ O
performs -X- _ O
the -X- _ O
best, -X- _ O
followed -X- _ O
by -X- _ O
“N” -X- _ O
and -X- _ O
“root” -X- _ O
(0.88 -X- _ B-MetricValue
vs. -X- _ O
0.87 -X- _ B-MetricValue
vs. -X- _ O
0.86 -X- _ B-MetricValue
in -X- _ O
Twitter16; -X- _ B-DatasetName
0.87 -X- _ B-MetricValue
vs. -X- _ O
0.86 -X- _ B-MetricValue
vs. -X- _ O
0.85 -X- _ B-MetricValue
in -X- _ O
CoAID -X- _ B-DatasetName
in -X- _ O
terms -X- _ O
of -X- _ O
Macro-F1). -X- _ B-MetricName

We -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
this -X- _ O
alternative -X- _ O
model -X- _ O
(“unpaired”)7 -X- _ O
and -X- _ O
the -X- _ O
different -X- _ O
aggregation -X- _ O
methods -X- _ O
(“root”, -X- _ O
“ -X- _ O
root”, -X- _ O
“N” -X- _ O
and -X- _ O
“all”; -X- _ O
equations -X- _ O
3, -X- _ O
4, -X- _ O
5 -X- _ O
and -X- _ O
6 -X- _ O
respectively) -X- _ O
in -X- _ O
Table -X- _ O
3. -X- _ O

That -X- _ O
is, -X- _ O
Equation -X- _ O
1 -X- _ O
is -X- _ O
now -X- _ O
modiﬁed -X- _ O
to: -X- _ O

5.2.1 -X- _ O
Comment -X- _ O
Tree -X- _ O
To -X- _ O
understand -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
using -X- _ O
BERT -X- _ O
for -X- _ O
processing -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
parent-child -X- _ O
posts, -X- _ O
we -X- _ O
present -X- _ O
an -X- _ O
alternative -X- _ O
method -X- _ O
(“unpaired”) -X- _ O
where -X- _ O
we -X- _ O
use -X- _ O
BERT -X- _ O
to -X- _ O
process -X- _ O
each -X- _ O
post -X- _ O
independently -X- _ O
before -X- _ O
feeding -X- _ O
their -X- _ O
[CLS] -X- _ O
representation -X- _ O
to -X- _ O
the -X- _ O
GAT. -X- _ O

All -X- _ O
results -X- _ O
are -X- _ O
an -X- _ O
average -X- _ O
over -X- _ O
5 -X- _ O
runs -X- _ O
(5-fold -X- _ O
cross-validation -X- _ O
for -X- _ O
Twitter15/16 -X- _ B-DatasetName
and -X- _ O
5 -X- _ O
independent -X- _ O
runs -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
for -X- _ O
WEIBO -X- _ B-DatasetName
and -X- _ O
CoAID -X- _ B-DatasetName
following -X- _ O
Ma -X- _ O
et -X- _ O
al. -X- _ O
(2016, -X- _ O
2017); -X- _ O
Cui -X- _ O
and -X- _ O
Lee -X- _ O
(2020)). -X- _ O

In -X- _ O
terms -X- _ O
of -X- _ O
evaluation -X- _ O
metrics, -X- _ O
we -X- _ O
present -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
for -X- _ O
each -X- _ O
class -X- _ O
and -X- _ O
macro-averaged -X- _ B-MetricName
F1 -X- _ I-MetricName
scores -X- _ O
as -X- _ O
the -X- _ O
aggregate -X- _ O
performance. -X- _ O

For -X- _ O
the -X- _ O
ﬁrst -X- _ O
three -X- _ O
questions, -X- _ O
we -X- _ O
present -X- _ O
development -X- _ O
performance -X- _ O
using -X- _ O
Twitter16 -X- _ B-DatasetName
and -X- _ O
CoAID -X- _ B-DatasetName
as -X- _ O
the -X- _ O
representative -X- _ O
datasets -X- _ O
(as -X- _ O
the -X- _ O
trends -X- _ O
are -X- _ O
largely -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
datasets), -X- _ O
while -X- _ O
for -X- _ O
the -X- _ O
ﬁnal -X- _ O
question -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
test -X- _ O
performance -X- _ O
for -X- _ O
all -X- _ O
datasets. -X- _ O

[Overall -X- _ O
performance]: -X- _ O
Do -X- _ O
the -X- _ O
three -X- _ O
different -X- _ O
components -X- _ O
complement -X- _ O
each -X- _ O
other -X- _ O
and -X- _ O
how -X- _ O
does -X- _ O
a -X- _ O
combined -X- _ O
approach -X- _ O
compared -X- _ O
to -X- _ O
existing -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
systems? -X- _ O

• -X- _ O
Q3 -X- _ O
[User -X- _ O
tree]: -X- _ O

• -X- _ O
Q2 -X- _ O
[Comment -X- _ O
chain]: -X- _ O
Does -X- _ O
incorporating -X- _ O
more -X- _ O
comments -X- _ O
help -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
when -X- _ O
modelling -X- _ O
them -X- _ O
as -X- _ O
a -X- _ O
stream -X- _ O
of -X- _ O
posts? -X- _ O

tree]: -X- _ O
Does -X- _ O
incorporating -X- _ O
BERT -X- _ O
to -X- _ O
analyse -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
parent -X- _ O
and -X- _ O
child -X- _ O
posts -X- _ O
help -X- _ O
modelling -X- _ O
the -X- _ O
comment -X- _ O
network, -X- _ O
and -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
way -X- _ O
to -X- _ O
aggregate -X- _ O
comment-pair -X- _ O
encodings -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
comment -X- _ O
graph? -X- _ O

Speciﬁcally, -X- _ O
we -X- _ O
are -X- _ O
interested -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
questions: -X- _ O

For -X- _ O
the -X- _ O
ﬁrst -X- _ O
set -X- _ O
of -X- _ O
results -X- _ O
where -X- _ O
we -X- _ O
evaluate -X- _ O
each -X- _ O
module -X- _ O
independently, -X- _ O
we -X- _ O
feed -X- _ O
their -X- _ O
representations -X- _ O
(i.e. -X- _ O
zct, -X- _ O
zcc -X- _ O
and -X- _ O
zut) -X- _ O
to -X- _ O
an -X- _ O
MLP -X- _ O
layer -X- _ O
to -X- _ O
do -X- _ O
classiﬁcation. -X- _ O

We -X- _ O
ﬁrst -X- _ O
present -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
modules -X- _ O
(comment -X- _ O
tree, -X- _ O
comment -X- _ O
chain -X- _ O
and -X- _ O
user -X- _ O
tree) -X- _ O
separately -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
best -X- _ O
approach -X- _ O
for -X- _ O
modelling -X- _ O
them, -X- _ O
and -X- _ O
then -X- _ O
present -X- _ O
the -X- _ O
ﬁnal -X- _ O
results -X- _ O
where -X- _ O
we -X- _ O
compare -X- _ O
our -X- _ O
full -X- _ O
model -X- _ O
DUCK -X- _ B-MethodName
to -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
benchmark -X- _ O
systems. -X- _ O

5.2 -X- _ O
Results -X- _ O

6For -X- _ O
Twitter15/16 -X- _ B-DatasetName
during -X- _ O
tuning -X- _ O
we -X- _ O
use -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
folds -X- _ O
and -X- _ O
reserve -X- _ O
1/4 -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
as -X- _ O
development -X- _ O
set -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
rest -X- _ O
(3/4) -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data. -X- _ O

s/twitter-api/v1 -X- _ O

5https://developer.twitter.com/en/doc -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
ﬁrst -X- _ O
introduce -X- _ O
the -X- _ O
datasets -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
and -X- _ O
then -X- _ O
present -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
DUCK -X- _ B-MethodName
by -X- _ O
comparing -X- _ O
against -X- _ O
a -X- _ O
number -X- _ O
state-ofthe-art -X- _ O
models. -X- _ O

Additional -X- _ O
implementation -X- _ O
details -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
for -X- _ O
tuning -X- _ O
hyper-parameters.6 -X- _ O

For -X- _ O
CoAID -X- _ B-DatasetName
and -X- _ O
WEIBO, -X- _ B-DatasetName
we -X- _ O
reserve -X- _ O
20% -X- _ O
data -X- _ O
as -X- _ O
test -X- _ O
and -X- _ O
split -X- _ O
the -X- _ O
rest -X- _ O
in -X- _ O
a -X- _ O
ratio -X- _ O
of -X- _ O
4:1 -X- _ B-HyperparameterValue
for -X- _ O
training -X- _ B-HyperparameterName
and -X- _ I-HyperparameterName
development -X- _ I-HyperparameterName
partitions -X- _ I-HyperparameterName
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
test -X- _ O
performance -X- _ O
over -X- _ O
5 -X- _ O
runs -X- _ O
(initialised -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds). -X- _ O

In -X- _ O
terms -X- _ O
of -X- _ O
data -X- _ O
partitioning, -X- _ O
for -X- _ O
Twitter15 -X- _ B-DatasetName
and -X- _ O
Twitter16 -X- _ B-DatasetName
we -X- _ O
follow -X- _ O
previous -X- _ O
studies -X- _ O
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2015, -X- _ O
2016) -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
based -X- _ O
on -X- _ O
5-fold -X- _ O
cross-validation. -X- _ O

For -X- _ O
Twitter-based -X- _ O
datasets -X- _ O
(Twitter15/16 -X- _ B-DatasetName
and -X- _ O
CoAID), -X- _ B-DatasetName
we -X- _ O
crawl -X- _ O
the -X- _ O
tweets -X- _ O
and -X- _ O
additional -X- _ O
user -X- _ O
information -X- _ O
(e.g. -X- _ O
user -X- _ O
proﬁle -X- _ O
metadata -X- _ O
and -X- _ O
followers) -X- _ O
via -X- _ O
the -X- _ O
ofﬁcial -X- _ O
Twitter -X- _ O
API.5 -X- _ O
For -X- _ O
WEIBO, -X- _ B-DatasetName
the -X- _ O
platform -X- _ O
does -X- _ O
not -X- _ O
provide -X- _ O
a -X- _ O
means -X- _ O
to -X- _ O
crawl -X- _ O
social -X- _ O
relations -X- _ O
and -X- _ O
so -X- _ O
the -X- _ O
user -X- _ O
tree -X- _ O
uses -X- _ O
GATprf. -X- _ O

Table -X- _ O
2 -X- _ O
presents -X- _ O
some -X- _ O
statistics -X- _ O
of -X- _ O
these -X- _ O
datasets. -X- _ O

WEIBO -X- _ B-DatasetName
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
contains -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
stories -X- _ O
from -X- _ O
Sina -X- _ O
Weibo, -X- _ O
a -X- _ O
Chinese -X- _ O
social -X- _ O
media -X- _ O
platform, -X- _ O
and -X- _ O
is -X- _ O
annotated -X- _ O
with -X- _ O
two -X- _ O
classes -X- _ O
(rumour -X- _ O
and -X- _ O
non-rumour). -X- _ O

CoAID -X- _ B-DatasetName
(Cui -X- _ O
and -X- _ O
Lee, -X- _ O
2020) -X- _ O
collects -X- _ O
of -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
COVID-19 -X- _ O
news -X- _ O
articles -X- _ O
shared -X- _ O
on -X- _ O
Twitter, -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
annotated -X- _ O
with -X- _ O
two -X- _ O
classes -X- _ O
(true -X- _ O
or -X- _ O
fake). -X- _ O

Twitter15 -X- _ B-DatasetName
and -X- _ O
Twitter16 -X- _ B-DatasetName
are -X- _ O
Twitter -X- _ O
datasets -X- _ O
with -X- _ O
four -X- _ O
rumour -X- _ O
classes: -X- _ O
true -X- _ O
rumour, -X- _ O
false -X- _ O
rumour, -X- _ O
non-rumour -X- _ O
and -X- _ O
unveriﬁed -X- _ O
rumour. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
four -X- _ O
widely -X- _ O
used -X- _ O
rumour -X- _ O
datasets: -X- _ O
Twitter15 -X- _ B-DatasetName
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2017); -X- _ O
Twitter16 -X- _ B-DatasetName
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2017); -X- _ O
CoAID -X- _ B-DatasetName
(Cui -X- _ O
and -X- _ O
Lee, -X- _ O
2020); -X- _ O
and -X- _ O
WEIBO -X- _ B-DatasetName
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2016). -X- _ O

5 -X- _ O
Experiments -X- _ O
and -X- _ O
Results -X- _ O

where -X- _ O
n -X- _ O
denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
instances. -X- _ O

Given -X- _ O
an -X- _ O
optimal -X- _ O
approach -X- _ O
for -X- _ O
each -X- _ O
module -X- _ O
(Section -X- _ O
5), -X- _ O
DUCK -X- _ B-MethodName
combines -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
all -X- _ O
modules -X- _ O
to -X- _ O
classify -X- _ O
a -X- _ O
source -X- _ O
post -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
standard -X- _ O
crossentropy -X- _ O
loss. -X- _ O

In -X- _ O
each -X- _ O
module -X- _ O
(comment -X- _ O
tree, -X- _ O
comment -X- _ O
chain -X- _ O
and -X- _ O
user -X- _ O
tree), -X- _ O
we -X- _ O
explore -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
approaches -X- _ O
to -X- _ O
model -X- _ O
its -X- _ O
structure -X- _ O
(e.g. -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
ways -X- _ O
to -X- _ O
aggregate -X- _ O
the -X- _ O
node -X- _ O
encodings -X- _ O
to -X- _ O
produce -X- _ O
zct -X- _ O
for -X- _ O
the -X- _ O
comment -X- _ O
tree -X- _ O
and -X- _ O
3 -X- _ O
different -X- _ O
methods -X- _ O
to -X- _ O
produce -X- _ O
zcc -X- _ O
for -X- _ O
the -X- _ O
comment -X- _ O
chain). -X- _ O

The -X- _ O
output -X- _ O
of -X- _ O
our -X- _ O
decoder -X- _ O
is -X- _ O
a -X- _ O
reconstructed -X- _ O
adjacency -X- _ O
matrix -X- _ O
ˆA. -X- _ O
Formally: -X- _ O

The -X- _ O
decoder -X- _ O
is -X- _ O
deﬁned -X- _ O
by -X- _ O
an -X- _ O
inner -X- _ O
product -X- _ O
between -X- _ O
latent -X- _ O
variable -X- _ O
Z. -X- _ O

It -X- _ O
takes -X- _ O
an -X- _ O
adjacency -X- _ O
matrix -X- _ O
A -X- _ O
and -X- _ O
a -X- _ O
feature -X- _ O
matrix -X- _ O
X -X- _ O
as -X- _ O
inputs -X- _ O
and -X- _ O
generates -X- _ O
the -X- _ O
latent -X- _ O
variable -X- _ O
Z -X- _ O
as -X- _ O
output. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
two-layer -X- _ O
GCN -X- _ O
as -X- _ O
the -X- _ O
encoder. -X- _ O

Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
transformad, -X- _ O
which -X- _ O
converts -X- _ O
users -X- _ O
to -X- _ O
a -X- _ O
tion -X- _ O
matrix -X- _ O
Z -X- _ O
latent -X- _ O
space -X- _ O
with -X- _ O
the -X- _ O
dimensionality -X- _ B-HyperparameterName
of -X- _ O
d. -X- _ B-HyperparameterName

Given -X- _ O
the -X- _ O
social -X- _ O
graph -X- _ O
Gs -X- _ O
constructed -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
data, -X- _ O
we -X- _ O
can -X- _ O
derive -X- _ O
an -X- _ O
adjacency -X- _ O
man, -X- _ O
where -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
users. -X- _ O

4944 -X- _ O

4For -X- _ O
the -X- _ O
unseen -X- _ O
or -X- _ O
isolated -X- _ O
users, -X- _ O
we -X- _ O
initialise -X- _ O
them -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
user -X- _ O
features -X- _ O
(used -X- _ O
in -X- _ O
GATprf), -X- _ O
and -X- _ O
project -X- _ O
them -X- _ O
via -X- _ O
a -X- _ O
learned -X- _ O
matrix -X- _ O
into -X- _ O
the -X- _ O
same -X- _ O
space -X- _ O
as -X- _ O
the -X- _ O
GAE-initialised -X- _ O
user -X- _ O
nodes. -X- _ O

3The -X- _ O
last -X- _ O
feature -X- _ O
is -X- _ O
technically -X- _ O
not -X- _ O
user -X- _ O
proﬁle -X- _ O
information, -X- _ O
but -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
user -X- _ O
characteristic -X- _ O
as -X- _ O
it -X- _ O
captures -X- _ O
how -X- _ O
quickly -X- _ O
they -X- _ O
engage -X- _ O
with -X- _ O
a -X- _ O
post. -X- _ O

The -X- _ O
idea -X- _ O
for -X- _ O
using -X- _ O
GAE-learned -X- _ O
encodings -X- _ O
to -X- _ O
initialise -X- _ O
user -X- _ O
nodes -X- _ O
is -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
more -X- _ O
informative, -X- _ O
since -X- _ O
they -X- _ O
capture -X- _ O
information -X- _ O
about -X- _ O
a -X- _ O
user -X- _ O
and -X- _ O
their -X- _ O
peers. -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
network -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
GAT -X- _ O
and -X- _ O
GAE -X- _ O
is -X- _ O
intrinsically -X- _ O
different -X- _ O
— -X- _ O
the -X- _ O
former -X- _ O
captures -X- _ O
the -X- _ O
users -X- _ O
that -X- _ O
engage -X- _ O
with -X- _ O
a -X- _ O
source -X- _ O
post -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
the -X- _ O
network -X- _ O
of -X- _ O
users -X- _ O
who -X- _ O
follow -X- _ O
one -X- _ O
another. -X- _ O

Intuitively, -X- _ O
GAE -X- _ O
is -X- _ O
an -X- _ O
unsupervised -X- _ O
graph -X- _ O
learning -X- _ O
algorithm -X- _ O
that -X- _ O
takes -X- _ O
in -X- _ O
an -X- _ O
adjacency -X- _ O
matrix -X- _ O
as -X- _ O
input, -X- _ O
and -X- _ O
learns -X- _ O
node -X- _ O
representations -X- _ O
that -X- _ O
can -X- _ O
reconstruct -X- _ O
the -X- _ O
adjacency -X- _ O
matrix -X- _ O
in -X- _ O
the -X- _ O
output. -X- _ O

GATprf+rel: -X- _ O
This -X- _ O
method -X- _ O
initialises -X- _ O
the -X- _ O
user -X- _ O
nodes -X- _ O
with -X- _ O
representations -X- _ O
learned -X- _ O
by -X- _ O
a -X- _ O
variational -X- _ O
graph -X- _ O
autoencoder -X- _ O
(GAE; -X- _ O
Kipf -X- _ O
and -X- _ O
Welling -X- _ O
(2016)) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
user -X- _ O
features -X- _ O
(deﬁned -X- _ O
above) -X- _ O
and -X- _ O
their -X- _ O
social -X- _ O
relations -X- _ O
(based -X- _ O
on -X- _ O
“follow” -X- _ O
relations).4 -X- _ O

GATprf: -X- _ O
Following -X- _ O
Liu -X- _ O
and -X- _ O
Wu -X- _ O
(2018), -X- _ O
this -X- _ O
method -X- _ O
initialises -X- _ O
the -X- _ O
user -X- _ O
nodes -X- _ O
based -X- _ O
on -X- _ O
features -X- _ O
derived -X- _ O
from -X- _ O
their -X- _ O
user -X- _ O
proﬁles: -X- _ O
username, -X- _ O
user -X- _ O
screen -X- _ O
name, -X- _ O
user -X- _ O
description, -X- _ O
user -X- _ O
account -X- _ O
age, -X- _ O
number -X- _ O
of -X- _ O
followers -X- _ O
and -X- _ O
following -X- _ O
users, -X- _ O
number -X- _ O
of -X- _ O
posts -X- _ O
and -X- _ O
favourite -X- _ O
posts, -X- _ O
whether -X- _ O
the -X- _ O
proﬁle -X- _ O
is -X- _ O
protected, -X- _ O
whether -X- _ O
the -X- _ O
account -X- _ O
is -X- _ O
GPS-enabled, -X- _ O
and -X- _ O
the -X- _ O
time -X- _ O
difference -X- _ O
with -X- _ O
the -X- _ O
source -X- _ O
post.3 -X- _ O
Thus, -X- _ O
the -X- _ O
static -X- _ O
user -X- _ O
node -X- _ O
h0 -X- _ O
Rk -X- _ O
from -X- _ O
user -X- _ O
proﬁles -X- _ O

tialise -X- _ O
the -X- _ O
user -X- _ O
nodes -X- _ O
with -X- _ O
random -X- _ O
vectors. -X- _ O

GATrnd: -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
base -X- _ O
method -X- _ O
where -X- _ O
we -X- _ O
ini -X- _ O

i -X- _ O

): -X- _ O

is -X- _ O
in -X- _ O
how -X- _ O
they -X- _ O
initialise -X- _ O
the -X- _ O
user -X- _ O
nodes -X- _ O
(h(0) -X- _ O

The -X- _ O
main -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
three -X- _ O
methods -X- _ O

2018) -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
network -X- _ O
(following -X- _ O
Equation -X- _ O
2), -X- _ O
and -X- _ O
we -X- _ O
aggregate -X- _ O
the -X- _ O
node -X- _ O
encodings -X- _ O
by -X- _ O
meanpooling -X- _ O
over -X- _ O
all -X- _ O
nodes -X- _ O
to -X- _ O
produce -X- _ O
the -X- _ O
graph -X- _ O
representation: -X- _ O

model_doc/longformer.html -X- _ O

2https://huggingface.co/transformers/ -X- _ O

All -X- _ O
methods -X- _ O
use -X- _ O
a -X- _ O
GAT -X- _ O
(Veliˇckovi´c -X- _ O
et -X- _ O
al., -X- _ O

We -X- _ O
explore -X- _ O
three -X- _ O
methods -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
user -X- _ O
network. -X- _ O

Note -X- _ O
that -X- _ O
unlike -X- _ O
previous -X- _ O
studies, -X- _ O
our -X- _ O
user -X- _ O
network -X- _ O
captures -X- _ O
all -X- _ O
users -X- _ O
who -X- _ O
reply -X- _ O
to -X- _ O
or -X- _ O
repost -X- _ O
the -X- _ O
source -X- _ O
post -X- _ O
(previous -X- _ O
studies -X- _ O
use -X- _ O
only -X- _ O
the -X- _ O
reposts, -X- _ O
see -X- _ O
Table -X- _ O
1). -X- _ O

Previous -X- _ O
studies -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
user -X- _ O
characteristics -X- _ O
are -X- _ O
different -X- _ O
for -X- _ O
those -X- _ O
that -X- _ O
engage -X- _ O
with -X- _ O
rumours -X- _ O
vs. -X- _ O
those -X- _ O
who -X- _ O
don’t -X- _ O
(Vosoughi -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Shu -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
motivating -X- _ O
us -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
user -X- _ O
network. -X- _ O

Moving -X- _ O
away -X- _ O
from -X- _ O
the -X- _ O
post -X- _ O
content, -X- _ O
here -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
network -X- _ O
of -X- _ O
users -X- _ O
that -X- _ O
interact -X- _ O
with -X- _ O
a -X- _ O
source -X- _ O
post -X- _ O
(“user -X- _ O
tree” -X- _ O
in -X- _ O
Figure -X- _ O
1). -X- _ O

4.3 -X- _ O
User -X- _ O
Tree -X- _ O

The -X- _ O
secondtier -X- _ O
transformer -X- _ O
has -X- _ O
a -X- _ O
similar -X- _ O
architecture -X- _ O
to -X- _ O
BERT, -X- _ O
but -X- _ O
has -X- _ O
only -X- _ O
2 -X- _ O
layers -X- _ O
and -X- _ O
its -X- _ O
parameters -X- _ O
are -X- _ O
initialised -X- _ O
randomly. -X- _ O

where -X- _ O
BERT -X- _ O
and -X- _ O
transformer -X- _ O
denote -X- _ O
the -X- _ O
ﬁrst- -X- _ O
and -X- _ O
second-tier -X- _ O
transformers -X- _ O
respectively. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
pretrained -X- _ O
longformer2, -X- _ O
and -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
approach -X- _ O
as -X- _ O
before -X- _ O
for -X- _ O
modelling -X- _ O
the -X- _ O
comment -X- _ O
chain: -X- _ O

Longformer -X- _ O
has -X- _ O
a -X- _ O
similar -X- _ O
architecture -X- _ O
as -X- _ O
the -X- _ O
onetier -X- _ O
transformer, -X- _ O
but -X- _ O
uses -X- _ O
a -X- _ O
sparser -X- _ O
attention -X- _ O
pattern -X- _ O
to -X- _ O
process -X- _ O
longer -X- _ O
sequences -X- _ O
more -X- _ O
efﬁciently. -X- _ O

the -X- _ O
sequence -X- _ O
length -X- _ O
limit, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
using -X- _ O
a -X- _ O
longformer, -X- _ O
which -X- _ O
can -X- _ O
process -X- _ O
up -X- _ O
to -X- _ O
4,096 -X- _ O
subwords, -X- _ O
allowing -X- _ O
us -X- _ O
to -X- _ O
use -X- _ O
most -X- _ O
if -X- _ O
not -X- _ O
all -X- _ O
the -X- _ O
comments. -X- _ O

Longformer: -X- _ O
To -X- _ O
circumvent -X- _ O

where -X- _ O
m0 -X- _ O
(< -X- _ O
m) -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
comments -X- _ O
we -X- _ O
can -X- _ O
incorporate -X- _ O
without -X- _ O
exceeding -X- _ O
BERT’s -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
(384 -X- _ O
in -X- _ O
our -X- _ O
experiments). -X- _ O

and -X- _ O
use -X- _ O
the -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
[CLS] -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
ﬁnal -X- _ O
representation: -X- _ O

BERT -X- _ O

Dynamic -X- _ O
Node -X- _ O
Encoding -X- _ O

One-tier -X- _ O
transformer: -X- _ O
Given -X- _ O
a -X- _ O
source -X- _ O
post -X- _ O
(c0) -X- _ O
c1, -X- _ O
..., -X- _ O
cm} -X- _ O
and -X- _ O
the -X- _ O
comments -X- _ O
( -X- _ O
), -X- _ O
we -X- _ O
simply -X- _ O
con{ -X- _ O
catenate -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
long -X- _ O
string -X- _ O
and -X- _ O
feed -X- _ O
it -X- _ O
to -X- _ O
BERT -X- _ O

We -X- _ O
explore -X- _ O
three -X- _ O
ways -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
comment -X- _ O
chain, -X- _ O
using: -X- _ O
(1) -X- _ O
one-tier -X- _ O
transformer; -X- _ O
(2) -X- _ O
longformer -X- _ O
(Beltagy -X- _ O
et -X- _ O
al., -X- _ O
2020); -X- _ O
and -X- _ O
(3) -X- _ O
two-tier -X- _ O
transformer. -X- _ O

As -X- _ O
such, -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
chain -X- _ O
or -X- _ O
list -X- _ O
structure -X- _ O
(rather -X- _ O
than -X- _ O
a -X- _ O
tree -X- _ O
structure); -X- _ O
see -X- _ O
“comment -X- _ O
chain” -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

Here -X- _ O
we -X- _ O
model -X- _ O
the -X- _ O
posts -X- _ O
as -X- _ O
a -X- _ O
stream -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
they -X- _ O
are -X- _ O
posted. -X- _ O

all: -X- _ O
Mean-pooling -X- _ O
of -X- _ O
all -X- _ O
nodes: -X- _ O

diate -X- _ O
neighbours: -X- _ O

N: -X- _ O
Mean-pooling -X- _ O
of -X- _ O
the -X- _ O
root -X- _ O
node -X- _ O
and -X- _ O
its -X- _ O
imme -X- _ O

where -X- _ O
m -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
replies/comments. -X- _ O

¬ -X- _ O
root: -X- _ O

root: -X- _ O
Mean-pooling -X- _ O
over -X- _ O
all -X- _ O
nodes -X- _ O
except -X- _ O
the -X- _ O

where -X- _ O
L -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
GAT -X- _ O
iterations. -X- _ O

root: -X- _ O
Uses -X- _ O
the -X- _ O
root -X- _ O
encoding -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
graph -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
post -X- _ O
is -X- _ O
ultimately -X- _ O
what -X- _ O
we -X- _ O
are -X- _ O
classifying: -X- _ O

representation -X- _ O
(zct), -X- _ O
we -X- _ O
explore -X- _ O
four -X- _ O
methods: -X- _ O

To -X- _ O
aggregate -X- _ O
the -X- _ O
node -X- _ O
encodings -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
graph -X- _ O

Note -X- _ O
that -X- _ O
h(0) -X- _ O
represents -X- _ O
the -X- _ O
encodings -X- _ O
produced -X- _ O
by -X- _ O
BERT -X- _ O
(Equation -X- _ O
1). -X- _ O

neighbours -X- _ O
of -X- _ O
node -X- _ O
i, -X- _ O
e(l) -X- _ O
ij -X- _ O
the -X- _ O
unnormalised -X- _ O
attention -X- _ O
score -X- _ O
between -X- _ O
node -X- _ O
i -X- _ O
and -X- _ O
j, -X- _ O
and -X- _ O
a -X- _ O
and -X- _ O
W -X- _ O
are -X- _ O
learnable -X- _ O
parameters. -X- _ O

1Preliminary -X- _ O
experiments -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
pseudo -X- _ O
pair -X- _ O
is -X- _ O
important -X- _ O
because -X- _ O
it -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
maintain -X- _ O
the -X- _ O
original -X- _ O
network -X- _ O
structure. -X- _ O

 -X- _ O
(2) -X- _ O
where -X- _ O
LR -X- _ O
denotes -X- _ O
the -X- _ O
LeakyReLU -X- _ O
activation -X- _ O
func(i) -X- _ O
the -X- _ O
the -X- _ O
concatenation -X- _ O
operation, -X- _ O
tion, -X- _ O

Different -X- _ O
from -X- _ O
graph -X- _ O
convolutional -X- _ O
networks -X- _ O
(Kipf -X- _ O
and -X- _ O
Welling, -X- _ O
2017), -X- _ O
GAT -X- _ O
iteratively -X- _ O
learns -X- _ O
node -X- _ O
encodings -X- _ O
via -X- _ O
multihead -X- _ O
attention -X- _ O
with -X- _ O
neighbouring -X- _ O
nodes, -X- _ O
and -X- _ O
has -X- _ O
the -X- _ O
advantage -X- _ O
to -X- _ O
infer -X- _ O
encodings -X- _ O
for -X- _ O
new -X- _ O
nodes -X- _ O
after -X- _ O
it -X- _ O
is -X- _ O
trained. -X- _ O

To -X- _ O
model -X- _ O
the -X- _ O
conversational -X- _ O
network -X- _ O
structure, -X- _ O
we -X- _ O
use -X- _ O
graph -X- _ O
attentional -X- _ O
networks -X- _ O
(GAT; -X- _ O
(Veliˇckovi´c -X- _ O
et -X- _ O
al., -X- _ O
2018)). -X- _ O

where -X- _ O
c -X- _ O
represents -X- _ O
the -X- _ O
text, -X- _ O
emb() -X- _ O
the -X- _ O
embedding -X- _ O
function -X- _ O
and -X- _ O
h -X- _ O
the -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
[CLS] -X- _ O
token -X- _ O
produced -X- _ O
by -X- _ O
BERT. -X- _ O

post.1 -X- _ O
Formally: -X- _ O

Using -X- _ O
the -X- _ O
comment -X- _ O
tree -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
as -X- _ O
an -X- _ O
example, -X- _ O
this -X- _ O
means -X- _ O
we -X- _ O
would -X- _ O
ﬁrst -X- _ O
process -X- _ O
the -X- _ O
following -X- _ O
pairs -X- _ O
of -X- _ O
posts -X- _ O
using -X- _ O
(0, -X- _ O
0), -X- _ O
(0, -X- _ O
1), -X- _ O
(0, -X- _ O
2), -X- _ O
(2, -X- _ O
6), -X- _ O
(2, -X- _ O
7), -X- _ O
(6, -X- _ O
9) -X- _ O
BERT: -X- _ O
, -X- _ O
} -X- _ O
{ -X- _ O
where -X- _ O
(0, -X- _ O
0) -X- _ O
is -X- _ O
a -X- _ O
pseudo -X- _ O
pair -X- _ O
created -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O

The -X- _ O
self-attention -X- _ O
mechanism -X- _ O
between -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
parent -X- _ O
and -X- _ O
child -X- _ O
posts -X- _ O
would -X- _ O
produce -X- _ O
a -X- _ O
more -X- _ O
ﬁne-grained -X- _ O
analysis -X- _ O
of -X- _ O
their -X- _ O
relationship, -X- _ O
which -X- _ O
representations -X- _ O
such -X- _ O
as -X- _ O
bag-of-words -X- _ O
cannot -X- _ O
model. -X- _ O

We -X- _ O
ﬁrst -X- _ O
process -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
parentchild -X- _ O
posts -X- _ O
with -X- _ O
BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
before -X- _ O
feeding -X- _ O
them -X- _ O
to -X- _ O
a -X- _ O
graph -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
full -X- _ O
conversational -X- _ O
structure. -X- _ O

To -X- _ O
capture -X- _ O
the -X- _ O
relations -X- _ O
of -X- _ O
crowd -X- _ O
opinions -X- _ O
in -X- _ O
the -X- _ O
comment -X- _ O
tree, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
(BERT; -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019)) -X- _ O
and -X- _ O
graph -X- _ O
attention -X- _ O
network -X- _ O
(GAT; -X- _ O
(Vieweg -X- _ O
et -X- _ O
al., -X- _ O
2010)) -X- _ O
to -X- _ O
model -X- _ O
comment -X- _ O
tree; -X- _ O
see -X- _ O
Figure -X- _ O
2 -X- _ O
for -X- _ O
an -X- _ O
illustration. -X- _ O

Previous -X- _ O
studies -X- _ O
typically -X- _ O
model -X- _ O
this -X- _ O
via -X- _ O
graph -X- _ O
networks, -X- _ O
but -X- _ O
most -X- _ O
use -X- _ O
simple -X- _ O
features -X- _ O
(e.g. -X- _ O
bag-of-words) -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
text -X- _ O
(Bian -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
which -X- _ O
fail -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
nuanced -X- _ O
relationships -X- _ O
(e.g. -X- _ O
agreement) -X- _ O
between -X- _ O
a -X- _ O
parent -X- _ O
post -X- _ O
and -X- _ O
its -X- _ O
child/reply -X- _ O
post. -X- _ O

Here -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
conversational -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
comments -X- _ O
that -X- _ O
a -X- _ O
source -X- _ O
post -X- _ O
generates. -X- _ O

4.1 -X- _ O
Comment -X- _ O
Tree -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
network -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
user -X- _ O
tree -X- _ O
differs -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
comment -X- _ O
tree -X- _ O
as -X- _ O
the -X- _ O
former -X- _ O
captures -X- _ O
both -X- _ O
comments -X- _ O
and -X- _ O
reposts/retweets -X- _ O
but -X- _ O
the -X- _ O
latter -X- _ O
considers -X- _ O
only -X- _ O
comments -X- _ O
(Figure -X- _ O
1). -X- _ O

It -X- _ O
consists -X- _ O
of -X- _ O
four -X- _ O
modules: -X- _ O
(1) -X- _ O
comment -X- _ O
tree: -X- _ O
models -X- _ O
the -X- _ O
comment -X- _ O
network -X- _ O
by -X- _ O
following -X- _ O
the -X- _ O
reply-to -X- _ O
structure -X- _ O
using -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
graph -X- _ O
attentional -X- _ O
networks -X- _ O
(Veliˇckovi´c -X- _ O
et -X- _ O
al., -X- _ O
2018); -X- _ O
(2) -X- _ O
comment -X- _ O
chain: -X- _ O
models -X- _ O
the -X- _ O
comments -X- _ O
as -X- _ O
a -X- _ O
stream -X- _ O
using -X- _ O
transformer-based -X- _ O
sequence -X- _ O
models; -X- _ O
(3) -X- _ O
user -X- _ O
tree: -X- _ O
incorporates -X- _ O
social -X- _ O
relations -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
user -X- _ O
network -X- _ O
using -X- _ O
graph -X- _ O
attentional -X- _ O
networks; -X- _ O
(4) -X- _ O
rumour -X- _ O
classiﬁer: -X- _ O
combines -X- _ O
the -X- _ O
output -X- _ O
from -X- _ O
comment -X- _ O
tree, -X- _ O
comment -X- _ O
chain -X- _ O
and -X- _ O
user -X- _ O
tree -X- _ O
to -X- _ O
classify -X- _ O
the -X- _ O
source -X- _ O
post. -X- _ O

The -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
our -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
approach -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

Let -X- _ O
X -X- _ O
= -X- _ O
be -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
stories, -X- _ O
where -X- _ O
a -X- _ O
story -X- _ O
xi -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
source -X- _ O
post -X- _ O
and -X- _ O
its -X- _ O
reply -X- _ O
comments, -X- _ O
deﬁned -X- _ O
as -X- _ O
xi -X- _ O
= -X- _ O
, -X- _ O
where -X- _ O
c -X- _ O
(c0, -X- _ O
u0, -X- _ O
p0, -X- _ O
t0), -X- _ O
..., -X- _ O
(cm, -X- _ O
um, -X- _ O
pm, -X- _ O
tm) -X- _ O
{ -X- _ O
} -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
textual -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
(empty -X- _ O
string -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
repost/retweet), -X- _ O
u -X- _ O
is -X- _ O
the -X- _ O
user -X- _ O
ID -X- _ O

3 -X- _ O
Problem -X- _ O
Statement -X- _ O

Although -X- _ O
these -X- _ O
two -X- _ O
studies -X- _ O
combine -X- _ O
sequence -X- _ O
and -X- _ O
graph -X- _ O
models, -X- _ O
their -X- _ O
task -X- _ O
has -X- _ O
a -X- _ O
different -X- _ O
data -X- _ O
structure -X- _ O
and -X- _ O
hence -X- _ O
their -X- _ O
methods -X- _ O
cannot -X- _ O
be -X- _ O
trivially -X- _ O
adapted -X- _ O
to -X- _ O
the -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
task. -X- _ O

Liu -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
use -X- _ O
BERT -X- _ O
to -X- _ O
encode -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
claim -X- _ O
and -X- _ O
evidence -X- _ O
passage -X- _ O
and -X- _ O
then -X- _ O
propose -X- _ O
a -X- _ O
kernel -X- _ O
graph -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
fully -X- _ O
connected -X- _ O
network -X- _ O
of -X- _ O
evidence -X- _ O
passages. -X- _ O

network -X- _ O
with -X- _ O
graph -X- _ O
models -X- _ O
to -X- _ O
detect -X- _ O
fake -X- _ O
news. -X- _ O

4 -X- _ O
Methodology -X- _ O

Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
classiﬁer -X- _ O
from -X- _ O
the -X- _ O
labelled -X- _ O
rumour -X- _ O
dataset, -X- _ O
that -X- _ O
is -X- _ O
f -X- _ O
: -X- _ O
X -X- _ O

Each -X- _ O
story -X- _ O
xi -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
a -X- _ O
groundY -X- _ O
, -X- _ O
where -X- _ O
Y -X- _ O
represents -X- _ O
the -X- _ O
label -X- _ O
truth -X- _ O
label -X- _ O
yi -X- _ O
∈ -X- _ O
set -X- _ O
(binary -X- _ O
or -X- _ O
4 -X- _ O
classes -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
rumour -X- _ O
dataset). -X- _ O

who -X- _ O
submits -X- _ O
the -X- _ O
post, -X- _ O
p -X- _ O
is -X- _ O
the -X- _ O
parent -X- _ O
post -X- _ O
ID -X- _ O
that -X- _ O
the -X- _ O
current -X- _ O
post -X- _ O
replies -X- _ O
to -X- _ O
(null -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
source -X- _ O
post, -X- _ O
e.g. -X- _ O
p0 -X- _ O
= -X- _ O
null), -X- _ O
and -X- _ O
t -X- _ O
the -X- _ O
timestamp -X- _ O
of -X- _ O
the -X- _ O
post. -X- _ O

), -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
considers -X- _ O
only -X- _ O
comments. -X- _ O

The -X- _ O
structure -X- _ O
of -X- _ O
user -X- _ O
tree -X- _ O
differs -X- _ O
from -X- _ O
that -X- _ O
of -X- _ O
comment -X- _ O
tree, -X- _ O
as -X- _ O
the -X- _ O
former -X- _ O
captures -X- _ O
both -X- _ O
comments -X- _ O
( -X- _ O

Using -X- _ O
the -X- _ O
FEVER -X- _ O
dataset, -X- _ O
Zhong -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
use -X- _ O
pretrained -X- _ O
models -X- _ O
to -X- _ O
perform -X- _ O
semantic -X- _ O
role -X- _ O
labelling -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
clauses -X- _ O
in -X- _ O
evidence -X- _ O
passages -X- _ O
and -X- _ O
then -X- _ O
encode -X- _ O
the -X- _ O

Beyond -X- _ O
rumour -X- _ B-TaskName
detection, -X- _ I-TaskName
recent -X- _ O
studies -X- _ O
explore -X- _ O
combining -X- _ O
modern -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
graph -X- _ O
models -X- _ O
for -X- _ O
modelling -X- _ O
texts -X- _ O
and -X- _ O
their -X- _ O
interactions. -X- _ O

Table -X- _ O
1 -X- _ O
summarises -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
previous -X- _ O
studies -X- _ O
and -X- _ O
our -X- _ O
work. -X- _ O

Deeper -X- _ O
interactions, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
a -X- _ O
post -X- _ O
and -X- _ O
its -X- _ O
reply -X- _ O
and -X- _ O
the -X- _ O
social -X- _ O
relations -X- _ O
of -X- _ O
users -X- _ O
(e.g. -X- _ O
followers) -X- _ O
, -X- _ O
remain -X- _ O
under-explored. -X- _ O

Ni -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

All -X- _ O
these -X- _ O
studies -X- _ O
largely -X- _ O
model -X- _ O
the -X- _ O
superﬁcial -X- _ O
characteristics -X- _ O
of -X- _ O
comments -X- _ O
and -X- _ O
users, -X- _ O
e.g. -X- _ O
comments -X- _ O
are -X- _ O
represented -X- _ O
using -X- _ O
static -X- _ O
features -X- _ O
such -X- _ O
as -X- _ O
bag-of-words -X- _ O
(Bian -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Nguyen -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
users -X- _ O
with -X- _ O
simple -X- _ O
features -X- _ O
extracted -X- _ O
from -X- _ O
their -X- _ O
proﬁles -X- _ O
(Liu -X- _ O
and -X- _ O
Wu, -X- _ O
2018; -X- _ O
Lu -X- _ O
and -X- _ O
Li, -X- _ O
2020; -X- _ O

Leveraging -X- _ O
dual -X- _ O
attention -X- _ O
mechanism -X- _ O
on -X- _ O
source -X- _ O
text -X- _ O
and -X- _ O
user -X- _ O
propagation -X- _ O
structure, -X- _ O
Ni -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
leverage -X- _ O
dual -X- _ O
attention -X- _ O
mechanism -X- _ O
on -X- _ O
source -X- _ O
text -X- _ O
and -X- _ O
user -X- _ O
propagation -X- _ O
structure -X- _ O
via -X- _ O
graph -X- _ O
attention -X- _ O
networks -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
task. -X- _ O

(2020) -X- _ O
propose -X- _ O
to -X- _ O
learn -X- _ O
representations -X- _ O
for -X- _ O
misinformation -X- _ O
detection -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
heterogeneous -X- _ O
graph -X- _ O
of -X- _ O
news, -X- _ O
news -X- _ O
sources, -X- _ O
users -X- _ O
and -X- _ O
their -X- _ O
stances -X- _ O
in -X- _ O
comments. -X- _ O

An -X- _ O
ensemble -X- _ O
deep -X- _ O
learning -X- _ O
architecture -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
Lu -X- _ O
and -X- _ O
Li -X- _ O
(2020), -X- _ O
which -X- _ O
incorporates -X- _ O
source -X- _ O
post -X- _ O
content -X- _ O
and -X- _ O
retweet -X- _ O
network. -X- _ O

There -X- _ O
are -X- _ O
also -X- _ O
studies -X- _ O
combining -X- _ O
signals -X- _ O
from -X- _ O
contents, -X- _ O
users -X- _ O
and -X- _ O
propagation -X- _ O
networks -X- _ O
for -X- _ O
rumour -X- _ O
and -X- _ O
fake -X- _ O
news -X- _ O
detection. -X- _ O

Bian -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
propose -X- _ O
a -X- _ O
bi-directional -X- _ O
graph -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
upward -X- _ O
and -X- _ O
downward -X- _ O
information -X- _ O
propagation -X- _ O
structure -X- _ O
among -X- _ O
user -X- _ O
comments -X- _ O
to -X- _ O
distinguish -X- _ O
false -X- _ O
from -X- _ O
true -X- _ O
rumours. -X- _ O

Liu -X- _ O
and -X- _ O
Wu -X- _ O
(2018) -X- _ O
experiment -X- _ O
with -X- _ O
using -X- _ O
convolutional -X- _ O
and -X- _ O
recurrent -X- _ O
neural -X- _ O
networks -X- _ O
to -X- _ O
process -X- _ O
user -X- _ O
features -X- _ O
in -X- _ O
the -X- _ O
retweet -X- _ O
propagation -X- _ O
path -X- _ O
of -X- _ O
stories, -X- _ O
and -X- _ O
Ma -X- _ O
et -X- _ O
al. -X- _ O
(2018) -X- _ O
present -X- _ O
a -X- _ O
tree-structure -X- _ O
recursive -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
model -X- _ O
information -X- _ O
propagation -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

Graph -X- _ O
neural -X- _ O
models -X- _ O
leverage -X- _ O
information -X- _ O
propagation -X- _ O
patterns -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

Most -X- _ O
of -X- _ O
these -X- _ O
approaches -X- _ O
model -X- _ O
user -X- _ O
comments -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
posts -X- _ O
and -X- _ O
ignore -X- _ O
the -X- _ O
conversational -X- _ O
structure -X- _ O
among -X- _ O
the -X- _ O
comments. -X- _ O

Tian -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
explore -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
a -X- _ O
source -X- _ O
tweet -X- _ O
and -X- _ O
its -X- _ O
comments -X- _ O
by -X- _ O
transferring -X- _ O
stance -X- _ O
prediction -X- _ O
model -X- _ O
to -X- _ O
classify -X- _ O
rumours. -X- _ O

many -X- _ O
responses -X- _ O
are -X- _ O
needed -X- _ O
to -X- _ O
classify -X- _ O
a -X- _ O
rumour. -X- _ O

To -X- _ O
detect -X- _ O
rumours -X- _ O
as -X- _ O
early -X- _ O
as -X- _ O
possible, -X- _ O
Zhou -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
incorporate -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
dynamically -X- _ O
decide -X- _ O
how -X- _ O

Shu -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
introduce -X- _ O
linguistic -X- _ O
features -X- _ O
to -X- _ O
represent -X- _ O
writing -X- _ O
styles -X- _ O
and -X- _ O
other -X- _ O
features -X- _ O
based -X- _ O
on -X- _ O
sensational -X- _ O
headlines -X- _ O
from -X- _ O
Twitter -X- _ O
to -X- _ O
detect -X- _ O
misinformation. -X- _ O

Signals -X- _ O
such -X- _ O
as -X- _ O
writing -X- _ O
style, -X- _ O
stance -X- _ O
and -X- _ O
opinions -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
emotions -X- _ O
are -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

Sequence -X- _ O
processing -X- _ O
models -X- _ O
leverage -X- _ O
the -X- _ O
textual -X- _ O
contents -X- _ O
from -X- _ O
the -X- _ O
source -X- _ O
posts -X- _ O
and -X- _ O
user -X- _ O
reply -X- _ O
comments -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

Recent -X- _ O
research -X- _ O
focuses -X- _ O
on -X- _ O
neural -X- _ O
models -X- _ O
to -X- _ O
automatically -X- _ O
extract -X- _ O
features -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

It -X- _ O
identiﬁed -X- _ O
53 -X- _ O
features -X- _ O
within -X- _ O
six -X- _ O
categories -X- _ O
to -X- _ O
represent -X- _ O
a -X- _ O
rumour -X- _ O
message, -X- _ O
from -X- _ O
semantic -X- _ O
meaning -X- _ O
to -X- _ O
information -X- _ O
transmission. -X- _ O

Turenne -X- _ O
(2018) -X- _ O
analysed -X- _ O
lexical -X- _ O
content -X- _ O
and -X- _ O
information -X- _ O
propagation -X- _ O
based -X- _ O
on -X- _ O
Allport’s -X- _ O
theory -X- _ O
of -X- _ O
transmission -X- _ O
(Allport -X- _ O
and -X- _ O
Postman, -X- _ O
1947). -X- _ O

Early -X- _ O
studies -X- _ O
of -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
focus -X- _ O
on -X- _ O
supervised -X- _ O
learning -X- _ O
algorithms -X- _ O
incorporating -X- _ O
engineered -X- _ O
features -X- _ O
from -X- _ O
post -X- _ O
contents, -X- _ O
user -X- _ O
proﬁles -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
information -X- _ O
propagation -X- _ O
patterns -X- _ O
(Castillo -X- _ O
et -X- _ O
al., -X- _ O
2011; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Kwon -X- _ O
et -X- _ O
al., -X- _ O
2013; -X- _ O
Ma -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Rath -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

Also, -X- _ O
when -X- _ O
modelling -X- _ O
the -X- _ O
network -X- _ O
of -X- _ O
users -X- _ O
who -X- _ O
engage -X- _ O
with -X- _ O
a -X- _ O
story, -X- _ O
incorporating -X- _ O
the -X- _ O
social -X- _ O
relations -X- _ O
of -X- _ O
users -X- _ O
proves -X- _ O
to -X- _ O
be -X- _ O
very -X- _ O
beneﬁcial. -X- _ O

Although -X- _ O
both -X- _ O
users -X- _ O
and -X- _ O
comments -X- _ O
provide -X- _ O
complementary -X- _ O
signals -X- _ O
for -X- _ O
our -X- _ O
task, -X- _ O
the -X- _ O
comments -X- _ O
have -X- _ O
a -X- _ O
stronger -X- _ O
impact. -X- _ O

We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
four -X- _ O
widely -X- _ O
used -X- _ O
benchmark -X- _ O
rumour -X- _ O
datasets -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
Chinese, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
DUCK -X- _ B-MethodName
produces -X- _ O
superior -X- _ O
performance, -X- _ O
creating -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art. -X- _ O

extensive -X- _ O
exploration -X- _ O
on -X- _ O
how -X- _ O
we -X- _ O
can -X- _ O
best -X- _ O
model -X- _ O
these -X- _ O
networks, -X- _ O
and -X- _ O
compared -X- _ O
to -X- _ O
previous -X- _ O
studies, -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
key -X- _ O
differences: -X- _ O
(1) -X- _ O
we -X- _ O
model -X- _ O
comments -X- _ O
as -X- _ O
both -X- _ O
(i) -X- _ O
a -X- _ O
stream -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
temporal -X- _ O
nature -X- _ O
of -X- _ O
evolving -X- _ O
comments; -X- _ O
and -X- _ O
(ii) -X- _ O
a -X- _ O
network -X- _ O
by -X- _ O
following -X- _ O
the -X- _ O
conversational -X- _ O
structure -X- _ O
(see -X- _ O
Figure -X- _ O
1 -X- _ O
for -X- _ O
an -X- _ O
illustration); -X- _ O
(2) -X- _ O
our -X- _ O
comment -X- _ O
network -X- _ O
uses -X- _ O
a -X- _ O
sequence -X- _ O
model -X- _ O
to -X- _ O
encode -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
comments -X- _ O
before -X- _ O
feeding -X- _ O
them -X- _ O
to -X- _ O
a -X- _ O
graph -X- _ O
network, -X- _ O
allowing -X- _ O
our -X- _ O
model -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
nuanced -X- _ O
characteristics -X- _ O
(e.g. -X- _ O
agreement -X- _ O
or -X- _ O
rebuttal) -X- _ O
exhibited -X- _ O
by -X- _ O
a -X- _ O
reply; -X- _ O
and -X- _ O
(3) -X- _ O
when -X- _ O
modelling -X- _ O
the -X- _ O
users -X- _ O
who -X- _ O
engage -X- _ O
with -X- _ O
a -X- _ O
story -X- _ O
via -X- _ O
graph -X- _ O
networks, -X- _ O
we -X- _ O
initialise -X- _ O
the -X- _ O
user -X- _ O
nodes -X- _ O
with -X- _ O
encodings -X- _ O
learned -X- _ O
from -X- _ O
their -X- _ O
proﬁles -X- _ O
and -X- _ O
characteristics -X- _ O
of -X- _ O
their -X- _ O
“friends” -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
social -X- _ O
networks. -X- _ O

Our -X- _ O
study -X- _ O
presents -X- _ O
an -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
propose -X- _ O
DUCK -X- _ B-MethodName
(rumour -X- _ B-MethodName
detection -X- _ I-MethodName
with -X- _ I-MethodName
user -X- _ I-MethodName
and -X- _ I-MethodName
comment -X- _ I-MethodName
networks), -X- _ I-MethodName
a -X- _ O
framework -X- _ O
that -X- _ O
jointly -X- _ O
models -X- _ O
the -X- _ O
user -X- _ O
and -X- _ O
comment -X- _ O
propagation -X- _ O
networks. -X- _ O

Most -X- _ O
studies -X- _ O
(Ma -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Liu -X- _ O
and -X- _ O
Wu, -X- _ O
2018; -X- _ O
Tian -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Bian -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
typically -X- _ O
use -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
these -X- _ O
signals. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
the -X- _ O
network -X- _ O
of -X- _ O
users -X- _ O
who -X- _ O
reply -X- _ O
to -X- _ O
and -X- _ O
repost/retweet -X- _ O
a -X- _ O
story -X- _ O
captures -X- _ O
who -X- _ O
engage -X- _ O
with -X- _ O
it, -X- _ O
which -X- _ O
provides -X- _ O
a -X- _ O
complementary -X- _ O
signal. -X- _ O

Reply -X- _ O
comments -X- _ O
of -X- _ O
a -X- _ O
story -X- _ O
contain -X- _ O
user -X- _ O
opinions -X- _ O
and -X- _ O
captures -X- _ O
how -X- _ O
users -X- _ O
react -X- _ O
to -X- _ O
the -X- _ O
story, -X- _ O
which -X- _ O
provides -X- _ O
a -X- _ O
strong -X- _ O
signal -X- _ O
for -X- _ O
understanding -X- _ O
the -X- _ O
truthfulness -X- _ O
of -X- _ O
a -X- _ O
story. -X- _ O

Research -X- _ O
found -X- _ O
that -X- _ O
misinformation -X- _ O
propagates -X- _ O
differently -X- _ O
from -X- _ O
genuine -X- _ O
information -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
(Vosoughi -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

Although -X- _ O
prior -X- _ O
approaches -X- _ O
explored -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
content -X- _ O
and -X- _ O
user -X- _ O
features -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection, -X- _ I-TaskName
how -X- _ O
to -X- _ O
leverage -X- _ O
pretrained -X- _ O
sequence -X- _ O
and -X- _ O
graph -X- _ O
networks -X- _ O
to -X- _ O
model -X- _ O
them -X- _ O
effectively -X- _ O
remains -X- _ O
under-explored. -X- _ O

Sequence -X- _ O
processing -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
contents -X- _ O
of -X- _ O
social -X- _ O
media -X- _ O
conversations, -X- _ O
e.g. -X- _ O
source -X- _ O
posts -X- _ O
and -X- _ O
the -X- _ O
stream -X- _ O
of -X- _ O
comments -X- _ O
(Kochkina -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Tian -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
while -X- _ O
graph -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
experimented -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
social -X- _ O
media -X- _ O
conversations -X- _ O
(Bian -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Ma -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Lu -X- _ O
and -X- _ O
Li, -X- _ O
2020). -X- _ O

Recent -X- _ O
neural -X- _ O
approaches -X- _ O
typically -X- _ O
explore -X- _ O
fusing -X- _ O
different -X- _ O
feature -X- _ O
representations -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

Early -X- _ O
studies -X- _ O
of -X- _ O
rumour -X- _ O
detection -X- _ O
focus -X- _ O
on -X- _ O
supervised -X- _ O
learning -X- _ O
algorithms -X- _ O
incorporating -X- _ O
features -X- _ O
manually -X- _ O
engineered -X- _ O
from -X- _ O
post -X- _ O
contents, -X- _ O
user -X- _ O
proﬁles -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
information -X- _ O
propagation -X- _ O
patterns -X- _ O
(Castillo -X- _ O
et -X- _ O
al., -X- _ O
2011; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Kwon -X- _ O
et -X- _ O
al., -X- _ O
2013; -X- _ O
Ma -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Rath -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

This -X- _ O
is -X- _ O
a -X- _ O
contrast -X- _ O
to -X- _ O
FEVER-style -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
(Thorne -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
which -X- _ O
relies -X- _ O
mainly -X- _ O
on -X- _ O
a -X- _ O
source -X- _ O
of -X- _ O
world -X- _ O
knowledge -X- _ O
(e.g. -X- _ O
Wikipedia) -X- _ O
to -X- _ O
fact-check -X- _ O
stories. -X- _ O

social -X- _ O
context -X- _ O
features -X- _ O
can -X- _ O
be -X- _ O
leveraged -X- _ O
for -X- _ O
detection. -X- _ O

Although -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
fake -X- _ O
news -X- _ O
detection, -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
social -X- _ O
media -X- _ O
for -X- _ O
propagation -X- _ O
means -X- _ O
that -X- _ O
various -X- _ O

(2011), -X- _ O
automatic -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
on -X- _ O
social -X- _ O
media -X- _ O
has -X- _ O
attracted -X- _ O
signiﬁcant -X- _ O
research, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
detect -X- _ O
rumour -X- _ O
stories -X- _ O
(in -X- _ O
contrast -X- _ O
to -X- _ O
news -X- _ O
articles -X- _ O
by -X- _ O
credible -X- _ O
news -X- _ O
sources) -X- _ O
or -X- _ O
determine -X- _ O
their -X- _ O
veracity -X- _ O
— -X- _ O
true, -X- _ O
false -X- _ O
or -X- _ O
unveriﬁed. -X- _ O

Since -X- _ O
the -X- _ O
seminal -X- _ O
work -X- _ O
on -X- _ O
prediction -X- _ O
of -X- _ O
information -X- _ O
credibility -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
by -X- _ O
Castillo -X- _ O
et -X- _ O
al. -X- _ O

Rumours, -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
misinformation -X- _ O
typically -X- _ O
deﬁned -X- _ O
as -X- _ O
stories -X- _ O
or -X- _ O
statements -X- _ O
with -X- _ O
unveriﬁed -X- _ O
truth -X- _ O
value -X- _ O
(Allport -X- _ O
and -X- _ O
Postman, -X- _ O
1947), -X- _ O
can -X- _ O
mislead -X- _ O
the -X- _ O
public -X- _ O
and -X- _ O
cause -X- _ O
signiﬁcant -X- _ O
economic -X- _ O
and -X- _ O
social -X- _ O
disruption. -X- _ O

On -X- _ O
the -X- _ O
ﬂip -X- _ O
side, -X- _ O
social -X- _ O
media -X- _ O
has -X- _ O
also -X- _ O
accelerated -X- _ O
the -X- _ O
spread -X- _ O
of -X- _ O
misinformation -X- _ O
(Starbird -X- _ O
et -X- _ O
al., -X- _ O
2014; -X- _ O
Jin -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

Social -X- _ O
media -X- _ O
platforms -X- _ O
bring -X- _ O
easy -X- _ O
access -X- _ O
to -X- _ O
a -X- _ O
wealth -X- _ O
of -X- _ O
information. -X- _ O

Introduction -X- _ O

1 -X- _ O

Source -X- _ O
code -X- _ O
for -X- _ O
DUCK -X- _ B-MethodName
is -X- _ O
available -X- _ O
at: -X- _ O
https://github.com/l -X- _ O
tian678/DUCK-code. -X- _ O

, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
DUCK -X- _ B-MethodName
produces -X- _ O
superior -X- _ O
performance -X- _ O
for -X- _ O
detecting -X- _ B-TaskName
rumours, -X- _ I-TaskName
creating -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art. -X- _ O

Over -X- _ O
four -X- _ O
widely -X- _ O
used -X- _ O
benchmark -X- _ O
rumour -X- _ O
datasets -X- _ O
in -X- _ O
English -X- _ O
and -X- _ O
Chinese -X- _ O

We -X- _ O
study -X- _ O
how -X- _ O
to -X- _ O
leverage -X- _ O
transformers -X- _ O
and -X- _ O
graph -X- _ O
attention -X- _ O
networks -X- _ O
to -X- _ O
jointly -X- _ O
model -X- _ O
the -X- _ O
contents -X- _ O
and -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
social -X- _ O
media -X- _ O
conversations, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
network -X- _ O
of -X- _ O
users -X- _ O
who -X- _ O
engage -X- _ O
in -X- _ O
these -X- _ O
conversations. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
DUCK -X- _ B-MethodName
(rumour -X- _ B-MethodName
detection -X- _ I-MethodName
with -X- _ I-MethodName
user -X- _ I-MethodName
and -X- _ I-MethodName
comment -X- _ I-MethodName
networks) -X- _ I-MethodName
for -X- _ O
rumour -X- _ B-TaskName
detection -X- _ I-TaskName
on -X- _ O
social -X- _ O
media. -X- _ O

Motivated -X- _ O
by -X- _ O
the -X- _ O
observation -X- _ O
that -X- _ O
the -X- _ O
user -X- _ O
network -X- _ O
— -X- _ O
which -X- _ O
captures -X- _ O
who -X- _ O
engages -X- _ O
with -X- _ O
a -X- _ O
story -X- _ O
— -X- _ O
and -X- _ O
the -X- _ O
comment -X- _ O
network -X- _ O
— -X- _ O
which -X- _ O
captures -X- _ O
how -X- _ O
they -X- _ O
react -X- _ O
to -X- _ O
it -X- _ O
— -X- _ O
provide -X- _ O
complementary -X- _ O
signals -X- _ O
for -X- _ O
rumour -X- _ B-TaskName
detection. -X- _ I-TaskName

Social -X- _ O
media -X- _ O
rumours, -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
misinformation, -X- _ O
can -X- _ O
mislead -X- _ O
the -X- _ O
public -X- _ O
and -X- _ O
cause -X- _ O
significant -X- _ O
economic -X- _ O
and -X- _ O
social -X- _ O
disruption. -X- _ O

Abstract -X- _ O

DUCK: -X- _ B-MethodName
Rumour -X- _ B-TaskName
Detection -X- _ I-TaskName
on -X- _ O
Social -X- _ O
Media -X- _ O
by -X- _ O
Modelling -X- _ O
User -X- _ O
and -X- _ O
Comment -X- _ O
Propagation -X- _ O
Networks -X- _ O

-DOCSTART- -X- O
And -X- _ O
we -X- _ O
use -X- _ O
Adam -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
whole -X- _ O
learning -X- _ O
task. -X- _ O

The -X- _ O
train -X- _ B-HyperparameterName
epoch -X- _ I-HyperparameterName
are -X- _ O
set -X- _ O
to -X- _ O
100, -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
best -X- _ O
epoch -X- _ O
are -X- _ O
selected -X- _ O
by -X- _ O
the -X- _ O
best -X- _ O
validation -X- _ O
score -X- _ O
on -X- _ O
development -X- _ O
set -X- _ O
for -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
test -X- _ O
set. -X- _ O

We -X- _ O
use -X- _ O
8 -X- _ O
V100 -X- _ O
GPUs -X- _ O
and -X- _ O
set -X- _ O
gradient -X- _ O
accumulation -X- _ O
steps -X- _ O
to -X- _ O
8. -X- _ O

λ3 -X- _ B-HyperparameterName
= -X- _ O
0.05, -X- _ B-HyperparameterValue
λ2 -X- _ B-HyperparameterName
= -X- _ O
1.0, -X- _ B-HyperparameterValue
λ4 -X- _ B-HyperparameterName
= -X- _ O
0.95. -X- _ B-HyperparameterValue

The -X- _ O
four -X- _ O
loss -X- _ B-HyperparameterName
weights -X- _ I-HyperparameterName
are -X- _ O
set -X- _ O
to -X- _ O
λ1 -X- _ B-HyperparameterName
= -X- _ O

During -X- _ O
train5, -X- _ O
batch -X- _ O
ing, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
lr -X- _ B-HyperparameterName
= -X- _ O
5e− -X- _ B-HyperparameterValue
size -X- _ O
b -X- _ B-HyperparameterName
= -X- _ O
64. -X- _ B-HyperparameterValue

For -X- _ O
all -X- _ O
native -X- _ O
transformers -X- _ O
and -X- _ O
RAATs, -X- _ B-MethodName
the -X- _ O
dimensions -X- _ B-HyperparameterName
of -X- _ O
hidden -X- _ O
layers -X- _ O
and -X- _ O
feed-forward -X- _ O
layers -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
768 -X- _ B-HyperparameterValue
and -X- _ O
1,024 -X- _ B-HyperparameterValue
respectively. -X- _ O

A.5 -X- _ O
More -X- _ O
Training -X- _ O
Settings -X- _ O

Table -X- _ O
9: -X- _ O
Complete -X- _ O
relation -X- _ O
triplets. -X- _ O

This -X- _ O
example -X- _ O
explicitly -X- _ O
shows -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
dealing -X- _ O
with -X- _ O
multievents -X- _ O
issue. -X- _ O

Compared -X- _ O
with -X- _ O
the -X- _ O
ground -X- _ O
truth, -X- _ O
our -X- _ O
model -X- _ O
correctly -X- _ O
predicts -X- _ O
all -X- _ O
event -X- _ O
arguments -X- _ O
except -X- _ O
one, -X- _ O
while -X- _ O
GIT -X- _ B-MethodName
only -X- _ O
captures -X- _ O
one -X- _ O
event, -X- _ O
with -X- _ O
an -X- _ O
argument -X- _ O
missed. -X- _ O

Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
prediction -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
model -X- _ O
GIT -X- _ B-MethodName
on -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

A.4 -X- _ O
Case -X- _ O
Study -X- _ O

There -X- _ O
are -X- _ O
85 -X- _ O
relation -X- _ O
types -X- _ O
in -X- _ O
total, -X- _ O
and -X- _ O
train, -X- _ O
development, -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
have -X- _ O
similar -X- _ O
pattern -X- _ O
in -X- _ O
distribution. -X- _ O

Table -X- _ O
10 -X- _ O
shows -X- _ O
the -X- _ O
relation -X- _ O
statistics -X- _ O
of -X- _ O
ChiFinAnn -X- _ B-DatasetName
dataset. -X- _ O

A.3 -X- _ O
Relation -X- _ O
Statistics -X- _ O
for -X- _ O
ChiFinAnn -X- _ B-DatasetName

Heavy -X- _ O
coupling -X- _ O
of -X- _ O
arguments -X- _ O
among -X- _ O
events -X- _ O
increases -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O
multi-event -X- _ O
issue. -X- _ O

Entities -X- _ O
in -X- _ O
blue -X- _ O
are -X- _ O
involved -X- _ O
in -X- _ O
both -X- _ O
two -X- _ O
event -X- _ O
records, -X- _ O
while -X- _ O
those -X- _ O
in -X- _ O
green -X- _ O
and -X- _ O
orange -X- _ O
are -X- _ O
exclusive -X- _ O
to -X- _ O
record -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
respectively. -X- _ O

Table -X- _ O
9 -X- _ O
demonstrates -X- _ O
the -X- _ O
complete -X- _ O
of -X- _ O
relation -X- _ O
triples -X- _ O
of -X- _ O
the -X- _ O
document -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
example -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

A.2 -X- _ O
Complete -X- _ O
Relation -X- _ O
Triples -X- _ O

Only -X- _ O
train -X- _ O
and -X- _ O
development -X- _ O
sets -X- _ O
are -X- _ O
shown -X- _ O
since -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
not -X- _ O
publicly -X- _ O
available. -X- _ O

Overall, -X- _ O
there -X- _ O
are -X- _ O
13 -X- _ O
event -X- _ O
types -X- _ O
in -X- _ O
total -X- _ O
with -X- _ O
uneven -X- _ O
distribution. -X- _ O

Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
complete -X- _ O
event -X- _ O
type -X- _ O
and -X- _ O
corresponding -X- _ O
distribution -X- _ O
of -X- _ O
DuEE-fin -X- _ B-DatasetName
dataset. -X- _ O

A.1 -X- _ O
Distribution -X- _ O
of -X- _ O
Event -X- _ O
Type -X- _ O
DuEE-fin -X- _ B-DatasetName

In -X- _ O
the -X- _ O
appendix, -X- _ O
we -X- _ O
incorporate -X- _ O
the -X- _ O
following -X- _ O
details -X- _ O
that -X- _ O
are -X- _ O
omitted -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
body -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
space -X- _ O
limit. -X- _ O

A -X- _ O
Appendix -X- _ O

Acknowledgements -X- _ O

In -X- _ O
the -X- _ O
future, -X- _ O
we -X- _ O
will -X- _ O
make -X- _ O
more -X- _ O
efforts -X- _ O
to -X- _ O
accelerate -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
process. -X- _ O

The -X- _ O
extensive -X- _ O
experimental -X- _ O
results -X- _ O
can -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets. -X- _ O

This -X- _ O
framework -X- _ O
features -X- _ O
a -X- _ O
new -X- _ O
RAAT -X- _ B-MethodName
structure -X- _ O
which -X- _ O
can -X- _ O
incorporate -X- _ O
the -X- _ O
relation -X- _ O
knowledge. -X- _ O

We -X- _ O
propose -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
relation -X- _ O
information -X- _ O
between -X- _ O
event -X- _ O
arguments -X- _ O
and -X- _ O
design -X- _ O
a -X- _ O
novel -X- _ O
framework -X- _ O
ReDEE. -X- _ B-TaskName

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
investigate -X- _ O
a -X- _ O
challenging -X- _ O
task -X- _ O
of -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
at -X- _ I-TaskName
document -X- _ I-TaskName
level, -X- _ I-TaskName
towards -X- _ O
the -X- _ O
across-sentence -X- _ O
and -X- _ O
multi-event -X- _ O
issues. -X- _ O

6 -X- _ O
Conclusion -X- _ O

When -X- _ O
it -X- _ O
comes -X- _ O
to -X- _ O
DuEE-fin, -X- _ B-DatasetName
a -X- _ O
similar -X- _ O
phenomenon -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
RAATs -X- _ B-MethodName
can -X- _ O
contribute -X- _ O
positively -X- _ O
to -X- _ O
our -X- _ O
model. -X- _ O

After -X- _ O
replacing -X- _ O
both -X- _ O
two -X- _ O
RAATs, -X- _ B-MethodName
the -X- _ O
value -X- _ O
of -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
task -X- _ O
becomes -X- _ O
more -X- _ O
weak -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
encounters -X- _ O
a -X- _ O
1.5% -X- _ B-MetricValue
drop -X- _ O
in -X- _ O
F1 -X- _ B-MetricName
score. -X- _ O

tribution -X- _ O
than -X- _ O
RAAT-1, -X- _ B-MethodName
with -X- _ O
a -X- _ O
decrease -X- _ O
of -X- _ O
0.7% -X- _ B-MetricValue
versus -X- _ O
0.4% -X- _ B-MetricValue
in -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
once -X- _ O
been -X- _ O
substituted. -X- _ O

Especially -X- _ O
on -X- _ O
ChiFinAnn, -X- _ B-DatasetName
RAAT-2 -X- _ B-MethodName
makes -X- _ O
more -X- _ O
con -X- _ O

The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
indicate -X- _ O
that -X- _ O
both -X- _ O
two -X- _ O
RAATs -X- _ B-MethodName
have -X- _ O
positive -X- _ O
influence -X- _ O
on -X- _ O
our -X- _ O
model. -X- _ O

3) -X- _ O
RAAT-1&2 -X- _ B-MethodName
substitutes -X- _ O
the -X- _ O
RAATs -X- _ B-MethodName
in -X- _ O
both -X- _ O
the -X- _ O
above -X- _ O
places -X- _ O
with -X- _ O
vanilla -X- _ O
transformers, -X- _ O
so -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
degrades -X- _ O
to -X- _ O
only -X- _ O
import -X- _ O
a -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
task -X- _ O
via -X- _ O
multi-task -X- _ O
learning. -X- _ O

2) -X- _ O
RAAT-2 -X- _ B-MethodName
substitutes -X- _ O
the -X- _ O
RAAT -X- _ B-MethodName
in -X- _ O
the -X- _ O
event -X- _ B-TaskName
record -X- _ I-TaskName
generation -X- _ I-TaskName
module -X- _ O
with -X- _ O
vanilla -X- _ O
transformer. -X- _ O

In -X- _ O
this -X- _ O
experiment, -X- _ O
we -X- _ O
implement -X- _ O
tests -X- _ O
on -X- _ O
three -X- _ O
variants: -X- _ O
1) -X- _ O
-RAAT-1 -X- _ B-MethodName
substitutes -X- _ O
the -X- _ O
RAAT -X- _ B-MethodName
in -X- _ O
the -X- _ O
ESE -X- _ B-TaskName
component -X- _ O
with -X- _ O
vanilla -X- _ O
transformer. -X- _ O

To -X- _ O
probe -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
RAAT -X- _ B-MethodName
structure -X- _ O
for -X- _ O
different -X- _ O
components -X- _ O
in -X- _ O
ReDEE, -X- _ B-TaskName
we -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
on -X- _ O
whether -X- _ O
to -X- _ O
use -X- _ O
RAAT -X- _ B-MethodName
or -X- _ O
vanilla -X- _ O
transformer. -X- _ O

5.5 -X- _ O
Ablation -X- _ O
Study -X- _ O

The -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
our -X- _ O
relation -X- _ O
modeling -X- _ O
method -X- _ O
is -X- _ O
more -X- _ O
effective -X- _ O
to -X- _ O
overcome -X- _ O
the -X- _ O
multi-event -X- _ O
issue -X- _ O
than -X- _ O
existing -X- _ O
baseline -X- _ O
models. -X- _ O

We -X- _ O
find -X- _ O
ReDEE -X- _ B-TaskName
performs -X- _ O
much -X- _ O
better -X- _ O
in -X- _ O
the -X- _ O
multi-event -X- _ O
scenario -X- _ O
and -X- _ O
outperforms -X- _ O
baseline -X- _ O
models -X- _ O
dramatically -X- _ O
in -X- _ O
all -X- _ O
five -X- _ O
event -X- _ O
types, -X- _ O
improving -X- _ O
ranging -X- _ O
from -X- _ O
1.9% -X- _ B-MetricValue
to -X- _ O
3.2% -X- _ B-MetricValue
F1 -X- _ B-MetricName
scores. -X- _ O

Table -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
comparison -X- _ O
results -X- _ O
of -X- _ O
all -X- _ O
baselines -X- _ O
and -X- _ O
ReDEE. -X- _ B-TaskName

Single -X- _ O
v.s. -X- _ O
Multi -X- _ O
Events -X- _ O
To -X- _ O
illustrate -X- _ O
how -X- _ O
well -X- _ O
our -X- _ O
model -X- _ O
performs -X- _ O
in -X- _ O
the -X- _ O
multi-event -X- _ O
aspect, -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
ChiFinAnn -X- _ B-DatasetName
into -X- _ O
two -X- _ O
parts: -X- _ O
one -X- _ O
for -X- _ O
documents -X- _ O
with -X- _ O
single -X- _ O
event -X- _ O
record, -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
for -X- _ O
documents -X- _ O
including -X- _ O
multiple -X- _ O
events. -X- _ O

It -X- _ O
indicates -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
capturing -X- _ O
longer -X- _ O
dependency -X- _ O
of -X- _ O
records -X- _ O
across -X- _ O
sentences -X- _ O
via -X- _ O
relation -X- _ O
dependency -X- _ O
modeling, -X- _ O
thus -X- _ O
alleviating -X- _ O
the -X- _ O
argument -X- _ O
scattering -X- _ O
challenge. -X- _ O

According -X- _ O
to -X- _ O
table -X- _ O
5, -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
other -X- _ O
baseline -X- _ O
models -X- _ O
in -X- _ O
all -X- _ O
settings, -X- _ O
and -X- _ O
meets -X- _ O
the -X- _ O
largest -X- _ O
growth -X- _ O
of -X- _ O
2.2% -X- _ B-MetricValue
F1 -X- _ B-MetricName
score -X- _ O
in -X- _ O
IV, -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
set -X- _ O
of -X- _ O
all. -X- _ O

average -X- _ O
number -X- _ O
of -X- _ O
involved -X- _ O
sentences -X- _ O
while -X- _ O
the -X- _ O
IV -X- _ O
set -X- _ O
has -X- _ O
the -X- _ O
largest -X- _ O
ones. -X- _ O

Then, -X- _ O
all -X- _ O
documents -X- _ O
for -X- _ O
testing -X- _ O
are -X- _ O
evenly -X- _ O
divided -X- _ O
into -X- _ O
four -X- _ O
sets, -X- _ O
namely, -X- _ O
I, -X- _ O
II, -X- _ O
III -X- _ O
and -X- _ O
IV, -X- _ O
which -X- _ O
means -X- _ O
the -X- _ O
I -X- _ O
set -X- _ O
is -X- _ O
a -X- _ O
cluster -X- _ O
of -X- _ O
documents -X- _ O
that -X- _ O
have -X- _ O
the -X- _ O
smallest -X- _ O

To -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
in -X- _ O
different -X- _ O
argument -X- _ O
scattering -X- _ O
degree, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
sentences -X- _ O
involved -X- _ O
in -X- _ O
records -X- _ O
for -X- _ O
each -X- _ O
document -X- _ O
and -X- _ O
sort -X- _ O
them -X- _ O
in -X- _ O
the -X- _ O
increasing -X- _ O
average -X- _ O
number -X- _ O
order. -X- _ O

By -X- _ O
our -X- _ O
statistics, -X- _ O
the -X- _ O
training -X- _ O
sets -X- _ O
of -X- _ O
ChiFinAnn -X- _ B-DatasetName
and -X- _ O
DuEE-fin -X- _ B-DatasetName
have -X- _ O
about -X- _ O
98.0% -X- _ O
and -X- _ O
98.9% -X- _ O
records -X- _ O
that -X- _ O
scatter -X- _ O
across -X- _ O
sentences -X- _ O
respectively. -X- _ O

Argument -X- _ O
Scattering -X- _ O
The -X- _ O
across-sentence -X- _ O
issue -X- _ O
widely -X- _ O
exists -X- _ O
in -X- _ O
datasets. -X- _ O

This -X- _ O
experiment -X- _ O
demonstrates -X- _ O
our -X- _ O
model -X- _ O
could -X- _ O
achieve -X- _ O
a -X- _ O
superior -X- _ O
performance -X- _ O
than -X- _ O
existing -X- _ O
methods. -X- _ O

For -X- _ O
the -X- _ O
online -X- _ O
testing -X- _ O
evaluation, -X- _ O
our -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
distinct -X- _ O
growth -X- _ O
of -X- _ O
2.8% -X- _ B-MetricValue
on -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
than -X- _ O
the -X- _ O
baselines. -X- _ O

Seeing -X- _ O
from -X- _ O
former -X- _ O
results, -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
in -X- _ O
a -X- _ O
great -X- _ O
leap -X- _ O
by -X- _ O
increasing -X- _ O
6.7% -X- _ B-MetricValue
on -X- _ O
F1 -X- _ B-MetricName
score. -X- _ O

DuEE-fin -X- _ B-DatasetName
and -X- _ O
its -X- _ O
online -X- _ O
testing. -X- _ O

: -X- _ O
results -X- _ O
from -X- _ O
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

: -X- _ O
results -X- _ O
from -X- _ O
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021b); -X- _ O

: -X- _ O
results -X- _ O
from -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2021); -X- _ O

The -X- _ O
missing -X- _ O
parts -X- _ O
are -X- _ O
caused -X- _ O
by -X- _ O
the -X- _ O
inaccessibility -X- _ O
of -X- _ O
baseline -X- _ O
codes. -X- _ O

Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
comparison -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
baselines -X- _ O
on -X- _ O
the -X- _ O
developing -X- _ O
set -X- _ O
of -X- _ O

Our -X- _ O
model -X- _ O
also -X- _ O
performs -X- _ O
competitively -X- _ O
well -X- _ O
on -X- _ O
precision -X- _ B-MetricName
results. -X- _ O

The -X- _ O
ReDEE -X- _ B-TaskName
can -X- _ O
achieve -X- _ O
the -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
micro -X- _ O
average -X- _ O
recall -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
on -X- _ O
almost -X- _ O
every -X- _ O
type -X- _ O
of -X- _ O
events -X- _ O
(i.e. -X- _ O
EF, -X- _ O
ER, -X- _ O
EU, -X- _ O
EO, -X- _ O
EP), -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
Avg. -X- _ O
results -X- _ O
increased -X- _ O
by -X- _ O
1.5% -X- _ B-MetricValue
and -X- _ O
1.6% -X- _ B-MetricValue
respectively. -X- _ O

Overall -X- _ O
Performance -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
comparison -X- _ O
between -X- _ O
baselines -X- _ O
and -X- _ O
our -X- _ O
ReDEE -X- _ B-TaskName
model -X- _ O
on -X- _ O
the -X- _ O
ChiFinAnn -X- _ B-DatasetName
dataset. -X- _ O

5.4 -X- _ O
Results -X- _ O
and -X- _ O
Analysis -X- _ O

More -X- _ O
training -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.5. -X- _ O

Both -X- _ O
RAAT-1 -X- _ B-MethodName
and -X- _ O
RAAT-2 -X- _ B-MethodName
have -X- _ O
four -X- _ O
layers -X- _ O
of -X- _ O
identical -X- _ O
blocks. -X- _ O

We -X- _ O
use -X- _ O
BERT -X- _ O
encoder -X- _ O
in -X- _ O
the -X- _ O
EER -X- _ B-TaskName
component -X- _ O
for -X- _ O
fine-tuning -X- _ O
and -X- _ O
Roberta-chinese-wwm -X- _ O
(Yiming -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
as -X- _ O
the -X- _ O
pre-trained -X- _ O
model. -X- _ O

In -X- _ O
our -X- _ O
implementation, -X- _ O
for -X- _ O
text -X- _ O
processing, -X- _ O
we -X- _ O
consistently -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
sentence -X- _ I-HyperparameterName
number -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
sentence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
as -X- _ O
128 -X- _ B-HyperparameterValue
and -X- _ O
64 -X- _ B-HyperparameterValue
separately. -X- _ O

5.3 -X- _ O
Settings -X- _ O

We -X- _ O
conduct -X- _ O
several -X- _ O
offline -X- _ O
evaluations -X- _ O
for -X- _ O
ChiFinAnn, -X- _ B-DatasetName
but -X- _ O
only -X- _ O
an -X- _ O
online -X- _ O
test -X- _ O
for -X- _ O
DuEE-fin. -X- _ B-DatasetName

The -X- _ O
overall -X- _ O
"Avg" -X- _ O
in -X- _ O
the -X- _ O
result -X- _ O
tables -X- _ O
denotes -X- _ O
the -X- _ O
micro -X- _ O
average -X- _ O
value -X- _ O
of -X- _ O
precision, -X- _ B-MetricName
recall, -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
score. -X- _ O

For -X- _ O
evaluation -X- _ O
metrics, -X- _ O
we -X- _ O
use -X- _ O
precision, -X- _ B-MetricName
recall, -X- _ B-MetricName
and -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
at -X- _ O
the -X- _ O
entity -X- _ O
argument -X- _ O
level -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
baselines. -X- _ O

5) -X- _ O
PTPCG -X- _ B-MethodName
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
a -X- _ O
light-weighted -X- _ O
and -X- _ O
latest -X- _ O
DEE -X- _ B-TaskName
model. -X- _ O

4) -X- _ O
GIT -X- _ B-MethodName
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021b), -X- _ O
a -X- _ O
model -X- _ O
using -X- _ O
heterogeneous -X- _ O
graph -X- _ O
interaction -X- _ O
network -X- _ O
as -X- _ O
encoder -X- _ O
and -X- _ O
maintaining -X- _ O
a -X- _ O
global -X- _ O
tracker -X- _ O
during -X- _ O
the -X- _ O
decoding -X- _ O
process. -X- _ O

3) -X- _ O
DE-PPN -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
a -X- _ O
pipeline -X- _ O
model -X- _ O
firstly -X- _ O
introducing -X- _ O
the -X- _ O
non-autoregressive -X- _ O
mechanism. -X- _ O

2) -X- _ O
Doc2EDAG -X- _ B-MethodName
(Zheng -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
proposed -X- _ O
an -X- _ O
end-to-end -X- _ O
model -X- _ O
which -X- _ O
transforms -X- _ O
DEE -X- _ B-TaskName
as -X- _ O
directly -X- _ O
filling -X- _ O
event -X- _ O
tables -X- _ O
with -X- _ O
entity-based -X- _ O
path -X- _ O
expending. -X- _ O

Five -X- _ O
different -X- _ O
baseline -X- _ O
models -X- _ O
are -X- _ O
taken -X- _ O
into -X- _ O
consideration: -X- _ O
1) -X- _ O
DCFEE -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
the -X- _ O
first -X- _ O
model -X- _ O
proposed -X- _ O
to -X- _ O
solve -X- _ O
DEE -X- _ B-TaskName
task. -X- _ O

5.2 -X- _ O
Baselines -X- _ O
and -X- _ O
Metrics -X- _ O

We -X- _ O
get -X- _ O
the -X- _ O
distribution -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
from -X- _ O
Appendix -X- _ O
A.1. -X- _ O

The -X- _ O
DuEE-fin -X- _ B-DatasetName
dataset -X- _ O
has -X- _ O
13 -X- _ O
different -X- _ O
event -X- _ O
types -X- _ O
and -X- _ O
its -X- _ O
test -X- _ O
set -X- _ O
includes -X- _ O
a -X- _ O
large -X- _ O
size -X- _ O
of -X- _ O
document -X- _ O
samples -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
any -X- _ O
event -X- _ O
records, -X- _ O
which -X- _ O
both -X- _ O
make -X- _ O
it -X- _ O
more -X- _ O
complicated. -X- _ O

differences. -X- _ O

*https://aistudio.baidu.com/aistudio/competition/detail/46 -X- _ O

Compared -X- _ O
to -X- _ O
ChiFinAnn, -X- _ B-DatasetName
there -X- _ O
are -X- _ O
two -X- _ O

Since -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
ground -X- _ O
truth -X- _ O
publicly -X- _ O
available -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
set, -X- _ O
we -X- _ O
can -X- _ O
only -X- _ O
submit -X- _ O
our -X- _ O
extracted -X- _ O
results -X- _ O
to -X- _ O
the -X- _ O
website -X- _ O
as -X- _ O
a -X- _ O
black-box -X- _ O
online -X- _ O
evaluation. -X- _ O

The -X- _ O
dataset -X- _ O
is -X- _ O
downloaded -X- _ O
from -X- _ O
an -X- _ O
online -X- _ O
competition -X- _ O
website*. -X- _ O

DuEE-fin -X- _ B-DatasetName
is -X- _ O
also -X- _ O
from -X- _ O
the -X- _ O
financial -X- _ O
domain -X- _ O
with -X- _ O
around -X- _ O
11,900 -X- _ O
documents -X- _ O
in -X- _ O
total. -X- _ O

Readers -X- _ O
can -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
for -X- _ O
details. -X- _ O

We -X- _ O
randomly -X- _ O
split -X- _ O
the -X- _ O
dataset -X- _ O
into -X- _ O
train/dev/test -X- _ B-HyperparameterName
sets -X- _ O
in -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
8/1/1. -X- _ B-HyperparameterValue

Statistics -X- _ O
show -X- _ O
that -X- _ O
about -X- _ O
30% -X- _ O
of -X- _ O
the -X- _ O
documents -X- _ O
contain -X- _ O
multiple -X- _ O
event -X- _ O
records. -X- _ O

ChiFinAnn -X- _ B-DatasetName
includes -X- _ O
32,040 -X- _ O
documents -X- _ O
with -X- _ O
5 -X- _ O
types -X- _ O
of -X- _ O
events, -X- _ O
involving -X- _ O
in -X- _ O
equity-related -X- _ O
activities -X- _ O
for -X- _ O
the -X- _ O
financial -X- _ O
domain. -X- _ O

In -X- _ O
our -X- _ O
experiments -X- _ O
we -X- _ O
adopt -X- _ O
two -X- _ O
public -X- _ O
Chinese -X- _ O
datasets, -X- _ O
i.e. -X- _ O
ChiFinAnn -X- _ B-DatasetName
(Zheng -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
DuEE-fin -X- _ B-DatasetName
(Li, -X- _ O
2021). -X- _ O

DEE -X- _ B-TaskName
is -X- _ O
a -X- _ O
relatively -X- _ O
new -X- _ O
task -X- _ O
and -X- _ O
there -X- _ O
are -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
datasets -X- _ O
published. -X- _ O

5.1 -X- _ O
Datasets -X- _ O

In -X- _ O
what -X- _ O
level -X- _ O
does -X- _ O
the -X- _ O
each -X- _ O
key -X- _ O
component -X- _ O
of -X- _ O
ReDEE -X- _ B-TaskName
contribute -X- _ O
to -X- _ O
the -X- _ O
final -X- _ O
performance? -X- _ O

sentence -X- _ O
and -X- _ O
multi-event -X- _ O
issues? -X- _ O

• -X- _ O
How -X- _ O
well -X- _ O
does -X- _ O
ReDEE -X- _ B-TaskName
overcome -X- _ O
across -X- _ O

perform -X- _ O
the -X- _ O
baseline -X- _ O
DEE -X- _ B-TaskName
methods? -X- _ O

• -X- _ O
To -X- _ O
what -X- _ O
degree -X- _ O
does -X- _ O
the -X- _ O
ReDEE -X- _ B-TaskName
model -X- _ O
out -X- _ O

In -X- _ O
summary, -X- _ O
the -X- _ O
experiments -X- _ O
could -X- _ O
answer -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
questions: -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
to -X- _ O
prove -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
method. -X- _ O

5 -X- _ O
Experiments -X- _ O

To -X- _ O
train -X- _ O
the -X- _ O
above -X- _ O
four -X- _ O
components, -X- _ O
we -X- _ O
leverage -X- _ O
the -X- _ O
multi-task -X- _ O
learning -X- _ O
method -X- _ O
(Collobert -X- _ O
and -X- _ O
Weston, -X- _ O
2008) -X- _ O
and -X- _ O
integrate -X- _ O
the -X- _ O
four -X- _ O
corresponding -X- _ O
loss -X- _ O
functions -X- _ O
together -X- _ O
as -X- _ O
the -X- _ O
following: -X- _ O

4.6 -X- _ O
Model -X- _ O
Training -X- _ O

ye -X- _ O
= -X- _ O
1 -X- _ O
means -X- _ O
e -X- _ O
is -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
argument -X- _ O
corresponding -X- _ O
to -X- _ O
current -X- _ O
step -X- _ O
event -X- _ O
role, -X- _ O
otherwise, -X- _ O
ye -X- _ O
= -X- _ O
0. -X- _ O

by -X- _ O
far, -X- _ O
s -X- _ O
denotes -X- _ O
embedding -X- _ O
of -X- _ O
sentences -X- _ O
and -X- _ O
event -X- _ O
argument -X- _ O
candidates, -X- _ O
and -X- _ O
ye -X- _ O
denotes -X- _ O
label -X- _ O
of -X- _ O
argument -X- _ O
candidate -X- _ O
e -X- _ O
in -X- _ O
current -X- _ O
step. -X- _ O

a -X- _ O
= -X- _ O

4.5.1 -X- _ O
Event -X- _ O
Type -X- _ O
Classifier -X- _ O
Given -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
sentences, -X- _ O
we -X- _ O
adopt -X- _ O
several -X- _ O
binary -X- _ O
classifiers -X- _ O
on -X- _ O
every -X- _ O
event -X- _ O
type -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
corresponding -X- _ O
event -X- _ O
is -X- _ O
identified -X- _ O
or -X- _ O

The -X- _ O
formal -X- _ O
definition -X- _ O
of -X- _ O
loss -X- _ O
function -X- _ O
for -X- _ O
event -X- _ O
recorder -X- _ O
decoder -X- _ O
is: -X- _ O

The -X- _ O
RAAT-2 -X- _ B-MethodName
has -X- _ O
the -X- _ O
same -X- _ O
structure -X- _ O
with -X- _ O
RAAT-1 -X- _ B-MethodName
but -X- _ O
independent -X- _ O
parameters. -X- _ O

Therefore, -X- _ O
the -X- _ O
RAAT -X- _ B-MethodName
can -X- _ O
strengthen -X- _ O
the -X- _ O
relation -X- _ O
signal -X- _ O
for -X- _ O
attention -X- _ O
computation. -X- _ O

After -X- _ O
extracting -X- _ O
the -X- _ O
argument, -X- _ O
it -X- _ O
is -X- _ O
added -X- _ O
into -X- _ O
memory, -X- _ O
meanwhile, -X- _ O
a -X- _ O
new -X- _ O
T -X- _ O
is -X- _ O
generated -X- _ O
to -X- _ O
adapt -X- _ O
next -X- _ O
iteration -X- _ O
prediction. -X- _ O

In -X- _ O
detail, -X- _ O
before -X- _ O
predicting -X- _ O
event -X- _ O
argument -X- _ O
for -X- _ O
current -X- _ O
iteration, -X- _ O
Matrix -X- _ O
T -X- _ O
is -X- _ O
constructed -X- _ O
in -X- _ O
the -X- _ O
way -X- _ O
shown -X- _ O
above -X- _ O
so -X- _ O
that -X- _ O
dependency -X- _ O
is -X- _ O
integrated -X- _ O
into -X- _ O
attention -X- _ O
computation. -X- _ O

In -X- _ O
our -X- _ O
method, -X- _ O
RAAT -X- _ B-MethodName
structure -X- _ O
can -X- _ O
connect -X- _ O
entities -X- _ O
in -X- _ O
memory -X- _ O
and -X- _ O
candidate -X- _ O
arguments -X- _ O
via -X- _ O
relation -X- _ O
triples -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
DRE -X- _ B-TaskName
component, -X- _ O
and -X- _ O
it -X- _ O
can -X- _ O
construct -X- _ O
a -X- _ O
structure -X- _ O
to -X- _ O
represent -X- _ O
dependencies. -X- _ O

However, -X- _ O
this -X- _ O
procedure -X- _ O
hardly -X- _ O
captures -X- _ O
dependency -X- _ O
between -X- _ O
entities -X- _ O
both -X- _ O
in -X- _ O
memory -X- _ O
and -X- _ O
argument -X- _ O
candidates -X- _ O
and -X- _ O
sentences. -X- _ O

More -X- _ O
specifically, -X- _ O
the -X- _ O
EDAG -X- _ O
method -X- _ O
uses -X- _ O
a -X- _ O
memory -X- _ O
structure -X- _ O
to -X- _ O
record -X- _ O
extracted -X- _ O
arguments -X- _ O
and -X- _ O
adds -X- _ O
role -X- _ O
type -X- _ O
representation -X- _ O
to -X- _ O
predict -X- _ O
current-iteration -X- _ O
arguments. -X- _ O

However, -X- _ O
different -X- _ O
from -X- _ O
EDAG, -X- _ O
we -X- _ O
substitute -X- _ O
its -X- _ O
vanilla -X- _ O
transformer -X- _ O
part -X- _ O
with -X- _ O
our -X- _ O
proposed -X- _ O
RAAT -X- _ B-MethodName
structure -X- _ O
(i.e. -X- _ O
RAAT-2 -X- _ B-MethodName
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2). -X- _ O

And -X- _ O
the -X- _ O
predicted -X- _ O
arguments -X- _ O
of -X- _ O
outputs -X- _ O
will -X- _ O
be -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
inputs -X- _ O
for -X- _ O
next -X- _ O
iteration. -X- _ O

Inputs -X- _ O
of -X- _ O
each -X- _ O
iteration -X- _ O
are -X- _ O
come -X- _ O
up -X- _ O
with -X- _ O
entities -X- _ O
and -X- _ O
sentences -X- _ O
embeddings. -X- _ O

The -X- _ O
objective -X- _ O
of -X- _ O
each -X- _ O
iteration -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
event -X- _ O
argument -X- _ O
of -X- _ O
certain -X- _ O
event -X- _ O
role. -X- _ O

EDAG -X- _ O
is -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
iterations -X- _ O
with -X- _ O
the -X- _ O
length -X- _ O
equaling -X- _ O
to -X- _ O
number -X- _ O
of -X- _ O
roles -X- _ O
for -X- _ O
certain -X- _ O
event -X- _ O
type. -X- _ O

4.5.2 -X- _ O
Event -X- _ O
Record -X- _ O
Decoder -X- _ O
To -X- _ O
iteratively -X- _ O
generate -X- _ O
every -X- _ O
argument -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
event -X- _ O
type, -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
entity-based -X- _ O
directed -X- _ O
acyclic -X- _ O
graph -X- _ O
(EDAG) -X- _ O
method -X- _ O
(Zheng -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

The -X- _ O
loss -X- _ O
function -X- _ O
to -X- _ O
optimize -X- _ O
this -X- _ O
classifier -X- _ O
is -X- _ O
as -X- _ O
the -X- _ O
following: -X- _ O

If -X- _ O
there -X- _ O
is -X- _ O
any -X- _ O
classifier -X- _ O
identifying -X- _ O
an -X- _ O
event -X- _ O
type, -X- _ O
the -X- _ O
following -X- _ O
event -X- _ O
record -X- _ O
decoder -X- _ O
would -X- _ O
be -X- _ O
activated -X- _ O
to -X- _ O
iteratively -X- _ O
generate -X- _ O
every -X- _ O
argument -X- _ O
for -X- _ O
the -X- _ O
corresponding -X- _ O
event -X- _ O
type. -X- _ O

With -X- _ O
the -X- _ O
outputs -X- _ O
from -X- _ O
previous -X- _ O
component, -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
entities -X- _ O
and -X- _ O
sentences, -X- _ O
this -X- _ O
ERG -X- _ B-TaskName
component -X- _ O
actually -X- _ O
includes -X- _ O
two -X- _ O
sub-modules: -X- _ O
event -X- _ O
type -X- _ O
classifier -X- _ O
and -X- _ O
event -X- _ O
record -X- _ O
decoder. -X- _ O

4.5 -X- _ O
Event -X- _ B-TaskName
Record -X- _ I-TaskName
Generation -X- _ I-TaskName

RAAT -X- _ B-MethodName
can -X- _ O
be -X- _ O
adaptive -X- _ O
to -X- _ O
the -X- _ O
change -X- _ O
of -X- _ O
input -X- _ O
length, -X- _ O
which -X- _ O
is -X- _ O
equivalent -X- _ O
to -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
sentences -X- _ O
and -X- _ O
entity -X- _ O
mentions. -X- _ O

Furthermore, -X- _ O
T -X- _ O
is -X- _ O
extensive -X- _ O
since -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
Co-relation -X- _ O
can -X- _ O
be -X- _ O
selected. -X- _ O

Similar -X- _ O
to -X- _ O
the -X- _ O
structure -X- _ O
of -X- _ O
native -X- _ O
transformer, -X- _ O
RAAT -X- _ B-MethodName
has -X- _ O
multiple -X- _ O
identical -X- _ O
blocks -X- _ O
stacking -X- _ O
up -X- _ O
layer -X- _ O
by -X- _ O
layer. -X- _ O

We -X- _ O
compute -X- _ O
self -X- _ O
attention -X- _ O
score -X- _ O
and -X- _ O
combine -X- _ O
it -X- _ O
with -X- _ O
Sa -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
way: -X- _ O

where -X- _ O
Sa -X- _ O
denotes -X- _ O
score -X- _ O
matrix -X- _ O
of -X- _ O
relationaugmented -X- _ O
attention, -X- _ O
denotes -X- _ O
element-wise -X- _ O
multiplication. -X- _ O

d -X- _ O
as -X- _ O
weight -X- _ O
matrices, -X- _ O
we -X- _ O
comM -X- _ O
pute -X- _ O
relation-augmented -X- _ O
attention -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
steps: -X- _ O

Let -X- _ O
d -X- _ O
as -X- _ O
input -X- _ O
embeddings -X- _ O
of -X- _ O
attenX -X- _ O
d, -X- _ O
tion -X- _ O
module, -X- _ O
Wrq, -X- _ O
Wrk, -X- _ O
Wq, -X- _ O
Wk, -X- _ O
Wv -X- _ O
∈ -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
we -X- _ O
finally -X- _ O
get -X- _ O
T -X- _ O
∈ -X- _ O
R(3+H) -X- _ O
(t+j) -X- _ O
where -X- _ O
H -X- _ O
denotes -X- _ O
the -X- _ O
num× -X- _ O
ber -X- _ O
of -X- _ O
head -X- _ O
entity -X- _ O
type -X- _ O
in -X- _ O
Co-relation, -X- _ O
and -X- _ O
3 -X- _ O
covers -X- _ O
NA, -X- _ O
Co-reference, -X- _ O
and -X- _ O
Co-existence. -X- _ O

For -X- _ O
example, -X- _ O
Pledger2Pledgee -X- _ O
and -X- _ O
Pledger2PledgedShares -X- _ O
are -X- _ O
clustered -X- _ O
as -X- _ O
one -X- _ O
Co-relation -X- _ O
dependency, -X- _ O
and -X- _ O
two -X- _ O
matrice -X- _ O
Ra -X- _ O
and -X- _ O
Rb -X- _ O
corresponding -X- _ O
to -X- _ O
them -X- _ O
are -X- _ O
merged -X- _ O
into -X- _ O
one -X- _ O
matrix. -X- _ O

To -X- _ O
squeeze -X- _ O
T -X- _ O
and -X- _ O
decrease -X- _ O
training -X- _ O
parameters, -X- _ O
we -X- _ O
cluster -X- _ O
Co-relation -X- _ O
dependency -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
head -X- _ O
entity -X- _ O
in -X- _ O
relation -X- _ O
triple. -X- _ O

However, -X- _ O
T -X- _ O
would -X- _ O
be -X- _ O
giant -X- _ O
and -X- _ O
sparse -X- _ O
if -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
above -X- _ O
strategy. -X- _ O

be -X- _ O
either -X- _ O
entity -X- _ O
mention -X- _ O
or -X- _ O
sentence. -X- _ O

However, -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O

That -X- _ O
is, -X- _ O
if -X- _ O
an -X- _ O
entity -X- _ O
has -X- _ O
several -X- _ O
mentions -X- _ O
existing -X- _ O
across -X- _ O
document, -X- _ O
then -X- _ O
each -X- _ O
two -X- _ O
of -X- _ O
them -X- _ O
has -X- _ O
Coreference -X- _ O
dependency. -X- _ O

Co-reference -X- _ O
shows -X- _ O
dependency -X- _ O
between -X- _ O
entity -X- _ O
mentions -X- _ O
pointing -X- _ O
to -X- _ O
same -X- _ O
entities. -X- _ O

Entity -X- _ O
pairs -X- _ O
are -X- _ O
considered -X- _ O
having -X- _ O
different -X- _ O
Co-relation -X- _ O
if -X- _ O
their -X- _ O
involved -X- _ O
triples -X- _ O
have -X- _ O
different -X- _ O
relations. -X- _ O

For -X- _ O
the -X- _ O
former -X- _ O
one, -X- _ O
two -X- _ O
entities -X- _ O
have -X- _ O
a -X- _ O
Co-relation -X- _ O
dependency -X- _ O
between -X- _ O
them -X- _ O
if -X- _ O
they -X- _ O
belong -X- _ O
to -X- _ O
a -X- _ O
predicted -X- _ O
relation -X- _ O
triple. -X- _ O

Co-relation -X- _ O
and -X- _ O
Co-reference -X- _ O
are -X- _ O
defined -X- _ O
to -X- _ O
represent -X- _ O
entity-entity -X- _ O
dependency. -X- _ O

First, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
mechanism: -X- _ O
entity -X- _ O
and -X- _ O
sentence -X- _ O
dependency, -X- _ O
which -X- _ O
not -X- _ O
only -X- _ O
includes -X- _ O
relation -X- _ O
triples, -X- _ O
but -X- _ O
also -X- _ O
describes -X- _ O
links -X- _ O
among -X- _ O
sentences -X- _ O
and -X- _ O
entities -X- _ O
beyond -X- _ O
triples. -X- _ O

4.4.1 -X- _ O
Entity -X- _ O
and -X- _ O
Sentence -X- _ O
Dependency -X- _ O

In -X- _ O
this -X- _ O
subsection, -X- _ O
we -X- _ O
would -X- _ O
introduce -X- _ O
the -X- _ O
method -X- _ O
that -X- _ O
translates -X- _ O
triple -X- _ O
relations -X- _ O
to -X- _ O
calculable -X- _ O
matrices -X- _ O
and -X- _ O
the -X- _ O
novel -X- _ O
RAAT -X- _ B-MethodName
structure -X- _ O
for -X- _ O
encoding -X- _ O
all -X- _ O
the -X- _ O
above -X- _ O
data. -X- _ O

Then -X- _ O
this -X- _ O
component -X- _ O
encodes -X- _ O
data -X- _ O
mentioned -X- _ O
above -X- _ O
and -X- _ O
output -X- _ O
embeddings -X- _ O
effectively -X- _ O
integrated -X- _ O
with -X- _ O
relation -X- _ O
information. -X- _ O

Now -X- _ O
we -X- _ O
have -X- _ O
embeddings -X- _ O
of -X- _ O
entity -X- _ O
mentions -X- _ O
and -X- _ O
sentences -X- _ O
from -X- _ O
EER -X- _ B-TaskName
component -X- _ O
and -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
predicted -X- _ O
triple -X- _ O
relations -X- _ O
from -X- _ O
DRE -X- _ B-TaskName
component. -X- _ O

4.4 -X- _ O
Entity -X- _ O
and -X- _ O
Sentence -X- _ O
Encoding -X- _ O

At -X- _ O
last -X- _ O
the -X- _ O
clustered -X- _ O
matrices -X- _ O
are -X- _ O
integrated -X- _ O
into -X- _ O
the -X- _ O
transformer -X- _ O
structure -X- _ O
for -X- _ O
attention -X- _ O
calculation. -X- _ O

Then -X- _ O
the -X- _ O
matrices -X- _ O
are -X- _ O
clustered -X- _ O
by -X- _ O
the -X- _ O
head -X- _ O
entities. -X- _ O

Firstly -X- _ O
each -X- _ O
relation -X- _ O
between -X- _ O
entities -X- _ O
and -X- _ O
sentences -X- _ O
are -X- _ O
represented -X- _ O
as -X- _ O
matrices. -X- _ O

∈ -X- _ O

According -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3, -X- _ B-MethodName
RAAT -X- _ I-MethodName
is -X- _ O
inherited -X- _ O
from -X- _ O
native -X- _ O
transformer -X- _ O
but -X- _ O
has -X- _ O
a -X- _ O
distinct -X- _ O
attention -X- _ O
computation -X- _ O
module -X- _ O
which -X- _ O
is -X- _ O
made -X- _ O
up -X- _ O
of -X- _ O
two -X- _ O
parts: -X- _ O
self-attention -X- _ O
and -X- _ O
relationaugmented -X- _ O
attention -X- _ O
computation. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
effectively -X- _ O
encode -X- _ O
entity -X- _ O
and -X- _ O
sentence -X- _ O
dependencies, -X- _ O
we -X- _ O
design -X- _ O
the -X- _ O
RAAT -X- _ B-MethodName
which -X- _ O
takes -X- _ O
advantage -X- _ O
of -X- _ O
a -X- _ O
calculable -X- _ O
matrix -X- _ O
representing -X- _ O
dependencies -X- _ O
and -X- _ O
integrates -X- _ O
it -X- _ O
into -X- _ O
attention -X- _ O
computation. -X- _ O

4.4.2 -X- _ O
RAAT -X- _ B-MethodName

Co-relation -X- _ O
differs -X- _ O
from -X- _ O
NA, -X- _ O
Co-reference, -X- _ O
and -X- _ O
Co-existence -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
has -X- _ O
several -X- _ O
sub-types, -X- _ O
with -X- _ O
number -X- _ O
equaling -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
relation -X- _ O
types -X- _ O
defined -X- _ O
in -X- _ O
document -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
task. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
complete -X- _ O
dependency -X- _ O
mechanism. -X- _ O

For -X- _ O
remaining -X- _ O
entity-entity -X- _ O
and -X- _ O
entitysentence -X- _ O
pairs -X- _ O
without -X- _ O
any -X- _ O
dependency -X- _ O
mentioned -X- _ O
above, -X- _ O
we -X- _ O
uniformly -X- _ O
treat -X- _ O
them -X- _ O
as -X- _ O
NA -X- _ O
dependency. -X- _ O

To -X- _ O
be -X- _ O
more -X- _ O
specific, -X- _ O
the -X- _ O
entity -X- _ O
mention -X- _ O
together -X- _ O
with -X- _ O
its -X- _ O
belonged -X- _ O
sentence -X- _ O
has -X- _ O
Coexistence. -X- _ O

We -X- _ O
use -X- _ O
Co-existence -X- _ O
to -X- _ O
describe -X- _ O
dependency -X- _ O
between -X- _ O
entities -X- _ O
and -X- _ O
sentences -X- _ O
where -X- _ O
entity -X- _ O
mentions -X- _ O
come -X- _ O
from. -X- _ O

where -X- _ O
yi,j -X- _ O
denotes -X- _ O
ground -X- _ O
truth -X- _ O
label -X- _ O
between -X- _ O
the -X- _ O
ith -X- _ O
and -X- _ O
jth -X- _ O
entity, -X- _ O
D -X- _ O
for -X- _ O
document -X- _ O
text -X- _ O
and -X- _ O
Y -X- _ O
for -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
relation -X- _ O
pairs -X- _ O
among -X- _ O
entities. -X- _ O

And -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
for -X- _ O
optimize -X- _ O
the -X- _ O
relation -X- _ B-TaskName
prediction -X- _ I-TaskName
task -X- _ O
is -X- _ O
denoted: -X- _ O

Wr -X- _ O
∈ -X- _ O
× -X- _ O
trix -X- _ O
trained -X- _ O
by -X- _ O
DRE -X- _ B-TaskName
task -X- _ O
and -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
relations. -X- _ O

Rd -X- _ O
denote -X- _ O
entity -X- _ O
embedding -X- _ O
from -X- _ O
where -X- _ O
ei, -X- _ O
ej -X- _ O
∈ -X- _ O
encoder -X- _ O
module -X- _ O
of -X- _ O
DRE -X- _ B-TaskName
and -X- _ O
d -X- _ O
is -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
d -X- _ O
denotes -X- _ O
biaffine -X- _ O
mac -X- _ O
embeddings. -X- _ O

The -X- _ O
relation -X- _ O
type -X- _ O
is -X- _ O
inferred -X- _ O
by -X- _ O
this -X- _ O
function: -X- _ O

However, -X- _ O
different -X- _ O
from -X- _ O
previous -X- _ O
work -X- _ O
using -X- _ O
multi-class -X- _ O
binary -X- _ O
cross-entropy -X- _ O
loss, -X- _ O
we -X- _ O
use -X- _ O
normal -X- _ O
cross-entropy -X- _ O
loss -X- _ O
to -X- _ O
predict -X- _ O
only -X- _ O
one -X- _ O
label -X- _ O
for -X- _ O
each -X- _ O
entity -X- _ O
pair. -X- _ O

To -X- _ O
predict -X- _ O
the -X- _ O
argument -X- _ O
relations -X- _ O
in -X- _ O
this -X- _ O
step, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
structured -X- _ O
self -X- _ O
attention -X- _ O
network -X- _ O
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021a) -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
latest -X- _ O
method -X- _ O
for -X- _ O
document-level -X- _ B-TaskName
relation -X- _ I-TaskName
extraction. -X- _ I-TaskName

The -X- _ O
complete -X- _ O
statistic -X- _ O
can -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
Appendix -X- _ O
A.3. -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
a -X- _ O
snippet -X- _ O
of -X- _ O
statistics -X- _ O
and -X- _ O
the -X- _ O
full -X- _ O
edition -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.3. -X- _ O

We -X- _ O
do -X- _ O
statistics -X- _ O
for -X- _ O
the -X- _ O
relation -X- _ O
types -X- _ O
for -X- _ O
ChiFinAnn -X- _ B-DatasetName
dataset. -X- _ O

Note -X- _ O
that -X- _ O
this -X- _ O
method -X- _ O
to -X- _ O
build -X- _ O
relations -X- _ O
is -X- _ O
general -X- _ O
to -X- _ O
event -X- _ O
extraction -X- _ O
tasks -X- _ O
from -X- _ O
various -X- _ O
domains, -X- _ O
and -X- _ O
the -X- _ O
supervised -X- _ O
relation -X- _ O
information -X- _ O
just -X- _ O
comes -X- _ O
from -X- _ O
event -X- _ O
record -X- _ O
data -X- _ O
itself, -X- _ O
without -X- _ O
any -X- _ O
extra -X- _ O
human -X- _ O
labeling -X- _ O
work. -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
every -X- _ O
event -X- _ O
record -X- _ O
with -X- _ O
n -X- _ O
arguments -X- _ O
could -X- _ O
create -X- _ O
C2 -X- _ O
n -X- _ O
relation -X- _ O
samples. -X- _ O

For -X- _ O
example, -X- _ O
Pledger -X- _ O
and -X- _ O
Pledgee -X- _ O
in -X- _ O
the -X- _ O
EquityPledge -X- _ O
event -X- _ O
could -X- _ O
have -X- _ O
a -X- _ O
relation -X- _ O
named -X- _ O
as -X- _ O
Pledge2Pledgee, -X- _ O
and -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
head -X- _ O
and -X- _ O
tail -X- _ O
entities -X- _ O
is -X- _ O
determined -X- _ O
by -X- _ O
the -X- _ O
pre-order -X- _ O
of -X- _ O
event -X- _ O
arguments -X- _ O
(Zheng -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Here -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
every -X- _ O
two -X- _ O
arguments -X- _ O
in -X- _ O
an -X- _ O
event -X- _ O
record -X- _ O
can -X- _ O
be -X- _ O
connected -X- _ O
by -X- _ O
a -X- _ O
relation. -X- _ O

An -X- _ O
important -X- _ O
aspect -X- _ O
is -X- _ O
how -X- _ O
to -X- _ O
define -X- _ O
and -X- _ O
collect -X- _ O
the -X- _ O
relations -X- _ O
from -X- _ O
data. -X- _ O

} -X- _ O
k, -X- _ O
et -X- _ O
[eh -X- _ O
k, -X- _ O
rk] -X- _ O
means -X- _ O
the -X- _ O
head -X- _ O
entity, -X- _ O
the -X- _ O
tail -X- _ O
entity -X- _ O
and -X- _ O
the -X- _ O
relationship -X- _ O
of -X- _ O
the -X- _ O
kth -X- _ O
triple -X- _ O
respectively. -X- _ O

The -X- _ O
DRE -X- _ B-TaskName
component -X- _ O
takes -X- _ O
the -X- _ O
document -X- _ O
text -X- _ O
e1, -X- _ O
e2, -X- _ O
..., -X- _ O
ej} -X- _ O
(D) -X- _ O
and -X- _ O
entities -X- _ O
( -X- _ O
) -X- _ O
extracted -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
step -X- _ O
as -X- _ O
inputs, -X- _ O
and -X- _ O
outputs -X- _ O
the -X- _ O
in -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
relation -X- _ O
pairs -X- _ O
among -X- _ O
entities, -X- _ O
k, -X- _ O
et -X- _ O
2 -X- _ O
, -X- _ O
et -X- _ O
k, -X- _ O
rk] -X- _ O
triples -X- _ O
). -X- _ O

4.3 -X- _ O
Document -X- _ O
Relation -X- _ O
Extraction -X- _ O

D -X- _ O
si∈ -X- _ O
X -X- _ O
where -X- _ O
si -X- _ O
denotes -X- _ O
the -X- _ O
ith -X- _ O
sequence -X- _ O
sentence -X- _ O
in -X- _ O
document, -X- _ O
and -X- _ O
yi -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
ground -X- _ O
truth -X- _ O
label -X- _ O
sequence. -X- _ O

R(j+i) -X- _ O
× -X- _ O

The -X- _ O
loss -X- _ O
function -X- _ O
for -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
is -X- _ O

Then -X- _ O
all -X- _ O
the -X- _ O
intermediate -X- _ O
embeddings -X- _ O
of -X- _ O
extracted -X- _ O
entity -X- _ O
mentions -X- _ O
and -X- _ O
sentences -X- _ O
are -X- _ O
concatenate -X- _ O
into -X- _ O
a -X- _ O
made -X- _ O
by -X- _ O
max-pooling -X- _ O
operation -X- _ O
trix -X- _ O
Mne+s -X- _ O
∈ -X- _ O
on -X- _ O
each -X- _ O
sentence -X- _ O
and -X- _ O
entity -X- _ O
mention -X- _ O
span, -X- _ O
where -X- _ O
j -X- _ O
and -X- _ O
i -X- _ O
are -X- _ O
the -X- _ O
numbers -X- _ O
of -X- _ O
entity -X- _ O
mentions -X- _ O
and -X- _ O
sentences, -X- _ O
and -X- _ O
de -X- _ O
is -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
embeddings. -X- _ O

ˆyne -X- _ O
= -X- _ O
CRF -X- _ O
(T -X- _ O
rans(D)). -X- _ O

The -X- _ O
labels -X- _ O
are -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
following -X- _ O
calculation: -X- _ O

We -X- _ O
adopt -X- _ O
the -X- _ O
classical -X- _ O
BIOSE -X- _ O
sequence -X- _ O
labeling -X- _ O
scheme. -X- _ O

(Lafferty -X- _ O
et -X- _ O
al., -X- _ O
2001) -X- _ O
to -X- _ O
classify -X- _ O
token -X- _ O
representations -X- _ O
into -X- _ O
labels -X- _ O
of -X- _ O
named -X- _ O
entities. -X- _ O

Then -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Conditional -X- _ O
Random -X- _ O
Field(CRF) -X- _ O

Specifically, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
encoder -X- _ O
pre-trained -X- _ O
in -X- _ O
Roberta -X- _ O
setting -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Given -X- _ O
a -X- _ O
document -X- _ O
D -X- _ O
s1, -X- _ O
s2, -X- _ O
..., -X- _ O
si} -X- _ O
with -X- _ O
multiple -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
{ -X- _ O
native -X- _ O
transformer -X- _ O
encoder -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
token -X- _ O
sequence. -X- _ O

We -X- _ O
treat -X- _ O
the -X- _ O
component -X- _ O
of -X- _ O
entity -X- _ B-TaskName
extraction -X- _ I-TaskName
as -X- _ O
a -X- _ O
sequence -X- _ B-TaskName
labeling -X- _ I-TaskName
task. -X- _ O

4.2 -X- _ O
Entity -X- _ O
Extraction -X- _ O
and -X- _ O
Representation -X- _ O

In -X- _ O
the -X- _ O
following, -X- _ O
we -X- _ O
would -X- _ O
introduce -X- _ O
the -X- _ O
detailed -X- _ O
definition -X- _ O
of -X- _ O
each -X- _ O
component. -X- _ O

More -X- _ O
specifically, -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2, -X- _ O
there -X- _ O
are -X- _ O
four -X- _ O
key -X- _ O
components -X- _ O
in -X- _ O
our -X- _ O
ReDEE -X- _ B-TaskName
framework: -X- _ O
Entity -X- _ B-TaskName
Extraction -X- _ I-TaskName
and -X- _ I-TaskName
Representation(EER), -X- _ I-TaskName
Document -X- _ B-TaskName
Relation -X- _ I-TaskName
Extraction(DRE), -X- _ I-TaskName
Entity -X- _ B-TaskName
and -X- _ I-TaskName
Sentence -X- _ I-TaskName
Encoding(ESE), -X- _ I-TaskName
and -X- _ O
Event -X- _ B-TaskName
Record -X- _ I-TaskName
Generation(ERG). -X- _ I-TaskName

Moreover, -X- _ O
a -X- _ O
relation -X- _ B-TaskName
prediction -X- _ I-TaskName
task -X- _ O
is -X- _ O
added -X- _ O
into -X- _ O
the -X- _ O
framework -X- _ O
to -X- _ O
fully -X- _ O
utilize -X- _ O
the -X- _ O
relation -X- _ O
knowledge -X- _ O
and -X- _ O
enhance -X- _ O
the -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
task. -X- _ O

Our -X- _ O
framework -X- _ O
features -X- _ O
leverage -X- _ O
the -X- _ O
relation -X- _ O
dependency -X- _ O
information -X- _ O
in -X- _ O
both -X- _ O
encoding -X- _ O
and -X- _ O
decoding -X- _ O
stages. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
Relation-augmented -X- _ B-TaskName
Documentlevel -X- _ I-TaskName
Event -X- _ I-TaskName
Extraction -X- _ I-TaskName
(ReDEE) -X- _ B-TaskName
framework -X- _ O
coordinated -X- _ O
with -X- _ O
the -X- _ O
paradigm. -X- _ O

End-to-end -X- _ O
training -X- _ O
methods -X- _ O
for -X- _ O
DEE -X- _ B-TaskName
usually -X- _ O
involve -X- _ O
a -X- _ O
pipeline -X- _ O
paradigm, -X- _ O
including -X- _ O
three -X- _ O
subtasks: -X- _ O
named -X- _ O
entity -X- _ O
recognition, -X- _ O
event -X- _ O
role -X- _ O
prediction -X- _ O
and -X- _ O
event -X- _ O
argument -X- _ O
extraction. -X- _ O

4.1 -X- _ O
Architecture -X- _ O
Overview -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
proposed -X- _ O
architecture -X- _ O
first -X- _ O
and -X- _ O
then -X- _ O
the -X- _ O
key -X- _ O
components -X- _ O
in -X- _ O
detail. -X- _ O

4 -X- _ O
Methodology -X- _ O

Further -X- _ O
more, -X- _ O
a -X- _ O
entity -X- _ O
can -X- _ O
have -X- _ O
multiple -X- _ O
event -X- _ O
mentions. -X- _ O

ument -X- _ O
can -X- _ O
contain -X- _ O
multiple -X- _ O
event -X- _ O
records, -X- _ O
and -X- _ O
an -X- _ O
event -X- _ O
record -X- _ O
may -X- _ O
miss -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
event -X- _ O
arguments. -X- _ O

In -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
task, -X- _ O
one -X- _ O
doc -X- _ O

5) -X- _ O
event -X- _ O
record: -X- _ O
a -X- _ O
record -X- _ O
expressing -X- _ O
an -X- _ O
event -X- _ O
itself, -X- _ O
including -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
event -X- _ O
arguments. -X- _ O

4) -X- _ O
event -X- _ O
argument: -X- _ O
an -X- _ O
entity -X- _ O
playing -X- _ O
a -X- _ O
specific -X- _ O
event -X- _ O
role. -X- _ O

3) -X- _ O
event -X- _ O
role: -X- _ O
an -X- _ O
attribute -X- _ O
corresponding -X- _ O
a -X- _ O
pre-defined -X- _ O
field -X- _ O
in -X- _ O
an -X- _ O
event. -X- _ O

1) -X- _ O
entity: -X- _ O
a -X- _ O
real -X- _ O
world -X- _ O
object, -X- _ O
such -X- _ O
as -X- _ O
person, -X- _ O
organization, -X- _ O
location, -X- _ O
etc.2) -X- _ O
entity -X- _ O
mention: -X- _ O
a -X- _ O
text -X- _ O
span -X- _ O
in -X- _ O
document -X- _ O
referring -X- _ O
to -X- _ O
an -X- _ O
entity -X- _ O
object. -X- _ O

Firstly, -X- _ O
we -X- _ O
clarify -X- _ O
several -X- _ O
key -X- _ O
concepts -X- _ O
in -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
tasks. -X- _ O

3 -X- _ O
Preliminaries -X- _ O

In -X- _ O
our -X- _ O
work, -X- _ O
we -X- _ O
unify -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
whole -X- _ O
to -X- _ O
avoid -X- _ O
error -X- _ O
propagation -X- _ O
between -X- _ O
sub-tasks. -X- _ O

And -X- _ O
secondly, -X- _ O
event -X- _ O
arguments, -X- _ O
the -X- _ O
main -X- _ O
attributes -X- _ O
of -X- _ O
events, -X- _ O
are -X- _ O
extracted -X- _ O
by -X- _ O
modeling -X- _ O
relationships -X- _ O
between -X- _ O
triggers -X- _ O
and -X- _ O
themselves. -X- _ O

Previously -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
works((Ji -X- _ O
and -X- _ O
Grishman, -X- _ O
2008; -X- _ O
Liao -X- _ O
and -X- _ O
Grishman, -X- _ O
2010; -X- _ O
Li -X- _ O
et -X- _ O
al., -X- _ O
2013; -X- _ O
Chen -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Nguyen -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2018)) -X- _ O
deal -X- _ O
with -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
in -X- _ O
two -X- _ O
stages: -X- _ O
firstly, -X- _ O
trigger -X- _ O
words -X- _ O
are -X- _ O
detected, -X- _ O
which -X- _ O
are -X- _ O
usually -X- _ O
nouns -X- _ O
or -X- _ O
verbs -X- _ O
that -X- _ O
clearly -X- _ O
express -X- _ O
event -X- _ O
occurrences. -X- _ O

2.3 -X- _ O
Trigger-aware -X- _ O
Event -X- _ O
Extraction -X- _ O

In -X- _ O
summary, -X- _ O
although -X- _ O
those -X- _ O
existing -X- _ O
works -X- _ O
target -X- _ O
for -X- _ O
solving -X- _ O
across-sentence -X- _ O
and -X- _ O
multi-event -X- _ O
issues -X- _ O
of -X- _ O
the -X- _ O
DEE -X- _ B-TaskName
task -X- _ O
from -X- _ O
various -X- _ O
perspectives, -X- _ O
to -X- _ O
our -X- _ O
best -X- _ O
knowledge, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
pioneer -X- _ O
investigation -X- _ O
on -X- _ O
relation -X- _ O
modeling -X- _ O
towards -X- _ O
this -X- _ O
research -X- _ O
field -X- _ O
in -X- _ O
this -X- _ O
paper. -X- _ O

Not -X- _ O
long -X- _ O
ago, -X- _ O
a -X- _ O
pruned -X- _ O
complete -X- _ O
graph-based -X- _ O
non-autoregressive -X- _ O
model -X- _ O
PTPCG -X- _ B-MethodName
was -X- _ O
proposed -X- _ O
to -X- _ O
speedup -X- _ O
the -X- _ O
record -X- _ O
decoding -X- _ O
and -X- _ O
get -X- _ O
competitive -X- _ O
overall -X- _ O
evaluation -X- _ O
results -X- _ O
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

DE-PPN -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
is -X- _ O
a -X- _ O
multi-granularity -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
generate -X- _ O
event -X- _ O
records -X- _ O
via -X- _ O
limiting -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
record -X- _ O
queries. -X- _ O

It -X- _ O
also -X- _ O
introduces -X- _ O
a -X- _ O
specific -X- _ O
Tracker -X- _ O
module -X- _ O
to -X- _ O
memorize -X- _ O
the -X- _ O
already -X- _ O
extracted -X- _ O
event -X- _ O
arguments -X- _ O
for -X- _ O
assisting -X- _ O
record -X- _ O
generation -X- _ O
during -X- _ O
next -X- _ O
iterations. -X- _ O

For -X- _ O
instance, -X- _ O
GIT -X- _ B-MethodName
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021b) -X- _ O
designs -X- _ O
a -X- _ O
heterogeneous -X- _ O
graph -X- _ O
interaction -X- _ O
network -X- _ O
to -X- _ O
capture -X- _ O
global -X- _ O
interaction -X- _ O
information -X- _ O
among -X- _ O
different -X- _ O
sentences -X- _ O
and -X- _ O
entity -X- _ O
mentions. -X- _ O

Based -X- _ O
on -X- _ O
Doc2EDAG, -X- _ B-MethodName
there -X- _ O
are -X- _ O
some -X- _ O
variants -X- _ O
appearing. -X- _ O

Later, -X- _ O
an -X- _ O
innovative -X- _ O
end-to-end -X- _ O
model -X- _ O
Doc2EDAG, -X- _ B-MethodName
is -X- _ O
proposed -X- _ O
(Zheng -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
which -X- _ O
can -X- _ O
generate -X- _ O
event -X- _ O
records -X- _ O
via -X- _ O
an -X- _ O
entity-based -X- _ O
directed -X- _ O
acyclic -X- _ O
graph -X- _ O
to -X- _ O
fulfill -X- _ O
the -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
effectively. -X- _ O

other -X- _ O
arguments -X- _ O
are -X- _ O
extracted -X- _ O
from -X- _ O
neighboring -X- _ O
sentences -X- _ O
separately -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

At -X- _ O
first, -X- _ O
the -X- _ O
event -X- _ O
is -X- _ O
identified -X- _ O
from -X- _ O
a -X- _ O
central -X- _ O
sentence -X- _ O
and -X- _ O

Recently, -X- _ O
DEE -X- _ B-TaskName
has -X- _ O
attracted -X- _ O
a -X- _ O
great -X- _ O
attention -X- _ O
from -X- _ O
both -X- _ O
academic -X- _ O
and -X- _ O
industrial -X- _ O
communities. -X- _ O

2.2 -X- _ O
Document-level -X- _ B-TaskName
Event -X- _ I-TaskName
Extraction -X- _ I-TaskName

However, -X- _ O
these -X- _ O
sentence-level -X- _ O
models -X- _ O
fail -X- _ O
to -X- _ O
extract -X- _ O
multiple -X- _ O
qualified -X- _ O
events -X- _ O
spanning -X- _ O
across -X- _ O
sentences, -X- _ O
while -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
is -X- _ O
a -X- _ O
more -X- _ O
common -X- _ O
need -X- _ O
in -X- _ O
real-world -X- _ O
scenarios. -X- _ O

To -X- _ O
utilize -X- _ O
more -X- _ O
knowledge, -X- _ O
some -X- _ O
studies -X- _ O
propose -X- _ O
to -X- _ O
leverage -X- _ O
document -X- _ O
contexts -X- _ O
(Chen -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Zhao -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
and -X- _ O
explicit -X- _ O
external -X- _ O
knowledge -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019a; -X- _ O
Tong -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Then -X- _ O
a -X- _ O
joint -X- _ O
model -X- _ O
is -X- _ O
created -X- _ O
to -X- _ O
extract -X- _ O
triggers -X- _ O
and -X- _ O
arguments -X- _ O
simultaneously -X- _ O
via -X- _ O
multi-task -X- _ O
learning -X- _ O
(Nguyen -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Sha -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

For -X- _ O
example, -X- _ O
a -X- _ O
neural -X- _ O
pipeline -X- _ O
model -X- _ O
is -X- _ O
proposed -X- _ O
to -X- _ O
identify -X- _ O
triggers -X- _ O
first -X- _ O
and -X- _ O
then -X- _ O
extracts -X- _ O
roles -X- _ O
and -X- _ O
arguments -X- _ O
(Chen -X- _ O
et -X- _ O
al., -X- _ O
2015). -X- _ O

Previously, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
related -X- _ O
works -X- _ O
focus -X- _ O
on -X- _ O
sentence-level -X- _ O
event -X- _ O
extraction. -X- _ O

2.1 -X- _ O
Sentence-level -X- _ O
Event -X- _ O
Extraction -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

form -X- _ O
the -X- _ O
baselines -X- _ O
and -X- _ O
achieve -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
by -X- _ O
1.6% -X- _ B-MetricValue
and -X- _ O
2.8% -X- _ B-MetricValue
F1 -X- _ B-MetricName
absolute -X- _ O
increasing -X- _ O
on -X- _ O
two -X- _ O
datasets -X- _ O
respectively. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
outper -X- _ O

This -X- _ O
network -X- _ O
is -X- _ O
general -X- _ O
to -X- _ O
cover -X- _ O
multi-scale -X- _ O
and -X- _ O
multi-amount -X- _ O
relations -X- _ O
in -X- _ O
DEE. -X- _ B-TaskName

We -X- _ O
design -X- _ O
a -X- _ O
novel -X- _ O
Relation-augmented -X- _ B-MethodName
Attention -X- _ I-MethodName
Transformer -X- _ I-MethodName
(RAAT). -X- _ B-MethodName

It -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
that -X- _ O
relation -X- _ O
information -X- _ O
is -X- _ O
implemented -X- _ O
in -X- _ O
the -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
field. -X- _ O

We -X- _ O
propose -X- _ O
a -X- _ O
Relation-augmented -X- _ B-TaskName
Documentlevel -X- _ I-TaskName
Event -X- _ I-TaskName
Extraction -X- _ I-TaskName
(ReDEE) -X- _ B-TaskName
framework. -X- _ O

In -X- _ O
summary, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows: -X- _ O

The -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
modeling -X- _ O
the -X- _ O
relation -X- _ O
information, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
and -X- _ O
method. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
public -X- _ O
datasets. -X- _ O

To -X- _ O
fully -X- _ O
leverage -X- _ O
the -X- _ O
relation -X- _ O
information, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
relation -X- _ O
prediction -X- _ O
task -X- _ O
into -X- _ O
the -X- _ O
ReDEE -X- _ B-TaskName
framework -X- _ O
and -X- _ O
adopt -X- _ O
multi-task -X- _ O
learning -X- _ O
method -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
task. -X- _ O

We -X- _ O
name -X- _ O
the -X- _ O
structure -X- _ O
as -X- _ O
Relationaugmented -X- _ B-MethodName
Attention -X- _ I-MethodName
Transformer -X- _ I-MethodName
(RAAT). -X- _ B-MethodName

This -X- _ O
structure -X- _ O
can -X- _ O
cover -X- _ O
multi-scale -X- _ O
and -X- _ O
multi-amount -X- _ O
relations -X- _ O
and -X- _ O
is -X- _ O
general -X- _ O
for -X- _ O
different -X- _ O
relation -X- _ O
modeling -X- _ O
situations. -X- _ O

the -X- _ O
relation -X- _ O
information -X- _ O
between -X- _ O
arguments -X- _ O
by -X- _ O
designing -X- _ O
a -X- _ O
tailored -X- _ O
transformer -X- _ O
structure. -X- _ O

More -X- _ O
information -X- _ O
of -X- _ O
entity -X- _ O
color -X- _ O
and -X- _ O
complete -X- _ O
event-related -X- _ O
relations -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.2. -X- _ O

We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
these -X- _ O
entity -X- _ O
mentions -X- _ O
have -X- _ O
intuitive -X- _ O
patterns -X- _ O
that -X- _ O
could -X- _ O
be -X- _ O
leveraged -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
task. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
DEE -X- _ B-TaskName
framework, -X- _ O
called -X- _ O
Relation-augmented -X- _ B-TaskName
Document-level -X- _ I-TaskName
Event -X- _ I-TaskName
Extraction -X- _ I-TaskName
(ReDEE), -X- _ B-TaskName
which -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
model -X- _ O

Therefore, -X- _ O
the -X- _ O
relation -X- _ O
information -X- _ O
could -X- _ O
increase -X- _ O
the -X- _ O
DEE -X- _ B-TaskName
accuracy -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
well -X- _ O
modeled. -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
[ORG1] -X- _ O
and -X- _ O
[ORG2] -X- _ O
have -X- _ O
a -X- _ O
prior -X- _ O
relation -X- _ O
pattern -X- _ O
of -X- _ O
Pledger -X- _ O
and -X- _ O
Pledgee, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
[ORG1] -X- _ O
and -X- _ O
[SHARE1] -X- _ O
for -X- _ O
the -X- _ O
relation -X- _ O
pattern -X- _ O
between -X- _ O
Pledger -X- _ O
and -X- _ O
its -X- _ O
Pledged -X- _ O
Shares. -X- _ O

For -X- _ O
multi-event -X- _ O
issue, -X- _ O
shared -X- _ O
arguments -X- _ O
within -X- _ O
one -X- _ O
document -X- _ O
could -X- _ O
be -X- _ O
distinguished -X- _ O
to -X- _ O
different -X- _ O
roles -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
different -X- _ O
prior -X- _ O
relation -X- _ O
knowledge. -X- _ O

Intuitively, -X- _ O
the -X- _ O
relation -X- _ O
information -X- _ O
could -X- _ O
build -X- _ O
long-range -X- _ O
relationship -X- _ O
knowledge -X- _ O
of -X- _ O
event -X- _ O
roles -X- _ O
among -X- _ O
multiple -X- _ O
sentences, -X- _ O
which -X- _ O
could -X- _ O
relieve -X- _ O
the -X- _ O
across-sentence -X- _ O
issue. -X- _ O

This -X- _ O
information -X- _ O
is -X- _ O
neglected -X- _ O
by -X- _ O
existing -X- _ O
DEE -X- _ B-TaskName
methods. -X- _ O

However, -X- _ O
by -X- _ O
our -X- _ O
observation, -X- _ O
we -X- _ O
discover -X- _ O
that -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
event -X- _ O
arguments -X- _ O
have -X- _ O
patterns -X- _ O
which -X- _ O
are -X- _ O
an -X- _ O
important -X- _ O
indicator -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
event -X- _ B-TaskName
extraction. -X- _ I-TaskName

Xu -X- _ O
et -X- _ O
al., -X- _ O
2021b; -X- _ O
Yang -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Zhu -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Recently, -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
(DEE) -X- _ B-TaskName
attracts -X- _ O
great -X- _ O
attention -X- _ O
from -X- _ O
both -X- _ O
academic -X- _ O
and -X- _ O
industrial -X- _ O
communities, -X- _ O
and -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
promising -X- _ O
direction -X- _ O
to -X- _ O
tackle -X- _ O
the -X- _ O
above -X- _ O
issues -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Zheng -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

As -X- _ O
seen -X- _ O
in -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
where -X- _ O
two -X- _ O
event -X- _ O
records -X- _ O
coincide, -X- _ O
we -X- _ O
should -X- _ O
recognize -X- _ O
that -X- _ O
they -X- _ O
may -X- _ O
partially -X- _ O
share -X- _ O
common -X- _ O
arguments. -X- _ O

Another -X- _ O
situation -X- _ O
involves -X- _ O
the -X- _ O
multi-event -X- _ O
issue, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
multiple -X- _ O
events -X- _ O
may -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
document. -X- _ O

We -X- _ O
call -X- _ O
this -X- _ O
across-sentence -X- _ O
issue. -X- _ O

[ORG2] -X- _ O
of -X- _ O
event -X- _ O
role -X- _ O
Pledgee -X- _ O
is -X- _ O
in -X- _ O
Sentence -X- _ O
5 -X- _ O
and -X- _ O
6. -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
the -X- _ O
event -X- _ O
argument -X- _ O
[ORG1] -X- _ O
of -X- _ O
event -X- _ O
role -X- _ O
Pledger -X- _ O
is -X- _ O
mentioned -X- _ O
in -X- _ O
Sentence -X- _ O
4 -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
argument -X- _ O

For -X- _ O
example, -X- _ O
event -X- _ O
arguments -X- _ O
may -X- _ O
scatter -X- _ O
across -X- _ O
different -X- _ O
sentences. -X- _ O

However, -X- _ O
SEE -X- _ O
is -X- _ O
mostly -X- _ O
inconsistent -X- _ O
with -X- _ O
actual -X- _ O
situations. -X- _ O

et -X- _ O
al., -X- _ O
2020; -X- _ O
Paolini -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Lu -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
extracting -X- _ O
events -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
sentence. -X- _ O

Yan -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Du -X- _ O
and -X- _ O
Cardie, -X- _ O
2020; -X- _ O
Li -X- _ O

Most -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
focus -X- _ O
on -X- _ O
sentencelevel -X- _ O
event -X- _ O
extraction -X- _ O
(SEE) -X- _ O
(Ahn, -X- _ O
2006; -X- _ O
Liao -X- _ O
and -X- _ O
Grishman, -X- _ O
2010; -X- _ O
Li -X- _ O
et -X- _ O
al., -X- _ O
2013; -X- _ O
Chen -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Nguyen -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O
Zhao -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Sha -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O

Liu -X- _ O
et -X- _ O
al., -X- _ O
2017), -X- _ O
knowledge -X- _ O
graph -X- _ O
construction -X- _ O
(Wu -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Bosselut -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
intelligent -X- _ O
question -X- _ O
answering -X- _ O
(Boyd-Graber -X- _ O
and -X- _ O
Börschinger, -X- _ O
2020; -X- _ O
Cao -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Event -X- _ B-TaskName
extraction -X- _ I-TaskName
(EE) -X- _ B-TaskName
task -X- _ O
aims -X- _ O
to -X- _ O
detect -X- _ O
the -X- _ O
event -X- _ O
from -X- _ O
texts -X- _ O
and -X- _ O
then -X- _ O
extracts -X- _ O
corresponding -X- _ O
arguments -X- _ O
as -X- _ O
different -X- _ O
roles, -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
structural -X- _ O
information -X- _ O
for -X- _ O
massive -X- _ O
downstream -X- _ O
applications, -X- _ O
such -X- _ O
as -X- _ O
recommendation -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2016; -X- _ O

Introduction -X- _ O

com/TencentYoutuResearch/RAAT. -X- _ O

Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
at -X- _ O
https://github. -X- _ O

Extensive -X- _ O
experiments -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method, -X- _ O
which -X- _ O
can -X- _ O
achieve -X- _ O
state-ofthe-art -X- _ O
performance -X- _ O
on -X- _ O
two -X- _ O
public -X- _ O
datasets. -X- _ O

To -X- _ O
further -X- _ O
leverage -X- _ O
relation -X- _ O
information, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
separate -X- _ O
event -X- _ B-TaskName
relation -X- _ I-TaskName
prediction -X- _ I-TaskName
task -X- _ O
and -X- _ O
adopt -X- _ O
multi-task -X- _ O
learning -X- _ O
method -X- _ O
to -X- _ O
explicitly -X- _ O
enhance -X- _ O
event -X- _ B-TaskName
extraction -X- _ I-TaskName
performance. -X- _ O

RAAT -X- _ B-MethodName
is -X- _ O
scalable -X- _ O
to -X- _ O
capture -X- _ O
multi-scale -X- _ O
and -X- _ O
multi-amount -X- _ O
argument -X- _ O
relations. -X- _ O

More -X- _ O
specifically, -X- _ O
this -X- _ O
framework -X- _ O
features -X- _ O
a -X- _ O
novel -X- _ O
and -X- _ O
tailored -X- _ O
transformer, -X- _ O
named -X- _ O
as -X- _ O
Relation-augmented -X- _ B-MethodName
Attention -X- _ I-MethodName
Transformer -X- _ I-MethodName
(RAAT). -X- _ B-MethodName

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
relation -X- _ O
information -X- _ O
of -X- _ O
event -X- _ O
arguments -X- _ O
is -X- _ O
of -X- _ O
great -X- _ O
significance -X- _ O
for -X- _ O
addressing -X- _ O
the -X- _ O
above -X- _ O
two -X- _ O
issues, -X- _ O
and -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
DEE -X- _ B-TaskName
framework -X- _ O
which -X- _ O
can -X- _ O
model -X- _ O
the -X- _ O
relation -X- _ O
dependencies, -X- _ O
called -X- _ O
Relation-augmented -X- _ B-TaskName
Document-level -X- _ I-TaskName
Event -X- _ I-TaskName
Extraction -X- _ I-TaskName
(ReDEE). -X- _ B-TaskName

In -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
(DEE) -X- _ B-TaskName
task, -X- _ O
event -X- _ O
arguments -X- _ O
always -X- _ O
scatter -X- _ O
across -X- _ O
sentences -X- _ O
(across-sentence -X- _ O
issue) -X- _ O
and -X- _ O
multiple -X- _ O
events -X- _ O
may -X- _ O
lie -X- _ O
in -X- _ O
one -X- _ O
document -X- _ O
(multi-event -X- _ O
issue). -X- _ O

Abstract -X- _ O

RAAT: -X- _ B-MethodName
Relation-Augmented -X- _ B-MethodName
Attention -X- _ I-MethodName
Transformer -X- _ I-MethodName
for -X- _ O
Relation -X- _ O
Modeling -X- _ O
in -X- _ O
Document-Level -X- _ B-TaskName
Event -X- _ I-TaskName
Extraction -X- _ I-TaskName

-DOCSTART- -X- O
2.77 -X- _ B-MetricValue
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
on -X- _ O
test -X- _ O
set. -X- _ O

Table -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
RAMS -X- _ B-DatasetName
dataset, -X- _ O
from -X- _ O
which -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
removing -X- _ O
different -X- _ O
modules -X- _ O
would -X- _ O
cause -X- _ O
1.34 -X- _ B-MetricValue

To -X- _ O
thoroughly -X- _ O
show -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
different -X- _ O
modules -X- _ O
of -X- _ O
TSAR, -X- _ B-MethodName
we -X- _ O
also -X- _ O
provide -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
ablation -X- _ O
study -X- _ O
for -X- _ O
TSARbase -X- _ B-MethodName
on -X- _ O
RAMS -X- _ B-DatasetName
dataset. -X- _ O

In -X- _ O
the -X- _ O
main -X- _ O
body -X- _ O
of -X- _ O
the -X- _ O
paper, -X- _ O
we -X- _ O
illustrate -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
ablation -X- _ O
study -X- _ O
for -X- _ O
TSARlarge -X- _ B-MethodName
on -X- _ O
RAMS -X- _ B-DatasetName
dataset. -X- _ O

Our -X- _ O
{ -X- _ O
} -X- _ O
code -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Transformers -X- _ O
(Wolf -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
DGL -X- _ O
libraries -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

We -X- _ O
search -X- _ O
the -X- _ O
boundary -X- _ O
, -X- _ O
and -X- _ O
L -X- _ B-HyperparameterName
from -X- _ O
loss -X- _ B-HyperparameterName
weight -X- _ I-HyperparameterName
λ -X- _ B-HyperparameterName
from -X- _ O
0.05, -X- _ B-HyperparameterValue
0.1, -X- _ B-HyperparameterValue
0.2 -X- _ B-HyperparameterValue
} -X- _ O
3, -X- _ B-HyperparameterValue
4 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
using -X- _ O
dev -X- _ O
set. -X- _ O

We -X- _ O
train -X- _ O
TSAR -X- _ B-MethodName
for -X- _ O
50 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
for -X- _ O
RAMS -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
100 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
for -X- _ O
WikiEvents -X- _ B-DatasetName
dataset. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
0.1, -X- _ B-HyperparameterValue
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
8, -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
TSAR -X- _ B-MethodName
using -X- _ O
Adam -X- _ O
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2015) -X- _ O
as -X- _ O
optimizer -X- _ O
with -X- _ O
3e-5 -X- _ B-HyperparameterValue
learning -X- _ B-HyperparameterName
rate. -X- _ I-HyperparameterName

B -X- _ O
Hyperparameters -X- _ O
Setting -X- _ O

Categories -X- _ O

As -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
AMR -X- _ O
relation -X- _ O
types -X- _ O
is -X- _ O
large, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
too -X- _ O
many -X- _ O
demanded -X- _ O
parameters, -X- _ O
we -X- _ O
follow -X- _ O
Zhang -X- _ O
and -X- _ O
Ji -X- _ O
(2021) -X- _ O
to -X- _ O
cluster -X- _ O
the -X- _ O
relation -X- _ O
types -X- _ O
into -X- _ O
main -X- _ O
categories -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6. -X- _ O

To -X- _ O
obtain -X- _ O
AMR -X- _ O
semantic -X- _ O
graphs -X- _ O
with -X- _ O
the -X- _ O
align -X- _ O
information -X- _ O
between -X- _ O
text -X- _ O
spans -X- _ O
and -X- _ O
AMR -X- _ O
nodes, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
transition-based -X- _ O
AMR -X- _ O
parser -X- _ O
proposed -X- _ O
by -X- _ O
Fernandez -X- _ O
Astudillo -X- _ O
et -X- _ O
al. -X- _ O
(2020), -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
state-of-theart -X- _ O
AMR -X- _ O
parser -X- _ O
and -X- _ O
can -X- _ O
achieve -X- _ O
satisfactory -X- _ O
results -X- _ O
for -X- _ O
downstream -X- _ O
application -X- _ O
(up -X- _ O
to -X- _ O
81.3 -X- _ B-MetricValue
Smatch -X- _ B-MetricName
on -X- _ O
AMR2.0 -X- _ B-DatasetName
data). -X- _ O

There -X- _ O
are -X- _ O
many -X- _ O
AMR -X- _ O
parsing -X- _ O
approaches -X- _ O
(Bevilacqua -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Fernandez -X- _ O
Astudillo -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2022; -X- _ O
Chen -X- _ O
et -X- _ O
al., -X- _ O
2022). -X- _ O

A -X- _ O
Abstract -X- _ O
Meaning -X- _ O
Representation -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
identification -X- _ B-TaskName
and -X- _ O
classification -X- _ B-TaskName
would -X- _ O
decrease -X- _ O
without -X- _ O
any -X- _ O
kind -X- _ O
of -X- _ O
module. -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
identification -X- _ B-TaskName
and -X- _ O
classification -X- _ B-TaskName
would -X- _ O
decrease -X- _ O
without -X- _ O
any -X- _ O
kind -X- _ O
of -X- _ O
module. -X- _ O

The -X- _ O
score -X- _ O
would -X- _ O
decrease -X- _ O
without -X- _ O
any -X- _ O
kind -X- _ O
of -X- _ O
module. -X- _ O

Similar -X- _ O
conclusions -X- _ O
can -X- _ O
be -X- _ O
drawn -X- _ O
from -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
TSARlarge, -X- _ B-MethodName
which -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
9. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8, -X- _ O
the -X- _ O
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
decreases -X- _ O
by -X- _ O
0.70 -X- _ B-MetricValue
2.96 -X- _ B-MetricValue
for -X- _ O
Arg -X- _ B-TaskName
Identification -X- _ I-TaskName
and -X- _ O
Arg -X- _ B-TaskName
Classification -X- _ I-TaskName
sub-tasks -X- _ O
respectively, -X- _ O
once -X- _ O
different -X- _ O
modules -X- _ O
are -X- _ O
removed -X- _ O
from -X- _ O
TSARbase. -X- _ B-MethodName

Besides, -X- _ O
we -X- _ O
do -X- _ O
ablation -X- _ O
study -X- _ O
on -X- _ O
WikiEvents. -X- _ B-DatasetName

Acknowledgements -X- _ O

Experiments -X- _ O
on -X- _ O
RAMS -X- _ B-DatasetName
and -X- _ O
WikiEvents -X- _ B-DatasetName
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
TSAR -X- _ B-MethodName
outperform -X- _ O
previous -X- _ O
state-of-the-art -X- _ O
methods -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin, -X- _ O
with -X- _ O
2.51 -X- _ B-MetricValue
and -X- _ O
5.13 -X- _ B-MetricValue
F1 -X- _ B-MetricName
improvements -X- _ O
respectively, -X- _ O
especially -X- _ O
for -X- _ O
cross-sentence -X- _ B-TaskName
argument -X- _ I-TaskName
extraction. -X- _ I-TaskName

An -X- _ O
auxiliary -X- _ O
boundary -X- _ O
loss -X- _ O
is -X- _ O
introduced -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
boundary -X- _ O
information -X- _ O
for -X- _ O
spans. -X- _ O

TSAR -X- _ B-MethodName
uses -X- _ O
two-stream -X- _ O
encoders -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
document -X- _ O
from -X- _ O
different -X- _ O
perspectives, -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
AMR-guided -X- _ O
interaction -X- _ O
module -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
document-level -X- _ O
semantic -X- _ O
interactions. -X- _ O

To -X- _ O
tackle -X- _ O
these -X- _ O
problems, -X- _ O
we -X- _ O
propose -X- _ O
Two-Stream -X- _ B-MethodName
AMRenhanced -X- _ I-MethodName
extraction -X- _ I-MethodName
model -X- _ O
(TSAR). -X- _ B-MethodName

It -X- _ O
is -X- _ O
challenging -X- _ O
to -X- _ O
extract -X- _ O
event -X- _ O
arguments -X- _ O
from -X- _ O
a -X- _ O
whole -X- _ O
document, -X- _ O
owing -X- _ O
to -X- _ O
the -X- _ O
long-distance -X- _ O
dependency -X- _ O
between -X- _ O
trigger -X- _ O
and -X- _ O
arguments -X- _ O
over -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
distracting -X- _ O
context. -X- _ O

7 -X- _ O
Conclusion -X- _ O

We -X- _ O
observe -X- _ O
TSAR -X- _ B-MethodName
decrease -X- _ O
the -X- _ O
number -X- _ B-MetricName
of -X- _ I-MetricName
errors -X- _ I-MetricName
from -X- _ O
275 -X- _ B-MetricValue
to -X- _ O
233, -X- _ B-MetricValue
especially -X- _ O
for -X- _ O
Wrong -X- _ B-TaskName
Role -X- _ I-TaskName
and -X- _ O
Over-extract, -X- _ B-TaskName
with -X- _ O
27 -X- _ B-MetricValue
and -X- _ O
16 -X- _ B-MetricValue
errors -X- _ O
reduction, -X- _ O
respectively. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
errors -X- _ O
of -X- _ O
Two-stepTCD -X- _ B-MethodName
and -X- _ O
TSARbase. -X- _ B-MethodName

Finally, -X- _ O
though -X- _ O
the -X- _ O
model -X- _ O
succeeds -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
golden -X- _ O
span, -X- _ O
it -X- _ O
can -X- _ O
still -X- _ O
assign -X- _ O
wrong -X- _ O
argument -X- _ O
role -X- _ O
to -X- _ O
the -X- _ O
span -X- _ O
(Wrong -X- _ O
Role). -X- _ O

Besides, -X- _ O
the -X- _ O
Partial -X- _ O
error -X- _ O
also -X- _ O
usually -X- _ O
occurs -X- _ O
in -X- _ O
cases -X- _ O
where -X- _ O
there -X- _ O
is -X- _ O
punctuation -X- _ O
like -X- _ O
a -X- _ O
comma -X- _ O
in -X- _ O
the -X- _ O
golden -X- _ O
span -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4. -X- _ O

Finally, -X- _ O
the -X- _ O
removal -X- _ O
of -X- _ O
boundary -X- _ O
loss -X- _ O
causes -X- _ O
the -X- _ O
boundary -X- _ O
information -X- _ O
lost -X- _ O
in -X- _ O
span -X- _ O
representations, -X- _ O
which -X- _ O
also -X- _ O
leads -X- _ O
to -X- _ O
1.62 -X- _ B-MetricValue
and -X- _ O
0.78 -X- _ B-MetricValue
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
decrease -X- _ O
on -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
set. -X- _ O

It -X- _ O
shows -X- _ O
the -X- _ O
semantic -X- _ O
structure -X- _ O
provided -X- _ O
by -X- _ O
AMR -X- _ O
graphs -X- _ O
is -X- _ O
helpful -X- _ O
to -X- _ O
the -X- _ O
arguments -X- _ O
extraction -X- _ O
of -X- _ O
the -X- _ O
document. -X- _ O

Secondly, -X- _ O
once -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
AMR-guided -X- _ O
interaction -X- _ O
module, -X- _ O
the -X- _ O
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
would -X- _ O
decrease -X- _ O
by -X- _ O
1.83 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O

It -X- _ O
suggests -X- _ O
the -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
encoders -X- _ O
are -X- _ O
complementary -X- _ O
to -X- _ O
each -X- _ O
other, -X- _ O
and -X- _ O
both -X- _ O
of -X- _ O
them -X- _ O
are -X- _ O
necessary -X- _ O
for -X- _ O
TSAR. -X- _ B-MethodName

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5, -X- _ O
the -X- _ O
removal -X- _ O
causes -X- _ O
drop -X- _ O
in -X- _ O
performance, -X- _ O
e.g., -X- _ O
3.04 -X- _ B-MetricValue
and -X- _ O
1.71 -X- _ B-MetricValue
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
drop -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
without -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
encoder. -X- _ O

TSAR -X- _ B-MethodName
manages -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
cross-sentence -X- _ O
argument -X- _ O
Minnesota -X- _ O
far -X- _ O
from -X- _ O
the -X- _ O
trigger, -X- _ O
while -X- _ O
other -X- _ O
methods -X- _ O
fail. -X- _ O

These -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
errors -X- _ O
are -X- _ O
usually -X- _ O
attributed -X- _ O
to -X- _ O

Some -X- _ O
extracted -X- _ O
spans -X- _ O
are -X- _ O
the -X- _ O
sub-strings -X- _ O
of -X- _ O
the -X- _ O
golden -X- _ O
spans -X- _ O
(Partial), -X- _ O
or -X- _ O
have -X- _ O
some -X- _ O
overlaps -X- _ O
with -X- _ O
them -X- _ O
(Overlap). -X- _ O

Over-extract -X- _ O
denotes -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
an -X- _ O
argument -X- _ O
role -X- _ O
while -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
in -X- _ O
the -X- _ O
document. -X- _ O

We -X- _ O
find -X- _ O
it -X- _ O
is -X- _ O
usually -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
negative -X- _ O
words -X- _ O
like -X- _ O
not, -X- _ O
and -X- _ O
the -X- _ O
coreference -X- _ O
spans -X- _ O
for -X- _ O
the -X- _ O
golden -X- _ O
one. -X- _ O

Wrong -X- _ O
Span -X- _ O
refers -X- _ O
to -X- _ O
assigning -X- _ O
a -X- _ O
specific -X- _ O
role -X- _ O
to -X- _ O
a -X- _ O
wrong -X- _ O
span -X- _ O
nonoverlapped -X- _ O
with -X- _ O
the -X- _ O
golden -X- _ O
one. -X- _ O

We -X- _ O
divide -X- _ O
the -X- _ O
errors -X- _ O
into -X- _ O
five -X- _ O
categories, -X- _ O
which -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4. -X- _ O

To -X- _ O
further -X- _ O
explore -X- _ O
the -X- _ O
errors -X- _ O
made -X- _ O
by -X- _ O
different -X- _ O
models -X- _ O
and -X- _ O
analyze -X- _ O
the -X- _ O
reasons -X- _ O
in -X- _ O
detail, -X- _ O
we -X- _ O
randomly -X- _ O
choose -X- _ O
200 -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
RAMS -X- _ B-DatasetName
test -X- _ O
set -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
predictions -X- _ O
with -X- _ O
golden -X- _ O
annotations -X- _ O
manually. -X- _ O

6.4 -X- _ O
Error -X- _ O
Analysis -X- _ O

It -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
that -X- _ O
our -X- _ O
AMR-enhanced -X- _ O
module -X- _ O
catches -X- _ O
Minnesota -X- _ O
is -X- _ O
the -X- _ O
place -X- _ O
of -X- _ O
attack -X- _ O
that -X- _ O
is -X- _ O
highly -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
trigger -X- _ O
stabbings -X- _ O
in -X- _ O
semantics. -X- _ O

Although -X- _ O
Two-Step -X- _ B-MethodName
and -X- _ O
BART-Gen -X- _ B-MethodName
wrongly -X- _ O
predict -X- _ O
the -X- _ O
place -X- _ O
as -X- _ O
Iraq -X- _ O
and -X- _ O
Syria, -X- _ O
and -X- _ O
Two-Step -X- _ B-MethodName
even -X- _ O
fails -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
Attacker, -X- _ O
TSAR -X- _ B-MethodName
manage -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
cross-sentence -X- _ O
arguments. -X- _ O

However, -X- _ O
extracting -X- _ O
Minnesota -X- _ O
and -X- _ O
Dahir -X- _ O
Adan -X- _ O
asks -X- _ O
for -X- _ O
capturing -X- _ O
long-distance -X- _ O
dependency. -X- _ O

Since -X- _ O
Nine -X- _ O
people -X- _ O
is -X- _ O
located -X- _ O
near -X- _ O
the -X- _ O
trigger, -X- _ O
all -X- _ O
the -X- _ O
methods -X- _ O
correctly -X- _ O
predict -X- _ O
it -X- _ O
as -X- _ O
the -X- _ O
target. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5, -X- _ O
stabbings -X- _ O
triggers -X- _ O
an -X- _ O
Attack -X- _ O
event -X- _ O
with -X- _ O
three -X- _ O
arguments -X- _ O
in -X- _ O
color. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
show -X- _ O
a -X- _ O
specific -X- _ O
case -X- _ O
of -X- _ O
the -X- _ O
extraction -X- _ O
results -X- _ O
among -X- _ O
different -X- _ O
methods. -X- _ O

6.3 -X- _ O
Case -X- _ O
Study -X- _ O

Compared -X- _ O
with -X- _ O
Two-step, -X- _ B-MethodName
TSAR -X- _ B-MethodName
decreases -X- _ O
errors -X- _ B-MetricName
in -X- _ O
most -X- _ O
error -X- _ O
categories, -X- _ O
especially -X- _ O
for -X- _ O
Wrong -X- _ B-TaskName
Role -X- _ I-TaskName
and -X- _ O
Over-extract. -X- _ B-TaskName

We -X- _ O
illustrate -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
different -X- _ O
kinds -X- _ O
of -X- _ O
errors -X- _ O
for -X- _ O
Two-step -X- _ B-MethodName
and -X- _ O
our -X- _ O
TSAR, -X- _ B-MethodName
which -X- _ O
has -X- _ O
275 -X- _ B-MetricValue
and -X- _ O
233 -X- _ B-MetricValue
errors -X- _ B-MetricName
in -X- _ O
total, -X- _ O
respectively. -X- _ O

The -X- _ O
[bracketed] -X- _ O
spans -X- _ O
denote -X- _ O
the -X- _ O
predicted -X- _ O
arguments, -X- _ O
with -X- _ O
their -X- _ O
roles -X- _ O
noted -X- _ O
in -X- _ O
red. -X- _ O

The -X- _ O
underlined -X- _ O
spans -X- _ O
refer -X- _ O
to -X- _ O
golden -X- _ O
arguments, -X- _ O
with -X- _ O
their -X- _ O
roles -X- _ O
in -X- _ O
blue. -X- _ O

The -X- _ O
triggers -X- _ O
are -X- _ O
in -X- _ O
bold -X- _ O
with -X- _ O
corresponding -X- _ O
event -X- _ O
types -X- _ O
in -X- _ O
green. -X- _ O

Firstly, -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
global -X- _ O
or -X- _ O
local -X- _ O
encoder -X- _ O
in -X- _ O

We -X- _ O
also -X- _ O
provide -X- _ O
results -X- _ O
for -X- _ O
TSARbase, -X- _ B-MethodName
and -X- _ O
those -X- _ O
on -X- _ O
WikiEvents -X- _ B-DatasetName
datasets -X- _ O
in -X- _ O
Appendix -X- _ O
C. -X- _ O

Table -X- _ O
5 -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
RAMS -X- _ B-DatasetName
datasets -X- _ O
for -X- _ O
TSARlarge. -X- _ B-MethodName

We -X- _ O
conduct -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
different -X- _ O
modules -X- _ O
in -X- _ O
TSAR. -X- _ B-MethodName

2We -X- _ O
use -X- _ O
TSARlarge -X- _ B-MethodName
based -X- _ O
on -X- _ O
RoBERTalarge -X- _ O
to -X- _ O
compare -X- _ O
with -X- _ O
BART-Gen -X- _ B-MethodName
based -X- _ O
on -X- _ O
BARTlarge, -X- _ O
as -X- _ O
they -X- _ O
are -X- _ O
pre-trained -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
corpus -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
training -X- _ O
steps. -X- _ O

Since -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
document, -X- _ O
some -X- _ O
event -X- _ O
arguments -X- _ O
are -X- _ O
located -X- _ O
far -X- _ O
away -X- _ O
from -X- _ O
the -X- _ O
trigger, -X- _ O
which -X- _ O
highly -X- _ O
increases -X- _ O
the -X- _ O
difficulty -X- _ O
of -X- _ O

6.2 -X- _ O
Ablation -X- _ O
Study -X- _ O

6.1 -X- _ O
Cross-sentence -X- _ O
Argument -X- _ O
Extraction -X- _ O

The -X- _ O
results -X- _ O
support -X- _ O
our -X- _ O
claims -X- _ O
that -X- _ O
TSAR -X- _ B-MethodName
is -X- _ O
good -X- _ O
at -X- _ O
capturing -X- _ O
both -X- _ O
intra-sentential -X- _ O
and -X- _ O
inter-sentential -X- _ O
features, -X- _ O
especially -X- _ O
the -X- _ O
longdistance -X- _ O
between -X- _ O
trigger -X- _ O
and -X- _ O
arguments. -X- _ O

More -X- _ O
importantly, -X- _ O
when -X- _ O
extracting -X- _ O
cross-sentence -X- _ O
arguments, -X- _ O
TSARbase -X- _ B-MethodName
and -X- _ O
TSARlarge -X- _ B-MethodName
yield -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
up -X- _ O
to -X- _ B-MetricValue
2.3 -X- _ I-MetricValue
and -X- _ O
2.7 -X- _ B-MetricValue
on -X- _ O
average. -X- _ O

In -X- _ O
detail, -X- _ O
TSARbase -X- _ B-MethodName
improves -X- _ O
0.4 -X- _ B-MetricValue
and -X- _ O
TSARlarge -X- _ B-MethodName
improves -X- _ O
0.7 -X- _ B-MetricValue
F1 -X- _ B-MetricName
compared -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
stateof-the-art, -X- _ O
respectively. -X- _ O

However, -X- _ O
TSAR -X- _ B-MethodName
still -X- _ O
surpasses -X- _ O
other -X- _ O
strong -X- _ O
baselines. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4, -X- _ O
the -X- _ O
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
for -X- _ O
= -X- _ O
0) -X- _ O
is -X- _ O
much -X- _ O
lower -X- _ O
cross-sentence -X- _ O
arguments -X- _ O
(d -X- _ O
than -X- _ O
local -X- _ O
arguments -X- _ O
(d -X- _ O
= -X- _ O
0), -X- _ O
suggesting -X- _ O
the -X- _ O
huge -X- _ O
challenge -X- _ O
to -X- _ O
capture -X- _ O
long-distance -X- _ O
dependency -X- _ O
between -X- _ O
triggers -X- _ O
and -X- _ O
cross-sentence -X- _ O
arguments. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
on -X- _ O
the -X- _ O
RAMS -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
for -X- _ O
different -X- _ O
methods. -X- _ O

To -X- _ O
explore -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
handling -X- _ O
such -X- _ O
cross-sentence -X- _ O
arguments -X- _ O
of -X- _ O
our -X- _ O
TSAR, -X- _ B-MethodName
we -X- _ O
divide -X- _ O
the -X- _ O
event -X- _ O
arguments -X- _ O
in -X- _ O
RAMS -X- _ B-DatasetName
dataset -X- _ O
into -X- _ O
five -X- _ O
bins -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
sentence -X- _ O
distance -X- _ O
between -X- _ O
arguments -X- _ O
and -X- _ O
trigger, -X- _ O
i.e., -X- _ O
d -X- _ O
= -X- _ O
. -X- _ O

Method -X- _ O

= -X- _ O
0) -X- _ O
arguments -X- _ O
extraction. -X- _ O

Most -X- _ O
improvements -X- _ O
by -X- _ O
TSAR -X- _ B-MethodName
come -X- _ O
from -X- _ O
cross-sentence -X- _ O
(d -X- _ O

6 -X- _ O
Analysis -X- _ O

These -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
TSAR -X- _ B-MethodName
is -X- _ O
superior -X- _ O
to -X- _ O
other -X- _ O
methods -X- _ O
in -X- _ O
not -X- _ O
only -X- _ O
detecting -X- _ O
the -X- _ O
boundary -X- _ O
of -X- _ O
argument -X- _ O
spans, -X- _ O
but -X- _ O
also -X- _ O
predicting -X- _ O
their -X- _ O
roles. -X- _ O

Moreover, -X- _ O
we -X- _ O
follow -X- _ O
Li -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
to -X- _ O
evaluate -X- _ O
both -X- _ O
argument -X- _ B-TaskName
identification -X- _ I-TaskName
and -X- _ O
argument -X- _ B-TaskName
classification, -X- _ I-TaskName
and -X- _ O
report -X- _ O
the -X- _ O
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
Coref -X- _ B-MetricName
F1. -X- _ I-MetricName

Similar -X- _ O
results -X- _ O
also -X- _ O
appear -X- _ O
among -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
BERTbase, -X- _ O
33.34 -X- _ B-MetricValue
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
with -X- _ O
5.69 -X- _ B-MetricValue
improvement -X- _ O
for -X- _ O
identification -X- _ B-TaskName
and -X- _ I-TaskName
classification. -X- _ I-TaskName

Compared -X- _ O
with -X- _ O
BART-Gen, -X- _ B-MethodName
TSAR -X- _ B-MethodName
improves -X- _ O
up -X- _ O
to -X- _ O
4.87/3.23 -X- _ B-MetricValue
Head/Coref -X- _ B-MetricName
F1 -X- _ B-MetricName
for -X- _ O
argument -X- _ O
identification, -X- _ O
and -X- _ O
5.13/3.68 -X- _ B-MetricValue
Head/Coref -X- _ B-MetricName
F1 -X- _ B-MetricName
for -X- _ O
argument -X- _ B-TaskName
classification. -X- _ I-TaskName

As -X- _ O
illustrated -X- _ O
in -X- _ O
Table -X- _ O
3, -X- _ O
TSAR -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
others -X- _ O
in -X- _ O
both -X- _ O
tasks. -X- _ O

Identification -X- _ O
requires -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
correctly -X- _ O
detect -X- _ O
the -X- _ O
argument -X- _ O
span -X- _ O
boundary, -X- _ O
while -X- _ O
classification -X- _ O
has -X- _ O
to -X- _ O
further -X- _ O
correctly -X- _ O
predict -X- _ O
its -X- _ O
argument -X- _ O
role. -X- _ O

These -X- _ O
results -X- _ O
suggest -X- _ O
that -X- _ O
encoding -X- _ O
the -X- _ O
document -X- _ O
in -X- _ O
a -X- _ O
two-stream -X- _ O
way, -X- _ O
and -X- _ O
introducing -X- _ O
AMR -X- _ O
graphs -X- _ O
to -X- _ O
facilitate -X- _ O
interactions, -X- _ O
is -X- _ O
beneficial -X- _ O
to -X- _ O
capturing -X- _ O
intra-sentential -X- _ O
and -X- _ O
inter-sentential -X- _ O
features, -X- _ O
and -X- _ O
thus -X- _ O
improves -X- _ O
the -X- _ O
performance. -X- _ O

Besides, -X- _ O
among -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
large -X- _ O
pre-trained -X- _ O
language -X- _ O
models, -X- _ O
TSAR -X- _ B-MethodName
outperforms -X- _ O
BART-Gen -X- _ B-MethodName
by -X- _ O
2.54 -X- _ B-MetricValue
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
1.21 -X- _ B-MetricValue
Head -X- _ B-MetricName
F12. -X- _ I-MetricName

6.00 -X- _ B-MetricValue
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
compared -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ B-MetricValue
3.70 -X- _ I-MetricValue
method -X- _ O
in -X- _ O
the -X- _ O
dev -X- _ O
set, -X- _ O
and -X- _ O
up -X- _ O
to -X- _ O
8.76 -X- _ B-MetricValue
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
in -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O

Compared -X- _ O
with -X- _ O
BART-Gen, -X- _ B-MethodName
TSAR -X- _ B-MethodName
improves -X- _ O
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
in -X- _ O
argument -X- _ O
classification -X- _ O
by -X- _ O
5.13 -X- _ B-MetricValue
score. -X- _ O

TSAR -X- _ B-MethodName
yields -X- _ O
evident -X- _ O
improvements -X- _ O
in -X- _ O
argument -X- _ O
identification -X- _ O
and -X- _ O
classification -X- _ O
sub-tasks. -X- _ O

Models -X- _ O
above -X- _ O
the -X- _ O
double -X- _ O
line -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
BERTbase. -X- _ O

For -X- _ O
example, -X- _ O
TSAR -X- _ B-MethodName
yields -X- _ O
7.13 -X- _ B-MetricValue
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
4.93 -X- _ B-MetricValue

As -X- _ O
is -X- _ O
shown, -X- _ O
among -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
BERTbase, -X- _ O
TSAR -X- _ B-MethodName
outperforms -X- _ O
other -X- _ O
previous -X- _ O
methods. -X- _ O

Table -X- _ O
2 -X- _ O
illustrates -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
both -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
on -X- _ O
RAMS -X- _ B-DatasetName
dataset. -X- _ O

5) -X- _ O
BART-Gen -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
formulate -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
sequence-to-sequence -X- _ O
task -X- _ O
and -X- _ O
uses -X- _ O
BARTlarge -X- _ O
(Lewis -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
to -X- _ O
generate -X- _ O
corresponding -X- _ O
arguments -X- _ O
in -X- _ O
a -X- _ O
predefined -X- _ O
format. -X- _ O

BERT-QA -X- _ B-MethodName
and -X- _ B-MethodName
BERT-QA-Doc -X- _ I-MethodName
extract -X- _ O
run -X- _ O
on -X- _ O
sentence-level -X- _ O
and -X- _ O
document-level, -X- _ O
respectively. -X- _ O

4) -X- _ O
BERT-QA -X- _ B-MethodName
(Du -X- _ O
and -X- _ O
Cardie, -X- _ O
2020c) -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
QA-based -X- _ O
model. -X- _ O

3) -X- _ O
FEAE -X- _ B-MethodName
(Wei -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
Frame-aware -X- _ B-MethodName
Event -X- _ I-MethodName
Argument -X- _ I-MethodName
Extraction, -X- _ I-MethodName
is -X- _ O
a -X- _ O
concurrent -X- _ O
work -X- _ O
based -X- _ O
on -X- _ O
question -X- _ O
answering. -X- _ O

BERTCRFTCD -X- _ B-MethodName
and -X- _ O
Two-StepTCD -X- _ B-MethodName
refers -X- _ O
to -X- _ O
adopting -X- _ O
Type-Constraint -X- _ O
Decoding -X- _ O
mechanism -X- _ O
as -X- _ O
used -X- _ O
in -X- _ O
(Ebner -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

2) -X- _ O
Two-Step -X- _ B-MethodName
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2020b) -X- _ O
is -X- _ O
a -X- _ O
span-based -X- _ O
method, -X- _ O
which -X- _ O
first -X- _ O
identifies -X- _ O
the -X- _ O
head -X- _ O
word -X- _ O
of -X- _ O
possible -X- _ O
argument -X- _ O
span, -X- _ O
and -X- _ O
then -X- _ O
extends -X- _ O
to -X- _ O
the -X- _ O
full -X- _ O
span. -X- _ O

1) -X- _ O
BERT-CRF -X- _ B-MethodName
(Shi -X- _ O
and -X- _ O
Lin, -X- _ O
2019) -X- _ O
is -X- _ O
a -X- _ O
tagging-based -X- _ O
method, -X- _ O
which -X- _ O
adopts -X- _ O
a -X- _ O
BERT-based -X- _ O
BIO-styled -X- _ O
sequence -X- _ O
labeling -X- _ O
model. -X- _ O

We -X- _ O
compare -X- _ O
TSAR -X- _ B-MethodName
with -X- _ O
the -X- _ O
following -X- _ O
baselines. -X- _ O

5.3 -X- _ O
Main -X- _ O
Results -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
given -X- _ O
full -X- _ O
credit -X- _ O
in -X- _ O
Coref -X- _ B-MetricName
F1 -X- _ I-MetricName
if -X- _ O
the -X- _ O
extracted -X- _ O
argument -X- _ O
is -X- _ O
coreferential -X- _ O
with -X- _ O
the -X- _ O
golden -X- _ O
argument -X- _ O
as -X- _ O
used -X- _ O
by -X- _ O
Ji -X- _ O
and -X- _ O
Grishman -X- _ O
(2008). -X- _ O

In -X- _ O
addition, -X- _ O
following -X- _ O
Li -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
Coref -X- _ B-MetricName
F1 -X- _ I-MetricName
scores -X- _ O
for -X- _ O
WikiEvents -X- _ B-TaskName
dataset. -X- _ O

The -X- _ O
head -X- _ O
word -X- _ O
of -X- _ O
a -X- _ O
span -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
word -X- _ O
that -X- _ O
has -X- _ O
the -X- _ O
smallest -X- _ O
arc -X- _ O
distance -X- _ O
to -X- _ O
the -X- _ O
root -X- _ O
in -X- _ O
the -X- _ O
dependency -X- _ O
tree. -X- _ O

match -X- _ O
the -X- _ O
golden -X- _ O
ones, -X- _ O
while -X- _ O
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
relaxes -X- _ O
the -X- _ O
constraint -X- _ O
and -X- _ O
evaluates -X- _ O
solely -X- _ O
on -X- _ O
the -X- _ O
head -X- _ O
word -X- _ O
of -X- _ O
the -X- _ O
argument -X- _ O
span. -X- _ O

Compared -X- _ O
with -X- _ O
BARTGen, -X- _ B-MethodName
TSAR -X- _ B-MethodName
improves -X- _ O
2.54 -X- _ B-MetricValue
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
in -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O

TSAR -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
others -X- _ O
on -X- _ O
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
Head -X- _ B-MetricName
F1. -X- _ I-MetricName

Models -X- _ O
above -X- _ O
the -X- _ O
double -X- _ O
line -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
BERTbase. -X- _ O

Method -X- _ O

Span -X- _ B-MetricName
F1 -X- _ I-MetricName
requires -X- _ O
the -X- _ O
predicted -X- _ O
argument -X- _ O
spans -X- _ O
to -X- _ O
fully -X- _ O

(2020b), -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
Span -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
Head -X- _ B-MetricName
F1 -X- _ I-MetricName
for -X- _ O
RAMS -X- _ B-TaskName
dataset. -X- _ O

Following -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O

Detailed -X- _ O
hyperparameters -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O

In -X- _ O
our -X- _ O
implementation, -X- _ O
we -X- _ O
use -X- _ O
BERTbase -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
RoBERTalarge -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
as -X- _ O
our -X- _ O
backbone -X- _ O
encoder -X- _ O
for -X- _ O
TSAR, -X- _ B-MethodName
with -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
encoders -X- _ O
sharing -X- _ O
parameters. -X- _ O

5.2 -X- _ O
Experiment -X- _ O
Setups -X- _ O
and -X- _ O
Metrics -X- _ O

The -X- _ O
detailed -X- _ O
data -X- _ O
statistics -X- _ O
of -X- _ O
RAMS -X- _ B-DatasetName
and -X- _ O
WikiEvents -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
official -X- _ O
train/dev/test -X- _ B-HyperparameterName
split -X- _ I-HyperparameterName
for -X- _ O
RAMS -X- _ B-DatasetName
and -X- _ O
WikiEvents -X- _ B-DatasetName
datasets, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
evaluation -X- _ O
script -X- _ O
provided -X- _ O
by -X- _ O
Ebner -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance. -X- _ O

WikiEvents -X- _ B-DatasetName
is -X- _ O
another -X- _ O
human-annotated -X- _ O
dataset, -X- _ O
with -X- _ O
50 -X- _ O
event -X- _ O
types -X- _ O
and -X- _ O
59 -X- _ O
event -X- _ O
argument -X- _ O
roles, -X- _ O
and -X- _ O
more -X- _ O
than -X- _ O
3.9k -X- _ O
events. -X- _ O

RAMS -X- _ B-DatasetName
contains -X- _ O
9, -X- _ O
124 -X- _ O
human-annotated -X- _ O
examples, -X- _ O
with -X- _ O
139 -X- _ O
event -X- _ O
types -X- _ O
and -X- _ O
65 -X- _ O
kinds -X- _ O
of -X- _ O
argument -X- _ O
roles, -X- _ O
and -X- _ O
more -X- _ O
than -X- _ O
21k -X- _ O
arguments. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
two -X- _ O
public -X- _ O
documentlevel -X- _ O
event -X- _ O
argument -X- _ O
extraction -X- _ O
datasets, -X- _ O
RAMS -X- _ B-DatasetName
v1.0 -X- _ I-DatasetName
(Ebner -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
WikiEvents -X- _ B-DatasetName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

5.1 -X- _ O
Datasets -X- _ O

5 -X- _ O
Experiments -X- _ O

with -X- _ O
the -X- _ O
final -X- _ O
loss -X- _ O
function -X- _ O
hyperparameter -X- _ O
λ. -X- _ B-HyperparameterName

j. -X- _ O
Finally, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
an -X- _ O
end-to-end -X- _ O
way -X- _ O
Lb -X- _ O
with -X- _ O

where -X- _ O
yi:j -X- _ O
is -X- _ O
the -X- _ O
golden -X- _ O
argument -X- _ O
role, -X- _ O
and -X- _ O
P -X- _ O
(ri:j) -X- _ O
is -X- _ O
derived -X- _ O
by -X- _ O
a -X- _ O
feed-forward -X- _ O
network -X- _ O
based -X- _ O
on -X- _ O
Ii: -X- _ O

(cid:12) -X- _ O
(cid:12) -X- _ O
(cid:12) -X- _ O

si:j -X- _ O

3) -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
span -X- _ O
length -X- _ O
Elen; -X- _ O

ht -X- _ O
− -X- _ O
(cid:12) -X- _ O
si:j; -X- _ O
2) -X- _ O
the -X- _ O
emelement-wise -X- _ O
multiplication, -X- _ O
(cid:12) -X- _ O
(cid:12)e -X- _ O
bedding -X- _ O
of -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
Etype. -X- _ O

Specifically, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
following -X- _ O
representations -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
prediction -X- _ O
vector -X- _ O
Ii:j: -X- _ O
1) -X- _ O
the -X- _ O
tright, -X- _ O
and -X- _ O
the -X- _ O
span -X- _ O
representation -X- _ O
ger -X- _ O
representation -X- _ O
si:j, -X- _ O
with -X- _ O
their -X- _ O
absolute -X- _ O
difference -X- _ O
, -X- _ O
and -X- _ O
ht -X- _ O
⊙ -X- _ O
e -X- _ O

Besides -X- _ O
the -X- _ O
span -X- _ O
representation -X- _ O
si:j, -X- _ O
we -X- _ O
also -X- _ O
consider -X- _ O
the -X- _ O
trigger, -X- _ O
event -X- _ O
type, -X- _ O
and -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
span. -X- _ O

In -X- _ O
the -X- _ O
classification -X- _ O
module, -X- _ O
we -X- _ O
predict -X- _ O
what -X- _ O
argument -X- _ O
role -X- _ O
the -X- _ O
candidate -X- _ O
span -X- _ O
plays, -X- _ O
or -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
belong -X- _ O
to -X- _ O
any -X- _ O
specific -X- _ O
argument -X- _ O
roles. -X- _ O

4.4 -X- _ O
Classification -X- _ O
Module -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
explicit -X- _ O
supervision -X- _ O
signal -X- _ O
to -X- _ O
inject -X- _ O
boundary -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
representation -X- _ O
of -X- _ O
an -X- _ O
span, -X- _ O
which -X- _ O
is -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
necessary -X- _ O
and -X- _ O
important -X- _ O
to -X- _ O
the -X- _ O
extraction -X- _ O
in -X- _ O
our -X- _ O
exploring -X- _ O
experiments. -X- _ O

(cid:17) -X- _ O
(cid:17) -X- _ O
Finally, -X- _ O
the -X- _ O
boundary -X- _ O
loss -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
following -X- _ O
cross-entropy -X- _ O
losses -X- _ O
of -X- _ O
detecting -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
position. -X- _ O

e -X- _ O

i -X- _ O
and -X- _ O
P -X- _ O
e -X- _ O
i -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
sigmoid -X- _ O
function, -X- _ O
to -X- _ O
derive -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
wi -X- _ O
being -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
last -X- _ O
word -X- _ O
of -X- _ O
a -X- _ O
golden -X- _ O
argument -X- _ O
span, -X- _ O
i.e., -X- _ O
P -X- _ O
s -X- _ O

In -X- _ O
detail, -X- _ O
we -X- _ O
predict -X- _ O
i -X- _ O
whether -X- _ O
the -X- _ O
word -X- _ O
wi -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
last -X- _ O
word -X- _ O
of -X- _ O
a -X- _ O
e -X- _ O
golden -X- _ O
argument -X- _ O
span -X- _ O
with -X- _ O
token-wise -X- _ O
classifiers. -X- _ O

Since -X- _ O
we -X- _ O
extract -X- _ O
arguments -X- _ O
in -X- _ O
span -X- _ O
level, -X- _ O
whose -X- _ O
e -X- _ O
boundary -X- _ O
may -X- _ O
be -X- _ O
ambiguous, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
auxiliary -X- _ O
boundary -X- _ O
loss -X- _ O
to -X- _ O
enhance -X- _ O
boundary -X- _ O
informahend -X- _ O
tion -X- _ O
for -X- _ O
the -X- _ O
. -X- _ O

e -X- _ O
ments, -X- _ O
so -X- _ O
we -X- _ O
adopt -X- _ O
this -X- _ O
simple -X- _ O
connection -X- _ O
paradigm. -X- _ O

1We -X- _ O
find -X- _ O
more -X- _ O
elaborate -X- _ O
methods -X- _ O
yield -X- _ O
no -X- _ O
further -X- _ O
improve -X- _ O

hG -X- _ O
i -X- _ O
and -X- _ O

i -X- _ O
+ -X- _ O
W3 -X- _ O
W2 -X- _ O
and -X- _ O
W3, -X- _ O
gi -X- _ O
= -X- _ O
sigmoid(W2 -X- _ O
hi: -X- _ O
Then -X- _ O
we -X- _ O
derive -X- _ O
the -X- _ O
fused -X- _ O
representations -X- _ O
e -X- _ O
e -X- _ O

hG -X- _ O
e -X- _ O
e -X- _ O
i -X- _ O
+ -X- _ O
b). -X- _ O

Given -X- _ O
i -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
gate -X- _ O
vector -X- _ O
gi -X- _ O
with -X- _ O
trainable -X- _ O
parameters -X- _ O
hL -X- _ O

i -X- _ O
In -X- _ O
detail, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
gated -X- _ O
fusion -X- _ O
to -X- _ O
control -X- _ O
how -X- _ O
much -X- _ O
information -X- _ O
is -X- _ O
incorporated -X- _ O
from -X- _ O
the -X- _ O
twohL -X- _ O
stream -X- _ O
representations. -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
the -X- _ O
intersentential -X- _ O
information -X- _ O
can -X- _ O
flow -X- _ O
through -X- _ O
the -X- _ O
sentence -X- _ O
boundaries, -X- _ O
and -X- _ O
therefore -X- _ O
long-distance -X- _ O
dependency -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
better -X- _ O
captured. -X- _ O

Then -X- _ O
similar -X- _ O
graph-based -X- _ O
interaction -X- _ O
methods -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
AMRhG -X- _ O
enhanced -X- _ O
global -X- _ O
representations -X- _ O
i -X- _ O
, -X- _ O
but -X- _ O
based -X- _ O
on -X- _ O
global -X- _ O
AMR -X- _ O
graphs -X- _ O
instead. -X- _ O

From -X- _ O
the -X- _ O
global -X- _ O
perspective, -X- _ O
we -X- _ O
first -X- _ O
construct -X- _ O
the -X- _ O
global -X- _ O
AMR -X- _ O
graphs -X- _ O
by -X- _ O
fully -X- _ O
connecting -X- _ O
the -X- _ O
root -X- _ O
nodes -X- _ O
of -X- _ O
AMR -X- _ O
graphs -X- _ O
of -X- _ O
different -X- _ O
sentences, -X- _ O
since -X- _ O
the -X- _ O
root -X- _ O
nodes -X- _ O
contain -X- _ O
the -X- _ O
core -X- _ O
semantics -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
AMR -X- _ O
core-semantic -X- _ O
principle -X- _ O
(Cai -X- _ O
and -X- _ O
Lam, -X- _ O
2019) -X- _ O
1. -X- _ O

) -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
indication -X- _ O
function: -X- _ O
· -X- _ O

Finally, -X- _ O
we -X- _ O
concatenate -X- _ O
vectors -X- _ O
in -X- _ O
all -X- _ O

; -X- _ O
hL -X- _ O
u -X- _ O
] -X- _ O
decomposed -X- _ O
into -X- _ O
the -X- _ O
local -X- _ O
representations -X- _ O
of -X- _ O
corresponding -X- _ O
words, -X- _ O
followed -X- _ O
by -X- _ O
token-wise -X- _ O
aggregation, -X- _ O
where -X- _ O
I( -X- _ O

Then -X- _ O
hu -X- _ O
is -X- _ O
u; -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

layers -X- _ O
and -X- _ O
derive -X- _ O
the -X- _ O
final -X- _ O
node -X- _ O
representation -X- _ O
by -X- _ O
hu -X- _ O
= -X- _ O
W1[h0 -X- _ O
Rdm. -X- _ O

Besides, -X- _ O
W -X- _ O
(l) -X- _ O
dm -X- _ O
is -X- _ O
a -X- _ O
trainable -X- _ O
parameter. -X- _ O

(cid:17) -X- _ O
Nk(u) -X- _ O
where -X- _ O
denotes -X- _ O
the -X- _ O
neighbors -X- _ O
for -X- _ O
u -X- _ O
connected -X- _ O
with -X- _ O
k-th -X- _ O
relation -X- _ O
types -X- _ O
and -X- _ O
cu,k -X- _ O
is -X- _ O
a -X- _ O
normalization -X- _ O
constant. -X- _ O

and -X- _ O

He -X- _ O
was -X- _ O
then -X- _ O
arrested -X- _ O
in -X- _ O
Iran -X- _ O
and -X- _ O
was -X- _ O
reportedly -X- _ O
tried -X- _ O
for -X- _ O
treason -X- _ O
. -X- _ O

One -X- _ O
key -X- _ O
challenge -X- _ O
to -X- _ O
extract -X- _ O
arguments -X- _ O
from -X- _ O
the -X- _ O
document -X- _ O
is -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
intra-sentential -X- _ O
and -X- _ O

i -X- _ O
4.2 -X- _ O
AMR-Guided -X- _ O
Interaction -X- _ O
Module -X- _ O

Hence, -X- _ O
we -X- _ O
encode -X- _ O
the -X- _ O
document -X- _ O
with -X- _ O
two -X- _ O
different -X- _ O
streams, -X- _ O
a -X- _ O
global -X- _ O
encoder -X- _ O
EncoderG -X- _ O
and -X- _ O
a -X- _ O
local -X- _ O
encoder -X- _ O
EncoderL, -X- _ O
finally -X- _ O
deriving -X- _ O
two -X- _ O
representations, -X- _ O
ZG -X- _ O
and -X- _ O
ZL: -X- _ O

However, -X- _ O
in -X- _ O
the -X- _ O
local -X- _ O
encoder, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
mask -X- _ O
matrix -X- _ O
M -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
tokens -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
sentence -X- _ O
itself -X- _ O
and -X- _ O
the -X- _ O
sentence -X- _ O
where -X- _ O
the -X- _ O
trigger -X- _ O
locates, -X- _ O
to -X- _ O
avoid -X- _ O
redundant -X- _ O
distracting -X- _ O
information: -X- _ O

In -X- _ O
the -X- _ O
global -X- _ O
encoder, -X- _ O
the -X- _ O
attention -X- _ O
technique -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
traditional -X- _ O
Transformer: -X- _ O

By -X- _ O
controlling -X- _ O
the -X- _ O
reception -X- _ O
field -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
self-attention -X- _ O
module -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
encode -X- _ O
the -X- _ O
document -X- _ O
from -X- _ O
different -X- _ O
perspectives. -X- _ O

Specifically, -X- _ O
the -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
encoders -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
Transformer-based -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
such -X- _ O
as -X- _ O
BERT. -X- _ O

Therefore, -X- _ O
we -X- _ O
can -X- _ O
leverage -X- _ O
their -X- _ O
complementary -X- _ O
advantages -X- _ O
to -X- _ O
make -X- _ O
better -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
information. -X- _ O

encoder -X- _ O
that -X- _ O
is -X- _ O
aware -X- _ O
of -X- _ O
all -X- _ O
context, -X- _ O
and -X- _ O
a -X- _ O
local -X- _ O
encoder -X- _ O
that -X- _ O
only -X- _ O
prudently -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
essential -X- _ O
information. -X- _ O

The -X- _ O
corresponding -X- _ O
text -X- _ O
spans -X- _ O
for -X- _ O
nodes -X- _ O
are -X- _ O
omitted. -X- _ O

For -X- _ O
initialization, -X- _ O
the -X- _ O
vector -X- _ O
representation -X- _ O
of -X- _ O
node -X- _ O
u -X- _ O
= -X- _ O
(au, -X- _ O
bu) -X- _ O
is -X- _ O
composed -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
local -X- _ O
representations -X- _ O
of -X- _ O
its -X- _ O
corresponding -X- _ O
text -X- _ O
span: -X- _ O

From -X- _ O
the -X- _ O
local -X- _ O
perspective, -X- _ O
we -X- _ O
construct -X- _ O
AMR -X- _ O
graphs -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
document, -X- _ O
and -X- _ O
they -X- _ O
are -X- _ O
isolated -X- _ O
from -X- _ O
each -X- _ O
other. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
AMR -X- _ O
graphs -X- _ O
as -X- _ O
skeletons -X- _ O
for -X- _ O
information -X- _ O
interactions, -X- _ O
under -X- _ O
a -X- _ O
composition, -X- _ O
interaction, -X- _ O
and -X- _ O
decomposition -X- _ O
paradigm. -X- _ O

The -X- _ O
AMR-guided -X- _ O
interaction -X- _ O
module -X- _ O
is -X- _ O
attached -X- _ O
after -X- _ O
the -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
encoders -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O

More -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O

As -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
AMR -X- _ O
relation -X- _ O
types -X- _ O
is -X- _ O
large, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
too -X- _ O
many -X- _ O
demanded -X- _ O
parameters, -X- _ O
we -X- _ O
also -X- _ O
follow -X- _ O
Zhang -X- _ O
and -X- _ O
Ji -X- _ O
(2021) -X- _ O
to -X- _ O
cluster -X- _ O
the -X- _ O
relation -X- _ O
types -X- _ O
into -X- _ O
main -X- _ O
categories. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
state-of-the-art -X- _ O
AMR -X- _ O
parser -X- _ O
Fernandez -X- _ O
Astudillo -X- _ O
et -X- _ O
al. -X- _ O
(2020), -X- _ O
which -X- _ O
achieves -X- _ O
satisfactory -X- _ O
results -X- _ O
(up -X- _ O
to -X- _ O
81.3 -X- _ O
Smatch -X- _ O
on -X- _ O
AMR2.0 -X- _ O
data) -X- _ O
for -X- _ O
downstream -X- _ O
application. -X- _ O

As -X- _ O
event -X- _ O
arguments -X- _ O
play -X- _ O
essential -X- _ O
roles -X- _ O
in -X- _ O
the -X- _ O
text, -X- _ O
most -X- _ O
of -X- _ O
them -X- _ O
would -X- _ O
be -X- _ O
involved, -X- _ O
if -X- _ O
not -X- _ O
all, -X- _ O
in -X- _ O
the -X- _ O
AMR -X- _ O
graphs -X- _ O
(90% -X- _ O
and -X- _ O
88% -X- _ O
arguments -X- _ O
in -X- _ O
RAMS -X- _ B-DatasetName
and -X- _ O
WikiEvents -X- _ B-DatasetName
datasets). -X- _ O

For -X- _ O
example, -X- _ O
Figure -X- _ O
3 -X- _ O
demonstrates -X- _ O
how -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
parsed -X- _ O
into -X- _ O
an -X- _ O
AMR -X- _ O
semantic -X- _ O
graph. -X- _ O

Thus, -X- _ O
AMR -X- _ O
focuses -X- _ O
on -X- _ O
semantic -X- _ O
relations -X- _ O
rather -X- _ O
than -X- _ O
syntactic -X- _ O
ones, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
high-level -X- _ O
and -X- _ O
beneficial -X- _ O
to -X- _ O
event -X- _ O
understanding, -X- _ O
and -X- _ O
the -X- _ O
structures -X- _ O
are -X- _ O
more -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
event -X- _ O
trigger-arguments -X- _ O
structures. -X- _ O

The -X- _ O
node -X- _ O
v -X- _ O
= -X- _ O
(a, -X- _ O
b) -X- _ O
V -X- _ O
represents -X- _ O
a -X- _ O
concept -X- _ O
that -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
span -X- _ O
ranging -X- _ O
from -X- _ O
wa -X- _ O
to -X- _ O
wb -X- _ O
in -X- _ O
the -X- _ O
origin -X- _ O
sentence, -X- _ O
while -X- _ O
the -X- _ O
edge -X- _ O
represents -X- _ O
a -X- _ O
specific -X- _ O
AMR -X- _ O
relation -X- _ O
(detail -X- _ O
in -X- _ O
Appendix -X- _ O
A). -X- _ O

(V, -X- _ O
E). -X- _ O

Concretely, -X- _ O
with -X- _ O
an -X- _ O
AMR -X- _ O
parser, -X- _ O
a -X- _ O
natural -X- _ O
sentence -X- _ O
can -X- _ O
be -X- _ O
parsed -X- _ O
into -X- _ O
an -X- _ O
AMR -X- _ O
graph -X- _ O
G -X- _ O
= -X- _ O

AMR -X- _ O
semantic -X- _ O
graph -X- _ O
models -X- _ O
the -X- _ O
meaning -X- _ O
representations -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
as -X- _ O
a -X- _ O
rooted, -X- _ O
directed, -X- _ O
labeled -X- _ O
graph. -X- _ O

Therefore, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
AMR-guided -X- _ O
interaction -X- _ O
module -X- _ O
that -X- _ O
adopts -X- _ O
Abstract -X- _ O
Meaning -X- _ O
Representation -X- _ O
(AMR, -X- _ O
Banarescu -X- _ O
et -X- _ O
al., -X- _ O
2013) -X- _ O
graph -X- _ O
to -X- _ O
provide -X- _ O
rich -X- _ O
semantic -X- _ O
structure -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
interactions -X- _ O
among -X- _ O
concepts, -X- _ O
which -X- _ O
also -X- _ O
offers -X- _ O
logical -X- _ O
meanings -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
from -X- _ O
a -X- _ O
linguistic-driven -X- _ O
perspective -X- _ O
to -X- _ O
benefit -X- _ O
the -X- _ O
language -X- _ O
understanding. -X- _ O

S1 -X- _ O

To -X- _ O
capture -X- _ O
useful -X- _ O
information -X- _ O
and -X- _ O
filter -X- _ O
distracting -X- _ O
one, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
two-stream -X- _ O
encoding -X- _ O
module, -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
global -X- _ O

These -X- _ O
noise -X- _ O
signals -X- _ O
can -X- _ O
be -X- _ O
harmful -X- _ O
to -X- _ O
the -X- _ O
argument -X- _ O
extraction -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

Although -X- _ O
more -X- _ O
context -X- _ O
is -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
document, -X- _ O
it -X- _ O
also -X- _ O
inevitably -X- _ O
introduces -X- _ O
irrelevant -X- _ O
and -X- _ O
distracting -X- _ O
information -X- _ O
towards -X- _ O
the -X- _ O
event. -X- _ O

4.1 -X- _ O
Two-Stream -X- _ O
Encoding -X- _ O
Module -X- _ O

The -X- _ O
information -X- _ O
fusion -X- _ O
module -X- _ O
fuses -X- _ O
these -X- _ O
two-stream -X- _ O
representations, -X- _ O
and -X- _ O
the -X- _ O
classification -X- _ O
module -X- _ O
finally -X- _ O
predicts -X- _ O
argument -X- _ O
roles -X- _ O
for -X- _ O
candidate -X- _ O
spans. -X- _ O

The -X- _ O
document -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
twostream -X- _ O
encoding -X- _ O
module, -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
AMRguided -X- _ O
interaction -X- _ O
module -X- _ O
to -X- _ O
derive -X- _ O
both -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
contextualized -X- _ O
representations. -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
TSAR. -X- _ B-MethodName

Then, -X- _ O
given -X- _ O
a -X- _ O
document -X- _ O
D -X- _ O
triggering -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
e -X- _ O
detect -X- _ O
all -X- _ O
(r, -X- _ O
s) -X- _ O
pairs -X- _ O
for -X- _ O
the -X- _ O
event, -X- _ O
where -X- _ O
r -X- _ O
is -X- _ O
an -X- _ O
argument -X- _ O
role -X- _ O
for -X- _ O
the -X- _ O
event -X- _ O
type -X- _ O
e, -X- _ O
and -X- _ O
s -X- _ O
is -X- _ O
a -X- _ O
contiguous -X- _ O
text -X- _ O
span -X- _ O
in -X- _ O
the -X- _ O
document. -X- _ O

, -X- _ O
and -X- _ O
SEN -X- _ O
(wi) -X- _ O

ing -X- _ O
argument -X- _ O
roles -X- _ O
set -X- _ O

We -X- _ O
and -X- _ O
the -X- _ O
correspondalso -X- _ O
define -X- _ O
the -X- _ O
event -X- _ O
types -X- _ O
set -X- _ O
. -X- _ O

[1, -X- _ O
N -X- _ O
] -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
sentence -X- _ O
that -X- _ O
wi -X- _ O
belongs -X- _ O
to. -X- _ O

We -X- _ O
consists -X- _ O
of -X- _ O
N -X- _ O
sentences, -X- _ O
define -X- _ O
that -X- _ O
a -X- _ O
document -X- _ O
D -X- _ O
and -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
comprised -X- _ O
of -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
words, -X- _ O
i.e., -X- _ O
∈ -X- _ O

Following -X- _ O
Ebner -X- _ O
et -X- _ O
al. -X- _ O
(2020), -X- _ O
we -X- _ O
formulate -X- _ O
doclevel -X- _ B-TaskName
event -X- _ I-TaskName
argument -X- _ I-TaskName
extraction -X- _ I-TaskName
as -X- _ O
follows. -X- _ O

3 -X- _ O
Task -X- _ O
Formulation -X- _ O

Instead, -X- _ O
TSAR -X- _ B-MethodName
introduces -X- _ O
a -X- _ O
two-stream -X- _ O
encoding -X- _ O
module -X- _ O
and -X- _ O
AMR-guided -X- _ O
interactions -X- _ O
module -X- _ O
to -X- _ O
model -X- _ O
intra-sentential -X- _ O
and -X- _ O
inter-sentential -X- _ O
semantics, -X- _ O
along -X- _ O
with -X- _ O
an -X- _ O
auxiliary -X- _ O
boundary -X- _ O
loss -X- _ O
to -X- _ O
enhance -X- _ O
span -X- _ O
boundary -X- _ O
information. -X- _ O

As -X- _ O
a -X- _ O
span-based -X- _ O
method, -X- _ O
TSAR -X- _ B-MethodName
is -X- _ O
different -X- _ O
from -X- _ O
prior -X- _ O
methods -X- _ O
that -X- _ O
simply -X- _ O
encode -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
long -X- _ O
sentence. -X- _ O

Another -X- _ O
line -X- _ O
of -X- _ O
studies -X- _ O
reformulate -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
sequence-to-sequence -X- _ O
task -X- _ O
(Du -X- _ O
et -X- _ O
al., -X- _ O
2021a,b; -X- _ O
Li -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
or -X- _ O
machine -X- _ O
reading -X- _ O
comprehension -X- _ O
task -X- _ O
(Wei -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

et -X- _ O
al., -X- _ O
2021), -X- _ O
while -X- _ O
span-based -X- _ O
methods -X- _ O
predict -X- _ O
the -X- _ O
argument -X- _ O
role -X- _ O
for -X- _ O
candidate -X- _ O
text -X- _ O
spans -X- _ O
which -X- _ O
usually -X- _ O
have -X- _ O
a -X- _ O
maximum -X- _ O
length -X- _ O
limitation -X- _ O
(Ebner -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Zhang -X- _ O
et -X- _ O
al., -X- _ O
2020b). -X- _ O

For -X- _ O
conciseness, -X- _ O
we -X- _ O
assume -X- _ O
the -X- _ O
document -X- _ O
has -X- _ O
three -X- _ O
sentences, -X- _ O
S1, -X- _ O
S2, -X- _ O
S3, -X- _ O
and -X- _ O
the -X- _ O
event -X- _ O
is -X- _ O
triggered -X- _ O
by -X- _ O
y2 -X- _ O
with -X- _ O
[z2, -X- _ O
z3] -X- _ O
being -X- _ O
a -X- _ O
candidate -X- _ O
argument -X- _ O
span. -X- _ O

Finally, -X- _ O
the -X- _ O
classification -X- _ O
module -X- _ O
makes -X- _ O
predictions -X- _ O
for -X- _ O
candidate -X- _ O
spans. -X- _ O

Next, -X- _ O
the -X- _ O
information -X- _ O
fusion -X- _ O
module -X- _ O
fuses -X- _ O
the -X- _ O
two-stream -X- _ O
representations, -X- _ O
and -X- _ O
also -X- _ O
strengthens -X- _ O
the -X- _ O
boundary -X- _ O
information -X- _ O
through -X- _ O
a -X- _ O
boundary -X- _ O
loss. -X- _ O

Then -X- _ O
the -X- _ O
AMR-guided -X- _ O
interaction -X- _ O
module -X- _ O
constructs -X- _ O
global -X- _ O
AMR -X- _ O
graphs -X- _ O
and -X- _ O
local -X- _ O
ones -X- _ O
to -X- _ O
stimulate -X- _ O
the -X- _ O
interactions -X- _ O
among -X- _ O
concepts -X- _ O
in -X- _ O
the -X- _ O
document, -X- _ O
especially -X- _ O
those -X- _ O
far -X- _ O
away -X- _ O
from -X- _ O
each -X- _ O
other, -X- _ O
based -X- _ O
on -X- _ O
graph -X- _ O
neural -X- _ O
network. -X- _ O

Firstly, -X- _ O
taking -X- _ O
an -X- _ O
entire -X- _ O
document -X- _ O
as -X- _ O
input, -X- _ O
TSAR -X- _ O
first -X- _ B-MethodName
encodes -X- _ O
the -X- _ O
document -X- _ O
by -X- _ O
the -X- _ O
two-stream -X- _ O
encoding -X- _ O
module, -X- _ O
where -X- _ O
the -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
encoders -X- _ O
with -X- _ O
different -X- _ O
attention -X- _ O
reception -X- _ O
fields -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
context -X- _ O
in -X- _ O
different -X- _ O
scopes. -X- _ O

Figure -X- _ O
2: -X- _ O
Overview -X- _ O
of -X- _ O
our -X- _ O
TSAR. -X- _ O

5027 -X- _ O

Tagging-based -X- _ O
methods -X- _ O
directly -X- _ O
conduct -X- _ O
sequence -X- _ O
labeling -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
with -X- _ O
BIO-schema -X- _ O
(Du -X- _ O
and -X- _ O
Cardie, -X- _ O
2020a; -X- _ O
Veyseh -X- _ O

Differently, -X- _ O
some -X- _ O
studies -X- _ O
try -X- _ O
to -X- _ O
jointly -X- _ O
extract -X- _ O
entities -X- _ O
and -X- _ O
argument -X- _ O
roles -X- _ O
simultaneously, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
divided -X- _ O
into -X- _ O
tagging-based -X- _ O
and -X- _ O
span-based -X- _ O
methods. -X- _ O

Xu -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Some -X- _ O
studies -X- _ O
first -X- _ O
identify -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
document, -X- _ O
followed -X- _ O
by -X- _ O
assigning -X- _ O
these -X- _ O
entities -X- _ O
as -X- _ O
specific -X- _ O
argument -X- _ O
roles -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Zheng -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

Yang -X- _ O
and -X- _ O
Mitchell -X- _ O
(2016) -X- _ O
utilize -X- _ O
welldefined -X- _ O
features -X- _ O
to -X- _ O
extract -X- _ O
arguments -X- _ O
across -X- _ O
sentences, -X- _ O
while -X- _ O
most -X- _ O
recent -X- _ O
methods -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
neural -X- _ O
networks. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
extract -X- _ O
events -X- _ O
from -X- _ O
a -X- _ O
whole -X- _ O
piece -X- _ O
of -X- _ O
article -X- _ O
with -X- _ O
multiple -X- _ O
sentences, -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
has -X- _ O
attracted -X- _ O
more -X- _ O
and -X- _ O
more -X- _ O
attention -X- _ O
recently. -X- _ O

2.2 -X- _ O
Document-level -X- _ B-TaskName
Event -X- _ I-TaskName
Extraction -X- _ I-TaskName

Thus, -X- _ O
they -X- _ O
fail -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
much -X- _ O
more -X- _ O
common -X- _ O
cases, -X- _ O
where -X- _ O
event -X- _ O
arguments -X- _ O
usually -X- _ O
spread -X- _ O
over -X- _ O
multiple -X- _ O
sentences -X- _ O
within -X- _ O
the -X- _ O
document. -X- _ O

However, -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
can -X- _ O
only -X- _ O
extract -X- _ O
events -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
sentence. -X- _ O

For -X- _ O
example, -X- _ O
Du -X- _ O
and -X- _ O
Cardie -X- _ O
(2020b) -X- _ O
and -X- _ O
Zhou -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
cast -X- _ O
event -X- _ O
extraction -X- _ O
as -X- _ O
question -X- _ O
answering, -X- _ O
and -X- _ O
Xiangyu -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
model -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
sequence-to-sequence -X- _ O
task. -X- _ O

Moreover, -X- _ O
some -X- _ O
works -X- _ O
try -X- _ O
to -X- _ O
reformulate -X- _ O
the -X- _ O
event -X- _ O
extraction -X- _ O
task -X- _ O
as -X- _ O
other -X- _ O
tasks. -X- _ O

Data -X- _ O
augmentation -X- _ O
is -X- _ O
also -X- _ O
considered -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

(2019) -X- _ O
enumerates -X- _ O
all -X- _ O
possible -X- _ O
spans -X- _ O
and -X- _ O
propagate -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
span -X- _ O
graph. -X- _ O

; -X- _ O
Ma -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
dependency -X- _ O
tree, -X- _ O
and -X- _ O
Wadden -X- _ O
et -X- _ O
al. -X- _ O

(2019) -X- _ O

(2018); -X- _ O
Yan -X- _ O
et -X- _ O
al. -X- _ O

To -X- _ O
better -X- _ O
model -X- _ O
the -X- _ O
interactions -X- _ O
among -X- _ O
words, -X- _ O
Liu -X- _ O
et -X- _ O
al. -X- _ O

(2016) -X- _ O
utilize -X- _ O
a -X- _ O
joint -X- _ O
model -X- _ O
to -X- _ O
mitigate -X- _ O
error -X- _ O
propagation. -X- _ O

Chen -X- _ O
et -X- _ O
al. -X- _ O
(2015) -X- _ O
firstly -X- _ O
propose -X- _ O
a -X- _ O
neural -X- _ O
pipeline -X- _ O
model -X- _ O
to -X- _ O
extract -X- _ O
events, -X- _ O
while -X- _ O
Nguyen -X- _ O
et -X- _ O
al. -X- _ O

Li -X- _ O
et -X- _ O
al. -X- _ O
(2014) -X- _ O
and -X- _ O
Judea -X- _ O
and -X- _ O
Strube -X- _ O
(2016) -X- _ O
use -X- _ O
handcrafted -X- _ O
features -X- _ O
to -X- _ O
extract -X- _ O
events -X- _ O
from -X- _ O
the -X- _ O
sentence. -X- _ O

Previous -X- _ O
studies -X- _ O
mainly -X- _ O
focus -X- _ O
on -X- _ O
sentence-level -X- _ O
event -X- _ O
extraction. -X- _ O

2.1 -X- _ O
Sentence-level -X- _ O
Event -X- _ O
Extraction -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

3) -X- _ O
Our -X- _ O
experiments -X- _ O
show -X- _ O
that -X- _ O
TSAR -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
previous -X- _ O
start-of-the-art -X- _ O
model -X- _ O
by -X- _ O
large -X- _ O
margins, -X- _ O
with -X- _ O
2.54 -X- _ B-MetricValue
F1 -X- _ B-MetricName
and -X- _ O
5.13 -X- _ B-MetricValue
F1 -X- _ B-MetricName
improvements -X- _ O
on -X- _ O
public -X- _ O
RAMS -X- _ B-DatasetName
and -X- _ O
WikiEvents -X- _ B-DatasetName
datasets -X- _ O
respectively, -X- _ O
especially -X- _ O
on -X- _ O
cross-sentence -X- _ B-TaskName
event -X- _ I-TaskName
arguments -X- _ I-TaskName
extraction. -X- _ I-TaskName

teraction -X- _ O
module -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
semantic -X- _ O
interactions -X- _ O
within -X- _ O
the -X- _ O
document, -X- _ O
so -X- _ O
that -X- _ O
long-distance -X- _ O
dependency -X- _ O
can -X- _ O
be -X- _ O
better -X- _ O
captured. -X- _ O

2) -X- _ O
We -X- _ O
introduce -X- _ O
an -X- _ O
AMR-guided -X- _ O
in -X- _ O

To -X- _ O
summarize, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
three-fold. -X- _ O
1) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
two-stream -X- _ O
encoding -X- _ O
module -X- _ O
for -X- _ O
document-level -X- _ B-TaskName
EAE, -X- _ I-TaskName
which -X- _ O
encodes -X- _ O
the -X- _ O
document -X- _ O
through -X- _ O
two -X- _ O
different -X- _ O
perspectives -X- _ O
to -X- _ O
better -X- _ O
utilize -X- _ O
the -X- _ O
context. -X- _ O

Finally, -X- _ O
as -X- _ O
TSAR -X- _ B-MethodName
extracts -X- _ O
arguments -X- _ O
in -X- _ O
span -X- _ O
level, -X- _ O
where -X- _ O
the -X- _ O
span -X- _ O
boundary -X- _ O
may -X- _ O
be -X- _ O
ambiguous, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
auxiliary -X- _ O
boundary -X- _ O
loss -X- _ O
to -X- _ O
enhance -X- _ O
span -X- _ O
representation -X- _ O
with -X- _ O
calibrated -X- _ O
boundary. -X- _ O

From -X- _ O
such -X- _ O
a -X- _ O
linguistic-driven -X- _ O
angle, -X- _ O
we -X- _ O
turn -X- _ O
the -X- _ O
linear -X- _ O
structure -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
into -X- _ O
both -X- _ O
global -X- _ O
and -X- _ O
local -X- _ O
graph -X- _ O
structures, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
interactions, -X- _ O
especially -X- _ O
for -X- _ O
those -X- _ O
non-local -X- _ O
elements. -X- _ O

Abstract -X- _ O
Meaning -X- _ O
Representation -X- _ O
(AMR, -X- _ O
Banarescu -X- _ O
et -X- _ O
al., -X- _ O
2013) -X- _ O
graph -X- _ O
contains -X- _ O
rich -X- _ O
hierarchical -X- _ O
semantic -X- _ O
relations -X- _ O
among -X- _ O
different -X- _ O
concepts, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
favorable -X- _ O
for -X- _ O
complex -X- _ O
event -X- _ O
extraction. -X- _ O

Besides, -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
long-distance -X- _ O
dependency, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
AMR-guided -X- _ O
interaction -X- _ O
module. -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
TSAR -X- _ B-MethodName
can -X- _ O
leverage -X- _ O
complementary -X- _ O
advantages -X- _ O
of -X- _ O
different -X- _ O
encoding -X- _ O
perspectives, -X- _ O
and -X- _ O
therefore -X- _ O
make -X- _ O
better -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
feasible -X- _ O
context -X- _ O
to -X- _ O
benefit -X- _ O
the -X- _ O
extraction. -X- _ O

It -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
global -X- _ O
encoder -X- _ O
that -X- _ O
encodes -X- _ O
global -X- _ O
semantics -X- _ O
with -X- _ O
as -X- _ O
much -X- _ O
context -X- _ O
as -X- _ O
possible -X- _ O
to -X- _ O
gather -X- _ O
adequate -X- _ O
context -X- _ O
information, -X- _ O
and -X- _ O
a -X- _ O
local -X- _ O
encoder -X- _ O
that -X- _ O
focuses -X- _ O
on -X- _ O
the -X- _ O
most -X- _ O
essential -X- _ O
information -X- _ O
and -X- _ O
prudently -X- _ O
takes -X- _ O
in -X- _ O
extra -X- _ O
context. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
essential -X- _ O
context -X- _ O
in -X- _ O
the -X- _ O
document, -X- _ O
and -X- _ O
avoid -X- _ O
being -X- _ O
misled -X- _ O
by -X- _ O
distractions, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
two-stream -X- _ O
encoding -X- _ O
module. -X- _ O

to -X- _ O
tackle -X- _ O
the -X- _ O
aforementioned -X- _ O
two -X- _ O
problems, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Two-Stream -X- _ B-MethodName
AMRenhanced -X- _ I-MethodName
extraction -X- _ I-MethodName
model -X- _ O
(TSAR). -X- _ B-MethodName

In -X- _ O
this -X- _ O
paper, -X- _ O

However, -X- _ O
how -X- _ O
to -X- _ O
model -X- _ O
long-distance -X- _ O
dependency -X- _ O
among -X- _ O
trigger -X- _ O
and -X- _ O
arguments, -X- _ O
and -X- _ O
how -X- _ O
to -X- _ O
handle -X- _ O
distracting -X- _ O
context -X- _ O
explicitly, -X- _ O
remain -X- _ O
largely -X- _ O
under-explored. -X- _ O

Some -X- _ O
studies -X- _ O
directly -X- _ O
generate -X- _ O
arguments -X- _ O
based -X- _ O
on -X- _ O
sequence-to-sequence -X- _ O
model -X- _ O
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Instead, -X- _ O
span-based -X- _ O
methods -X- _ O
predict -X- _ O
argument -X- _ O
roles -X- _ O
for -X- _ O
candidate -X- _ O
spans -X- _ O
(Ebner -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Zhang -X- _ O
et -X- _ O
al., -X- _ O
2020b). -X- _ O

Recently, -X- _ O
Du -X- _ O
and -X- _ O
Cardie -X- _ O
(2020a) -X- _ O
use -X- _ O
a -X- _ O
taggingbased -X- _ O
method, -X- _ O
which -X- _ O
fails -X- _ O
to -X- _ O
handle -X- _ O
nested -X- _ O
arguments. -X- _ O

It -X- _ O
remains -X- _ O
challenging -X- _ O
to -X- _ O
pinpoint -X- _ O
the -X- _ O
useful -X- _ O
context -X- _ O
while -X- _ O
discarding -X- _ O
the -X- _ O
distracting -X- _ O
information. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
the -X- _ O
origin -X- _ O
argument -X- _ O
U.S. -X- _ O
can -X- _ O
be -X- _ O
identified -X- _ O
more -X- _ O
easily -X- _ O
without -X- _ O
Sentence -X- _ O
4, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
offer -X- _ O
useful -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
event, -X- _ O
but -X- _ O
contains -X- _ O
many -X- _ O
place -X- _ O
entities -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
distracting, -X- _ O
like -X- _ O
Saudi -X- _ O
Arabia -X- _ O
and -X- _ O
Russia -X- _ O
or -X- _ O
Iran. -X- _ O

last -X- _ O
week, -X- _ O
according -X- _ O
to -X- _ O
oil -X- _ O
data -X- _ O
research -X- _ O
firm -X- _ O
ClipperData. -X- _ O

pumped -X- _ O
in -X- _ O
the -X- _ O
U.S. -X- _ O
docked -X- _ O
at -X- _ O
a -X- _ O
terminal -X- _ O
owned -X- _ O
by -X- _ O
Venezuela -X- _ O

[1] -X- _ O
A -X- _ O
ship -X- _ O
carrying -X- _ O
half -X- _ O
a -X- _ O
million -X- _ O
barrels -X- _ O
of -X- _ O
oil -X- _ O
that -X- _ O
was -X- _ O

While -X- _ O
a -X- _ O
document -X- _ O
naturally -X- _ O
encompasses -X- _ O
more -X- _ O
context -X- _ O
than -X- _ O
a -X- _ O
single -X- _ O
sentence, -X- _ O
some -X- _ O
distracting -X- _ O
context -X- _ O
can -X- _ O
mislead -X- _ O
the -X- _ O
argument -X- _ O
extraction. -X- _ O

(2) -X- _ O
Distracting -X- _ O
context. -X- _ O

To -X- _ O
accommodate -X- _ O
the -X- _ O
long-range -X- _ O
extraction, -X- _ O
not -X- _ O
only -X- _ O
intra-sentential -X- _ O
but -X- _ O
also -X- _ O
inter-sentential -X- _ O
semantics -X- _ O
should -X- _ O
be -X- _ O
well -X- _ O
modeled. -X- _ O

In -X- _ O
Figure -X- _ O
1, -X- _ O
while -X- _ O
the -X- _ O
trigger -X- _ O
shipment -X- _ O
is -X- _ O
in -X- _ O
Sentence -X- _ O
2, -X- _ O
the -X- _ O
vehicle, -X- _ O
origin, -X- _ O
artifact, -X- _ O
and -X- _ O
importer -X- _ O
arguments -X- _ O
are -X- _ O
located -X- _ O
in -X- _ O
Sentence -X- _ O
1 -X- _ O
or -X- _ O
3, -X- _ O
which -X- _ O
highly -X- _ O
increases -X- _ O
the -X- _ O
extraction -X- _ O
difficulty. -X- _ O

The -X- _ O
arguments -X- _ O
are -X- _ O
usually -X- _ O
located -X- _ O
in -X- _ O
different -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
trigger -X- _ O
word -X- _ O
and -X- _ O
their -X- _ O
distance -X- _ O
can -X- _ O
be -X- _ O
quite -X- _ O
far -X- _ O
away. -X- _ O

(1) -X- _ O
Long-distance -X- _ O
dependency -X- _ O
among -X- _ O
trigger -X- _ O
and -X- _ O
arguments. -X- _ O

Different -X- _ O
from -X- _ O
sentence-level -X- _ O
EAE, -X- _ B-TaskName
extracting -X- _ O
arguments -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
entire -X- _ O
document -X- _ O
faces -X- _ O
two -X- _ O
critical -X- _ O
challenges. -X- _ O

Figure -X- _ O
1 -X- _ O
illustrates -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
documentlevel -X- _ B-TaskName
EAE, -X- _ I-TaskName
in -X- _ O
which -X- _ O
a -X- _ O
Transport -X- _ O
event -X- _ O
is -X- _ O
triggered -X- _ O
by -X- _ O
shipment. -X- _ O

However, -X- _ O
in -X- _ O
real-life -X- _ O
scenarios, -X- _ O
the -X- _ O
events -X- _ O
are -X- _ O
often -X- _ O
described -X- _ O
through -X- _ O
a -X- _ O
whole -X- _ O
document -X- _ O
consisting -X- _ O
of -X- _ O
multiple -X- _ O
sentences -X- _ O
(e.g., -X- _ O
a -X- _ O
news -X- _ O
article -X- _ O
or -X- _ O
a -X- _ O
financial -X- _ O
report), -X- _ O
which -X- _ O
still -X- _ O
remains -X- _ O
under-explored. -X- _ O

expressed -X- _ O
by -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
and -X- _ O
hence -X- _ O
focus -X- _ O
on -X- _ O
sentence-level -X- _ O
extraction -X- _ O
(Chen -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Zhou -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

A -X- _ O
transport -X- _ O
event -X- _ O
is -X- _ O
triggered -X- _ O
by -X- _ O
shipment, -X- _ O
with -X- _ O
five -X- _ O
event -X- _ O
arguments -X- _ O
scattering -X- _ O
across -X- _ O
the -X- _ O
document. -X- _ O

Most -X- _ O
previous -X- _ O
studies -X- _ O
assume -X- _ O
that -X- _ O
the -X- _ O
events -X- _ O
are -X- _ O
only -X- _ O

It -X- _ O
helps -X- _ O
to -X- _ O
transform -X- _ O
the -X- _ O
unstructured -X- _ O
text -X- _ O
into -X- _ O
structured -X- _ O
event -X- _ O
knowledge -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
utilized -X- _ O
in -X- _ O
recommendation -X- _ O
systems -X- _ O
(Li -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
dialogue -X- _ O
systems -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2020a), -X- _ O
and -X- _ O
so -X- _ O
on. -X- _ O

Event -X- _ B-TaskName
Argument -X- _ I-TaskName
Extraction -X- _ I-TaskName
(EAE) -X- _ B-TaskName
aims -X- _ O
at -X- _ O
identifying -X- _ O
the -X- _ O
entities -X- _ O
that -X- _ O
serve -X- _ O
as -X- _ O
event -X- _ O
arguments, -X- _ O
and -X- _ O
predicting -X- _ O
the -X- _ O
roles -X- _ O
they -X- _ O
play -X- _ O
in -X- _ O
the -X- _ O
event, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
step -X- _ O
for -X- _ O
Event -X- _ B-TaskName
Extraction -X- _ I-TaskName
(EE). -X- _ B-TaskName

Introduction -X- _ O

We -X- _ O
release -X- _ O
our -X- _ O
code -X- _ O
in -X- _ O
https://github.com/ -X- _ O
PKUnlp-icler/TSAR. -X- _ O

Extensive -X- _ O
experiments -X- _ O
illustrate -X- _ O
that -X- _ O
TSAR -X- _ B-MethodName
outperforms -X- _ O
previous -X- _ O
state-of-the-art -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin, -X- _ O
with -X- _ O
2.54 -X- _ B-MetricValue
F1 -X- _ B-MetricName
and -X- _ O
5.13 -X- _ B-MetricValue
F1 -X- _ B-MetricName
performance -X- _ O
gain -X- _ O
on -X- _ O
the -X- _ O
public -X- _ O
RAMS -X- _ B-DatasetName
and -X- _ O
WikiEvents -X- _ B-DatasetName
datasets -X- _ O
respectively, -X- _ O
showing -X- _ O
the -X- _ O
superiority -X- _ O
in -X- _ O
the -X- _ O
cross-sentence -X- _ O
arguments -X- _ O
extraction. -X- _ O

An -X- _ O
auxiliary -X- _ O
boundary -X- _ O
loss -X- _ O
is -X- _ O
introduced -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
boundary -X- _ O
information -X- _ O
for -X- _ O
text -X- _ O
spans -X- _ O
explicitly. -X- _ O

Besides, -X- _ O
TSAR -X- _ B-MethodName
introduces -X- _ O
an -X- _ O
AMR-guided -X- _ O
interaction -X- _ O
module -X- _ O
to -X- _ O
capture -X- _ O
both -X- _ O
intra-sentential -X- _ O
and -X- _ O
inter-sentential -X- _ O
features, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
locally -X- _ O
and -X- _ O
globally -X- _ O
constructed -X- _ O
AMR -X- _ O
semantic -X- _ O
graphs. -X- _ O

TSAR -X- _ B-MethodName
encodes -X- _ O
the -X- _ O
document -X- _ O
from -X- _ O
different -X- _ O
perspectives -X- _ O
by -X- _ O
a -X- _ O
twostream -X- _ O
encoding -X- _ O
module, -X- _ O
to -X- _ O
utilize -X- _ O
local -X- _ O
and -X- _ O
global -X- _ O
information -X- _ O
and -X- _ O
lower -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
distracting -X- _ O
context. -X- _ O

To -X- _ O
address -X- _ O
these -X- _ O
issues, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
Two-Stream -X- _ B-MethodName
Abstract -X- _ I-MethodName
meaning -X- _ I-MethodName
Representation -X- _ I-MethodName
enhanced -X- _ O
extraction -X- _ O
model -X- _ O
(TSAR). -X- _ B-MethodName

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
extracting -X- _ O
event -X- _ O
arguments -X- _ O
from -X- _ O
an -X- _ O
entire -X- _ O
document, -X- _ O
which -X- _ O
mainly -X- _ O
faces -X- _ O
two -X- _ O
critical -X- _ O
problems: -X- _ O
a) -X- _ O
the -X- _ O
longdistance -X- _ O
dependency -X- _ O
between -X- _ O
trigger -X- _ O
and -X- _ O
arguments -X- _ O
over -X- _ O
sentences; -X- _ O
b) -X- _ O
the -X- _ O
distracting -X- _ O
context -X- _ O
towards -X- _ O
an -X- _ O
event -X- _ O
in -X- _ O
the -X- _ O
document. -X- _ O

Most -X- _ O
previous -X- _ O
studies -X- _ O
aim -X- _ O
at -X- _ O
extracting -X- _ O
events -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
sentence, -X- _ O
while -X- _ O
document-level -X- _ B-TaskName
event -X- _ I-TaskName
extraction -X- _ I-TaskName
still -X- _ O
remains -X- _ O
under-explored. -X- _ O

A -X- _ O
Two-Stream -X- _ O
AMR-enhanced -X- _ O
Model -X- _ O
for -X- _ O
Document-level -X- _ B-TaskName
Event -X- _ I-TaskName
Argument -X- _ I-TaskName
Extraction -X- _ I-TaskName

-DOCSTART- -X- O
Because -X- _ O
there -X- _ O
are -X- _ O
many -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
subgraph, -X- _ O
we -X- _ O
represent -X- _ O
some -X- _ O
nodes -X- _ O
and -X- _ O
relationships -X- _ O
in -X- _ O
the -X- _ O
subgraph -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
links. -X- _ O

V -X- _ O
contains -X- _ O
Vq, -X- _ O
Va, -X- _ O
and -X- _ O
any -X- _ O
bridging -X- _ O
entity -X- _ O
with -X- _ O
no -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
hops -X- _ O
between -X- _ O
any -X- _ O
pair -X- _ O
of -X- _ O
entities -X- _ O
in -X- _ O
Vq -X- _ O
and -X- _ O
Va. -X- _ O

Va -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
entities -X- _ O
included -X- _ O
in -X- _ O
a -X- _ O
choice. -X- _ O

Vq -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
entities -X- _ O
included -X- _ O
in -X- _ O
a -X- _ O
question. -X- _ O

We -X- _ O
consider -X- _ O
the -X- _ O
reverse -X- _ O
edge -X- _ O
of -X- _ O
each -X- _ O
relation -X- _ O
during -X- _ O
training -X- _ O
and -X- _ O
testing, -X- _ O
so -X- _ O
there -X- _ O
are -X- _ O
38 -X- _ O
relation -X- _ O
types -X- _ O
in -X- _ O
total. -X- _ O

Only -X- _ O
some -X- _ O
important -X- _ O
nodes -X- _ O
are -X- _ O
shown -X- _ O
here. -X- _ O

Because -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
subgraph -X- _ O
nodes -X- _ O
corresponding -X- _ O
to -X- _ O
each -X- _ O
case -X- _ O
is -X- _ O
about -X- _ O
100, -X- _ O
we -X- _ O
cannot -X- _ O
list -X- _ O
them -X- _ O
all. -X- _ O

In -X- _ O
Table -X- _ O
9, -X- _ O
we -X- _ O
present -X- _ O
examples -X- _ O
for -X- _ O
each -X- _ O
error -X- _ O
type -X- _ O
in -X- _ O
the -X- _ O
Commonsense -X- _ B-DatasetName
IHdev -X- _ O
set. -X- _ O

C -X- _ O
Error -X- _ O
Types -X- _ O
and -X- _ O
Examples -X- _ O

For -X- _ O
each -X- _ O
entity, -X- _ O
we -X- _ O
perform -X- _ O
mean -X- _ O
pooling -X- _ O
over -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
entity’s -X- _ O
occurrences -X- _ O
across -X- _ O
all -X- _ O
the -X- _ O
sentences -X- _ O
to -X- _ O
form -X- _ O
the -X- _ O
initial -X- _ O
embeddings -X- _ O
x0 -X- _ O
i -X- _ O
. -X- _ O

Following -X- _ O
(Feng -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
the -X- _ O
template -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
knowledge -X- _ O
triples -X- _ O
in -X- _ O
ConceptNet -X- _ O
into -X- _ O
sentences, -X- _ O
and -X- _ O
feed -X- _ O
them -X- _ O
into -X- _ O
BERT-Large, -X- _ O
obtaining -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
embeddings -X- _ O
from -X- _ O
the -X- _ O
last -X- _ O
layer. -X- _ O

For -X- _ O
each -X- _ O
entity -X- _ O
in -X- _ O
the -X- _ O
subgraph, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
obtain -X- _ O
its -X- _ O
feature -X- _ O
representation. -X- _ O

B -X- _ O
Node -X- _ O
Initialization -X- _ O

The -X- _ O
relation -X- _ O
types -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7, -X- _ O
and -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
retrieved -X- _ O
nodes -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8. -X- _ O

In -X- _ O
addition, -X- _ O
we -X- _ O
add -X- _ O
question -X- _ O
as -X- _ O
a -X- _ O
node -X- _ O
q -X- _ O
to -X- _ O
V -X- _ O
, -X- _ O
and -X- _ O
add -X- _ O
the -X- _ O
bidirectional -X- _ O
edges -X- _ O
of -X- _ O
q -X- _ O
to -X- _ O
Vq -X- _ O
and -X- _ O
q -X- _ O
to -X- _ O
Va. -X- _ O

We -X- _ O
retrieve -X- _ O
all -X- _ O
the -X- _ O
edges -X- _ O
in -X- _ O
R -X- _ O
of -X- _ O
any -X- _ O
two -X- _ O
nodes -X- _ O
in -X- _ O
V -X- _ O
. -X- _ O

Finally, -X- _ O
we -X- _ O
get -X- _ O
the -X- _ O
relation -X- _ O
set -X- _ O
R -X- _ O
by -X- _ O
merging -X- _ O
the -X- _ O
relation -X- _ O
types -X- _ O
in -X- _ O
ConceptNet -X- _ O
and -X- _ O
adding -X- _ O
reverse -X- _ O
relation. -X- _ O

The -X- _ O
former -X- _ O
is -X- _ O
to -X- _ O
score -X- _ O
only -X- _ O
one -X- _ O
node -X- _ O
and -X- _ O
separate -X- _ O
from -X- _ O
the -X- _ O
whole -X- _ O
subgraph -X- _ O
where -X- _ O
the -X- _ O
node -X- _ O
is -X- _ O
located, -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
recursive -X- _ O
pruning -X- _ O
in -X- _ O
the -X- _ O
updating -X- _ O
process -X- _ O
of -X- _ O
the -X- _ O
modeling -X- _ O
subgraph). -X- _ O

We -X- _ O
only -X- _ O
retain -X- _ O
the -X- _ O
top -X- _ O
200 -X- _ O
scoring -X- _ O
nodes -X- _ O
(It -X- _ O
is -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
preprocessing -X- _ O
of -X- _ O
the -X- _ O
retrieval -X- _ O
process, -X- _ O
which -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
dynamic -X- _ O
pruning -X- _ O
in -X- _ O
section -X- _ O
3.5. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
preprocessing -X- _ O
method -X- _ O
of -X- _ O
Yasunaga -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
connect -X- _ O
the -X- _ O
nodes -X- _ O
with -X- _ O
question -X- _ O
+ -X- _ O
choice, -X- _ O
and -X- _ O
calculate -X- _ O
the -X- _ O
relevant -X- _ O
scores -X- _ O
of -X- _ O
the -X- _ O
nodes -X- _ O
through -X- _ O
a -X- _ O
pre-trained -X- _ O
LM. -X- _ O

There -X- _ O
may -X- _ O
be -X- _ O
many -X- _ O
nodes -X- _ O
in -X- _ O
V -X- _ O
, -X- _ O
especially -X- _ O
long -X- _ O
questions -X- _ O
contain -X- _ O
many -X- _ O
concepts. -X- _ O

Then, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
subgraph -X- _ O
related -X- _ O
to -X- _ O
question -X- _ O
and -X- _ O
choice, -X- _ O
we -X- _ O
add -X- _ O
the -X- _ O
bridge -X- _ O
entities -X- _ O
on -X- _ O
the -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
hop -X- _ O
paths -X- _ O
between -X- _ O
any -X- _ O
pair -X- _ O
of -X- _ O
entities -X- _ O
in -X- _ O
Vq,a, -X- _ O
thus -X- _ O
obtaining -X- _ O
the -X- _ O
retrieved -X- _ O
entity -X- _ O
set -X- _ O
V -X- _ O
. -X- _ O

References -X- _ O

We -X- _ O
neither -X- _ O
introduce -X- _ O
any -X- _ O
social/ethical -X- _ O
bias -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
nor -X- _ O
amplify -X- _ O
any -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
data, -X- _ O
so -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
foresee -X- _ O
any -X- _ O
direct -X- _ O
social -X- _ O
consequences -X- _ O
or -X- _ O
ethical -X- _ O
issues. -X- _ O

In -X- _ O
all -X- _ O
the -X- _ O
experiments, -X- _ O
we -X- _ O
use -X- _ O
public -X- _ O
datasets -X- _ O
and -X- _ O
consist -X- _ O
of -X- _ O
their -X- _ O
intended -X- _ O
use. -X- _ O

We -X- _ O
worked -X- _ O
within -X- _ O
the -X- _ O
purview -X- _ O
of -X- _ O
acceptable -X- _ O
privacy -X- _ O
practices -X- _ O
and -X- _ O
strictly -X- _ O
followed -X- _ O
the -X- _ O
data -X- _ O
usage -X- _ O
policy. -X- _ O

This -X- _ O
paper -X- _ O
proposes -X- _ O
a -X- _ O
general -X- _ O
approach -X- _ O
to -X- _ O
fuse -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
graphs -X- _ O
for -X- _ O
commonsense -X- _ O
reasoning. -X- _ O

Ethical -X- _ O
Impact -X- _ O

In -X- _ O
addition, -X- _ O
our -X- _ O
research -X- _ O
results -X- _ O
can -X- _ O
be -X- _ O
broadly -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
KGs -X- _ O
as -X- _ O
additional -X- _ O
background -X- _ O
knowledge -X- _ O
to -X- _ O
augment -X- _ O
LMs, -X- _ O
such -X- _ O
as -X- _ O
entity -X- _ O
linking, -X- _ O
KG -X- _ O
completion -X- _ O
and -X- _ O
the -X- _ O
recommendation -X- _ O
system. -X- _ O

Our -X- _ O
results -X- _ O
on -X- _ O
CommonsenseQA -X- _ B-DatasetName
and -X- _ O
OpenBookQA -X- _ B-DatasetName
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
JointLK -X- _ B-MethodName
over -X- _ O
other -X- _ O
methods -X- _ O
using -X- _ O
external -X- _ O
knowledge -X- _ O
and -X- _ O
the -X- _ O
strong -X- _ O
performance -X- _ O
in -X- _ O
performing -X- _ O
complex -X- _ O
reasoning. -X- _ O

(ii) -X- _ O
Dynamic -X- _ O
pruning -X- _ O
module -X- _ O
can -X- _ O
recursively -X- _ O
delete -X- _ O
irrelevant -X- _ O
subgraph -X- _ O
nodes -X- _ O
at -X- _ O
each -X- _ O
layer -X- _ O
of -X- _ O
JointLK -X- _ B-MethodName
to -X- _ O
provide -X- _ O
fine -X- _ O
appropriate -X- _ O
evidence. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
propose -X- _ O
JointLK -X- _ B-MethodName
and -X- _ O
provide -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
to -X- _ O
prove -X- _ O
that -X- _ O
(i) -X- _ O
LM -X- _ O
and -X- _ O
KG -X- _ O
interactive -X- _ O
fusion -X- _ O
can -X- _ O
reduce -X- _ O
the -X- _ O
semantic -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
information -X- _ O
modalities -X- _ O
and -X- _ O
make -X- _ O
better -X- _ O
use -X- _ O
of -X- _ O
KG -X- _ O
for -X- _ O
joint -X- _ O
reasoning -X- _ O
with -X- _ O
LM. -X- _ O

6 -X- _ O
Conclusion -X- _ O

The -X- _ O
above -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
errors -X- _ O
show -X- _ O
that -X- _ O
selecting -X- _ O
complete, -X- _ O
accurate, -X- _ O
and -X- _ O
context-sensitive -X- _ O
for -X- _ O
more -X- _ O
effective -X- _ O
KGknowledge -X- _ O
is -X- _ O
vital -X- _ O
augmented -X- _ O
models. -X- _ O

Some -X- _ O
questions -X- _ O
may -X- _ O
require -X- _ O
reasoning -X- _ O
based -X- _ O
on -X- _ O
events, -X- _ O
but -X- _ O
the -X- _ O
knowledge -X- _ O
in -X- _ O
ConceptNet -X- _ O
is -X- _ O
more -X- _ O
based -X- _ O
on -X- _ O
entities -X- _ O
and -X- _ O
attributes. -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
scene -X- _ O
described -X- _ O
by -X- _ O
the -X- _ O
question. -X- _ O

Incomprehensible -X- _ O
questions -X- _ O
(23/100) -X- _ O
This -X- _ O
type -X- _ O
of -X- _ O
error -X- _ O
often -X- _ O
occurs -X- _ O
when -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
particularly -X- _ O
long, -X- _ O
involving -X- _ O
various -X- _ O
events -X- _ O
and -X- _ O
changes -X- _ O
in -X- _ O
the -X- _ O
characters’ -X- _ O
emotions. -X- _ O

The -X- _ O
model -X- _ O
may -X- _ O
choose -X- _ O
bed -X- _ O
because -X- _ O
the -X- _ O
bed -X- _ O
appears -X- _ O
more -X- _ O
frequently -X- _ O
in -X- _ O
the -X- _ O
pre-trained -X- _ O
corpus. -X- _ O

“cat” -X- _ O
may -X- _ O
be -X- _ O
at -X- _ O
location -X- _ O
“bed” -X- _ O
or -X- _ O
“comfortable -X- _ O
chair”, -X- _ O
and -X- _ O
the -X- _ O
knowledge -X- _ O
provided -X- _ O
by -X- _ O
ConceptNet -X- _ O
is -X- _ O
also -X- _ O
the -X- _ O
same. -X- _ O

For -X- _ O
example, -X- _ O
“human” -X- _ O
and -X- _ O

Indistinguishable -X- _ O
knowledge -X- _ O
(25/100) -X- _ O
Several -X- _ O
choices -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
may -X- _ O
be -X- _ O
correct, -X- _ O
difficult -X- _ O
to -X- _ O
distinguish, -X- _ O
and -X- _ O
which -X- _ O
one -X- _ O
is -X- _ O
correct -X- _ O
may -X- _ O
vary -X- _ O
from -X- _ O
person -X- _ O
to -X- _ O
person. -X- _ O

However, -X- _ O
ConceptNet -X- _ O
does -X- _ O
not -X- _ O
cover -X- _ O
such -X- _ O
knowledge -X- _ O
or -X- _ O
not -X- _ O
is -X- _ O
retrieved. -X- _ O

For -X- _ O
example, -X- _ O
although -X- _ O
“eating_dinner” -X- _ O
will -X- _ O
cause -X- _ O
“sleepiness” -X- _ O
or -X- _ O
“indigestion”, -X- _ O
knowledge -X- _ O
such -X- _ O
as -X- _ O
“lactose -X- _ O
intolerance -X- _ O
causes -X- _ O
indigestion” -X- _ O
is -X- _ O
essential -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
(Wikipedia: -X- _ O
Lactose -X- _ O
intolerance -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
condition -X- _ O
caused -X- _ O
by -X- _ O
a -X- _ O
decreased -X- _ O
ability -X- _ O
to -X- _ O
digest -X- _ O
lactose, -X- _ O
a -X- _ O
sugar -X- _ O
found -X- _ O
in -X- _ O
dairy -X- _ O
products.). -X- _ O

Although -X- _ O
we -X- _ O
can -X- _ O
retrieve -X- _ O
many -X- _ O
nodes -X- _ O
related -X- _ O
to -X- _ O
questions -X- _ O
and -X- _ O
choices -X- _ O
from -X- _ O
ConceptNet, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
incompleteness -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
graph, -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
missing -X- _ O
essential -X- _ O
evidence -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
reasoning -X- _ O
paths -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question. -X- _ O

There -X- _ O
are -X- _ O
three -X- _ O
main -X- _ O
types -X- _ O
of -X- _ O
errors, -X- _ O
and -X- _ O
we -X- _ O
show -X- _ O
some -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
C. -X- _ O
Miss -X- _ O
important -X- _ O
evidence -X- _ O
(39/100) -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
understand -X- _ O
why -X- _ O
our -X- _ O
model -X- _ O
fails -X- _ O
in -X- _ O
some -X- _ O
cases, -X- _ O
we -X- _ O
randomly -X- _ O
select -X- _ O
100 -X- _ O
error -X- _ O
cases -X- _ O
and -X- _ O
group -X- _ O
them -X- _ O
into -X- _ O
several -X- _ O
categories. -X- _ O

5.5 -X- _ O
Error -X- _ O
Analysis -X- _ O

These -X- _ O
two -X- _ O
paths -X- _ O
describe -X- _ O
two -X- _ O
possible -X- _ O
scenarios -X- _ O
that -X- _ O
support -X- _ O
answering -X- _ O
the -X- _ O
question. -X- _ O

The -X- _ O
question -X- _ O
and -X- _ O
answer -X- _ O
choices -X- _ O
corresponding -X- _ O
to -X- _ O
this -X- _ O
case -X- _ O
are: -X- _ O
"What -X- _ O
do -X- _ O
people -X- _ O
typically -X- _ O
do -X- _ O
while -X- _ O
playing -X- _ O
guitar? -X- _ O

From -X- _ O
(a) -X- _ O
to -X- _ O
(b), -X- _ O
although -X- _ O
the -X- _ O
nodes -X- _ O
wood -X- _ O
and -X- _ O
burn -X- _ O
bridge -X- _ O
the -X- _ O
reasoning -X- _ O
gap -X- _ O
between -X- _ O
question -X- _ O
entity -X- _ O
and -X- _ O
answer -X- _ O
entity, -X- _ O
their -X- _ O

The -X- _ O
flow -X- _ O
from -X- _ O
(a) -X- _ O
to -X- _ O
(b) -X- _ O
to -X- _ O
(c) -X- _ O
represents -X- _ O
the -X- _ O
recursive -X- _ O
pruning -X- _ O
of -X- _ O
the -X- _ O
subgraph -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
LM-to-KG -X- _ O
attention -X- _ O
weight -X- _ O
at -X- _ O
each -X- _ O
GNN -X- _ O
update -X- _ O
layer. -X- _ O

Figure -X- _ O
4 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
from -X- _ O
CommonsenseQA -X- _ B-DatasetName
where -X- _ O
our -X- _ O
model -X- _ O
correctly -X- _ O
answers -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
finally -X- _ O
retains -X- _ O
reasonable -X- _ O
reasoning -X- _ O
paths -X- _ O
by -X- _ O
pruning -X- _ O
the -X- _ O
subgraph. -X- _ O

We -X- _ O
aim -X- _ O
to -X- _ O
interpret -X- _ O
JointLK’s -X- _ B-MethodName
reasoning -X- _ O
process -X- _ O
by -X- _ O
analyzing -X- _ O
the -X- _ O
pruning -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
subgraph. -X- _ O

5.4 -X- _ O
Interpretability: -X- _ O
A -X- _ O
Case -X- _ O
Study -X- _ O

Compared -X- _ O
with -X- _ O
QA-GNN, -X- _ B-MethodName
JointLK -X- _ B-MethodName
has -X- _ O
a -X- _ O
bigger -X- _ O
boost -X- _ O
on -X- _ O
questions -X- _ O
with -X- _ O
more -X- _ O
entities -X- _ O
( -X- _ O
2.01%) -X- _ B-MetricValue
than -X- _ O
those -X- _ O
with -X- _ O
fewer -X- _ O
entities -X- _ O
↑ -X- _ O
( -X- _ O
0.96%), -X- _ B-MetricValue
suggesting -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
reduce -X- _ O
↑ -X- _ O
the -X- _ O
reasoning -X- _ O
difficulty -X- _ O
of -X- _ O
complex -X- _ O
questions -X- _ O
because -X- _ O
it -X- _ O
can -X- _ O
remove -X- _ O
irrelevant -X- _ O
nodes -X- _ O
in -X- _ O
reasoning. -X- _ O

According -X- _ O
to -X- _ O
statistics -X- _ O
(see -X- _ O
Appendix -X- _ O
A), -X- _ O
questions -X- _ O
contain -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
7 -X- _ O
entities, -X- _ O
so -X- _ O
we -X- _ O
divide -X- _ O
the -X- _ O
question -X- _ O
into -X- _ O
two -X- _ O
categories: -X- _ O
containing -X- _ O
fewer -X- _ O
entities -X- _ O
( -X- _ O
7) -X- _ O
and -X- _ O
more -X- _ O
entities(>7). -X- _ O

Questions -X- _ O
with -X- _ O
fewer/more -X- _ O
entities -X- _ O
When -X- _ O
the -X- _ O
question -X- _ O
contains -X- _ O
many -X- _ O
entities, -X- _ O
the -X- _ O
size -X- _ O
and -X- _ O
noise -X- _ O
of -X- _ O
the -X- _ O
retrieved -X- _ O
KG -X- _ O
may -X- _ O
limit -X- _ O
the -X- _ O
model’s -X- _ O
performance -X- _ O
because -X- _ O
the -X- _ O
model -X- _ O
needs -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
complex -X- _ O
relationship -X- _ O
between -X- _ O
entities. -X- _ O

The -X- _ O
fine-grained -X- _ O
joint -X- _ O
inference -X- _ O
of -X- _ O
LM -X- _ O
and -X- _ O
GNN -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
pay -X- _ O
attention -X- _ O
to -X- _ O
the -X- _ O
semantic -X- _ O
nuances -X- _ O
of -X- _ O
language -X- _ O
expressions. -X- _ O

JointLK -X- _ B-MethodName
exhibits -X- _ O
a -X- _ O
big -X- _ O
boost -X- _ O
( -X- _ O
3.00%) -X- _ B-MetricValue
over -X- _ O
QA↑ -X- _ O
GNN, -X- _ O
suggesting -X- _ O
its -X- _ O
strength -X- _ O
in -X- _ O
negation -X- _ O
reasoning. -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
reasoning -X- _ O
ability -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
negation, -X- _ O
we -X- _ O
retrieved -X- _ O
133 -X- _ O
questions -X- _ O
with -X- _ O
negation -X- _ O
terms -X- _ O
(e.g., -X- _ O
no, -X- _ O
not, -X- _ O
nothing, -X- _ O
never, -X- _ O
unlikely, -X- _ O
don’t, -X- _ O
doesn’t, -X- _ O
didn’t, -X- _ O
can’t, -X- _ O
couldn’t) -X- _ O
from -X- _ O
the -X- _ O
CommonsenseQA -X- _ B-DatasetName
IHdev -X- _ O
set. -X- _ O

Questions -X- _ O
with -X- _ O
negation -X- _ O
Large -X- _ O
LMs -X- _ O
do -X- _ O
well -X- _ O
due -X- _ O
to -X- _ O
memorizing -X- _ O
subject -X- _ O
and -X- _ O
filler -X- _ O
co-occurrences -X- _ O
but -X- _ O
are -X- _ O
easily -X- _ O
distracted -X- _ O
by -X- _ O
elements -X- _ O
like -X- _ O
negation -X- _ O
(Zagoury -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
prior -X- _ O
best -X- _ O
LM+KG -X- _ O
model, -X- _ O
QA-GNN -X- _ B-MethodName
in -X- _ O
Table -X- _ O
6. -X- _ O

more -X- _ O
entities. -X- _ O

The -X- _ O
questions -X- _ O
are -X- _ O
retrieved -X- _ O
from -X- _ O
the -X- _ O
CommonsenseQA -X- _ B-DatasetName
IHdev -X- _ O
set. -X- _ O

Considering -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
improvement -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
these -X- _ O
two -X- _ O
datasets, -X- _ O
we -X- _ O
analyze -X- _ O
whether -X- _ O
the -X- _ O
improvement -X- _ O
is -X- _ O
reflected -X- _ O
in -X- _ O
questions -X- _ O
that -X- _ O
require -X- _ O
more -X- _ O
complex -X- _ O
reasoning, -X- _ O
such -X- _ O
as -X- _ O
questions -X- _ O
with -X- _ O
negation -X- _ O
and -X- _ O
complex -X- _ O
questions -X- _ O
with -X- _ O

5.3 -X- _ O
Quantitative -X- _ O
Analysis -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
(b), -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
JointLK -X- _ B-MethodName
layers -X- _ B-HyperparameterName
N -X- _ B-HyperparameterName
= -X- _ O
5, -X- _ B-HyperparameterValue
K -X- _ B-HyperparameterName
= -X- _ O
0.92 -X- _ B-HyperparameterValue
(about -X- _ O
66% -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
nodes -X- _ O
remain -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
layer) -X- _ O
works -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
CommonsenseQA -X- _ B-DatasetName
dev -X- _ O
set. -X- _ O

Experiments -X- _ O
show -X- _ O
that -X- _ O
if -X- _ O
the -X- _ O
retention -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
is -X- _ O
too -X- _ O
high, -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
almost -X- _ O
no -X- _ O
pruning -X- _ O
effect -X- _ O
(for -X- _ O
example, -X- _ O
K=0.98, -X- _ B-HyperparameterName
90% -X- _ O
of -X- _ O
the -X- _ O
nodes -X- _ O
are -X- _ O
retained -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
layer); -X- _ O
otherwise, -X- _ O
useful -X- _ O
nodes -X- _ O
may -X- _ O
be -X- _ O
deleted. -X- _ O

Since -X- _ O
it -X- _ O
is -X- _ O
recursively -X- _ O
pruning -X- _ O
in -X- _ O
each -X- _ O
stacked -X- _ O
layer -X- _ O
of -X- _ O
JointLK, -X- _ O
the -X- _ O
percentage -X- _ O
of -X- _ O
graph -X- _ O
nodes -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
ultimately -X- _ O
retains -X- _ O
is -X- _ O
also -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
of -X- _ O
JointLK, -X- _ B-MethodName
that -X- _ O
is, -X- _ O
KN -X- _ O
, -X- _ O
where -X- _ O
N -X- _ B-HyperparameterName
= -X- _ O
5. -X- _ B-HyperparameterValue

Impact -X- _ O
of -X- _ O
the -X- _ O
Retention -X- _ B-HyperparameterName
Ratio -X- _ I-HyperparameterName
in -X- _ O
Pruning -X- _ O
The -X- _ O
retention -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
hyperparameter -X- _ O
of -X- _ O
the -X- _ O
dynamic -X- _ O
pruning -X- _ O
module. -X- _ O

As -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
increases, -X- _ O
the -X- _ O
model -X- _ O
changes -X- _ O
from -X- _ O
underfitting -X- _ O
to -X- _ O
overfitting. -X- _ O

However, -X- _ O
performance -X- _ O
begins -X- _ O
to -X- _ O
drop -X- _ O
when -X- _ O
N -X- _ B-HyperparameterName
> -X- _ O
5. -X- _ B-HyperparameterValue

The -X- _ O
increase -X- _ O
of -X- _ O
layers -X- _ O
continues -X- _ O
to -X- _ O
bring -X- _ O
benefits -X- _ O
until -X- _ O
layers -X- _ O
N -X- _ B-HyperparameterName
= -X- _ O
5. -X- _ B-HyperparameterValue

We -X- _ O
investigate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
JointLK -X- _ O
layers -X- _ O
(shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
(a)). -X- _ O

results -X- _ O
have -X- _ O
a -X- _ O
significant -X- _ O
drop: -X- _ O
77.88% -X- _ B-MetricValue
76.61%, -X- _ B-MetricValue
suggesting -X- _ O
that -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
between -X- _ O
LM -X- _ O
and -X- _ O
KG -X- _ O
is -X- _ O
critical. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
IHdev -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
CommonsenseQA. -X- _ B-DatasetName

Especially, -X- _ O
when -X- _ O
we -X- _ O
disable -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
module, -X- _ O
the -X- _ O
corresponding -X- _ O
dynamic -X- _ O
pruning -X- _ O
module -X- _ O
will -X- _ O
also -X- _ O
be -X- _ O
removed, -X- _ O
because -X- _ O
the -X- _ O
latter -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
attention -X- _ O
value -X- _ O
in -X- _ O
the -X- _ O
former. -X- _ O

Disabling -X- _ O
the -X- _ O
dynamic -X- _ O
pruning -X- _ O
module -X- _ O
results -X- _ O
in -X- _ O
0.5% -X- _ B-MetricValue
drop -X- _ O
in -X- _ O
performance, -X- _ O
showing -X- _ O
that -X- _ O
some -X- _ O
nodes -X- _ O
in -X- _ O
subgraph -X- _ O
are -X- _ O
not -X- _ O
conducive -X- _ O
to -X- _ O
reasoning. -X- _ O

Impact -X- _ O
of -X- _ O
JointLK -X- _ B-MethodName
components -X- _ O
We -X- _ O
assess -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
module -X- _ O
(§ -X- _ O
3.4) -X- _ O
and -X- _ O
the -X- _ O
dynamic -X- _ O
pruning -X- _ O
module -X- _ O
(§ -X- _ O
3.5), -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5. -X- _ O

We -X- _ O
show -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
JointLK -X- _ B-MethodName
on -X- _ O
the -X- _ O
CommonsenseQA -X- _ B-DatasetName
IHdev -X- _ O
set. -X- _ O

We -X- _ O
further -X- _ O
conduct -X- _ O
in-depth -X- _ O
analyses -X- _ O
to -X- _ O
investigate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
different -X- _ O
components -X- _ O
in -X- _ O
our -X- _ O
model. -X- _ O

5.2 -X- _ O
Ablation -X- _ O
Studies -X- _ O

In -X- _ O
particular, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
compare -X- _ O
with -X- _ O
the -X- _ O
higher -X- _ O
ranking -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
leaderboard, -X- _ O
such -X- _ O
as -X- _ O
unified -X- _ O
QA -X- _ O
(Khashabi -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
Albert -X- _ O
+ -X- _ O
DESC-KCR -X- _ O
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
because -X- _ O
they -X- _ O
either -X- _ O
use -X- _ O
a -X- _ O
stronger -X- _ O
text -X- _ O
encoder -X- _ O
or -X- _ O
use -X- _ O
additional -X- _ O
data -X- _ O
resources, -X- _ O
while -X- _ O
our -X- _ O
model -X- _ O
focuses -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
between -X- _ O
LM -X- _ O
and -X- _ O
KG. -X- _ O

The -X- _ O
previous -X- _ O
top -X- _ O
2 -X- _ O
systems, -X- _ O
UnifiedQA -X- _ O
(11B -X- _ O
params) -X- _ O
and -X- _ O
T5 -X- _ O
(3B -X- _ O
params) -X- _ O
are -X- _ O
30x -X- _ O
and -X- _ O
8x -X- _ O
larger -X- _ O
than -X- _ O
our -X- _ O
model. -X- _ O

All -X- _ O
listed -X- _ O
methods -X- _ O
use -X- _ O
the -X- _ O
provided -X- _ O
science -X- _ O
facts -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
context. -X- _ O

Methods -X- _ O
with -X- _ O
AristoRoBERTa -X- _ O
use -X- _ O
the -X- _ O
textual -X- _ O
evidence -X- _ O
by -X- _ O
Clark -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
QA -X- _ O
context. -X- _ O

Compared -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
model -X- _ O
MHGRN -X- _ B-MethodName
and -X- _ O
QA-GNN, -X- _ B-MethodName
the -X- _ O
boost -X- _ O
over -X- _ O
them -X- _ O
suggests -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
proposed -X- _ O
joint -X- _ O
reasoning -X- _ O
between -X- _ O
LM -X- _ O
and -X- _ O
KG -X- _ O
and -X- _ O
the -X- _ O
dy -X- _ O

Additionally, -X- _ O
we -X- _ O
also -X- _ O
submit -X- _ O
our -X- _ O
best -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
leaderboards, -X- _ O
and -X- _ O
our -X- _ O
JointLK -X- _ B-MethodName
(with -X- _ O
the -X- _ O
text -X- _ O
encoder -X- _ O
being -X- _ O
RoBERTa-large) -X- _ O
ranks -X- _ O
first -X- _ O
among -X- _ O
comparable -X- _ O
approaches. -X- _ O

On -X- _ O
OpenbookQA, -X- _ B-DatasetName
our -X- _ O
model’s -X- _ O
test -X- _ O
performance -X- _ O
improves -X- _ O
by -X- _ O
6.52% -X- _ B-MetricValue
over -X- _ O
fine-tuned -X- _ O
AristoRoBERTa, -X- _ B-MethodName
and -X- _ O
2.15% -X- _ B-MetricValue
over -X- _ O
QA-GNN. -X- _ B-MethodName

On -X- _ O
CommonsenseQA, -X- _ B-DatasetName
our -X- _ O
model’s -X- _ O
test -X- _ O
performance -X- _ O
improves -X- _ O
by -X- _ O
5.74% -X- _ B-MetricValue
over -X- _ O
fine-tuned -X- _ O
LMs -X- _ O
and -X- _ O
1.02% -X- _ B-MetricValue
over -X- _ O
the -X- _ O
prior -X- _ O
best -X- _ O
LM+KG -X- _ O
model, -X- _ O
QA-GNN. -X- _ B-MethodName

We -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
JointLK -X- _ B-MethodName
performs -X- _ O
best -X- _ O
among -X- _ O
all -X- _ O
fine-tuned -X- _ O
LMs -X- _ O
and -X- _ O
existing -X- _ O
LM+KG -X- _ O
models. -X- _ O

The -X- _ O
results -X- _ O
on -X- _ O
OpenBookQA -X- _ B-DatasetName
test -X- _ O
dataset -X- _ O
and -X- _ O
leaderboard -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
and -X- _ O
Table -X- _ O
4. -X- _ O

The -X- _ O
results -X- _ O
on -X- _ O
CommonsenseQA -X- _ B-DatasetName
in-house -X- _ O
split -X- _ O
dataset -X- _ O
and -X- _ O
official -X- _ O
test -X- _ O
dataset -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
Table -X- _ O
2. -X- _ O

5.1 -X- _ O
Main -X- _ O
Results -X- _ O

5 -X- _ O
Results -X- _ O
and -X- _ O
Analysis -X- _ O

Our -X- _ O
model -X- _ O
has -X- _ O
achieved -X- _ O
state-of-the-art -X- _ O
under -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
RoBERTa-large. -X- _ O

Methods -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
data -X- _ O
division -X- _ O
method -X- _ O
of -X- _ O
Lin -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
in-house -X- _ O
Dev -X- _ O
(IHdev) -X- _ O
and -X- _ O
Test -X- _ O
(IHtest) -X- _ O
accuracy(mean -X- _ O
and -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
four -X- _ O
runs). -X- _ O

Methods -X- _ O

To -X- _ O
be -X- _ O
fair, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
LM -X- _ O
for -X- _ O
all -X- _ O
comparison -X- _ O
methods. -X- _ O

(1), -X- _ O
(2) -X- _ O
and -X- _ O
(3) -X- _ O
are -X- _ O
the -X- _ O
relational -X- _ O
perception -X- _ O
GNNs -X- _ O
for -X- _ O
KGs, -X- _ O
and -X- _ O
(4), -X- _ O
(5) -X- _ O
and -X- _ O
(6) -X- _ O
are -X- _ O
further -X- _ O
model -X- _ O
paths -X- _ O
in -X- _ O
KGs. -X- _ O

GconAttn -X- _ B-MethodName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
(4)KagNet -X- _ B-MethodName
(Lin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
(5)MHGRN -X- _ B-MethodName
(Feng -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
(6) -X- _ O
QA-GNN -X- _ B-MethodName
(Yasunaga -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

For -X- _ O
LM+KG -X- _ O
methods, -X- _ O
they -X- _ O
share -X- _ O
a -X- _ O
similar -X- _ O
high-level -X- _ O
framework -X- _ O
with -X- _ O
our -X- _ O
methods, -X- _ O
that -X- _ O
is, -X- _ O
LM -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
text -X- _ O
encoder, -X- _ O
GNN -X- _ O
or -X- _ O
RN -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
KG -X- _ O
encoder, -X- _ O
but -X- _ O
the -X- _ O
way -X- _ O
of -X- _ O
using -X- _ O
knowledge -X- _ O
or -X- _ O
reasoning -X- _ O
is -X- _ O
different: -X- _ O
(1) -X- _ O
Relationship -X- _ B-MethodName
network -X- _ I-MethodName
(RN) -X- _ B-MethodName
(Santoro -X- _ O
et -X- _ O
al., -X- _ O
2017), -X- _ O
(2) -X- _ O
RGCN -X- _ B-MethodName
(Schlichtkrull -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
(3) -X- _ O

To -X- _ O
investigate -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
KGs, -X- _ O
we -X- _ O
compare -X- _ O
with -X- _ O
the -X- _ O
benchmark -X- _ O
model -X- _ O
RoBERTa-large -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
for -X- _ O
CommonsenseQA, -X- _ B-DatasetName
and -X- _ O
compare -X- _ O
with -X- _ O
RoBERTa-large -X- _ B-MethodName
and -X- _ O
AristoRoBERTa -X- _ B-MethodName
(Clark -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
for -X- _ O
OpenBookQA. -X- _ B-DatasetName

Although -X- _ O
text -X- _ O
corpus -X- _ O
can -X- _ O
provide -X- _ O
complementary -X- _ O
knowledge -X- _ O
except -X- _ O
for -X- _ O
knowledge -X- _ O
graphs, -X- _ O
our -X- _ O
model -X- _ O
focuses -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
KG -X- _ O
and -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
between -X- _ O
LM -X- _ O
and -X- _ O
KG, -X- _ O
so -X- _ O
we -X- _ O
choose -X- _ O
LM -X- _ B-MethodName
and -X- _ O
LM+KG -X- _ B-MethodName
as -X- _ O
the -X- _ O
comparison -X- _ O
methods. -X- _ O

4.3 -X- _ O
Compared -X- _ O
Method -X- _ O

We -X- _ O
use -X- _ O
separate -X- _ O
learning -X- _ O
rates -X- _ O
for -X- _ O
the -X- _ O
LM -X- _ O
encoder -X- _ O
and -X- _ O
the -X- _ O
graph -X- _ O
encoder. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
dimension -X- _ B-HyperparameterName
(D -X- _ B-HyperparameterName
= -X- _ O
200) -X- _ B-HyperparameterValue
and -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
(N -X- _ B-HyperparameterName
= -X- _ O
5) -X- _ B-HyperparameterValue
of -X- _ O
our -X- _ O
GNN -X- _ O
module, -X- _ O
with -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.2 -X- _ B-HyperparameterValue
applied -X- _ O
to -X- _ O
each -X- _ O
layer -X- _ O
(Srivastava -X- _ O
et -X- _ O
al., -X- _ O
2014). -X- _ O

In -X- _ O
training, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
maximum -X- _ O
input -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
to -X- _ O
text -X- _ O
encoders -X- _ O
to -X- _ O
100, -X- _ B-HyperparameterValue
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
to -X- _ O
128, -X- _ B-HyperparameterValue
and -X- _ O
perform -X- _ O
early -X- _ O
stopping. -X- _ O

We -X- _ O
use -X- _ O
cross-entropy -X- _ O
loss -X- _ O
and -X- _ O
RAdam -X- _ O
optimizer -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Given -X- _ O
each -X- _ O
query, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
preprocessing -X- _ O
steps -X- _ O
described -X- _ O
in -X- _ O
Feng -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
subgraph -X- _ O
from -X- _ O
ConceptNet, -X- _ O
and -X- _ O
the -X- _ O
max -X- _ B-HyperparameterName
hop -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
3 -X- _ B-HyperparameterValue
(see -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
the -X- _ O
detail). -X- _ O

Following -X- _ O
previous -X- _ O
work -X- _ O
(Yasunaga -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
we -X- _ O
use -X- _ O
ConceptNet -X- _ O
(Speer -X- _ O
et -X- _ O
al., -X- _ O
2017), -X- _ O
a -X- _ O
commonsense -X- _ O
knowledge -X- _ O
graph, -X- _ O
as -X- _ O
our -X- _ O
structured -X- _ O
knowledge -X- _ O
source -X- _ O
for -X- _ O
both -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
tasks. -X- _ O

4.2 -X- _ O
Implementation -X- _ O
Details -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
official -X- _ O
data -X- _ O
split. -X- _ O

It -X- _ O
contains -X- _ O
5,957 -X- _ O
questions -X- _ O
along -X- _ O
with -X- _ O
an -X- _ O
open -X- _ O
book -X- _ O
of -X- _ O
scientific -X- _ O
facts. -X- _ O

question -X- _ O
answering -X- _ O
dataset -X- _ O
that -X- _ O
requires -X- _ O
reasoning -X- _ O
with -X- _ O
elementary -X- _ O
science -X- _ O
knowledge. -X- _ O

OpenBookQA -X- _ B-DatasetName
is -X- _ O
a -X- _ O
4-way -X- _ O
multiple -X- _ O
choice -X- _ O

(2019), -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
our -X- _ O
final -X- _ O
system -X- _ O
on -X- _ O
the -X- _ O
official -X- _ O
test -X- _ O
set. -X- _ O

We -X- _ O
experiment -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
accuracy -X- _ O
on -X- _ O
the -X- _ O
in-house -X- _ O
dev -X- _ O
(IHdev) -X- _ O
and -X- _ O
test -X- _ O
(IHtest) -X- _ O
splits -X- _ O
used -X- _ O
by -X- _ O
Lin -X- _ O
et -X- _ O
al. -X- _ O

CommonsenseQA -X- _ B-DatasetName
is -X- _ O
a -X- _ O
5-way -X- _ O
multiple-choice -X- _ O
question -X- _ O
answering -X- _ O
dataset -X- _ O
that -X- _ O
requires -X- _ O
commonsense -X- _ O
for -X- _ O
reasoning -X- _ O
and -X- _ O
contains -X- _ O
12,102 -X- _ O
questions. -X- _ O

(Talmor -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
OpenBookQA -X- _ B-DatasetName
(Mihaylov -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
two -X- _ O
typical -X- _ O
commonsense -X- _ O
question -X- _ O
answering -X- _ O
datasets -X- _ O
CommonsenseQA -X- _ B-DatasetName

4.1 -X- _ O
Datasets -X- _ O

4 -X- _ O
Experimental -X- _ O
Setup -X- _ O

We -X- _ O
get -X- _ O
the -X- _ O
final -X- _ O
probability -X- _ O
by -X- _ O
normalize -X- _ O
all -X- _ O
question-choice -X- _ O
pairs -X- _ O
with -X- _ O
softmax. -X- _ O

where -X- _ O
s -X- _ O
is -X- _ O
the -X- _ O
mean -X- _ O
pooling -X- _ O
of -X- _ O
QN -X- _ O
, -X- _ O
and -X- _ O
g -X- _ O
is -X- _ O
the -X- _ O
attention-based -X- _ O
pooling -X- _ O
of -X- _ O
XN -X- _ O
. -X- _ O

We -X- _ O
compute -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
being -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
as: -X- _ O

After -X- _ O
N -X- _ O
layers -X- _ O
of -X- _ O
iteration, -X- _ O
we -X- _ O
finally -X- _ O
obtain -X- _ O
the -X- _ O
query -X- _ O
representation -X- _ O
QN -X- _ O
that -X- _ O
fuses -X- _ O
knowledge -X- _ O
information -X- _ O
and -X- _ O
the -X- _ O
graph -X- _ O
representation -X- _ O
XN -X- _ O
that -X- _ O
fuses -X- _ O
question -X- _ O
information. -X- _ O

3.6 -X- _ O
Answer -X- _ O
Prediction -X- _ O

Next, -X- _ O
the -X- _ O
subgraph -X- _ O
is -X- _ O
formed -X- _ O
by -X- _ O
pooling -X- _ O
out -X- _ O
the -X- _ O
less -X- _ O
essential -X- _ O
entity -X- _ O
nodes -X- _ O
as: -X- _ O

where -X- _ O
top-rank -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
that -X- _ O
returns -X- _ O
the -X- _ O
index -X- _ O
of -X- _ O
top -X- _ O
·idx -X- _ O
is -X- _ O
an -X- _ O
indexing -X- _ O
operation, -X- _ O
and -X- _ O
Zmask -X- _ O
is -X- _ O
corresponding -X- _ O
attention -X- _ O
mask. -X- _ O

K -X- _ O

We -X- _ O
choose -X- _ O
the -X- _ O
top -X- _ O
nodes -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
LM-to-KG -X- _ O
attention: -X- _ O

We -X- _ O
define -X- _ O
a -X- _ O
hyperparameter, -X- _ O
the -X- _ O
Retention -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
(0, -X- _ B-HyperparameterValue
1], -X- _ B-HyperparameterValue
which -X- _ O
determines -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
nodes -X- _ O
K -X- _ B-HyperparameterName
to -X- _ O
be -X- _ O
retained. -X- _ O

Inspired -X- _ O
by -X- _ O
SAGPool -X- _ O
(Lee -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
under -X- _ O
the -X- _ O
guidance -X- _ O
of -X- _ O
query, -X- _ O
we -X- _ O
retain -X- _ O
relevant -X- _ O
nodes -X- _ O
and -X- _ O
cut -X- _ O
out -X- _ O
irrelevant -X- _ O
nodes -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
LM-to-KG -X- _ O
attention. -X- _ O

In -X- _ O
Equation -X- _ O
10, -X- _ O
the -X- _ O
LM-to-KG -X- _ O
attention -X- _ O
value -X- _ O
implies -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
different -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
subgraph -X- _ O
for -X- _ O
question -X- _ B-TaskName
answering. -X- _ I-TaskName

ql -X- _ O
i} -X- _ O
{ -X- _ O

M -X- _ O
i=1 -X- _ O
will -X- _ O
be -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
l-th -X- _ O
stacked -X- _ O
JointLK -X- _ B-MethodName
layer -X- _ O
of -X- _ O
to -X- _ O
continue -X- _ O
participating -X- _ O
in -X- _ O
joint -X- _ O
reasoning, -X- _ O
and -X- _ O
the -X- _ O
V -X- _ O
updated -X- _ O
KG -X- _ O
representation -X- _ O
¯Xl -X- _ O
= -X- _ O
¯xl -X- _ O
i=1 -X- _ O
will -X- _ O
be -X- _ O
| -X- _ O
i} -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
module -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
JointLK -X- _ B-MethodName
layer -X- _ O
for -X- _ O
pruning. -X- _ O

The -X- _ O
attended -X- _ O
features -X- _ O
are -X- _ O
fused -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
modality -X- _ O
by -X- _ O
concatenation -X- _ O
and -X- _ O
then -X- _ O
compressed -X- _ O
to -X- _ O
low-dimensional -X- _ O
space -X- _ O
by: -X- _ O

3.4 -X- _ O
e -X- _ O
To -X- _ O
reduce -X- _ O
the -X- _ O
gap -X- _ O
of -X- _ O
query -X- _ O
and -X- _ O
knowledge -X- _ O
graph -X- _ O
features, -X- _ O
we -X- _ O
fuse -X- _ O
them -X- _ O
in -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
module -X- _ O
by -X- _ O
the -X- _ O
dense -X- _ O
bidirectional -X- _ O
attention -X- _ O
mechanism -X- _ O
that -X- _ O
connects -X- _ O
two -X- _ O
encoding -X- _ O
layers -X- _ O
of -X- _ O
query -X- _ O
and -X- _ O

The -X- _ O
following -X- _ O
joint -X- _ O
reasoning -X- _ O
module -X- _ O
will -X- _ O
further -X- _ O
fuse -X- _ O
i -X- _ O
and -X- _ O
ql -X- _ O
xl -X- _ O
to -X- _ O
obtain -X- _ O
their -X- _ O
updated -X- _ O
representations. -X- _ O

ψ(eji, -X- _ O
uj, -X- _ O
ui) -X- _ O
is -X- _ O
the -X- _ O
relation -X- _ O
feature -X- _ O
vector, -X- _ O
where -X- _ O
eji -X- _ O
is -X- _ O
a -X- _ O
one-hot -X- _ O
vector -X- _ O
denoting -X- _ O
the -X- _ O
relation -X- _ O
type -X- _ O
of -X- _ O
the -X- _ O
edge -X- _ O
(j, -X- _ O
i) -X- _ O
and -X- _ O
uj, -X- _ O
ui -X- _ O
are -X- _ O
one-hot -X- _ O
vectors -X- _ O
denoting -X- _ O
the -X- _ O
node -X- _ O
types -X- _ O
of -X- _ O
j -X- _ O
and -X- _ O
i. -X- _ O

D -X- _ O
are -X- _ O
where -X- _ O
matrices -X- _ O
Wq, -X- _ O
Wk, -X- _ O
Wv, -X- _ O
Wo -X- _ O
∈ -X- _ O
trainable -X- _ O
parameters, -X- _ O
Ni -X- _ O
is -X- _ O
the -X- _ O
neighbor -X- _ O
of -X- _ O
node -X- _ O
i. -X- _ O
rji -X- _ O
= -X- _ O

The -X- _ O
attended -X- _ O
representations -X- _ O
are -X- _ O
computed -X- _ O
as -X- _ O
follows: -X- _ O

and -X- _ O
also -X- _ O
normalize -X- _ O
Sl -X- _ O
ij -X- _ O
in -X- _ O
column-wise -X- _ O
to -X- _ O
derive -X- _ O
LM-to-KG -X- _ O
attention -X- _ O
maps -X- _ O
on -X- _ O
entities -X- _ O
conditioned -X- _ O
by -X- _ O
each -X- _ O
query -X- _ O
token -X- _ O
as -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
inputs -X- _ O
to -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
module -X- _ O
in -X- _ O
the -X- _ O
l-st -X- _ O
fusion -X- _ O
layer -X- _ O
by -X- _ O
V -X- _ O
1 -X- _ O
i=1. -X- _ O

The -X- _ O
module -X- _ O
takes -X- _ O
the -X- _ O
query -X- _ O
and -X- _ O
KG -X- _ O
representations -X- _ O
Q -X- _ O
and -X- _ O
X -X- _ O
as -X- _ O
inputs -X- _ O
and -X- _ O
then -X- _ O
outputs -X- _ O
their -X- _ O
updated -X- _ O
versions. -X- _ O

knowledge -X- _ O
graph -X- _ O
and -X- _ O
captures -X- _ O
the -X- _ O
fine-grained -X- _ O
interplay -X- _ O
between -X- _ O
them. -X- _ O

For -X- _ O
brevity, -X- _ O
we -X- _ O
formulate -X- _ O
the -X- _ O
entire -X- _ O
computation -X- _ O
in -X- _ O
one -X- _ O
layer -X- _ O
as: -X- _ O

Then, -X- _ O
we -X- _ O
apply -X- _ O
GNN -X- _ O
Layer -X- _ O
to -X- _ O
update -X- _ O
node -X- _ O
representation -X- _ O
through -X- _ O
iterative -X- _ O
message -X- _ O
passing -X- _ O
between -X- _ O
neighbors -X- _ O
on -X- _ O
the -X- _ O
graph, -X- _ O
while -X- _ O
GNN -X- _ O
is -X- _ O
built -X- _ O
on -X- _ O
the -X- _ O
RGAT -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2020a) -X- _ O
and -X- _ O
is -X- _ O
a -X- _ O
simplification -X- _ O
of -X- _ O
Yasunaga -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

First, -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
BERT -X- _ O
model -X- _ O
with -X- _ O
average -X- _ O
pooling -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
initial -X- _ O
repRD. -X- _ O

After -X- _ O
obtaining -X- _ O
token -X- _ O
representations -X- _ O
by -X- _ O
the -X- _ O
query -X- _ O
encoder, -X- _ O
we -X- _ O
further -X- _ O
model -X- _ O
the -X- _ O
subgraph -X- _ O
to -X- _ O
obtain -X- _ O
entity -X- _ O
representations. -X- _ O

M -X- _ O
i=1 -X- _ O
∈ -X- _ O

The -X- _ O
representations -X- _ O
of -X- _ O
tokens -X- _ O
Q0 -X- _ O
= -X- _ O
RD -X- _ O
will -X- _ O
be -X- _ O
provided -X- _ O
to -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
module -X- _ O
for -X- _ O
further -X- _ O
interaction -X- _ O
with -X- _ O
the -X- _ O
graph -X- _ O
entities -X- _ O
representations. -X- _ O

RD -X- _ O
is -X- _ O
a -X- _ O
linear -X- _ O
transformation, -X- _ O
where -X- _ O
fs -X- _ O
: -X- _ O
RT -X- _ O
and -X- _ O
σ -X- _ O
is -X- _ O
the -X- _ O
activation -X- _ O
function. -X- _ O

Then -X- _ O
we -X- _ O
feed -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
tokens -X- _ O
into -X- _ O
a -X- _ O
non-linear -X- _ O
layer -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
text -X- _ O
representation -X- _ O
space -X- _ O
is -X- _ O
aligned -X- _ O
to -X- _ O
the -X- _ O
entity -X- _ O
representation -X- _ O
space: -X- _ O

We -X- _ O
follow -X- _ O
baselines -X- _ O
to -X- _ O
use -X- _ O
pre-trained -X- _ O
language -X- _ O
M -X- _ O
wi} -X- _ O
i=1 -X- _ O
(question -X- _ O
and -X- _ O
models -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
query -X- _ O
{ -X- _ O
M -X- _ O
i=1: -X- _ O
choice) -X- _ O
into -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
vectors -X- _ O

We -X- _ O
describe -X- _ O
the -X- _ O
detailed -X- _ O
extraction -X- _ O
process -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O

E -X- _ O
V -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
edges -X- _ O
that -X- _ O
connect -X- _ O
nodes -X- _ O
in -X- _ O
V -X- _ O
, -X- _ O
where -X- _ O
R -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
relations -X- _ O
types. -X- _ O

Here -X- _ O
V -X- _ O
is -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
entity -X- _ O
nodes -X- _ O
retrieved -X- _ O
from -X- _ O
the -X- _ O
external -X- _ O
KG. -X- _ O

(V, -X- _ O
R) -X- _ O
with -X- _ O
the -X- _ O
guidance -X- _ O
of -X- _ O
question -X- _ O
and -X- _ O
choice. -X- _ O

We -X- _ O
extract -X- _ O
from -X- _ O
the -X- _ O
external -X- _ O
KG -X- _ O
a -X- _ O
subgraph -X- _ O
g -X- _ O
= -X- _ O

In -X- _ O
general, -X- _ O
questions -X- _ O
do -X- _ O
not -X- _ O
contain -X- _ O
any -X- _ O
reference -X- _ O
to -X- _ O
answer -X- _ O
choices, -X- _ O
so -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
graph -X- _ O
provides -X- _ O
the -X- _ O
necessary -X- _ O
background -X- _ O
knowledge. -X- _ O

Given -X- _ O
a -X- _ O
commonsense -X- _ O
question -X- _ O
q -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
answer -X- _ O
choices -X- _ O
a1, -X- _ O
a2, -X- _ O
..., -X- _ O
an} -X- _ O
, -X- _ O
our -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
plausi{ -X- _ O
bility -X- _ O
score -X- _ O
between -X- _ O
q -X- _ O
and -X- _ O
each -X- _ O
answer -X- _ O
choice -X- _ O
a -X- _ O
then -X- _ O
select -X- _ O
the -X- _ O
answer -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
plausibility -X- _ O
score. -X- _ O

The -X- _ O
CSQA -X- _ B-TaskName
task -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
a -X- _ O
multiple-choice -X- _ O
problem -X- _ O
with -X- _ O
some -X- _ O
answer -X- _ O
choices. -X- _ O

3.1 -X- _ O
Task -X- _ O
Definition -X- _ O

After -X- _ O
N -X- _ B-HyperparameterName
layers -X- _ O
of -X- _ O
iteration, -X- _ O
the -X- _ O
query -X- _ O
representation -X- _ O
and -X- _ O
the -X- _ O
trimmed -X- _ O
graph -X- _ O
representation -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
answer -X- _ O
(§ -X- _ O
3.6). -X- _ O

weights -X- _ O
and -X- _ O
finally -X- _ O
retains -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
nodes -X- _ O
(§ -X- _ O
3.5). -X- _ O

The -X- _ O
LM-to-KG -X- _ O
attention -X- _ O
weights -X- _ O
generated -X- _ O
in -X- _ O
reasoning -X- _ O
represents -X- _ O
the -X- _ O
global -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
node -X- _ O
in -X- _ O
the -X- _ O
graph, -X- _ O
so -X- _ O
the -X- _ O
dynamic -X- _ O
pruning -X- _ O
module -X- _ O
prunes -X- _ O
the -X- _ O
graph -X- _ O
layer -X- _ O
by -X- _ O
layer -X- _ O
according -X- _ O
to -X- _ O
this -X- _ O

The -X- _ O
Joint -X- _ O
Reasoning -X- _ O
Module -X- _ O
receives -X- _ O
these -X- _ O
two -X- _ O
modalities’ -X- _ O
representations -X- _ O
and -X- _ O
then -X- _ O
apply -X- _ O
dense -X- _ O
bidirectional -X- _ O
attention -X- _ O
to -X- _ O
make -X- _ O
information -X- _ O
fusion -X- _ O
and -X- _ O
representation -X- _ O
update -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
and -X- _ O
node -X- _ O
(§ -X- _ O
3.4). -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
query -X- _ O
representation -X- _ O
(§ -X- _ O
3.2), -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
GNN -X- _ O
layer -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
graph -X- _ O
representation -X- _ O
(§ -X- _ O
3.3). -X- _ O

The -X- _ O
model -X- _ O
is -X- _ O
mainly -X- _ O
composed -X- _ O
of -X- _ O
four -X- _ O
parts: -X- _ O
query -X- _ O
encoder, -X- _ O
GNN -X- _ O
layer, -X- _ O
joint -X- _ O
reasoning -X- _ O
module -X- _ O
and -X- _ O
dynamic -X- _ O
pruning -X- _ O
module, -X- _ O
of -X- _ O
which -X- _ O
the -X- _ O
latter -X- _ O
three -X- _ O
form -X- _ O
a -X- _ O
stack -X- _ O
of -X- _ O
N -X- _ B-HyperparameterName
identical -X- _ O
layers. -X- _ O

JointLK -X- _ B-MethodName
takes -X- _ O
the -X- _ O
query -X- _ O
and -X- _ O
the -X- _ O
retrieved -X- _ O
knowledge -X- _ O
subgraph -X- _ O
as -X- _ O
input, -X- _ O
and -X- _ O
outputs -X- _ O
a -X- _ O
real -X- _ O
value -X- _ O
as -X- _ O
the -X- _ O
correctness -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
answer. -X- _ O

The -X- _ O
model -X- _ O
framework -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
task -X- _ O
definition -X- _ O
(§ -X- _ O
3.1) -X- _ O
and -X- _ O
our -X- _ O
JointLK -X- _ B-MethodName
model. -X- _ O

3 -X- _ O
Methodology -X- _ O

Furthermore, -X- _ O
we -X- _ O
gradually -X- _ O
prune -X- _ O
the -X- _ O
KG -X- _ O
size -X- _ O
in -X- _ O
each -X- _ O
stacked -X- _ O
model -X- _ O
layer -X- _ O
under -X- _ O
the -X- _ O
guidance -X- _ O
of -X- _ O
attention -X- _ O
weights -X- _ O
generated -X- _ O
in -X- _ O
the -X- _ O
interactions, -X- _ O
making -X- _ O
the -X- _ O
reasoning -X- _ O
path -X- _ O
transparent -X- _ O
and -X- _ O
interpretable. -X- _ O

grained -X- _ O
interaction -X- _ O
between -X- _ O
any -X- _ O
token -X- _ O
in -X- _ O
question -X- _ O
and -X- _ O
any -X- _ O
entity -X- _ O
in -X- _ O
KG -X- _ O
through -X- _ O
dense -X- _ O
bidirectional -X- _ O
attention, -X- _ O
and -X- _ O
perform -X- _ O
multi-step -X- _ O
joint -X- _ O
reasoning -X- _ O
by -X- _ O
stacking -X- _ O
several -X- _ O
interaction -X- _ O
layers. -X- _ O

JointLK -X- _ B-MethodName
mainly -X- _ O
consists -X- _ O
of -X- _ O
four -X- _ O
modules -X- _ O
the -X- _ O
Query -X- _ O
Encoder, -X- _ O
the -X- _ O
Graph -X- _ O
Layer, -X- _ O
the -X- _ O
Joint -X- _ O
Reasoning -X- _ O
Module -X- _ O
and -X- _ O
the -X- _ O
Dynamic -X- _ O
Pruning -X- _ O
Module, -X- _ O
of -X- _ O
which -X- _ O
the -X- _ O
latter -X- _ O
three -X- _ O
form -X- _ O
a -X- _ O
stack -X- _ O
of -X- _ O
N -X- _ B-HyperparameterName
identical -X- _ O
layers. -X- _ O

Compared -X- _ O
with -X- _ O
prior -X- _ O
works, -X- _ O
we -X- _ O
retain -X- _ O
the -X- _ O
individual -X- _ O
structure -X- _ O
of -X- _ O
both -X- _ O
modalities, -X- _ O
consider -X- _ O
fine -X- _ O

However, -X- _ O
it -X- _ O
pools -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
context -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
node, -X- _ O
which -X- _ O
limits -X- _ O
the -X- _ O
updating -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
representation -X- _ O
and -X- _ O
fine-grained -X- _ O
interaction -X- _ O
between -X- _ O
LM -X- _ O
and -X- _ O
GNN. -X- _ O

Recently, -X- _ O
QA-GNN -X- _ O
(Yasunaga -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
explicitly -X- _ O
views -X- _ O
the -X- _ O
QA -X- _ O
context -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
node, -X- _ O
connects -X- _ O
it -X- _ O
and -X- _ O
KG -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
joint -X- _ O
graph, -X- _ O
and -X- _ O
mutually -X- _ O
updates -X- _ O
their -X- _ O
representations -X- _ O
through -X- _ O
graphbased -X- _ O
message -X- _ O
passing. -X- _ O

Although -X- _ O
this -X- _ O
method -X- _ O
can -X- _ O
retain -X- _ O
the -X- _ O
original -X- _ O
information -X- _ O
of -X- _ O
question -X- _ O
context -X- _ O
and -X- _ O
KGs, -X- _ O
the -X- _ O
limited -X- _ O
interaction -X- _ O
will -X- _ O
affect -X- _ O
the -X- _ O
flow -X- _ O
of -X- _ O
information -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
modalities, -X- _ O
so -X- _ O
we -X- _ O
mainly -X- _ O
improve -X- _ O
on -X- _ O
this -X- _ O
point. -X- _ O

Other -X- _ O
works -X- _ O
(Lin -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Feng -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Yan -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
use -X- _ O
LM -X- _ O
and -X- _ O
GNN -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
separately, -X- _ O
and -X- _ O
perform -X- _ O
shallow -X- _ O
interactions -X- _ O
in -X- _ O
the -X- _ O
latter -X- _ O
model -X- _ O
stage, -X- _ O
such -X- _ O
as -X- _ O
attentive -X- _ O
pooling -X- _ O
or -X- _ O
simple -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
modal -X- _ O
representations. -X- _ O

However, -X- _ O
the -X- _ O
original -X- _ O
structural/textual -X- _ O
information -X- _ O
will -X- _ O
inevitably -X- _ O
be -X- _ O
lost -X- _ O
during -X- _ O
the -X- _ O
conversion -X- _ O
process. -X- _ O

Some -X- _ O
works -X- _ O
(Lv -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Bian -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Xu -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
unify -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
during -X- _ O
model -X- _ O
input, -X- _ O
such -X- _ O
as -X- _ O
transforming -X- _ O
structured -X- _ O
knowledge -X- _ O
into -X- _ O
plain -X- _ O
text -X- _ O
through -X- _ O
templates -X- _ O
or -X- _ O
transforming -X- _ O
question -X- _ O
context -X- _ O
into -X- _ O
structured -X- _ O
graphs. -X- _ O

Due -X- _ O
to -X- _ O
the -X- _ O
heterogeneity -X- _ O
between -X- _ O
structured -X- _ O
knowledge -X- _ O
and -X- _ O
unstructured -X- _ O
text -X- _ O
questions, -X- _ O
there -X- _ O
are -X- _ O
currently -X- _ O
two -X- _ O
main -X- _ O
research -X- _ O
methods. -X- _ O

Therefore, -X- _ O
many -X- _ O
works -X- _ O
obtain -X- _ O
the -X- _ O
required -X- _ O
knowledge -X- _ O
from -X- _ O
external -X- _ O
sources -X- _ O
(e.g., -X- _ O
KGs, -X- _ O
corpus) -X- _ O
to -X- _ O
augment -X- _ O
CSQA -X- _ B-TaskName
models. -X- _ O

Commonsense -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
is -X- _ O
challenging -X- _ O
because -X- _ O
the -X- _ O
required -X- _ O
commonsense -X- _ O
knowledge -X- _ O
is -X- _ O
rarely -X- _ O
given -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
questions -X- _ O
and -X- _ O
answer -X- _ O
choices -X- _ O
or -X- _ O
encoded -X- _ O
in -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
pre-trained -X- _ O
LMs. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

Furthermore, -X- _ O
through -X- _ O
the -X- _ O
multi-layer -X- _ O
fusion -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
modalities, -X- _ O
JointLK -X- _ B-MethodName
exhibits -X- _ O
strong -X- _ O
performance -X- _ O
over -X- _ O
previous -X- _ O
state-of-the-art -X- _ O
LM+KG -X- _ O
methods -X- _ O
in -X- _ O
performing -X- _ O
complex -X- _ O
reasoning, -X- _ O
such -X- _ O
as -X- _ O
solving -X- _ O
questions -X- _ O
with -X- _ O
negation -X- _ O
and -X- _ O
complex -X- _ O
questions -X- _ O
with -X- _ O
more -X- _ O
entities. -X- _ O

• -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
JointLK -X- _ B-MethodName
is -X- _ O
superior -X- _ O
to -X- _ O
current -X- _ O
LM+KG -X- _ O
methods, -X- _ O
and -X- _ O
the -X- _ O
refined -X- _ O
evidence -X- _ O
is -X- _ O
interpretable. -X- _ O

nodes -X- _ O
at -X- _ O
each -X- _ O
JointLK -X- _ O
layer -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
reasons -X- _ O
correctly -X- _ O
with -X- _ O
complete -X- _ O
and -X- _ O
appropriate -X- _ O
evidence. -X- _ O

It -X- _ O
uses -X- _ O
dense -X- _ O
bidirectional -X- _ O
attention -X- _ O
to -X- _ O
simultaneously -X- _ O
update -X- _ O
query-aware -X- _ O
knowledge -X- _ O
graph -X- _ O
representation -X- _ O
and -X- _ O
knowledgeaware -X- _ O
query -X- _ O
representation, -X- _ O
bridging -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
information -X- _ O
modalities. -X- _ O

We -X- _ O
propose -X- _ O
JointLK, -X- _ B-MethodName
a -X- _ O
novel -X- _ O
model -X- _ O
that -X- _ O
supports -X- _ O
multi-step -X- _ O
joint -X- _ O
reasoning -X- _ O
between -X- _ O
LM -X- _ O
and -X- _ O
KG. -X- _ O

• -X- _ O

In -X- _ O
summary, -X- _ O
our -X- _ O
contributions -X- _ O
are -X- _ O
three-fold: -X- _ O

Multiple -X- _ O
JointLK -X- _ B-MethodName
layers -X- _ O
are -X- _ O
stacked -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
hierarchy -X- _ O
that -X- _ O
supports -X- _ O
multi-step -X- _ O
interactions -X- _ O
and -X- _ O
recursive -X- _ O
pruning. -X- _ O

Guided -X- _ O
by -X- _ O
the -X- _ O
attention -X- _ O
generated -X- _ O
in -X- _ O
the -X- _ O
interaction -X- _ O
process, -X- _ O
the -X- _ O
dynamic -X- _ O
pruning -X- _ O
module -X- _ O
deletes -X- _ O
irrelevant -X- _ O
nodes -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
model -X- _ O
reason -X- _ O
along -X- _ O
the -X- _ O
correct -X- _ O
knowledge -X- _ O
path. -X- _ O

Then -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
joint -X- _ O
reasoning -X- _ O
module -X- _ O
to -X- _ O
generate -X- _ O
fine-grained -X- _ O
bidirectional -X- _ O
attention -X- _ O
maps -X- _ O
between -X- _ O
each -X- _ O
question -X- _ O
token -X- _ O
and -X- _ O
each -X- _ O
KG -X- _ O
node -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
each -X- _ O
modality -X- _ O
to -X- _ O
the -X- _ O
other. -X- _ O

Specifically, -X- _ O
given -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
retrieved -X- _ O
subgraphs, -X- _ O
JointLK -X- _ B-MethodName
first -X- _ O
obtain -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
by -X- _ O
using -X- _ O
an -X- _ O
LM -X- _ O
encoder -X- _ O
and -X- _ O
a -X- _ O
GNN -X- _ O
encoder -X- _ O
respectively. -X- _ O

Based -X- _ O
on -X- _ O
the -X- _ O
above -X- _ O
consideration, -X- _ O
we -X- _ O
propose -X- _ O
JointLK, -X- _ B-MethodName
a -X- _ O
model -X- _ O
that -X- _ O
performs -X- _ O
the -X- _ O
fine-grained -X- _ O
modal -X- _ O
fusion -X- _ O
and -X- _ O
multi-layer -X- _ O
joint -X- _ O
reasoning -X- _ O
between -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
(see -X- _ O
Figure -X- _ O
2). -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
limited -X- _ O
interaction -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
is -X- _ O
the -X- _ O
main -X- _ O
bottleneck -X- _ O
that -X- _ O
may -X- _ O
prevent -X- _ O
the -X- _ O
model -X- _ O
from -X- _ O
understanding -X- _ O
the -X- _ O
complex -X- _ O
question-knowledge -X- _ O
relations -X- _ O
necessary -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
correctly. -X- _ O

Specifically, -X- _ O
existing -X- _ O
LM+KG -X- _ O
methods -X- _ O
(Lin -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Feng -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
model -X- _ O
question -X- _ O
context -X- _ O
and -X- _ O
knowledge -X- _ O
subgraphs -X- _ O
in -X- _ O
isolation -X- _ O
by -X- _ O
LMs -X- _ O
and -X- _ O
GNNs, -X- _ O
and -X- _ O
perform -X- _ O
only -X- _ O
one -X- _ O
interaction -X- _ O
in -X- _ O
a -X- _ O
shallow -X- _ O
manner -X- _ O
to -X- _ O
fuse -X- _ O
their -X- _ O
representations -X- _ O
at -X- _ O
the -X- _ O
output -X- _ O
for -X- _ O
prediction. -X- _ O

Second, -X- _ O
there -X- _ O
are -X- _ O
limited -X- _ O
interactions -X- _ O
between -X- _ O
language -X- _ O
representation -X- _ O
and -X- _ O
knowledge -X- _ O
graph -X- _ O
representation. -X- _ O

As -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
some -X- _ O
graph -X- _ O
nodes -X- _ O
such -X- _ O
as -X- _ O
“wood”, -X- _ O
“burn”, -X- _ O
and -X- _ O
“gas”, -X- _ O
although -X- _ O
related -X- _ O
to -X- _ O
some -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
questions -X- _ O
and -X- _ O
choice, -X- _ O
can -X- _ O
mislead -X- _ O
the -X- _ O
global -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
question. -X- _ O

simple -X- _ O
string -X- _ O
matching -X- _ O
or -X- _ O
semantic -X- _ O
matching, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
retrieve -X- _ O
sufficient -X- _ O
relevant -X- _ O
knowledge, -X- _ O
noise -X- _ O
knowledge -X- _ O
graph -X- _ O
nodes -X- _ O
will -X- _ O
inevitably -X- _ O
be -X- _ O
included -X- _ O
(Lin -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Yasunaga -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Whether -X- _ O
through -X- _ O

First, -X- _ O
the -X- _ O
retrieved -X- _ O
knowledge -X- _ O
subgraph -X- _ O
contains -X- _ O
many -X- _ O
noisy -X- _ O
nodes. -X- _ O

However, -X- _ O
these -X- _ O
approaches -X- _ O
have -X- _ O
two -X- _ O
main -X- _ O
issues. -X- _ O

Second, -X- _ O
the -X- _ O
retrieved -X- _ O
subgraphs -X- _ O
are -X- _ O
modeled -X- _ O
by -X- _ O
a -X- _ O
well-designed -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
module -X- _ O
(Lin -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Feng -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Yasunaga -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
to -X- _ O
perform -X- _ O
reasoning -X- _ O
over -X- _ O
knowledge -X- _ O
graphs. -X- _ O

First, -X- _ O
the -X- _ O
knowledge -X- _ O
subgraphs -X- _ O
or -X- _ O
paths -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
are -X- _ O
retrieved -X- _ O
by -X- _ O
string -X- _ O
matching -X- _ O
or -X- _ O
semantic -X- _ O
similarity; -X- _ O
such -X- _ O
retrieved -X- _ O
structured -X- _ O
information -X- _ O
indicates -X- _ O
the -X- _ O
relation -X- _ O
between -X- _ O
concepts -X- _ O
or -X- _ O
implies -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
multi-hop -X- _ O
reasoning. -X- _ O

Related -X- _ O
methods -X- _ O
usually -X- _ O
follow -X- _ O
a -X- _ O
retrieval-and-modeling -X- _ O
paradigm. -X- _ O

An -X- _ O
extensive -X- _ O
research -X- _ O
path -X- _ O
is -X- _ O
to -X- _ O
elaborately -X- _ O
design -X- _ O
graph -X- _ O
neural -X- _ O
networks -X- _ O
(GNNs) -X- _ O
(Scarselli -X- _ O
et -X- _ O
al., -X- _ O
2008) -X- _ O
to -X- _ O
perform -X- _ O
reasoning -X- _ O
over -X- _ O
explicit -X- _ O
structural -X- _ O
common -X- _ O
sense -X- _ O
knowledge -X- _ O
from -X- _ O
external -X- _ O
knowledge -X- _ O
bases -X- _ O
(Vrandeˇci´c -X- _ O
and -X- _ O
Krötzsch, -X- _ O
2014; -X- _ O
Speer -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

knowledge -X- _ O
is -X- _ O
self-evident -X- _ O
to -X- _ O
humans -X- _ O
and -X- _ O
is -X- _ O
rarely -X- _ O
expressed -X- _ O
clearly -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
(Gunning, -X- _ O
2018), -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
difficult -X- _ O
for -X- _ O
LMs -X- _ O
to -X- _ O
learn -X- _ O
commonsense -X- _ O
knowledge -X- _ O
from -X- _ O
the -X- _ O
pre-training -X- _ O
text -X- _ O
corpus -X- _ O
alone. -X- _ O

Nevertheless, -X- _ O
commonsense -X- _ O

Recently, -X- _ O
large -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
(LMs) -X- _ O
have -X- _ O
achieved -X- _ O
remarkable -X- _ O
success -X- _ O
in -X- _ O
many -X- _ O
QA -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
appear -X- _ O
to -X- _ O
use -X- _ O
implicit -X- _ O
(factual) -X- _ O
knowledge -X- _ O
encoded -X- _ O
in -X- _ O
their -X- _ O
model -X- _ O
parameters -X- _ O
during -X- _ O
fine-tuning -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Raffel -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Commonsense -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
(CSQA) -X- _ B-TaskName
requires -X- _ O
systems -X- _ O
to -X- _ O
acquire -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
commonsense -X- _ O
knowledge -X- _ O
and -X- _ O
reasoning -X- _ O
skills, -X- _ O
which -X- _ O
is -X- _ O
normal -X- _ O
for -X- _ O
humans, -X- _ O
but -X- _ O
challenging -X- _ O
for -X- _ O
machines -X- _ O
(Talmor -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Introduction -X- _ O

We -X- _ O
evaluate -X- _ O
JointLK -X- _ B-MethodName
on -X- _ O
the -X- _ O
CommonsenseQA -X- _ B-DatasetName
and -X- _ O
OpenBookQA -X- _ B-DatasetName
datasets, -X- _ O
and -X- _ O
demonstrate -X- _ O
its -X- _ O
improvements -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
LM -X- _ O
and -X- _ O
LM+KG -X- _ O
models, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
its -X- _ O
capability -X- _ O
to -X- _ O
perform -X- _ O
interpretable -X- _ B-TaskName
reasoning1. -X- _ I-TaskName

Then, -X- _ O
the -X- _ O
dynamic -X- _ O
pruning -X- _ O
module -X- _ O
uses -X- _ O
the -X- _ O
attention -X- _ O
weights -X- _ O
generated -X- _ O
by -X- _ O
joint -X- _ O
reasoning -X- _ O
to -X- _ O
prune -X- _ O
irrelevant -X- _ O
KG -X- _ O
nodes -X- _ O
recursively. -X- _ O

Specifically, -X- _ O
JointLK -X- _ B-MethodName
performs -X- _ O
joint -X- _ O
reasoning -X- _ O
between -X- _ O
LM -X- _ O
and -X- _ O
GNN -X- _ O
through -X- _ O
a -X- _ O
novel -X- _ O
dense -X- _ O
bidirectional -X- _ O
attention -X- _ O
module, -X- _ O
in -X- _ O
which -X- _ O
each -X- _ O
question -X- _ O
token -X- _ O
attends -X- _ O
on -X- _ O
KG -X- _ O
nodes -X- _ O
and -X- _ O
each -X- _ O
KG -X- _ O
node -X- _ O
attends -X- _ O
on -X- _ O
question -X- _ O
tokens, -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
modal -X- _ O
representations -X- _ O
fuse -X- _ O
and -X- _ O
update -X- _ O
mutually -X- _ O
by -X- _ O
multi-step -X- _ O
interactions. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
model, -X- _ O
JointLK, -X- _ B-MethodName
which -X- _ O
solves -X- _ O
the -X- _ O
above -X- _ O
limitations -X- _ O
through -X- _ O
the -X- _ O
joint -X- _ O
reasoning -X- _ O
of -X- _ O
LM -X- _ O
and -X- _ O
GNN -X- _ O
and -X- _ O
the -X- _ O
dynamic -X- _ O
KGs -X- _ O
pruning -X- _ O
mechanism. -X- _ O

However, -X- _ O
they -X- _ O
ignore -X- _ O
(i) -X- _ O
the -X- _ O
effectively -X- _ O
fusing -X- _ O
and -X- _ O
reasoning -X- _ O
over -X- _ O
question -X- _ O
context -X- _ O
representations -X- _ O
and -X- _ O
the -X- _ O
KG -X- _ O
representations, -X- _ O
and -X- _ O
(ii) -X- _ O
automatically -X- _ O
selecting -X- _ O
relevant -X- _ O
nodes -X- _ O
from -X- _ O
the -X- _ O
noisy -X- _ O
KGs -X- _ O
during -X- _ O
reasoning. -X- _ O

Existing -X- _ O
KG-augmented -X- _ O
models -X- _ O
for -X- _ O
commonsense -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
primarily -X- _ O
focus -X- _ O
on -X- _ O
designing -X- _ O
elaborate -X- _ O
Graph -X- _ O
Neural -X- _ O
Networks -X- _ O
(GNNs) -X- _ O
to -X- _ O
model -X- _ O
knowledge -X- _ O
graphs -X- _ O
(KGs). -X- _ O

Abstract -X- _ O

JointLK: -X- _ B-MethodName
Joint -X- _ B-MethodName
Reasoning -X- _ I-MethodName
with -X- _ I-MethodName
Language -X- _ I-MethodName
Models -X- _ I-MethodName
and -X- _ I-MethodName
Knowledge -X- _ I-MethodName
Graphs -X- _ I-MethodName
for -X- _ O
Commonsense -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName

-DOCSTART- -X- O
We -X- _ O
ﬁnd -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
particularly -X- _ O
helpful -X- _ O
when -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
speech -X- _ O
data -X- _ O
is -X- _ O
extremely -X- _ O
small, -X- _ O
like -X- _ O
only -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
MT -X- _ O
pre-trained -X- _ O
Transformer -X- _ O
module -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
paper. -X- _ O

In -X- _ O
the -X- _ O
experiment, -X- _ O
we -X- _ O
reduce -X- _ O
the -X- _ O
labeled -X- _ O
ST -X- _ O
data -X- _ O
to -X- _ O
1, -X- _ O
10, -X- _ O
and -X- _ O
100 -X- _ O
hours, -X- _ O
corresponding -X- _ O
to -X- _ O
sentence -X- _ O
counts -X- _ O
of -X- _ O
about -X- _ O
500, -X- _ O
5k, -X- _ O
and -X- _ O
50k -X- _ O
sentences. -X- _ O

Here, -X- _ O
we -X- _ O
simulate -X- _ O
the -X- _ O
scenario -X- _ O
with -X- _ O
plenty -X- _ O
of -X- _ O
MT -X- _ O
and -X- _ O
speech -X- _ O
data -X- _ O
and -X- _ O
limited -X- _ O
ST -X- _ O
triple-labeled -X- _ O
data, -X- _ O
and -X- _ O
does -X- _ O
ConST -X- _ B-MethodName
have -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
low-resource -X- _ O
learning? -X- _ O

The -X- _ O
experiments -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
can -X- _ O
perform -X- _ O
well -X- _ O
by -X- _ O
introducing -X- _ O
external -X- _ O
MT -X- _ O
data -X- _ O
pre-training. -X- _ O

D -X- _ O
Data -X- _ O
Scale -X- _ O
for -X- _ O
Fine-tuning -X- _ O

In -X- _ O
general, -X- _ O
we -X- _ O
recommend -X- _ O
that -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
hyperparameter -X- _ O
takes -X- _ O
a -X- _ O
value -X- _ O
between -X- _ O
0.8 -X- _ B-HyperparameterValue
and -X- _ O
1.5. -X- _ B-HyperparameterValue

Therefore, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
loss -X- _ B-HyperparameterName
weight -X- _ I-HyperparameterName
to -X- _ O
1.0 -X- _ B-HyperparameterValue
uniformly -X- _ O
for -X- _ O
simplicity. -X- _ O

And -X- _ O
when -X- _ O
analyzing -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
data -X- _ O
augmentation -X- _ O
strategies -X- _ O
(Section -X- _ O
5.4), -X- _ O
since -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
combination -X- _ O
between -X- _ O
them, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
complicated. -X- _ O

Then, -X- _ O
the -X- _ O
best -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
is -X- _ O
LMLT -X- _ O
only -X- _ O
achieved -X- _ O
at -X- _ O
loss -X- _ O
weight -X- _ O
λ -X- _ B-HyperparameterName
= -X- _ O
1.5, -X- _ B-HyperparameterValue
corresponding -X- _ O
to -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

First, -X- _ O
all -X- _ O
objective -X- _ O
functions -X- _ O
containing -X- _ O
LCTR, -X- _ O
even -X- _ O
if -X- _ O
their -X- _ O
weights -X- _ O
λ -X- _ B-HyperparameterName
take -X- _ O
different -X- _ O
values, -X- _ O
are -X- _ O
apparently -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
with -X- _ O
LCTR. -X- _ O

Figure -X- _ O
7 -X- _ O
depicts -X- _ O
the -X- _ O
performances. -X- _ O

To -X- _ O
investigate -X- _ O
how -X- _ O
much -X- _ O
contrastive -X- _ O
term -X- _ O
the -X- _ O
contrastive -X- _ O
terms -X- _ O
affect -X- _ O
BLEU, -X- _ B-MetricName
we -X- _ O
ﬁx -X- _ O
its -X- _ O
temperature -X- _ B-HyperparameterName
τ -X- _ B-HyperparameterName
= -X- _ O
0.02, -X- _ B-HyperparameterValue
adjust -X- _ O
the -X- _ O
values -X- _ O
of -X- _ O
its -X- _ O
loss -X- _ O
weight -X- _ O
λ -X- _ B-HyperparameterName
from -X- _ O
0.1 -X- _ B-HyperparameterValue
to -X- _ O
2.0, -X- _ B-HyperparameterValue
performed -X- _ O
three -X- _ O
experiments -X- _ O
for -X- _ O
each -X- _ O
value, -X- _ O
and -X- _ O
test -X- _ O
the -X- _ O
average -X- _ O
BLEU -X- _ B-MetricName
on -X- _ O
En-De -X- _ B-DatasetName
tst-COMMON -X- _ I-DatasetName
set. -X- _ O

Inﬂuence -X- _ O
of -X- _ O
Contrastive -X- _ O
Loss -X- _ O
Weight -X- _ O
The -X- _ O
total -X- _ O
loss -X- _ O
we -X- _ O
optimize, -X- _ O
Eq.(1), -X- _ O
is -X- _ O
a -X- _ O
linear -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
multi-task -X- _ O
cross-entropy -X- _ O
losses -X- _ O
LMLT -X- _ O
and -X- _ O
the -X- _ O
LCTR. -X- _ O

Second, -X- _ O
the -X- _ O
multi-task -X- _ O
training -X- _ O
strategy -X- _ O
is -X- _ O
also -X- _ O
very -X- _ O
effective -X- _ O
in -X- _ O
improving -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
performance. -X- _ O

In -X- _ O
the -X- _ O
experiment, -X- _ O
we -X- _ O
use -X- _ O
τ -X- _ B-HyperparameterName
= -X- _ O
0.02. -X- _ B-HyperparameterValue

We -X- _ O
ﬁnd -X- _ O
that -X- _ O
(1) -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
the -X- _ O
temperature -X- _ B-HyperparameterName
does -X- _ O
not -X- _ O
drastically -X- _ O
affect -X- _ O
the -X- _ O
ﬁnal -X- _ O
BLEU -X- _ B-MetricName
score, -X- _ O
and -X- _ O
(2) -X- _ O
we -X- _ O
recommend -X- _ O
that -X- _ O
the -X- _ O
temperature -X- _ B-HyperparameterName
τ -X- _ B-HyperparameterName
be -X- _ O
set -X- _ O
between -X- _ O
0.02 -X- _ B-HyperparameterValue
and -X- _ O
0.05 -X- _ B-HyperparameterValue
to -X- _ O
ensure -X- _ O
a -X- _ O
relatively -X- _ O
good -X- _ O
ST -X- _ B-TaskName
performance. -X- _ O

We -X- _ O
choose -X- _ O
several -X- _ O
temperature -X- _ B-HyperparameterName
hyper-parameters -X- _ O
ranging -X- _ O
from -X- _ O
0.01 -X- _ B-HyperparameterValue
to -X- _ O
0.5, -X- _ B-HyperparameterValue
and -X- _ O
Figure -X- _ O
6 -X- _ O
shows -X- _ O
their -X- _ O
BLEUs -X- _ B-MetricName
on -X- _ O
the -X- _ O
test -X- _ O
and -X- _ O
dev -X- _ O
sets -X- _ O
. -X- _ O

A -X- _ O
high -X- _ O
temperature -X- _ B-HyperparameterName
helps -X- _ O
to -X- _ O
smooth -X- _ O
the -X- _ O
distribution, -X- _ O
making -X- _ O
it -X- _ O
more -X- _ O
difﬁcult -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
distinguish -X- _ O
between -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
samples -X- _ O
(corresponding -X- _ O
to -X- _ O
correct -X- _ O
transcriptions -X- _ O
and -X- _ O
other -X- _ O
transcriptions -X- _ O
in -X- _ O
this -X- _ O
work), -X- _ O
while -X- _ O
the -X- _ O
low -X- _ O
temperature -X- _ B-HyperparameterName
behaves -X- _ O
just -X- _ O
the -X- _ O
opposite. -X- _ O

Inﬂuence -X- _ O
of -X- _ O
Temperature -X- _ B-HyperparameterName
In -X- _ O
the -X- _ O
contrastive -X- _ O
loss, -X- _ O
the -X- _ O
temperature -X- _ B-HyperparameterName
hyper-parameter -X- _ O
is -X- _ O
provided -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
smoothness -X- _ O
of -X- _ O
the -X- _ O
distribution -X- _ O
normalized -X- _ O
by -X- _ O
softmax -X- _ O
operation. -X- _ O

C -X- _ O
The -X- _ O
Choice -X- _ O
for -X- _ O
Hyper-parameters -X- _ O

the -X- _ O
model -X- _ O
that -X- _ O
bridges -X- _ O
the -X- _ O
modality -X- _ O
representation -X- _ O
gap -X- _ O
by -X- _ O
minimizing -X- _ O
the -X- _ O
Jensen–Shannon -X- _ O
divergence -X- _ O
between -X- _ O
the -X- _ O
original -X- _ O
speech -X- _ O
representation -X- _ O
and -X- _ O
the -X- _ O
manifold -X- _ O
mix-up -X- _ O
representation. -X- _ O

• -X- _ O
STEMM -X- _ O
(Fang -X- _ O
et -X- _ O
al., -X- _ O
2022): -X- _ O

• -X- _ O
XSTNet -X- _ O
(Ye -X- _ O
et -X- _ O
al., -X- _ O
2021): -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
structure -X- _ O
as -X- _ O
ours, -X- _ O
and -X- _ O
adopted -X- _ O
a -X- _ O
multi-task -X- _ O
ﬁne-tuning -X- _ O
strategy. -X- _ O

• -X- _ O
Chimera-ST -X- _ O
(Han -X- _ O
et -X- _ O
al., -X- _ O
2021): -X- _ O
the -X- _ O
model -X- _ O
that -X- _ O
builds -X- _ O
a -X- _ O
shared -X- _ O
semantic -X- _ O
memory -X- _ O
for -X- _ O
both -X- _ O
audio -X- _ O
and -X- _ O
text -X- _ O
modalities. -X- _ O

(Ye -X- _ O
et -X- _ O
al., -X- _ O
2021): -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
structure -X- _ O
as -X- _ O
ours, -X- _ O
but -X- _ O
is -X- _ O
only -X- _ O
trained -X- _ O
on -X- _ O
<speech, -X- _ O
translation> -X- _ O
parallel -X- _ O
data. -X- _ O

We -X- _ O
also -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
baseline -X- _ O
models -X- _ O
that -X- _ O
have -X- _ O
pretrained -X- _ O
Wav2vec2.0 -X- _ O
as -X- _ O
a -X- _ O
module, -X- _ O
including: -X- _ O
• -X- _ O
W-Transf. -X- _ O

et -X- _ O
al., -X- _ O
2021), -X- _ O
TaskAware -X- _ B-MethodName
(Indurthi -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
and -X- _ O
STPT -X- _ B-MethodName
(Tang -X- _ O
et -X- _ O
al., -X- _ O
2022). -X- _ O

(Wang -X- _ O
et -X- _ O
al., -X- _ O
2020a), -X- _ O
NeurST -X- _ B-MethodName
(Zhao -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
Espnet -X- _ B-MethodName
ST -X- _ I-MethodName
(Inaguma -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
Dual-decoder -X- _ B-MethodName
Transformer -X- _ I-MethodName
(Le -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
SATE -X- _ B-MethodName
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
Speechformer -X- _ B-MethodName
(Papi -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
self -X- _ B-MethodName
training -X- _ I-MethodName
(Pino -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
mutual -X- _ B-MethodName
learning -X- _ I-MethodName
(Zhao -X- _ O
et -X- _ O
al., -X- _ O
2021b) -X- _ O
method, -X- _ O
STAST -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2020b), -X- _ O
bi-KD -X- _ B-MethodName
(Inaguma -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
MLT -X- _ B-MethodName
method -X- _ O
(Tang -X- _ O
et -X- _ O
al., -X- _ O
2021b), -X- _ O
Lightweight -X- _ B-MethodName
Adaptor -X- _ I-MethodName
(Le -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
JT-S-MT -X- _ B-MethodName
(Tang -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
FAT-ST -X- _ B-MethodName
(Zheng -X- _ O

In -X- _ O
Table -X- _ O
1, -X- _ O
we -X- _ O
compared -X- _ O
Baseline -X- _ O
Models -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
end-to-end -X- _ O
baseline -X- _ O
models -X- _ O
whose -X- _ O
audio -X- _ O
inputs -X- _ O
are -X- _ O
80-channel -X- _ O
log -X- _ O
Mel-ﬁlter -X- _ O
bank, -X- _ O
including: -X- _ O
FairseqST -X- _ B-MethodName

We -X- _ O
use -X- _ O
Fairseq -X- _ O
(Ott -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
as -X- _ O
the -X- _ O
code-base -X- _ O
for -X- _ O
our -X- _ O
implementation. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
in -X- _ O
8 -X- _ O
Nvidia -X- _ O
Tesla -X- _ O
V100 -X- _ O
GPUs -X- _ O
for -X- _ O
each -X- _ O
experiment. -X- _ O

For -X- _ O
decoding, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
and -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
0.7 -X- _ B-HyperparameterValue
for -X- _ O
German, -X- _ O
1.0 -X- _ B-HyperparameterValue
for -X- _ O
French, -X- _ O
and -X- _ O
0.4 -X- _ B-HyperparameterValue
for -X- _ O
Russian. -X- _ O

We -X- _ O
save -X- _ O
the -X- _ O
checkpoint -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
BLEU -X- _ B-MetricName
on -X- _ O
dev-set -X- _ O
and -X- _ O
average -X- _ O
the -X- _ O
last -X- _ O
10 -X- _ O
checkpoints. -X- _ O

The -X- _ O
hyper-parameters -X- _ O
for -X- _ O
different -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
are -X- _ O
as -X- _ O
follows: -X- _ O
for -X- _ O
masked -X- _ O
audio -X- _ O
span -X- _ O
strategy, -X- _ O
we -X- _ O
set -X- _ O
masking -X- _ B-HyperparameterName
probability -X- _ I-HyperparameterName
p -X- _ B-HyperparameterName
= -X- _ O
0.25 -X- _ B-HyperparameterValue
and -X- _ O
masking -X- _ B-HyperparameterName
span -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
M -X- _ B-HyperparameterName
= -X- _ O
3600 -X- _ B-HyperparameterValue
frames; -X- _ O
for -X- _ O
both -X- _ O
sequence -X- _ O
and -X- _ O
feature -X- _ O
cut-off, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
cut-off -X- _ B-HyperparameterName
dropout -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
as -X- _ O
0.1. -X- _ B-HyperparameterValue

For -X- _ O
robust -X- _ O
training, -X- _ O
we -X- _ O
set -X- _ O
label -X- _ B-HyperparameterName
smoothing -X- _ I-HyperparameterName
to -X- _ O
0.1, -X- _ B-HyperparameterValue
and -X- _ O
dropout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
0.1. -X- _ B-HyperparameterValue

In -X- _ O
the -X- _ O
pre-training -X- _ O
stage, -X- _ O
4 -X- _ O
and -X- _ O
warmup -X- _ O
4000 -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
= -X- _ O
7e− -X- _ B-HyperparameterValue
steps. -X- _ O

We -X- _ O
also -X- _ O
implement -X- _ O
the -X- _ O
expanded -X- _ O
setting -X- _ O
with -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
external -X- _ O
WMT -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
Transformer -X- _ O
module. -X- _ O

We -X- _ O
use -X- _ O
Adam -X- _ O
optimizer -X- _ O
(β1 -X- _ B-HyperparameterName
= -X- _ O
0.9, -X- _ B-HyperparameterValue
β2 -X- _ B-HyperparameterName
= -X- _ O
0.98) -X- _ B-HyperparameterValue
with -X- _ O
learn4 -X- _ O
and -X- _ O
warmup -X- _ O
25k -X- _ O
steps -X- _ O
during -X- _ O
the -X- _ O
ing -X- _ O
rate -X- _ O
= -X- _ O
1e− -X- _ O
ST -X- _ B-TaskName
training. -X- _ O

Table -X- _ O
8: -X- _ O
Statistics -X- _ O
of -X- _ O
all -X- _ O
datasets -X- _ O

Training -X- _ O
and -X- _ O
Implementation -X- _ O
Details -X- _ O

B -X- _ O
Experimental -X- _ O
Details -X- _ O

We -X- _ O
hope -X- _ O
that -X- _ O
our -X- _ O
work -X- _ O
achieves -X- _ O
better -X- _ O
results -X- _ O
using -X- _ O
more -X- _ O
data -X- _ O
(e.g. -X- _ O
raw -X- _ O
speech, -X- _ O
raw -X- _ O
text, -X- _ O
ASR, -X- _ O
MT -X- _ O
data) -X- _ O
in -X- _ O
the -X- _ O
future. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
improvement -X- _ O
brought -X- _ O
by -X- _ O
the -X- _ O
better -X- _ O
speech -X- _ O
representation -X- _ O
on -X- _ O
the -X- _ O
ST -X- _ B-TaskName
task, -X- _ O
and -X- _ O
obtained -X- _ O
good -X- _ O
results -X- _ O
with -X- _ O
hundreds -X- _ O
of -X- _ O
hours -X- _ O
of -X- _ O
speech -X- _ O
data. -X- _ O

The -X- _ O
shortcoming -X- _ O
of -X- _ O
this -X- _ O
model -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
still -X- _ O
needs -X- _ O
a -X- _ O
certain -X- _ O
amount -X- _ O
of -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
training, -X- _ O
especially -X- _ O
<speech,transcription> -X- _ O
to -X- _ O
learn -X- _ O
better -X- _ O
speech -X- _ O
representation, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
more -X- _ O
than -X- _ O
7, -X- _ O
000 -X- _ O
languages -X- _ O
and -X- _ O
dialects -X- _ O
in -X- _ O
the -X- _ O
world, -X- _ O
most -X- _ O
of -X- _ O
them -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
corresponding -X- _ O
translations -X- _ O
or -X- _ O
even -X- _ O
transcriptions, -X- _ O
our -X- _ O
method -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
in -X- _ O
untranscribed -X- _ O
scenarios. -X- _ O

In -X- _ O
real -X- _ O
scenarios, -X- _ O
for -X- _ O
example, -X- _ O
the -X- _ O
original -X- _ O
voice -X- _ O
is -X- _ O
noisier -X- _ O
and -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
speech -X- _ O
lengths -X- _ O
is -X- _ O
more -X- _ O
complex -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
public -X- _ O
dataset, -X- _ O
which -X- _ O
cannot -X- _ O
be -X- _ O
handled -X- _ O
by -X- _ O
an -X- _ O
end-toend -X- _ O
model -X- _ O
alone. -X- _ O

This -X- _ O
work -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
ST -X- _ B-TaskName
tasks -X- _ O
on -X- _ O
public -X- _ O
datasets -X- _ O
by -X- _ O
learning -X- _ O
speech -X- _ O
representations -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
text -X- _ O
representations, -X- _ O
but -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
far -X- _ O
from -X- _ O
being -X- _ O
achieved -X- _ O
for -X- _ O
industrialgrade -X- _ O
implementations. -X- _ O

9 -X- _ O
Broader -X- _ O
Impact -X- _ O

The -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
MuST-C -X- _ B-DatasetName
ST -X- _ B-TaskName
dataset -X- _ O
prove -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
method. -X- _ O

We -X- _ O
also -X- _ O
provide -X- _ O
feasible -X- _ O
hard -X- _ O
example -X- _ O
mining -X- _ O
methods -X- _ O
to -X- _ O
learn -X- _ O
robust -X- _ O
representations. -X- _ O

ST -X- _ B-TaskName
with -X- _ O
limited -X- _ O
data. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
ConST, -X- _ B-MethodName
a -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
contrastive -X- _ O
learning -X- _ O
framework -X- _ O
bridging -X- _ O
the -X- _ O
speech-text -X- _ O
representation -X- _ O
gap -X- _ O
and -X- _ O
facilitating -X- _ O
the -X- _ O

8 -X- _ O
Conclusion -X- _ O

We -X- _ O
believe -X- _ O
this -X- _ O
improvement -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
cross-modal -X- _ O
contrastive -X- _ O
learning. -X- _ O

Whereas -X- _ O
ConST -X- _ B-MethodName
successfully -X- _ O
conveys -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
“this -X- _ O
idea” -X- _ O
, -X- _ O
and -X- _ O
translates -X- _ O
more -X- _ O
accurately -X- _ O
than -X- _ O
XSTNet. -X- _ B-MethodName

For -X- _ O
the -X- _ O
second -X- _ O
case, -X- _ O
the -X- _ O
previous -X- _ O
end-to-end -X- _ O
XSTNet -X- _ B-MethodName
model -X- _ O
cannot -X- _ O
accurately -X- _ O
translate -X- _ O
the -X- _ O
phrase -X- _ O
“started -X- _ O
exploring -X- _ O
this -X- _ O
idea -X- _ O
of”, -X- _ O
which -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
cascaded -X- _ O
one. -X- _ O

For -X- _ O
this -X- _ O
ﬁrst -X- _ O
case, -X- _ O
the -X- _ O
cascaded -X- _ O
system -X- _ O
fails -X- _ O
to -X- _ O
give -X- _ O
a -X- _ O
right -X- _ O
translation -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
mis-punctuation -X- _ O
issue -X- _ O
(klingt -X- _ O
is -X- _ O
a -X- _ O
verb), -X- _ O
while -X- _ O
the -X- _ O
end-to-end -X- _ O
model, -X- _ O
XSTNet -X- _ B-MethodName
and -X- _ O
ConST -X- _ B-MethodName
translate -X- _ O
correctly. -X- _ O

Two -X- _ O
different -X- _ O
representations -X- _ O
are -X- _ O
used, -X- _ O
based -X- _ O
on -X- _ O
which, -X- _ O
ConST -X- _ B-MethodName
achieves -X- _ O
huge -X- _ O
accuracy -X- _ B-MetricName
improvements. -X- _ O

Ideally, -X- _ O
if -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
speech -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
tran -X- _ O

To -X- _ O
visualize -X- _ O
it, -X- _ O
we -X- _ O
plot -X- _ O
the -X- _ O
bivariate -X- _ O
kernel -X- _ O
density -X- _ O
estimation -X- _ O
(Parzen, -X- _ O
1962) -X- _ O
(KDE) -X- _ O
contour -X- _ O
of -X- _ O
their -X- _ O
dim-reduced -X- _ O
features, -X- _ O
where -X- _ O
T-SNE -X- _ O
(Van -X- _ O
der -X- _ O
Maaten -X- _ O
and -X- _ O
Hinton, -X- _ O
2008) -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
dimension -X- _ O
into -X- _ O
two -X- _ O
(Figure -X- _ O
5). -X- _ O

Speech-text -X- _ O
modality -X- _ O
gap -X- _ O
means -X- _ O
the -X- _ O
discrepancy -X- _ O
between -X- _ O
the -X- _ O
audio -X- _ O
representations -X- _ O
and -X- _ O
transcription -X- _ O
sentence -X- _ O
embeddings. -X- _ O

Does -X- _ O
the -X- _ O
speech-text -X- _ O
modality -X- _ O
gap -X- _ O
exist -X- _ O
without -X- _ O
explicitly -X- _ O
bridging -X- _ O
the -X- _ O
two? -X- _ O

6.1 -X- _ O
Visualization -X- _ O
of -X- _ O
Representation -X- _ O

Does -X- _ O
ConST -X- _ B-MethodName
reduce -X- _ O
the -X- _ O
representation -X- _ O
gap -X- _ O
between -X- _ O
speech -X- _ O
and -X- _ O
text? -X- _ O

As -X- _ O
mentioned -X- _ O
earlier, -X- _ O
the -X- _ O
existing -X- _ O
multi-task -X- _ O
training -X- _ O
models -X- _ O
cannot -X- _ O
address -X- _ O
the -X- _ O
speech-text -X- _ O
modality -X- _ O
gap. -X- _ O

6 -X- _ O
Why -X- _ O
does -X- _ O
cross-modal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
work? -X- _ O

On -X- _ O
the -X- _ O
contrary, -X- _ O
without -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
“original” -X- _ O
loss, -X- _ O
the -X- _ O
performance -X- _ O
with -X- _ O
both -X- _ O
sequence -X- _ O
cut-off -X- _ O
and -X- _ O
feature -X- _ O
cut-off -X- _ O
is -X- _ O
the -X- _ O
worst -X- _ O
in -X- _ O
Figure -X- _ O
4, -X- _ O
probably -X- _ O
because -X- _ O
too -X- _ O
much -X- _ O
information -X- _ O
is -X- _ O
lost -X- _ O
by -X- _ O
superimposing -X- _ O
the -X- _ O
two. -X- _ O

We -X- _ O
argue -X- _ O
that -X- _ O
we -X- _ O
need -X- _ O
the -X- _ O
original -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
examples -X- _ O
to -X- _ O
give -X- _ O
more -X- _ O
accurate -X- _ O
representations -X- _ O
(without -X- _ O
any -X- _ O
dropout) -X- _ O
for -X- _ O
contrastive -X- _ O
learning. -X- _ O

The -X- _ O
combinations -X- _ O
of -X- _ O
the -X- _ O
hard -X- _ O
examples -X- _ O
mining -X- _ O
methods -X- _ O
and -X- _ O
the -X- _ O
“original” -X- _ B-MethodName
have -X- _ O
relatively -X- _ O
better -X- _ O
performances. -X- _ O

Generally, -X- _ O
to -X- _ O
ﬁnd -X- _ O
the -X- _ O
best -X- _ O
model, -X- _ O
we -X- _ O
suggest -X- _ O
adopting -X- _ O
multiple -X- _ O
strategies -X- _ O
and -X- _ O
choosing -X- _ O
the -X- _ O
best -X- _ O
checkpoint -X- _ O
on -X- _ O
the -X- _ O
dev-set. -X- _ O

the -X- _ O
best -X- _ O
result -X- _ O
(28.3), -X- _ B-MetricValue
and -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
any -X- _ O
expanded -X- _ O
operations -X- _ O
(p -X- _ O
< -X- _ O
0.01). -X- _ O

Sentences -X- _ O
are -X- _ O
from -X- _ O
En-De -X- _ O
test -X- _ O
set. -X- _ O

T-SNE -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
reduce -X- _ O
into -X- _ O
2D. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
cascaded -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
previous -X- _ O
end-to-end -X- _ O
model, -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
use -X- _ O
several -X- _ O
cases -X- _ O
that -X- _ O
ConST -X- _ B-MethodName
generates. -X- _ O

7 -X- _ O
Case -X- _ O
Analysis -X- _ O

With -X- _ O
such -X- _ O
a -X- _ O
degree -X- _ O
of -X- _ O
crossmodal -X- _ O
alignment, -X- _ O
if -X- _ O
we -X- _ O
construct -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
with -X- _ O
semantic -X- _ O
representations, -X- _ O
its -X- _ O
gain -X- _ O
to -X- _ O
the -X- _ O
ST -X- _ B-TaskName
performance -X- _ O
turns -X- _ O
out -X- _ O
to -X- _ O
be -X- _ O
limited, -X- _ O
which -X- _ O
exactly -X- _ O
corroborates -X- _ O
the -X- _ O
ﬁndings -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
– -X- _ O
low-level -X- _ O
representations -X- _ O
are -X- _ O
preferred -X- _ O
in -X- _ O
the -X- _ O
crossmodal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning. -X- _ I-MethodName

We -X- _ O
believe -X- _ O
that -X- _ O
such -X- _ O
high -X- _ O
accuracy -X- _ O
is -X- _ O
automatically -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
triple-supervised -X- _ O
data -X- _ O
itself -X- _ O
under -X- _ O
the -X- _ O
multi-task -X- _ O
learning -X- _ O
framework. -X- _ O

In -X- _ O
addition, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
without -X- _ O
explicit -X- _ O
contrastive -X- _ O
modeling, -X- _ O
the -X- _ O
baseline -X- _ O
can -X- _ O
achieve -X- _ O
retrieval -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
more -X- _ O
than -X- _ O
94% -X- _ B-MetricValue
according -X- _ O
to -X- _ O
the -X- _ O
semantic -X- _ O
representations -X- _ O
outputted -X- _ O
from -X- _ O
the -X- _ O
Transformer -X- _ O
encoder. -X- _ O

When -X- _ O
retrieving -X- _ O
the -X- _ O
text -X- _ O
using -X- _ O
low-level -X- _ O
representations, -X- _ O
our -X- _ O
method -X- _ O
gains -X- _ O
a -X- _ O
substantial -X- _ O
79% -X- _ B-MetricValue
increase -X- _ O
over -X- _ O
the -X- _ O
baseline. -X- _ O

We -X- _ O
compare -X- _ O
ConST -X- _ B-MethodName
model -X- _ O
with -X- _ O
the -X- _ O
baseline -X- _ O
without -X- _ O
crossmodal -X- _ O
contrastive -X- _ O
learning -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
top-1 -X- _ O
retrieval -X- _ B-MetricName
accuracy -X- _ I-MetricName
using -X- _ O
(1) -X- _ O
the -X- _ O
low-level -X- _ O
representations -X- _ O
and -X- _ O
(2) -X- _ O
the -X- _ O
high-level -X- _ O
semantic -X- _ O
representations, -X- _ O
in -X- _ O
Table -X- _ O
7. -X- _ O

To -X- _ O
answer -X- _ O
this -X- _ O
question, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
retrieval -X- _ O
experiment, -X- _ O
i.e. -X- _ O
ﬁnding -X- _ O
the -X- _ O
nearest -X- _ O
(smallest -X- _ O
cosine -X- _ O
similarity) -X- _ O
transcript -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
speech -X- _ O
representation. -X- _ O

How -X- _ O
good -X- _ O
is -X- _ O
the -X- _ O
cross-modal -X- _ O
representation -X- _ O
space -X- _ O
learned -X- _ O
from -X- _ O
ConST? -X- _ B-MethodName

6.2 -X- _ O
Cross-modal -X- _ O
Retrieval -X- _ O

This -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
audio -X- _ O
representation -X- _ O
contains -X- _ O
more -X- _ O
linguistic -X- _ O
information -X- _ O
similar -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
textual -X- _ O
transcription, -X- _ O
which -X- _ O
is -X- _ O
more -X- _ O
advantageous -X- _ O
for -X- _ O
the -X- _ O
downstream -X- _ O
ST -X- _ O
generation -X- _ O
through -X- _ O
the -X- _ O
shared -X- _ O
Transformer -X- _ O
encoder -X- _ O
and -X- _ O
decoder. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5(b), -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
model -X- _ O
without -X- _ O
contrastive -X- _ O
learning, -X- _ O
ConST -X- _ B-MethodName
with -X- _ O
cross-modal -X- _ O
contrastive -X- _ O
learning -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
bring -X- _ O
representations -X- _ O
of -X- _ O
different -X- _ O
modalities -X- _ O
much -X- _ O
closer. -X- _ O

Does -X- _ O
ConST -X- _ B-MethodName
reduce -X- _ O
the -X- _ O
modality -X- _ O
gap? -X- _ O

It -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
representations -X- _ O
are -X- _ O
so -X- _ O
dissimilar -X- _ O
that -X- _ O
they -X- _ O
are -X- _ O
organically -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
clusters, -X- _ O
i.e. -X- _ O
speech-text -X- _ O
modality -X- _ O
gap -X- _ O
exists. -X- _ O

However, -X- _ O
Figure -X- _ O
5(a) -X- _ O
is -X- _ O
the -X- _ O
KDE -X- _ O
contour -X- _ O
of -X- _ O
the -X- _ O
multi-task -X- _ O
framework -X- _ O
without -X- _ O
any -X- _ O
explicit -X- _ O
modeling -X- _ O
to -X- _ O
bring -X- _ O
two -X- _ O
modalities -X- _ O
together -X- _ O
(Ye -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

script -X- _ O
are -X- _ O
similar, -X- _ O
their -X- _ O
KDEs -X- _ O
will -X- _ O
be -X- _ O
similar, -X- _ O
and -X- _ O
thus -X- _ O
the -X- _ O
contour -X- _ O
lines -X- _ O
will -X- _ O
overlap -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
possible. -X- _ O

Among -X- _ O
all -X- _ O
the -X- _ O
strategies, -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
original -X- _ B-MethodName
and -X- _ O
SCut -X- _ B-MethodName
reaches -X- _ O

Note -X- _ O
that -X- _ O
“Original” -X- _ B-MethodName
means -X- _ O
the -X- _ O
original -X- _ O
contrastive -X- _ O
loss -X- _ O
in -X- _ O
Eq.(4) -X- _ O
without -X- _ O
any -X- _ O
additional -X- _ O
hard -X- _ O
examples -X- _ O
mining -X- _ O
operation, -X- _ O
and -X- _ O
the -X- _ O
diagonal -X- _ O
in -X- _ O
the -X- _ O
heat -X- _ O
map -X- _ O
represents -X- _ O
only -X- _ O
one -X- _ O
strategy -X- _ O
used. -X- _ O

All -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
exceed -X- _ O
the -X- _ O
strong -X- _ O
multi-task -X- _ O
model -X- _ O
trained -X- _ O
without -X- _ O
contrastive -X- _ O
learning -X- _ O
(27.1). -X- _ B-MetricValue

All -X- _ O
the -X- _ O
hard -X- _ O
examples -X- _ O
mining -X- _ O
methods -X- _ O
are -X- _ O
effective. -X- _ O

We -X- _ O
have -X- _ O
the -X- _ O
following -X- _ O
observations. -X- _ O

For -X- _ O
an -X- _ O
easy -X- _ O
and -X- _ O
fair -X- _ O
comparison, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
contrastive -X- _ I-HyperparameterName
term -X- _ I-HyperparameterName
to -X- _ O
1.0 -X- _ B-HyperparameterValue
uniformly. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
study -X- _ O
how -X- _ O
effective -X- _ O
these -X- _ O
methods -X- _ O
are, -X- _ O
and -X- _ O
to -X- _ O
do -X- _ O
so, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
performances -X- _ O
of -X- _ O
their -X- _ O
15 -X- _ O
combinations -X- _ O
(Figure -X- _ O
4). -X- _ O

In -X- _ O
Section -X- _ O
3.3, -X- _ O
we -X- _ O
proposed -X- _ O
four -X- _ O
methods -X- _ O
to -X- _ O
mine -X- _ O
the -X- _ O
hard -X- _ O
examples -X- _ O
for -X- _ O
contrastive -X- _ O
learning, -X- _ O
namely -X- _ O
span-masked -X- _ B-MethodName
augmentation -X- _ I-MethodName
(SMA), -X- _ B-MethodName
word -X- _ B-MethodName
repetition -X- _ I-MethodName
(Rep), -X- _ B-MethodName
sequence -X- _ B-MethodName
cut-off -X- _ I-MethodName
(SCut), -X- _ B-MethodName
and -X- _ O
feature -X- _ B-MethodName
cut-off -X- _ I-MethodName
(FCut). -X- _ B-MethodName

5.4 -X- _ O
Analysis -X- _ O
on -X- _ O
the -X- _ O
hard -X- _ O
example -X- _ O
mining -X- _ O

Our -X- _ O
explanation -X- _ O
is -X- _ O
that -X- _ O
information -X- _ O
on -X- _ O
the -X- _ O
negative -X- _ O
samples -X- _ O
beneﬁts -X- _ O
the -X- _ O
contrastive -X- _ O
loss, -X- _ O
bringing -X- _ O
the -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
speech -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
transcription -X- _ O
closer -X- _ O
while -X- _ O
pushing -X- _ O
the -X- _ O
distance -X- _ O
to -X- _ O
the -X- _ O
irrelevant -X- _ O
text -X- _ O
farther. -X- _ O

The -X- _ O
answer -X- _ O
is -X- _ O
yes -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5. -X- _ O

P -X- _ O
Q -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
ways -X- _ O
of -X- _ O
bridging -X- _ O
the -X- _ O
modality -X- _ O
gap, -X- _ O
L2 -X- _ O
and -X- _ O
CTC -X- _ O
loss, -X- _ O
is -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
term -X- _ O
better? -X- _ O

t=1 -X- _ O
pt(πt| -X- _ O
all -X- _ O
valid -X- _ O
alignments. -X- _ O

Unlike -X- _ O
contrastive -X- _ O
loss -X- _ O
that -X- _ O
cares -X- _ O
about -X- _ O
the -X- _ O
representation, -X- _ O
CTC -X- _ O
loss -X- _ O
connects -X- _ O
the -X- _ O
two -X- _ O
modalities -X- _ O
by -X- _ O
establishing -X- _ O
a) -X- _ O
= -X- _ O
speech-text -X- _ O
alignment -X- _ O
and -X- _ O
maximizing -X- _ O
p(x -X- _ O
a), -X- _ O
where -X- _ O
Πs,a -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O

• -X- _ O
CTC -X- _ O
Loss: -X- _ O
The -X- _ O
connectionist -X- _ O
temporal -X- _ O
classiﬁcation -X- _ O
(CTC) -X- _ O
loss -X- _ O
(Graves -X- _ O
et -X- _ O
al., -X- _ O
2006) -X- _ O
is -X- _ O
commonly -X- _ O
used -X- _ O
in -X- _ O
speech-related -X- _ O
tasks -X- _ O
(Xu -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Dong -X- _ O
et -X- _ O
al., -X- _ O
2021b). -X- _ O

Dong -X- _ O
et -X- _ O
al., -X- _ O
2021b). -X- _ O

L2 -X- _ O
loss -X- _ O
can -X- _ O
= -X- _ O
ties -X- _ O
by -X- _ O
minimizing -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
an -X- _ O
implementation -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
knowledge -X- _ O
distillation -X- _ O
(Heo -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

Without -X- _ O
introducing -X- _ O
any -X- _ O
negative -X- _ O
samples, -X- _ O
L2 -X- _ O
loss -X- _ O
directly -X- _ O
reduces -X- _ O
the -X- _ O
Euclidean -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
two -X- _ O
modali2. -X- _ O

Whereas, -X- _ O
there -X- _ O
are -X- _ O
other -X- _ O
options -X- _ O
to -X- _ O
achieve -X- _ O
this -X- _ O
goal, -X- _ O
such -X- _ O
as -X- _ O
L2 -X- _ O
loss -X- _ O
and -X- _ O
CTC -X- _ O
loss. -X- _ O

Our -X- _ O
goal -X- _ O
for -X- _ O
introducing -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
term -X- _ O
(denoted -X- _ O
as -X- _ O
CTR -X- _ O
Loss) -X- _ O
is -X- _ O
to -X- _ O
close -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
representations. -X- _ O

Is -X- _ O
contrastive -X- _ O
loss -X- _ O
better -X- _ O
than -X- _ O
other -X- _ O
losses? -X- _ O

5.3 -X- _ O

The -X- _ O
detailed -X- _ O
analysis -X- _ O
of -X- _ O
possible -X- _ O
explanations -X- _ O
will -X- _ O
be -X- _ O
shown -X- _ O
in -X- _ O
Section -X- _ O
6.2. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
although -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
Line -X- _ O
2 -X- _ O
is -X- _ O
relatively -X- _ O
inferior, -X- _ O
it -X- _ O
still -X- _ O
outperforms -X- _ O
the -X- _ O
multi-task -X- _ O
model -X- _ O
without -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
(Line -X- _ O
3). -X- _ O

Table -X- _ O
4 -X- _ O
shows -X- _ O
that -X- _ O
contrastive -X- _ O
learning -X- _ O
using -X- _ O
the -X- _ O
low-level -X- _ O
representations -X- _ O
(Line -X- _ O
1) -X- _ O
is -X- _ O
better -X- _ O
than -X- _ O
using -X- _ O
the -X- _ O
high-level -X- _ O
ones -X- _ O
(Line -X- _ O
2). -X- _ O

Whereas -X- _ O
inspired -X- _ O
by -X- _ O
a -X- _ O
recent -X- _ O
study -X- _ O
in -X- _ O
multilingual -X- _ O
MT -X- _ O
(Pan -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
we -X- _ O
also -X- _ O
provide -X- _ O
an -X- _ O
alternative -X- _ O
contrastive -X- _ O
loss -X- _ O
as -X- _ O
a -X- _ O
comparison, -X- _ O
whose -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
features -X- _ O
are -X- _ O
average-pooled -X- _ O
semantic -X- _ O
repre -X- _ O

In -X- _ O
the -X- _ O
method -X- _ O
part -X- _ O
(Section -X- _ O
3.2), -X- _ O
we -X- _ O
use -X- _ O
averaged -X- _ O
audio -X- _ O
representation -X- _ O
u -X- _ O
for -X- _ O
speech -X- _ O
s -X- _ O
(Eq.(2)) -X- _ O
and -X- _ O
averaged -X- _ O
lexical -X- _ O
embedding -X- _ O
v -X- _ O
for -X- _ O
the -X- _ O
transcript -X- _ O
x -X- _ O
(Eq.(3)), -X- _ O
denoted -X- _ O
as -X- _ O
low-level -X- _ O
repr.. -X- _ O

An -X- _ O
intriguing -X- _ O
question -X- _ O
is -X- _ O
which -X- _ O
representations -X- _ O
should -X- _ O
be -X- _ O
considered -X- _ O
in -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
function. -X- _ O

5.2 -X- _ O
Which -X- _ O
layer -X- _ O
to -X- _ O
contrast -X- _ O
on? -X- _ O

improvement -X- _ O
of -X- _ O
0.9 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
over -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
by -X- _ O
only -X- _ O
optimizing -X- _ O
LST -X- _ O
(corresponding -X- _ O
to -X- _ O
the -X- _ O
last -X- _ O
row -X- _ O
of -X- _ O
the -X- _ O
Table -X- _ O
3), -X- _ O
and -X- _ O
multi-task -X- _ O
learning -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
further -X- _ O
improvement -X- _ O
of -X- _ O
about -X- _ O
1.2 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
on -X- _ O
top -X- _ O
of -X- _ O
that. -X- _ O

We -X- _ O
test -X- _ O
the -X- _ O
results -X- _ O
under -X- _ O
settings -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
external -X- _ O
MT -X- _ O
data. -X- _ O

By -X- _ O
gradually -X- _ O
removing -X- _ O
each -X- _ O
losses -X- _ O
in -X- _ O
Eq.( -X- _ O
1), -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
improvements -X- _ O
bringing -X- _ O
by -X- _ O
the -X- _ O
multi-task -X- _ O
learning -X- _ O
and -X- _ O
the -X- _ O
contrastive -X- _ O
learning. -X- _ O

Comparing -X- _ O
the -X- _ O
BLEU -X- _ B-MetricName
results -X- _ O
of -X- _ O
w/o -X- _ O
and -X- _ O
w/ -X- _ O
external -X- _ O
MT -X- _ O
data -X- _ O
situations -X- _ O
in -X- _ O
Table -X- _ O
1, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
ConST -X- _ B-MethodName
further -X- _ O
improves -X- _ O
0.5 -X- _ B-MetricValue
and -X- _ B-MetricValue
0.6 -X- _ I-MetricValue
BLEU -X- _ B-MetricName
scores -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
eight -X- _ O
translation -X- _ O
directions -X- _ O
on -X- _ O
average, -X- _ O
which -X- _ O
proves -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
cross-modal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning. -X- _ I-MethodName

With -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
pretraining -X- _ O
+ -X- _ O
ﬁne-tuning -X- _ O
procedure, -X- _ O
the -X- _ O
main -X- _ O
difference -X- _ O
between -X- _ O
ConST -X- _ B-MethodName
and -X- _ O
XSTNet -X- _ B-MethodName
(Ye -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
is -X- _ O
whether -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
term -X- _ O
during -X- _ O
the -X- _ O
ﬁne-tuning -X- _ O
or -X- _ O
not. -X- _ O

Is -X- _ O
contrastive -X- _ O
loss -X- _ O
effective? -X- _ O

5.1 -X- _ O

5 -X- _ O
Analysis -X- _ O

Models -X- _ O

As -X- _ O
recommended, -X- _ O
checkpoint -X- _ O
we -X- _ O
use -X- _ O
is -X- _ O
BLEURT-20. -X- _ B-MetricName

5https://github.com/google-research/ -X- _ O
bleurt -X- _ O
(Sellam -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

In -X- _ O
Appendix -X- _ O
7, -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
case -X- _ O
study -X- _ O
to -X- _ O
show -X- _ O
such -X- _ O
improvement. -X- _ O

From -X- _ O
Table -X- _ O
2, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
as -X- _ O
an -X- _ O
end-to-end -X- _ O
model, -X- _ O
ConST -X- _ B-MethodName
can -X- _ O
outperform -X- _ O
these -X- _ O
strong -X- _ O
cascade -X- _ O
models. -X- _ O

Comparison -X- _ O
with -X- _ O
cascaded -X- _ O
ST -X- _ O
systems -X- _ O
We -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
several -X- _ O
cascade -X- _ O
baselines, -X- _ O
where -X- _ O
Ye -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
and -X- _ O
Xu -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
provided -X- _ O
two -X- _ O
strong -X- _ O
cascade -X- _ O
systems -X- _ O
trained -X- _ O
using -X- _ O
MuSTC -X- _ B-DatasetName
and -X- _ O
external -X- _ O
ASR -X- _ O
and -X- _ O
MT -X- _ O
data -X- _ O
(LibriSpeech, -X- _ O
WMT, -X- _ O
and -X- _ O
Opensubtitles). -X- _ O

However, -X- _ O
the -X- _ O
shared -X- _ O
memory -X- _ O
with -X- _ O
ﬁxed -X- _ O
size -X- _ O
actually -X- _ O
compromises -X- _ O
the -X- _ O
MT -X- _ O
performance, -X- _ O
while -X- _ O
our -X- _ O
contrastive -X- _ O
learning -X- _ O
approach -X- _ O
is -X- _ O
more -X- _ O
straightforward -X- _ O
and -X- _ O
effective. -X- _ O

Among -X- _ O
the -X- _ O
benchmark -X- _ O
models, -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
goal -X- _ O
of -X- _ O
closing -X- _ O
two -X- _ O
modality -X- _ O
gaps, -X- _ O
Chimera -X- _ O
(Han -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
constructed -X- _ O
an -X- _ O
extra -X- _ O
ﬁxed-length -X- _ O
shared -X- _ O
semantic -X- _ O
space. -X- _ O

When -X- _ O
extra -X- _ O
MT -X- _ O
data -X- _ O
are -X- _ O
introduced, -X- _ O
our -X- _ O
method -X- _ O
also -X- _ O
outperforms -X- _ O
SOTA -X- _ B-MethodName
by -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
0.6 -X- _ B-MetricValue
BLEU. -X- _ B-MetricName

Also -X- _ O
when -X- _ O
speech -X- _ O
data -X- _ O
is -X- _ O
introduced -X- _ O
for -X- _ O
pre-training, -X- _ O
our -X- _ O
method -X- _ O
works -X- _ O
better -X- _ O
than -X- _ O
others -X- _ O
(Self-training, -X- _ B-MethodName
W-Transf. -X- _ B-MethodName
and -X- _ O
XSTNet). -X- _ B-MethodName

Without -X- _ O
the -X- _ O
external -X- _ O
MT -X- _ O
data, -X- _ O
our -X- _ O
method -X- _ O
already -X- _ O
gains -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
0.5 -X- _ B-MetricValue
BLEU -X- _ B-MetricName
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
models. -X- _ O

For -X- _ O
a -X- _ O
relatively -X- _ O
fair -X- _ O
comparison, -X- _ O
we -X- _ O
investigate -X- _ O
two -X- _ O
cases: -X- _ O
(1) -X- _ O
without -X- _ O
external -X- _ O
MT -X- _ O
data -X- _ O
and -X- _ O
(2) -X- _ O
with -X- _ O
external -X- _ O
MT -X- _ O
data. -X- _ O

Since -X- _ O
many -X- _ O
existing -X- _ O
works -X- _ O
regard -X- _ O
“leveraging -X- _ O
external -X- _ O
data” -X- _ O
to -X- _ O
be -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
model’s -X- _ O
features, -X- _ O
their -X- _ O
strong -X- _ O
performances -X- _ O
are -X- _ O
largely -X- _ O
predicated -X- _ O
on -X- _ O
the -X- _ O
utilization -X- _ O
of -X- _ O
auxiliary -X- _ O
data, -X- _ O
especially -X- _ O
large-scale -X- _ O
MT -X- _ O
data. -X- _ O

Comparison -X- _ O
with -X- _ O
end-to-end -X- _ B-TaskName
ST -X- _ I-TaskName
models -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
main -X- _ O
results. -X- _ O

3https://github.com/mjpost/sacrebleu, -X- _ O
BLEU -X- _ O
Signature: -X- _ O

fairseq/wav2vec/wav2vec_small.pt -X- _ O

https://ict.fbk.eu/must-c/ -X- _ O
2https://dl.fbaipublicfiles.com/ -X- _ O

1We -X- _ O
use -X- _ O
v1.0. -X- _ O

In -X- _ O
the -X- _ O
analysis, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
ChrF++ -X- _ B-MetricName
score -X- _ O
4 -X- _ O
(Popovi´c, -X- _ O
2017) -X- _ O

Experiment -X- _ O
Details -X- _ O
We -X- _ O
evaluate -X- _ O
case-sensitive -X- _ O
detokenized -X- _ O
BLEU -X- _ B-MetricName
using -X- _ O
sacreBLEU3 -X- _ O
(Post, -X- _ O
2018) -X- _ O
on -X- _ O
MuST-C -X- _ B-DatasetName
tst-COMMON -X- _ O
set. -X- _ O

The -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
above -X- _ O
conﬁgurations -X- _ O
has -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
about -X- _ O
150M -X- _ O
parameters. -X- _ O

We -X- _ O
use -X- _ O
pre-layer -X- _ O
normalization -X- _ O
for -X- _ O
stable -X- _ O
training. -X- _ O

The -X- _ O
Transformer -X- _ O
follows -X- _ O
the -X- _ O
base -X- _ O
conﬁguration, -X- _ O
with -X- _ O
6 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
of -X- _ O
encoder -X- _ O
and -X- _ O
decoder, -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
= -X- _ O
512, -X- _ B-HyperparameterValue
8 -X- _ B-HyperparameterValue
attention -X- _ B-HyperparameterName
heads, -X- _ I-HyperparameterName
and -X- _ O
2048 -X- _ B-HyperparameterValue
FFN -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
states. -X- _ I-HyperparameterName

Two -X- _ O
layers -X- _ O
of -X- _ O
CNNs -X- _ O
after -X- _ O
the -X- _ O
Wav2vec2.0 -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
kernel -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
5, -X- _ B-HyperparameterValue
stride -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
2 -X- _ B-HyperparameterValue
and -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
512. -X- _ B-HyperparameterValue

The -X- _ O
Wav2vec2.0 -X- _ O
in -X- _ O
the -X- _ O
SEnc -X- _ O
is -X- _ O
only -X- _ O
pre-trained -X- _ O
on -X- _ O
Librispeech -X- _ O
(Panayotov -X- _ O
et -X- _ O
al., -X- _ O
2015) -X- _ O
speech -X- _ O
without -X- _ O
any -X- _ O
downstream -X- _ O
ﬁnetuning2. -X- _ O

Model -X- _ O
Conﬁgurations -X- _ O

MT -X- _ B-TaskName
datasets -X- _ O
We -X- _ O
also -X- _ O
introduce -X- _ O
external -X- _ O
WMT -X- _ B-DatasetName
datasets -X- _ O
(Bojar -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
for -X- _ O
En-De/Es/Fr/Ro/Ru -X- _ O
and -X- _ O
OPUS100 -X- _ O
datasets -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
for -X- _ O
EnIt/Nl/Pt -X- _ O
directions, -X- _ O
as -X- _ O
the -X- _ O
expanded -X- _ O
setup. -X- _ O

ST -X- _ B-TaskName
datasets -X- _ O
We -X- _ O
conduct -X- _ O
experiments -X- _ O
on -X- _ O
all -X- _ O
in -X- _ O
MuST-C -X- _ B-DatasetName
dataset -X- _ O
1 -X- _ O
(Di -X- _ O
Gangi -X- _ O
et -X- _ O
al., -X- _ O
2019): -X- _ O
English -X- _ O
(En) -X- _ O
to -X- _ O
German -X- _ O
(De), -X- _ O
Spanish -X- _ O
(Es), -X- _ O
French -X- _ O
(Fr), -X- _ O
Italian -X- _ O
(It), -X- _ O
Dutch -X- _ O
(Nl), -X- _ O
Portuguese -X- _ O
(Pt), -X- _ O
Romanian -X- _ O
(Ro) -X- _ O
and -X- _ O
Russian -X- _ O
(Ru). -X- _ O

As -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
largest -X- _ O
ST -X- _ B-TaskName
benchmarks, -X- _ O
MuST-C -X- _ B-DatasetName
contains -X- _ O
more -X- _ O
than -X- _ O
385 -X- _ O
hours -X- _ O
of -X- _ O
TED -X- _ O
talks -X- _ O
for -X- _ O
each -X- _ O
direction. -X- _ O

4.2 -X- _ O
Main -X- _ O
Results -X- _ O

4.1 -X- _ O
Experimental -X- _ O
Setups -X- _ O

Appendix -X- _ O
C -X- _ O
shows -X- _ O
the -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
the -X- _ O
hyper-parameters. -X- _ O

Appendix -X- _ O
B -X- _ O
contains -X- _ O
more -X- _ O
detailed -X- _ O
settings -X- _ O
and -X- _ O
explanations -X- _ O
for -X- _ O
the -X- _ O
baseline -X- _ O
models -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

λ -X- _ B-HyperparameterName
= -X- _ O
1.5 -X- _ B-HyperparameterValue
for -X- _ O
German -X- _ O
and -X- _ O
Dutch, -X- _ O
and -X- _ B-HyperparameterName
λ -X- _ I-HyperparameterName
= -X- _ O
1.0 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
other -X- _ O
languages. -X- _ O

For -X- _ O
the -X- _ O
training -X- _ O
loss, -X- _ O
we -X- _ O
set -X- _ O
contrastive -X- _ O
temperature -X- _ B-HyperparameterName
τ -X- _ B-HyperparameterName
= -X- _ O
0.02 -X- _ B-HyperparameterValue
and -X- _ O
weight -X- _ O
of -X- _ O
contrastive -X- _ O
term -X- _ O

We -X- _ O
jointly -X- _ O
tokenize -X- _ O
the -X- _ O
bilingual -X- _ O
text -X- _ O
using -X- _ O
SentencePiece -X- _ O
(Kudo -X- _ O
and -X- _ O
Richardson, -X- _ O
2018), -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
size -X- _ O
of -X- _ O
10k, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
Ye -X- _ O
et -X- _ O
al. -X- _ O
(2021)’s -X- _ O
setup. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
raw -X- _ O
16-bit -X- _ O
16kHz -X- _ O
mono-channel -X- _ O
speech -X- _ O
input. -X- _ O

and -X- _ O
the -X- _ O
learning-based -X- _ O
BLEURT -X- _ O
score -X- _ O
5. -X- _ O

4 -X- _ O
Experiments -X- _ O

Similarly, -X- _ O
we -X- _ O
treat -X- _ O
the -X- _ O
cut-off -X- _ O
audio -X- _ O
representation -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
transcribed -X- _ O
sentence -X- _ O
as -X- _ O
positive -X- _ O
pairs, -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ O
as -X- _ O
negative -X- _ O
pairs. -X- _ O

Dropout -X- _ O
randomly -X- _ O
sets -X- _ O
some -X- _ O
elements -X- _ O
to -X- _ O
0, -X- _ O
while -X- _ O
cut-off -X- _ O
is -X- _ O
a -X- _ O
dimensional -X- _ O
“block" -X- _ O
dropout. -X- _ O

Note -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
difference -X- _ O
between -X- _ O
cut-off -X- _ O
and -X- _ O
dropout. -X- _ O

Here, -X- _ O
we -X- _ O
present -X- _ O
two -X- _ O
variants: -X- _ O
sequence -X- _ O
cut-off -X- _ O
, -X- _ O
which -X- _ O
erases -X- _ O
some -X- _ O
sequence -X- _ O
dimension, -X- _ O
and -X- _ O
feature -X- _ O
cut-off -X- _ O
, -X- _ O
which -X- _ O
erases -X- _ O
some -X- _ O
feature -X- _ O
dimension. -X- _ O

We -X- _ O
analogize -X- _ O
a -X- _ O
similar -X- _ O
idea -X- _ O
to -X- _ O
the -X- _ O
cut-off -X- _ O
approach -X- _ O
for -X- _ O
speech -X- _ O
representation. -X- _ O

Yan -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Cut-off -X- _ O
strategy -X- _ O
Recent -X- _ O
studies -X- _ O
on -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
and -X- _ O
generation -X- _ O
have -X- _ O
proved -X- _ O
cut-off -X- _ O
strategy -X- _ O
to -X- _ O
be -X- _ O
successful -X- _ O
(Shen -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O

We -X- _ O
regard -X- _ O
x0 -X- _ O
as -X- _ O
the -X- _ O
additional -X- _ O
positive -X- _ O
example -X- _ O
for -X- _ O
the -X- _ O
speech -X- _ O
s -X- _ O
and -X- _ O
the -X- _ O
samples -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
operation -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ O
as -X- _ O
the -X- _ O
negative -X- _ O
examples. -X- _ O

Speciﬁcally, -X- _ O
given -X- _ O
sentence -X- _ O
x, -X- _ O
each -X- _ O
sub-word -X- _ O
token -X- _ O
xi -X- _ O
can -X- _ O
be -X- _ O
duplicated -X- _ O
k -X- _ O
more -X- _ O
times, -X- _ O
resulting -X- _ O
in -X- _ O
the -X- _ O
duplicated -X- _ O
sentence -X- _ O
x0, -X- _ O
where -X- _ O
k -X- _ O
= -X- _ O
0, -X- _ O
1, -X- _ O
2, -X- _ O
... -X- _ O
and -X- _ O
k -X- _ O
Poisson(1). -X- _ O

Second, -X- _ O
repeating -X- _ O
words -X- _ O
does -X- _ O
not -X- _ O
change -X- _ O
the -X- _ O
semantics -X- _ O
and -X- _ O
is -X- _ O
suitable -X- _ O
as -X- _ O
an -X- _ O
extra -X- _ O
positive -X- _ O
example -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
speech. -X- _ O

First, -X- _ O
as -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
shorter -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
its -X- _ O
audio -X- _ O
representation, -X- _ O
randomly -X- _ O
repeating -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
yet -X- _ O
useful -X- _ O
technique -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
length. -X- _ O

The -X- _ O
word -X- _ O
repetition -X- _ O
strategy -X- _ O
randomly -X- _ O
replicates -X- _ O
some -X- _ O
words -X- _ O
(or -X- _ O
sub-words) -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
sentences, -X- _ O
with -X- _ O
two -X- _ O
advantages -X- _ O
for -X- _ O
improving -X- _ O
representation -X- _ O
robustness. -X- _ O

Since -X- _ O
the -X- _ O
masked -X- _ O
speech -X- _ O
fragment -X- _ O
is -X- _ O
very -X- _ O
short, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
masked -X- _ O
speech -X- _ O
and -X- _ O
the -X- _ O
original -X- _ O
transcript -X- _ O
to -X- _ O
be -X- _ O
positive -X- _ O
pairs, -X- _ O
and -X- _ O
the -X- _ O
remaining -X- _ O
transcripts -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ O
to -X- _ O
be -X- _ O
negative -X- _ O
pairs. -X- _ O

In -X- _ O
the -X- _ O
experiment, -X- _ O
we -X- _ O
tried -X- _ O
multiple -X- _ O
conﬁgurations, -X- _ O
and -X- _ O
found -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
0.25, -X- _ B-HyperparameterValue
M -X- _ B-HyperparameterName
= -X- _ O
3600 -X- _ B-HyperparameterValue
the -X- _ O
best, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
masked -X- _ O
span -X- _ O
of -X- _ O
0.225 -X- _ O
second. -X- _ O

We -X- _ O
randomly -X- _ O
sample -X- _ O
without -X- _ O
replacement -X- _ O
all -X- _ O
time -X- _ O
steps -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
waveform -X- _ O
of -X- _ O
the -X- _ O
speech -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
starting -X- _ O
indices -X- _ O
with -X- _ O
a -X- _ O
probability -X- _ O
p, -X- _ B-HyperparameterName
and -X- _ O
then -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
sub-sequence -X- _ O
M -X- _ B-HyperparameterName
successive -X- _ O
time -X- _ O
steps -X- _ O
to -X- _ O
be -X- _ O
blank. -X- _ O

We -X- _ O
take -X- _ O
s0 -X- _ O
as -X- _ O
an -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
model, -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
on -X- _ O
its -X- _ O
original -X- _ O
corresponding -X- _ O
transcript. -X- _ O

We -X- _ O
mask -X- _ O
consecutive -X- _ O
segments -X- _ O
of -X- _ O
an -X- _ O
original -X- _ O
audio -X- _ O
waveform -X- _ O
sequence -X- _ O
s -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
new -X- _ O
modiﬁed -X- _ O
speech -X- _ O
s0. -X- _ O

In -X- _ O
the -X- _ O
cut-off -X- _ O
strategy, -X- _ O
the -X- _ O
gray -X- _ O
shaded -X- _ O
grid -X- _ O
represents -X- _ O
the -X- _ O
zero-out -X- _ O
element. -X- _ O

Speciﬁc -X- _ O
schematic -X- _ O
illustrations -X- _ O
of -X- _ O
each -X- _ O
operations -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3. -X- _ O

These -X- _ O
strategies -X- _ O
are -X- _ O
at -X- _ O
input -X- _ O
and -X- _ O
representation -X- _ O
(gray -X- _ O
shaded -X- _ O
modules -X- _ O
in -X- _ O
Figure -X- _ O
2(a)). -X- _ O

To -X- _ O
further -X- _ O
enhance -X- _ O
the -X- _ O
contrastive -X- _ O
learning, -X- _ O
we -X- _ O
introduce -X- _ O
three -X- _ O
strategies -X- _ O
to -X- _ O
mine -X- _ O
additional -X- _ O
hard -X- _ O
examples. -X- _ O

Learning -X- _ O

3.3 -X- _ O
Mining -X- _ O
Hard -X- _ O
Examples -X- _ O
for -X- _ O
Contrastive -X- _ O

exp(sim(u, -X- _ O
v(xj))/τ -X- _ B-HyperparameterName
) -X- _ O
(4) -X- _ O
N -X- _ O
i=1 -X- _ O
, -X- _ O
τ -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
temperature -X- _ B-HyperparameterName
where -X- _ O
hyper-parameter, -X- _ O
and -X- _ O
sim -X- _ O
is -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
function -X- _ O
sim(a, -X- _ O
b) -X- _ O
= -X- _ O

x−i -X- _ O
} -X- _ O

For -X- _ O
speech -X- _ O
s -X- _ O
and -X- _ O
its -X- _ O
transcript -X- _ O
x, -X- _ O
we -X- _ O
ﬁrst -X- _ O
average -X- _ O
them -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
dimension, -X- _ O

Given -X- _ O
a -X- _ O
positive -X- _ O
example -X- _ O
of -X- _ O
such -X- _ O
a -X- _ O
speechtranscript -X- _ O
pair -X- _ O
(s, -X- _ O
x), -X- _ O
we -X- _ O
randomly -X- _ O
pick -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
N -X- _ O
N -X- _ O
i=1 -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
batch -X- _ O
as -X- _ O
negative -X- _ O
examples. -X- _ O

1 -X- _ O
transcripts -X- _ O

The -X- _ O
main -X- _ O
idea -X- _ O
of -X- _ O
cross-modal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
is -X- _ O
to -X- _ O
introduce -X- _ O
a -X- _ O
loss -X- _ O
that -X- _ O
brings -X- _ O
speech -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
transcript -X- _ O
(positive -X- _ O
example) -X- _ O
near -X- _ O
together -X- _ O
while -X- _ O
pushing -X- _ O
irrelevant -X- _ O
ones -X- _ O
(negative -X- _ O
examples) -X- _ O
far -X- _ O
apart. -X- _ O

As -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
beginning, -X- _ O
since -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
produce -X- _ O
similar -X- _ O
representations -X- _ O
for -X- _ O
the -X- _ O
speech -X- _ O
and -X- _ O
transcript -X- _ O
sharing -X- _ O
the -X- _ O
same -X- _ O
semantic -X- _ O
meanings, -X- _ O
we -X- _ O
propose -X- _ O
cross-modal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
method -X- _ O
to -X- _ O
bring -X- _ O
their -X- _ O
representations -X- _ O
closer -X- _ O
together. -X- _ O

3.2 -X- _ O
Cross-modal -X- _ O
Contrastive -X- _ O
Learning -X- _ O

λ -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
tuned -X- _ O
hyper-parameter -X- _ O
of -X- _ O
the -X- _ O
weighted -X- _ O
contrastive -X- _ O
loss -X- _ O
term. -X- _ O

It -X- _ O
aims -X- _ O
to -X- _ O
bring -X- _ O
the -X- _ O
representation -X- _ O
between -X- _ O
the -X- _ O
speech -X- _ O
and -X- _ O
textual -X- _ O
transcription -X- _ O
modalities -X- _ O
closer -X- _ O
(its -X- _ O
effect -X- _ O
will -X- _ O
be -X- _ O
analyzed -X- _ O
in -X- _ O
detail -X- _ O
in -X- _ O
Section -X- _ O
6). -X- _ O

These -X- _ O
pairs -X- _ O
are -X- _ O
built -X- _ O
from -X- _ O
the -X- _ O
triplet -X- _ O
ST -X- _ O
data. -X- _ O

The -X- _ O
ﬁrst -X- _ O
three -X- _ O
elements -X- _ O
are -X- _ O
cross-entropy -X- _ O
losses -X- _ O
on -X- _ O
<speech, -X- _ O
target -X- _ O
text>, -X- _ O
<speech, -X- _ O
source -X- _ O
text> -X- _ O
and -X- _ O
<source -X- _ O
text, -X- _ O
target -X- _ O
text> -X- _ O
pairs. -X- _ O

= -X- _ O

Our -X- _ O
training -X- _ O
loss -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
following -X- _ O
elements. -X- _ O

Previous -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
multi-task -X- _ O
learning -X- _ O
on -X- _ O
ST, -X- _ O
MT -X- _ O
and -X- _ O
ASR -X- _ O
improves -X- _ O
translation -X- _ O
performance -X- _ O
(Indurthi -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Tang -X- _ O
et -X- _ O
al., -X- _ O
2021b; -X- _ O
Ye -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Since -X- _ O
our -X- _ O
model -X- _ O
has -X- _ O
a -X- _ O
complete -X- _ O
Transformer -X- _ O
encoder-decoder -X- _ O
as -X- _ O
a -X- _ O
sub-module, -X- _ O
this -X- _ O
makes -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
pre-train -X- _ O
using -X- _ O
large-scale -X- _ O
extra -X- _ O
MT -X- _ O
parallel -X- _ O
data. -X- _ O

The -X- _ O
Transformer -X- _ O
decoder -X- _ O
generates -X- _ O
the -X- _ O
word -X- _ O
sequences -X- _ O
(transcription -X- _ O
and -X- _ O
translation) -X- _ O
for -X- _ O
ST, -X- _ O
MT -X- _ O
and -X- _ O
ASR -X- _ O
tasks. -X- _ O

To -X- _ O
explain, -X- _ O
the -X- _ O
Transformer -X- _ O
encoder -X- _ O
further -X- _ O
extracts -X- _ O
the -X- _ O
high-level -X- _ O
semantic -X- _ O
hidden -X- _ O
representation -X- _ O
of -X- _ O
two -X- _ O
modalities. -X- _ O

The -X- _ O
Transformer -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
are -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
conﬁguration -X- _ O
as -X- _ O
the -X- _ O
original -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

Both -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
and -X- _ O
word -X- _ O
embedding -X- _ O
layer -X- _ O
are -X- _ O
connect -X- _ O
to -X- _ O
Transformer -X- _ O
encoder -X- _ O
and -X- _ O
then -X- _ O
passed -X- _ O
to -X- _ O
the -X- _ O
Transformer -X- _ O
decoder. -X- _ O

It -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
word -X- _ O
embedding -X- _ O
for -X- _ O
text -X- _ O
translation. -X- _ O

Parallel -X- _ O
to -X- _ O
the -X- _ O
speech -X- _ O
encoder -X- _ O
is -X- _ O
the -X- _ O
word -X- _ O
embeeding -X- _ O
layer. -X- _ O

Denote -X- _ O
a -X- _ O
= -X- _ O
S-Enc(s) -X- _ O
as -X- _ O
the -X- _ O
audio -X- _ O
representation -X- _ O
. -X- _ O

In -X- _ O
total, -X- _ O
it -X- _ O
shrinks -X- _ O
the -X- _ O
time -X- _ O
dimension -X- _ O
by -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
4. -X- _ B-HyperparameterValue

Each -X- _ O
convolutional -X- _ O
layer -X- _ O
has -X- _ O
a -X- _ O
stride -X- _ B-HyperparameterName
of -X- _ O
4 -X- _ B-HyperparameterValue
and -X- _ O
d -X- _ B-HyperparameterName
channels. -X- _ B-HyperparameterName

The -X- _ O
input -X- _ O
is -X- _ O
raw -X- _ O
waveform -X- _ O
signal -X- _ O
sampled -X- _ O
at -X- _ O
16kHz. -X- _ O

It -X- _ O
contains -X- _ O
Wav2vec2.0 -X- _ O
(Baevski -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
two -X- _ O
additional -X- _ O
convolutional -X- _ O
layers. -X- _ O

The -X- _ O
speech -X- _ O
encoder -X- _ O
module -X- _ O
(S-Enc) -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
extract -X- _ O
low-level -X- _ O
features -X- _ O
for -X- _ O
speech -X- _ O
signals. -X- _ O

Such -X- _ O
architecture -X- _ O
enables -X- _ O
a -X- _ O
universal -X- _ O
framework -X- _ O
for -X- _ O
multiple -X- _ O
tasks, -X- _ O
including -X- _ O
ST, -X- _ B-TaskName
MT -X- _ O
and -X- _ O
ASR. -X- _ O

It -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
take -X- _ O
either -X- _ O
speech -X- _ O
or -X- _ O
a -X- _ O
sentence -X- _ O
as -X- _ O
input, -X- _ O
and -X- _ O
to -X- _ O
output -X- _ O
either -X- _ O
source -X- _ O
transcript -X- _ O
or -X- _ O
target -X- _ O
translation -X- _ O
text. -X- _ O

Our -X- _ O
model -X- _ O
consists -X- _ O
four -X- _ O
sub-modules: -X- _ O
a -X- _ O
speech -X- _ O
encoder, -X- _ O
a -X- _ O
word -X- _ O
embedding -X- _ O
layer, -X- _ O
a -X- _ O
Transformer -X- _ O
Encoder -X- _ O
and -X- _ O
a -X- _ O
Transformer -X- _ O
decoder -X- _ O
(Figure -X- _ O
2). -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
architecture -X- _ O
as -X- _ O
XSTNet -X- _ O
(Ye -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

3.1 -X- _ O
Model -X- _ O
Framework -X- _ O

We -X- _ O
also -X- _ O
provide -X- _ O
several -X- _ O
feasible -X- _ O
strategies -X- _ O
to -X- _ O
construct -X- _ O
more -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
pairs -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
contrastive -X- _ O
learning. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
overall -X- _ O
speech -X- _ B-TaskName
translation -X- _ I-TaskName
model -X- _ O
and -X- _ O
cross-modal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning. -X- _ I-MethodName

vated -X- _ O
by -X- _ O
the -X- _ O
contrastive -X- _ O
learning -X- _ O
frameworks -X- _ O
in -X- _ O
cross-lingual -X- _ O
and -X- _ O
cross-modal -X- _ O
topics, -X- _ O
we -X- _ O
introduce -X- _ O
a -X- _ O
similar -X- _ O
idea -X- _ O
in -X- _ O
speech -X- _ B-TaskName
translation. -X- _ I-TaskName

Very -X- _ O
recently, -X- _ O
contrastive -X- _ O
learning -X- _ O
is -X- _ O
also -X- _ O
applied -X- _ O
to -X- _ O
learning -X- _ O
a -X- _ O
uniﬁed -X- _ O
representation -X- _ O
of -X- _ O
image -X- _ O
and -X- _ O
text -X- _ O
(Dong -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zhou -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Li -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Shen -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Gao -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Wu -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Yan -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Fu -X- _ O
et -X- _ O
al., -X- _ O
2022), -X- _ O
machine -X- _ O
translation -X- _ O
(Pan -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
and -X- _ O
summarization -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2021b; -X- _ O
Cao -X- _ O
and -X- _ O
Wang, -X- _ O
2021). -X- _ O

In -X- _ O
the -X- _ O
NLP -X- _ O
area, -X- _ O
the -X- _ O
contrastive -X- _ O
framework -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
sentence -X- _ O
representation -X- _ O
learning -X- _ O
(Fang -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O

In -X- _ O
speech -X- _ O
processing, -X- _ O
representative -X- _ O
methods -X- _ O
focused -X- _ O
on -X- _ O
speaker -X- _ O
identiﬁcation -X- _ O
(Ravanelli -X- _ O
and -X- _ O
Bengio, -X- _ O
2018), -X- _ O
speech -X- _ O
recognition -X- _ O
(Schneider -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
and -X- _ O
audio -X- _ O
representation -X- _ O
learning -X- _ O
(van -X- _ O
den -X- _ O
Oord -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Baevski -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

(2020) -X- _ O
extended -X- _ O
the -X- _ O
self-supervised -X- _ O
batch -X- _ O
contrastive -X- _ O
approach -X- _ O
to -X- _ O
the -X- _ O
fully-supervised -X- _ O
setting -X- _ O
and -X- _ O
proposed -X- _ O
a -X- _ O
supervised -X- _ O
contrastive -X- _ O
learning -X- _ O
method. -X- _ O

Oord -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Chen -X- _ O
et -X- _ O
al., -X- _ O
2020a; -X- _ O
Grill -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

The -X- _ O
contrastive -X- _ O
learning -X- _ O
method -X- _ O
was -X- _ O
ﬁrst -X- _ O
proposed -X- _ O
to -X- _ O
learn -X- _ O
representations -X- _ O
from -X- _ O
unlabeled -X- _ O
datasets -X- _ O
(hence -X- _ O
the -X- _ O
term, -X- _ O
self-supervised -X- _ O
learning) -X- _ O
by -X- _ O
telling -X- _ O
which -X- _ O
data -X- _ O
points -X- _ O
are -X- _ O
similar -X- _ O
or -X- _ O
distinct, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
ﬁeld -X- _ O
of -X- _ O
computer -X- _ O
vision -X- _ O
(Chopra -X- _ O
et -X- _ O
al., -X- _ O
2005; -X- _ O
Gutmann -X- _ O
and -X- _ O
Hyvärinen, -X- _ O
2010; -X- _ O
Schroff -X- _ O
et -X- _ O
al., -X- _ O
2015; -X- _ O
Sohn, -X- _ O
2016; -X- _ O

Contrastive -X- _ O
learning -X- _ O
Our -X- _ O
method -X- _ O
is -X- _ O
motivated -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
success -X- _ O
in -X- _ O
contrastive -X- _ O
representation -X- _ O
learning. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
its -X- _ O
dual -X- _ O
form, -X- _ O
i.e., -X- _ O
grounding -X- _ O
speech -X- _ O
representations -X- _ O
using -X- _ O
text. -X- _ O

These -X- _ O
works -X- _ O
usually -X- _ O
focus -X- _ O
on -X- _ O
enhancing -X- _ O
textual -X- _ O
representations -X- _ O
with -X- _ O
acoustic -X- _ O
or -X- _ O
visual -X- _ O
information, -X- _ O
in -X- _ O
other -X- _ O
words, -X- _ O
grounding -X- _ O
learning. -X- _ O

We -X- _ O
are -X- _ O
also -X- _ O
inspired -X- _ O
by -X- _ O
crossmodal -X- _ O
representation -X- _ O
learning -X- _ O
in -X- _ O
the -X- _ O
acoustic -X- _ O
word -X- _ O
embedding -X- _ O
(AWE) -X- _ O
(Palaskar -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Kamper -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Hu -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
the -X- _ O
visuallanguage -X- _ O
pre-training -X- _ O
(VLP) -X- _ O
(Wu -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

Cross-modal -X- _ O
grounding -X- _ O
learning -X- _ O
This -X- _ O
paper -X- _ O
attempts -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
problem -X- _ O
in -X- _ O
speech -X- _ O
translation -X- _ O
from -X- _ O
the -X- _ O
perspective -X- _ O
of -X- _ O
cross-speech-text -X- _ O
representation -X- _ O
learning. -X- _ O

So -X- _ O
in -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
contrastive -X- _ O
learning -X- _ O
method -X- _ O
to -X- _ O
bridge -X- _ O
the -X- _ O
gap -X- _ O
and -X- _ O
to -X- _ O
improve -X- _ O
ST -X- _ B-TaskName
performance. -X- _ O

However, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
this -X- _ O
approach -X- _ O
actually -X- _ O
sacriﬁces -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
MT. -X- _ O

(Han -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
designed -X- _ O
a -X- _ O
ﬁx-size -X- _ O
semantic -X- _ O
memory -X- _ O
module -X- _ O
to -X- _ O
bridge -X- _ O
such -X- _ O
a -X- _ O
gap, -X- _ O
from -X- _ O
the -X- _ O
neuroscience -X- _ O
perspective. -X- _ O

As -X- _ O
a -X- _ O
cross-modal -X- _ O
task, -X- _ O
some -X- _ O
work -X- _ O
has -X- _ O
noted -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
the -X- _ O
modality -X- _ O
gap. -X- _ O

2021) -X- _ O
are -X- _ O
widely -X- _ O
applied -X- _ O
to -X- _ O
further -X- _ O
enhance -X- _ O
the -X- _ O
robustness -X- _ O
for -X- _ O
ST. -X- _ B-TaskName

Also, -X- _ O
multi-task -X- _ O
frameworks -X- _ O
(Le -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Tang -X- _ O
et -X- _ O
al., -X- _ O
2021b; -X- _ O
Ye -X- _ O
et -X- _ O
al., -X- _ O

Xu -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
proposed -X- _ O
a -X- _ O
stacked -X- _ O
acoustic-and-textual -X- _ O
encoder -X- _ O
and -X- _ O
introduced -X- _ O
largescale -X- _ O
out-of-domain -X- _ O
data. -X- _ O

(2021b) -X- _ O
ﬁrst -X- _ O
proposed -X- _ O
a -X- _ O
second -X- _ O
encoder -X- _ O
to -X- _ O
further -X- _ O
extract -X- _ O
semantic -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
speech -X- _ O
sequence. -X- _ O

For -X- _ O
example, -X- _ O
Dong -X- _ O
et -X- _ O
al. -X- _ O

Meanwhile, -X- _ O
some -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
encoderdecoder -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
encoder -X- _ O
cannot -X- _ O
encode -X- _ O
speech -X- _ O
information -X- _ O
well. -X- _ O

Pino -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Chen -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
pre-training -X- _ O
(Weiss -X- _ O
et -X- _ O
al., -X- _ O
2017; -X- _ O
Berard -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Bansal -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2020b; -X- _ O
Alinejad -X- _ O
and -X- _ O
Sarkar, -X- _ O
2020; -X- _ O
Dong -X- _ O
et -X- _ O
al., -X- _ O
2021a; -X- _ O
Zheng -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
self-training -X- _ O
(Pino -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
utilizing -X- _ O
selfsupervised -X- _ O
pre-trained -X- _ O
audio -X- _ O
representation -X- _ O
(Wu -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Han -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Ye -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
are -X- _ O
proved -X- _ O
to -X- _ O
be -X- _ O
effective. -X- _ O

However, -X- _ O
training -X- _ O
an -X- _ O
end-to-end -X- _ B-TaskName
speech -X- _ I-TaskName
translation -X- _ I-TaskName
model -X- _ O
is -X- _ O
difﬁcult -X- _ O
because -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
design -X- _ O
a -X- _ O
cross-modal -X- _ O
cross-language -X- _ O
model, -X- _ O
meanwhile, -X- _ O
the -X- _ O
speech-transcription-translation -X- _ O
supervised -X- _ O
data -X- _ O
for -X- _ O
speech -X- _ O
translation -X- _ O
is -X- _ O
signiﬁcantly -X- _ O
less -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
MT -X- _ O
and -X- _ O
ASR. -X- _ O

Kano -X- _ O
et -X- _ O
al. -X- _ O
(2017); -X- _ O
Berard -X- _ O
et -X- _ O
al. -X- _ O
(2018); -X- _ O
Inaguma -X- _ O
et -X- _ O
al. -X- _ O
(2020); -X- _ O
Wang -X- _ O
et -X- _ O
al. -X- _ O
(2020a); -X- _ O
Zhao -X- _ O
et -X- _ O
al. -X- _ O
(2021a) -X- _ O
implemented -X- _ O
several -X- _ O
off-the-shelf -X- _ O
encoderdecoder -X- _ O
E2E-ST -X- _ B-TaskName
models, -X- _ O
such -X- _ O
as -X- _ O
BiLSTM -X- _ O
(Greff -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
and -X- _ O
Speech-Transformer -X- _ B-MethodName
(Dong -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

Weiss -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
proposed -X- _ O
to -X- _ O
use -X- _ O
an -X- _ O
end-to-end -X- _ O
architecture -X- _ O
to -X- _ O
directly -X- _ O
translate -X- _ O
speech -X- _ O
into -X- _ O
text -X- _ O
in -X- _ O
another -X- _ O
language, -X- _ O
without -X- _ O
the -X- _ O
intermediate -X- _ O
transcription. -X- _ O

End-to-end -X- _ B-TaskName
ST -X- _ I-TaskName
To -X- _ O
alleviate -X- _ O
the -X- _ O
error -X- _ O
propagation -X- _ O
in -X- _ O
the -X- _ O
cascaded -X- _ O
ST -X- _ B-TaskName
systems -X- _ O
and -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
deployment -X- _ O
simpler, -X- _ O
Bérard -X- _ O
et -X- _ O
al. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

We -X- _ O
demonstrate -X- _ O
that -X- _ O
ConST -X- _ B-MethodName
indeed -X- _ O
learns -X- _ O
similar -X- _ O
representations -X- _ O
for -X- _ O
two -X- _ O
modalities -X- _ O
and -X- _ O
better -X- _ O
retrieves -X- _ O
text -X- _ O
with -X- _ O
speech -X- _ O
input. -X- _ O

Our -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
MuST-C -X- _ B-DatasetName
benchmark -X- _ O
show -X- _ O
that -X- _ O
ConST -X- _ B-MethodName
achieves -X- _ O
an -X- _ O
average -X- _ O
BLEU -X- _ B-MetricName
score -X- _ O
of -X- _ O
29.4, -X- _ B-MetricValue
outperforming -X- _ O
the -X- _ O
best -X- _ O
previous -X- _ O
baselines. -X- _ O

We -X- _ O
develop -X- _ O
ConST -X- _ B-MethodName
for -X- _ O
speech -X- _ B-TaskName
translation, -X- _ I-TaskName
a -X- _ O
cross-modal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
method, -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
multi-task -X- _ O
training -X- _ O
framework. -X- _ O

Our -X- _ O
contributions -X- _ O
are -X- _ O
as -X- _ O
follows. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
it -X- _ O
reduces -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
speech -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
transcription. -X- _ O

On -X- _ O
the -X- _ O
one -X- _ O
hand, -X- _ O
our -X- _ O
model -X- _ O
inherits -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
progress -X- _ O
of -X- _ O
contrastive -X- _ O
learning -X- _ O
approaches -X- _ O
in -X- _ O
cross-lingual -X- _ O
(Lample -X- _ O
and -X- _ O
Conneau, -X- _ O
2019; -X- _ O
Pan -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
cross-modal -X- _ O
vision-and-language -X- _ O
domains -X- _ O
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Zhou -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Dong -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
we -X- _ O
designed -X- _ O
a -X- _ O
simple -X- _ O
contrastive -X- _ B-MethodName
learning -X- _ I-MethodName
method -X- _ O
for -X- _ O
ST -X- _ B-TaskName
(ConST) -X- _ B-MethodName
to -X- _ O
learn -X- _ O
the -X- _ O
representations -X- _ O
that -X- _ O
meet -X- _ O
the -X- _ O
aforementioned -X- _ O
conditions -X- _ O
explicitly. -X- _ O

Nevertheless, -X- _ O
how -X- _ O
to -X- _ O
learn -X- _ O
uniﬁed -X- _ O
and -X- _ O
aligned -X- _ O
speech-text -X- _ O
representations? -X- _ O

An -X- _ O
ideal -X- _ O
representation -X- _ O
should -X- _ O
satisfy: -X- _ O
if -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
speech -X- _ O
and -X- _ O
transcription -X- _ O
are -X- _ O
similar, -X- _ O
their -X- _ O
encoded -X- _ O
representations -X- _ O
should -X- _ O
likewise -X- _ O
be -X- _ O
close -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
(as -X- _ O
in -X- _ O
Figure -X- _ O
1b). -X- _ O

Existing -X- _ O
approaches -X- _ O
for -X- _ O
ST -X- _ B-TaskName
focus -X- _ O
on -X- _ O
using -X- _ O
additional -X- _ O
data -X- _ O
from -X- _ O
MT -X- _ O
and -X- _ O
automatic -X- _ O
speech -X- _ O
recognition -X- _ O
(ASR). -X- _ O

We -X- _ O
analyze -X- _ O
Transformer -X- _ O
models -X- _ O
for -X- _ O
speech -X- _ O
translation -X- _ O
and -X- _ O
observe -X- _ O
a -X- _ O
noticeable -X- _ O
modality -X- _ O
gap -X- _ O
between -X- _ O
encoder -X- _ O
representations -X- _ O
of -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
from -X- _ O
existing -X- _ O
ST -X- _ B-TaskName
models -X- _ O
(as -X- _ O
in -X- _ O
Figure -X- _ O
1a. -X- _ O

We -X- _ O
believe -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
audio -X- _ O
input -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
its -X- _ O
corresponding -X- _ O
textual -X- _ O
representation, -X- _ O
it -X- _ O
is -X- _ O
easier -X- _ O
for -X- _ O
information -X- _ O
to -X- _ O
transfer -X- _ O
from -X- _ O
MT -X- _ O
to -X- _ O
ST, -X- _ B-TaskName
thus -X- _ O
improving -X- _ O
speech -X- _ B-TaskName
translation -X- _ I-TaskName
performance. -X- _ O

Different -X- _ O
from -X- _ O
the -X- _ O
data -X- _ O
perspective, -X- _ O
this -X- _ O
paper -X- _ O
investigates -X- _ O
the -X- _ O
bottleneck -X- _ O
of -X- _ O
E2E -X- _ B-TaskName
ST -X- _ I-TaskName
from -X- _ O
the -X- _ O
neural -X- _ O
representation -X- _ O
perspective. -X- _ O

Ye -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Han -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

This -X- _ O
can -X- _ O
be -X- _ O
realized -X- _ O
through -X- _ O
pretraining -X- _ O
approaches -X- _ O
(Zheng -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Dong -X- _ O
et -X- _ O
al., -X- _ O
2021b,a) -X- _ O
or -X- _ O
multi-task -X- _ O
training -X- _ O
frameworks -X- _ O
(Tang -X- _ O
et -X- _ O
al., -X- _ O
2021b; -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
an -X- _ O
E2E -X- _ B-TaskName
ST -X- _ I-TaskName
model -X- _ O
is -X- _ O
still -X- _ O
restricted -X- _ O
for -X- _ O
languages -X- _ O
with -X- _ O
relatively -X- _ O
small -X- _ O
parallel -X- _ O
data, -X- _ O
compared -X- _ O
to -X- _ O
text -X- _ O
machine -X- _ O
translation -X- _ O
(MT). -X- _ O

Compared -X- _ O
with -X- _ O
the -X- _ O
conventional -X- _ O
cascade -X- _ O
ST -X- _ O
models, -X- _ O
E2E -X- _ B-TaskName
ST -X- _ I-TaskName
models -X- _ O
have -X- _ O
achieved -X- _ O
almost -X- _ O
comparable -X- _ O
(Bentivogli -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
or -X- _ O
even -X- _ O
superior -X- _ O
(Ansari -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Potapczyk -X- _ O
and -X- _ O
Przybysz, -X- _ O
2020; -X- _ O
Xu -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
performance. -X- _ O

An -X- _ O
E2E -X- _ B-TaskName
ST -X- _ I-TaskName
system -X- _ O
accepts -X- _ O
audio -X- _ O
signals -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
generates -X- _ O
the -X- _ O
target -X- _ O
translation -X- _ O
using -X- _ O
a -X- _ O
single -X- _ O
model. -X- _ O

End-to-end -X- _ B-TaskName
speech-to-text -X- _ I-TaskName
translation -X- _ I-TaskName
(E2E -X- _ B-TaskName
ST) -X- _ I-TaskName
becomes -X- _ O
important -X- _ O
in -X- _ O
many -X- _ O
internet -X- _ O
products -X- _ O
and -X- _ O
real -X- _ O
applications. -X- _ O

Introduction -X- _ O

com/ReneeYe/ConST. -X- _ O

Code -X- _ O
and -X- _ O
models -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https://github. -X- _ O

The -X- _ O
analysis -X- _ O
further -X- _ O
veriﬁes -X- _ O
that -X- _ O
ConST -X- _ B-MethodName
indeed -X- _ O
closes -X- _ O
the -X- _ O
representation -X- _ O
gap -X- _ O
of -X- _ O
different -X- _ O
modalities -X- _ O
— -X- _ O
its -X- _ O
learned -X- _ O
representation -X- _ O
improves -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
cross-modal -X- _ B-TaskName
speechtext -X- _ I-TaskName
retrieval -X- _ I-TaskName
from -X- _ O
4% -X- _ B-MetricValue
to -X- _ O
88%. -X- _ B-MetricValue

We -X- _ O
evaluate -X- _ O
ConST -X- _ B-MethodName
and -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
previous -X- _ O
baselines -X- _ O
on -X- _ O
a -X- _ O
popular -X- _ O
benchmark -X- _ O
MuST-C. -X- _ B-DatasetName
Experiments -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
ConST -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
the -X- _ O
previous -X- _ O
methods, -X- _ O
and -X- _ O
achieves -X- _ O
an -X- _ O
average -X- _ O
BLEU -X- _ B-MetricName
of -X- _ O
29.4. -X- _ B-MetricValue

To -X- _ O
this -X- _ O
end, -X- _ O
we -X- _ O
propose -X- _ O
ConST, -X- _ B-MethodName
a -X- _ O
cross-modal -X- _ B-MethodName
contrastive -X- _ I-MethodName
learning -X- _ I-MethodName
method -X- _ O
for -X- _ O
end-to-end -X- _ B-TaskName
speech-to-text -X- _ I-TaskName
translation. -X- _ I-TaskName

Learning -X- _ O
similar -X- _ O
representations -X- _ O
for -X- _ O
semantically -X- _ O
similar -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
speech -X- _ B-TaskName
translation. -X- _ I-TaskName

How -X- _ O
can -X- _ O
we -X- _ O
learn -X- _ O
uniﬁed -X- _ O
representations -X- _ O
for -X- _ O
spoken -X- _ O
utterances -X- _ O
and -X- _ O
their -X- _ O
written -X- _ O
text? -X- _ O

Abstract -X- _ O

Cross-modal -X- _ B-MethodName
Contrastive -X- _ I-MethodName
Learning -X- _ I-MethodName
for -X- _ O
Speech -X- _ B-TaskName
Translation -X- _ I-TaskName

-DOCSTART- -X- O
References -X- _ O

Acknowledgements -X- _ O

Although -X- _ O
recent -X- _ O
works -X- _ O
on -X- _ O
automatic -X- _ O
selection -X- _ O
of -X- _ O
prompts -X- _ O
and -X- _ O
label -X- _ O
mappings -X- _ O
are -X- _ O
making -X- _ O
meaningful -X- _ O
contribution -X- _ O
to -X- _ O
the -X- _ O
practicability -X- _ O
of -X- _ O
few-shot -X- _ O
learning, -X- _ O
we -X- _ O
believe -X- _ O
more -X- _ O
work -X- _ O
should -X- _ O
be -X- _ O
done -X- _ O
to -X- _ O
simplify -X- _ O
the -X- _ O
learning -X- _ O
procedure -X- _ O
and -X- _ O
eliminate -X- _ O
human -X- _ O
effort -X- _ O
while -X- _ O
achieving -X- _ O
good -X- _ O
performance. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2, -X- _ O
64 -X- _ O
examples -X- _ O
per -X- _ O
class -X- _ O
are -X- _ O
enough -X- _ O
to -X- _ O
bring -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
standard -X- _ B-MethodName
fine-tuning -X- _ I-MethodName
to -X- _ O
the -X- _ O
same -X- _ O
level -X- _ O
of -X- _ O
prompting. -X- _ O

For -X- _ O
most -X- _ O
techniques, -X- _ O
the -X- _ O
required -X- _ O
effort -X- _ O
for -X- _ O
finding -X- _ O
good -X- _ O
templates -X- _ O
and -X- _ O
label -X- _ O
mappings, -X- _ O
and -X- _ O
sometimes -X- _ O
training -X- _ O
models -X- _ O
outweighs -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
simply -X- _ O
labeling -X- _ O
more -X- _ O
training -X- _ O
examples. -X- _ O

In -X- _ O
addition, -X- _ O
complicated -X- _ O
prompting -X- _ O
techniques -X- _ O
are -X- _ O
not -X- _ O
practically -X- _ O
useful -X- _ O
for -X- _ O
real-world -X- _ O
scenarios. -X- _ O

Also, -X- _ O
in-context -X- _ O
learning -X- _ O
cannot -X- _ O
handle -X- _ O
more -X- _ O
training -X- _ O
examples -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
maximum -X- _ O
length -X- _ O
limit -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
while -X- _ O
AMuLaP -X- _ B-MethodName
without -X- _ O
fine-tuning -X- _ O
gets -X- _ O
saturated -X- _ O
quickly, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O

However, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
our -X- _ O
Table -X- _ O
2, -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
backbone -X- _ O
model -X- _ O
, -X- _ O
GPT-3-style -X- _ B-MethodName
in-context -X- _ I-MethodName
learning -X- _ I-MethodName
and -X- _ O
other -X- _ O
methods -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
access -X- _ O
the -X- _ O
model -X- _ O
weights -X- _ O
generally -X- _ O
underperform -X- _ O
those -X- _ O
with -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
weights -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin. -X- _ O

Brown -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
highlights -X- _ O
few-shot -X- _ O
prompting -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
mitigate -X- _ O
their -X- _ O
decision -X- _ O
to -X- _ O
not -X- _ O
release -X- _ O
the -X- _ O
model -X- _ O
weights. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
natural -X- _ O
contradiction -X- _ O
between -X- _ O
performance -X- _ O
and -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
weights. -X- _ O

More -X- _ O
broadly, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
point -X- _ O
out -X- _ O
some -X- _ O
limitation -X- _ O
and -X- _ O
contradictions -X- _ O
within -X- _ O
current -X- _ O
fewshot -X- _ O
prompting -X- _ O
techniques. -X- _ O

M -X- _ O

Jointly -X- _ O
searching -X- _ O
for -X- _ O
M -X- _ B-HyperparameterName
be -X- _ O
a -X- _ O
promising -X- _ O
direction -X- _ O
for -X- _ O
future -X- _ O
research. -X- _ O

However, -X- _ O
these -X- _ O
two -X- _ O
variables -X- _ O
are -X- _ O
closely -X- _ O
related -X- _ O
and -X- _ O
greedily -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
may -X- _ O
be -X- _ O
then -X- _ O
the -X- _ O
best -X- _ O
mapping -X- _ O
under -X- _ O
template -X- _ O
T -X- _ O
could -X- _ O
and -X- _ O
suboptimal. -X- _ O

Similar -X- _ O
to -X- _ O
our -X- _ O
paper, -X- _ O
previous -X- _ O
works -X- _ O
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
the -X- _ O
separately -X- _ O
search -X- _ O
for -X- _ O
a -X- _ O
prompt -X- _ O
template -X- _ O
label -X- _ O
mapping -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
more -X- _ O
to -X- _ O
explore -X- _ O
when -X- _ O
considering -X- _ O
the -X- _ O
prompt -X- _ O
template -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time. -X- _ O

In -X- _ O
this -X- _ O
paLimitations -X- _ O
and -X- _ O
Future -X- _ O
Directions -X- _ O
per, -X- _ O
we -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
selection -X- _ O
of -X- _ O
the -X- _ O
label -X- _ O
mapping -X- _ O
with -X- _ O
a -X- _ O
fixed -X- _ O
prompt -X- _ O
template. -X- _ O

Thus, -X- _ O
for -X- _ O
the -X- _ O
optimal -X- _ O
performance, -X- _ O
we -X- _ O
find -X- _ O
it -X- _ O
essential -X- _ O
to -X- _ O
search -X- _ O
k -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
development -X- _ O
set. -X- _ O

In -X- _ O
general, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
observe -X- _ O
a -X- _ O
clear -X- _ O
law -X- _ O
for -X- _ O
choosing -X- _ O
the -X- _ O
best -X- _ B-HyperparameterName
k -X- _ I-HyperparameterName
for -X- _ B-MethodName
AMuLaP. -X- _ I-MethodName
As -X- _ O
mentioned -X- _ O
before, -X- _ O
k -X- _ B-HyperparameterName
can -X- _ O
influence -X- _ O
both -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
of -X- _ O
labels -X- _ O
(in -X- _ O
both -X- _ O
ways) -X- _ O
and -X- _ O
the -X- _ O
training -X- _ O
procedure -X- _ O
(for -X- _ O
fine-tuning). -X- _ O

of -X- _ O
a -X- _ O
larger -X- _ O
k. -X- _ B-HyperparameterName

However, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
observe -X- _ O
significant -X- _ O
improvement -X- _ O
when -X- _ O
continuing -X- _ O
increasing -X- _ O
k -X- _ B-HyperparameterName
with -X- _ O
labels -X- _ O
selected -X- _ O
by -X- _ O
AMuLaP. -X- _ B-MethodName
As -X- _ O
we -X- _ O
analyze, -X- _ O
increasing -X- _ O
k -X- _ B-HyperparameterName
harms -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
of -X- _ O
selected -X- _ O
labels -X- _ O
and -X- _ O
thus -X- _ O
overrides -X- _ O
the -X- _ O
benefit -X- _ O

This -X- _ O
suggests -X- _ O
our -X- _ O
guess -X- _ O
may -X- _ O
be -X- _ O
correct. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
for -X- _ O
random -X- _ O
mapping, -X- _ O
more -X- _ O
labels -X- _ O
(i.e., -X- _ O
a -X- _ O
larger -X- _ O
k) -X- _ B-HyperparameterName
often -X- _ O
leads -X- _ O
to -X- _ O
better -X- _ O
performance. -X- _ O

To -X- _ O
verify -X- _ O
this -X- _ O
guess, -X- _ O
we -X- _ O
test -X- _ O
the -X- _ O
fine-tuning -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
random -X- _ O
mapping -X- _ O
with -X- _ O
different -X- _ O
labels -X- _ O
selected. -X- _ O

Allowing -X- _ O
multiple -X- _ O
labels -X- _ O
can -X- _ O
resolve -X- _ O
mishaps -X- _ O
like -X- _ O
this -X- _ O
and -X- _ O
thus -X- _ O
improve -X- _ O
the -X- _ O
final -X- _ O
performance. -X- _ O

This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
format -X- _ O
processing -X- _ O
in -X- _ O
the -X- _ O
pretraining -X- _ O
of -X- _ O
. -X- _ O

One -X- _ O
example -X- _ O
is -X- _ O
the -X- _ O
meaningless -X- _ O
</s> -X- _ O
(endof-sequence -X- _ O
marker) -X- _ O
label -X- _ O
found -X- _ O
by -X- _ O
AMuLaP, -X- _ B-MethodName
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

Under -X- _ O
a -X- _ O
few-shot -X- _ O
setting, -X- _ O
the -X- _ O
limited -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
examples -X- _ O
n -X- _ O
and -X- _ O
complex -X- _ O
training -X- _ O
procedure -X- _ O
of -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
can -X- _ O
often -X- _ O
bring -X- _ O
noise -X- _ O
to -X- _ O
both -X- _ O
automatic -X- _ O
label -X- _ O
selection -X- _ O
and -X- _ O
inference. -X- _ O

However, -X- _ O
we -X- _ O
find -X- _ O
this -X- _ O
explanation -X- _ O
insufficient -X- _ O
for -X- _ O
understanding -X- _ O
the -X- _ O
mechanism -X- _ O
behind -X- _ O
the -X- _ O
improved -X- _ O
performance -X- _ O
with -X- _ O
multiple -X- _ O
labels. -X- _ O

Why -X- _ O
Does -X- _ O
AMuLaP -X- _ B-MethodName
Work? -X- _ O

7 -X- _ O
Discussion -X- _ O

With -X- _ O
only -X- _ O
one -X- _ O
example, -X- _ O
AMuLaP -X- _ B-MethodName
achieves -X- _ O
decent -X- _ O
performance -X- _ O
while -X- _ O
standard -X- _ B-MethodName
fine-tuning -X- _ I-MethodName
is -X- _ O
close -X- _ O
to -X- _ O
random. -X- _ O

In -X- _ O
addition, -X- _ O
the -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
AMuLaP -X- _ O
especially -X- _ O
for -X- _ O
extreme -X- _ O
few-shot -X- _ O
settings. -X- _ O

For -X- _ O
MRPC, -X- _ B-DatasetName
although -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
AMuLaP -X- _ B-MethodName
and -X- _ O
standard -X- _ B-MethodName
fine-tuning -X- _ I-MethodName
fluctuate -X- _ O
as -X- _ O
n -X- _ B-HyperparameterName
increases, -X- _ O
in -X- _ O
general, -X- _ O
AMuLaP -X- _ B-MethodName
with -X- _ O
fine-tuning -X- _ O
can -X- _ O
still -X- _ O
achieve -X- _ O
comparable -X- _ O
performance -X- _ O
to -X- _ O
standard -X- _ B-MethodName
fine-tuning. -X- _ I-MethodName

For -X- _ O
a -X- _ O
harder -X- _ O
task -X- _ O
like -X- _ O
MNLI, -X- _ B-DatasetName
although -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
AMuLaP -X- _ B-MethodName
under -X- _ O
nonfinetuning -X- _ O
setting -X- _ O
gradually -X- _ O
becomes -X- _ O
saturated -X- _ O
as -X- _ O
n -X- _ O
increases, -X- _ O
AMuLaP -X- _ B-MethodName
under -X- _ O
fine-tuning -X- _ O
settings -X- _ O
continues -X- _ O
to -X- _ O
improve -X- _ O
as -X- _ O
n -X- _ B-HyperparameterName
increases -X- _ O
and -X- _ O
continues -X- _ O
to -X- _ O
outperform -X- _ O
the -X- _ O
standard -X- _ O
fine-tuning. -X- _ O

For -X- _ O
an -X- _ O
easier -X- _ O
task -X- _ O
like -X- _ O
SST-2, -X- _ B-DatasetName
although -X- _ O
only -X- _ O
32 -X- _ O
training -X- _ O
examples -X- _ O
are -X- _ O
used, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
AMuLaP -X- _ B-MethodName
with -X- _ O
non-finetuning -X- _ O
and -X- _ O
fine-tuning -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
saturation -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
comparable -X- _ O
to -X- _ O
standard -X- _ O
fine-tuning -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
dataset. -X- _ O

When -X- _ O
using -X- _ O
more -X- _ O
than -X- _ O
16 -X- _ O
training -X- _ O
examples, -X- _ O
AMuLaP -X- _ B-MethodName
under -X- _ O
fine-tuning -X- _ O
setting -X- _ O
still -X- _ O
out -X- _ O

For -X- _ O
MNLI -X- _ B-DatasetName
and -X- _ O
SST-2 -X- _ B-DatasetName
task, -X- _ O
AMuLaP -X- _ B-MethodName
outperforms -X- _ O
standard -X- _ O
fine-tuning -X- _ O
when -X- _ O
we -X- _ O
use -X- _ O
no -X- _ O
more -X- _ O
than -X- _ O
16 -X- _ O
training -X- _ O
examples -X- _ O
for -X- _ O
non-finetuning -X- _ O
and -X- _ O
fine-tuning -X- _ O
setting. -X- _ O

Figure -X- _ O
2 -X- _ O
illustrates -X- _ O
how -X- _ O
standard -X- _ O
fine-tuning -X- _ O
and -X- _ O
our -X- _ O
AMuLaP -X- _ B-MethodName
with -X- _ O
non-finetuning -X- _ O
and -X- _ O
fine-tuning -X- _ O
compare -X- _ O
as -X- _ O
n -X- _ B-HyperparameterName
increases. -X- _ O

Similarly, -X- _ O
in -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
test -X- _ O
how -X- _ O
AMuLaP -X- _ B-MethodName
scales -X- _ O
to -X- _ O
different -X- _ O
training -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
sizes -X- _ I-HyperparameterName
n. -X- _ B-HyperparameterName

Le -X- _ O
Scao -X- _ O
and -X- _ O
Rush -X- _ O
(2021) -X- _ O
explore -X- _ O
the -X- _ O
scaling -X- _ O
law -X- _ O
of -X- _ O
PET -X- _ O
(Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021a) -X- _ O
when -X- _ O
using -X- _ O
more -X- _ O
examples -X- _ O
for -X- _ O
training. -X- _ O

6.3 -X- _ O
Scaling -X- _ O
Few-Shot -X- _ O
Learning -X- _ O

An -X- _ O
interesting -X- _ O
exception -X- _ O
is -X- _ O
that -X- _ O
for -X- _ O
CoLA, -X- _ B-DatasetName
the -X- _ O
random -X- _ O
mapping -X- _ O
outperforms -X- _ O
all -X- _ O
label -X- _ O
selection -X- _ O
methods -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
(both -X- _ O
manual -X- _ O
and -X- _ O
automatic) -X- _ O
and -X- _ O
is -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
fine-tuning -X- _ O
baseline. -X- _ O

Moreover, -X- _ O
a -X- _ O
random -X- _ O
label -X- _ O
mapping -X- _ O
often -X- _ O
leads -X- _ O
to -X- _ O
lower -X- _ O
performance -X- _ O
than -X- _ O
a -X- _ O
label -X- _ O
mapping -X- _ O
selected -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set. -X- _ O

Also, -X- _ O
our -X- _ O
multi-label -X- _ O
strategy -X- _ O
is -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
at -X- _ O
improving -X- _ O
the -X- _ O
average -X- _ O
GLUE -X- _ B-DatasetName
scores -X- _ O
by -X- _ O
3.6 -X- _ B-MetricValue
and -X- _ O
1.1 -X- _ B-MetricValue
for -X- _ O
non-finetuning -X- _ O
and -X- _ O
fine-tuning -X- _ O
settings, -X- _ O
respectively. -X- _ O

maps -X- _ O
to -X- _ O
two -X- _ O
classes, -X- _ O
optimization -X- _ O
would -X- _ O
be -X- _ O
difficult -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
contradiction -X- _ O
of -X- _ O
supervision -X- _ O
signals. -X- _ O

Notably, -X- _ O
deduplication -X- _ O
is -X- _ O
especially -X- _ O
important -X- _ O
for -X- _ O
prompt-based -X- _ O
fine-tuning -X- _ O
since -X- _ O
if -X- _ O
the -X- _ O
same -X- _ O
label -X- _ O

For -X- _ O
both -X- _ O
non-finetuning -X- _ O
and -X- _ O
prompt-based -X- _ O
fine-tuning -X- _ O
settings, -X- _ O
our -X- _ O
deduplication -X- _ O
algorithm -X- _ O
can -X- _ O
effectively -X- _ O
improve -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
by -X- _ O
1.1 -X- _ B-MetricValue
and -X- _ O
9.9 -X- _ B-MetricValue
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
average -X- _ O
score, -X- _ O
respectively. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
each -X- _ O
design -X- _ O
choice -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark. -X- _ O

6.2 -X- _ O
Ablation -X- _ O
Study -X- _ O

This -X- _ O
may -X- _ O
explain -X- _ O
why -X- _ O
AMuLaP -X- _ B-MethodName
works -X- _ O
well, -X- _ O
especially -X- _ O
for -X- _ O
the -X- _ O
nonfinetuning -X- _ O
settings. -X- _ O

Additionally, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
highlight -X- _ O
that -X- _ O
AMuLaP -X- _ B-MethodName
mainly -X- _ O
collects -X- _ O
common -X- _ O
words -X- _ O
while -X- _ O
other -X- _ O
methods -X- _ O
prefer -X- _ O
rare -X- _ O
words. -X- _ O

Thus, -X- _ O
introducing -X- _ O
top-k -X- _ O
truncation -X- _ O
can -X- _ O
resolve -X- _ O
the -X- _ O
problem. -X- _ O

Although -X- _ O
AMuLaP -X- _ B-MethodName
outputs -X- _ O
three -X- _ O
labels -X- _ O
that -X- _ O
are -X- _ O
rated -X- _ O
not -X- _ O
suitable -X- _ O
by -X- _ O
the -X- _ O
human -X- _ O
annotator, -X- _ O
it -X- _ O
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
all -X- _ O
three -X- _ O
tokens -X- _ O
are -X- _ O
ranked -X- _ O
low -X- _ O
in -X- _ O
the -X- _ O
candidate -X- _ O
set. -X- _ O

AMuLaP -X- _ B-MethodName
achieves -X- _ O
interpretability -X- _ O
that -X- _ O
is -X- _ O
competitive -X- _ O
to -X- _ O
automatic -X- _ O
labels -X- _ O
obtained -X- _ O
by -X- _ O
a -X- _ O
fine-tuned -X- _ O
pretrained -X- _ O
language -X- _ O
model, -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
human -X- _ B-MetricName
agreement -X- _ I-MetricName
ratio. -X- _ I-MetricName

PETAL-CE -X- _ B-MethodName
suffers -X- _ O
from -X- _ O
incorrect -X- _ O
mappings -X- _ O
for -X- _ O
“negative” -X- _ O
while -X- _ O
PETAL-LR -X- _ B-MethodName
occasionally -X- _ O
outputs -X- _ O
vague -X- _ O
labels. -X- _ O

We -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
5 -X- _ O
runs -X- _ O
along -X- _ O
with -X- _ O
their -X- _ O
standard -X- _ O
deviation -X- _ O
in -X- _ O
the -X- _ O
parentheses. -X- _ O

All -X- _ O
of -X- _ O
these -X- _ O
we -X- _ O
use -X- _ O
are -X- _ O
from -X- _ O
https://github.com/princeton-nlp/ -X- _ O
LM-BFF/tree/main/auto_label_mapping. -X- _ O

No -X- _ O
external -X- _ O
data -X- _ O
used. -X- _ O

2The -X- _ O
validation -X- _ O
scores -X- _ O
of -X- _ O
all -X- _ O
fine-tuned -X- _ O
assignments -X- _ O
are -X- _ O
obtained -X- _ O
on -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

We -X- _ O
shuffle -X- _ O
the -X- _ O
labels -X- _ O
from -X- _ O
each -X- _ O
model -X- _ O
and -X- _ O
ask -X- _ O
a -X- _ O
human -X- _ O
annotator -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3, -X- _ O
we -X- _ O
list -X- _ O
the -X- _ O
10 -X- _ O
most -X- _ O
likely -X- _ O
label -X- _ O
mappings -X- _ O
output -X- _ O
by -X- _ O
PETAL -X- _ B-MethodName
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
Auto-L -X- _ B-MethodName
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
AMuLaP -X- _ B-MethodName
for -X- _ O
the -X- _ O
SST-2 -X- _ B-DatasetName
dataset, -X- _ O
respectively. -X- _ O

6.1 -X- _ O
Case -X- _ O
Study -X- _ O

6 -X- _ O
Analysis -X- _ O

On -X- _ O
all -X- _ O
tasks -X- _ O
except -X- _ O
CoLA, -X- _ B-DatasetName
AMuLaP -X- _ B-MethodName
outperforms -X- _ O
direct -X- _ O
few-shot -X- _ O
fine-tuning, -X- _ O
suggesting -X- _ O
that -X- _ O
prompting -X- _ O
is -X- _ O
a -X- _ O
promising -X- _ O
method -X- _ O
for -X- _ O
exploiting -X- _ O
large -X- _ O
pretrained -X- _ O
LMs. -X- _ O

Under -X- _ O
Setting -X- _ O
3, -X- _ O
AMuLaP -X- _ B-MethodName
FT -X- _ I-MethodName
outperforms -X- _ O
all -X- _ O
baselines -X- _ O
including -X- _ O
Auto-L. -X- _ B-MethodName
Generally -X- _ O
speaking, -X- _ O
methods -X- _ O
with -X- _ O
parameter -X- _ O
update -X- _ O
(Setting -X- _ O
3) -X- _ O
have -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
those -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
access -X- _ O
to -X- _ O
parameters. -X- _ O

Additionally, -X- _ O
we -X- _ O
attempt -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
predicted -X- _ O
token -X- _ O
distribution -X- _ O
of -X- _ O
AMuLaP -X- _ B-MethodName
with -X- _ O
the -X- _ O
validation -X- _ O
score -X- _ O
of -X- _ O
all -X- _ O
fine-tuned -X- _ O
assignments -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021).2 -X- _ O
With -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
many -X- _ O
trials -X- _ O
in -X- _ O
automatic -X- _ O
search, -X- _ O
AMuLaP -X- _ B-MethodName
outperforms -X- _ O
Auto-L -X- _ B-MethodName
by -X- _ O
a -X- _ O
considerable -X- _ O
margin -X- _ O
of -X- _ O
3.8 -X- _ B-MetricValue
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
average -X- _ O
score, -X- _ O
verifying -X- _ O
the -X- _ O
versatility -X- _ O
of -X- _ O
our -X- _ O
multi-label -X- _ O
mechanism -X- _ O
and -X- _ O
label -X- _ O
selection -X- _ O
algorithm. -X- _ O

Notably, -X- _ O
AMuLaP -X- _ B-MethodName
even -X- _ O
outperforms -X- _ O
Auto-L -X- _ B-MethodName
by -X- _ O
1.3 -X- _ B-MetricValue
without -X- _ O
using -X- _ O
any -X- _ O
external -X- _ O
model -X- _ O
or -X- _ O
data. -X- _ O

Under -X- _ O
Setting -X- _ O
2, -X- _ O
compared -X- _ O
to -X- _ O
variants -X- _ O
of -X- _ O
PETAL -X- _ B-MethodName
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
AMuLaP -X- _ B-MethodName
has -X- _ O
an -X- _ O
advantage -X- _ O
of -X- _ O
5.8 -X- _ B-MetricValue
and -X- _ O
8.5 -X- _ B-MetricValue
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
over -X- _ O
CE -X- _ B-MethodName
and -X- _ O
LR, -X- _ B-MethodName
respectively. -X- _ O

outperforms -X- _ O
GPT-3-style -X- _ B-MethodName
in-context -X- _ O
learning -X- _ O
by -X- _ O
4.5 -X- _ B-MetricValue
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
and -X- _ O
outperforms -X- _ O
zero-shot -X- _ O
inference -X- _ O
with -X- _ O
manually -X- _ O
designed -X- _ O
labels -X- _ O
by -X- _ O
2.4. -X- _ B-MetricValue

Under -X- _ O
Setting -X- _ O
1, -X- _ O
AMuLaP -X- _ B-MethodName

We -X- _ O
demonstrate -X- _ O
experimental -X- _ O
results -X- _ O
under -X- _ O
three -X- _ O
settings -X- _ O
in -X- _ O
Table -X- _ O
2. -X- _ O

5.2 -X- _ O
Experimental -X- _ O
Results -X- _ O

Following -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
we -X- _ O
grid -X- _ O
search -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
from -X- _ O
{1e-5, -X- _ B-HyperparameterValue
2e-5, -X- _ B-HyperparameterValue
5e-5} -X- _ B-HyperparameterValue
and -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ B-HyperparameterName
from -X- _ O
{2, -X- _ B-HyperparameterValue
4, -X- _ B-HyperparameterValue
8}. -X- _ B-HyperparameterValue

For -X- _ O
prompt-based -X- _ B-MethodName
fine-tuning -X- _ I-MethodName
(Setting -X- _ O
3), -X- _ O
where -X- _ O
we -X- _ O
, -X- _ O
we -X- _ O
search -X- _ O
k -X- _ B-HyperparameterName
in -X- _ O
a -X- _ O
smaller -X- _ O
fine-tune -X- _ O
the -X- _ O
model -X- _ O
L -X- _ O
1, -X- _ B-HyperparameterValue
2, -X- _ B-HyperparameterValue
4, -X- _ B-HyperparameterValue
8, -X- _ B-HyperparameterValue
16 -X- _ B-HyperparameterValue
due -X- _ O
to -X- _ O
the -X- _ O
increased -X- _ O
compuspace -X- _ O
} -X- _ O
tational -X- _ O
overhead. -X- _ O

Note -X- _ O
that -X- _ O
for -X- _ O
settings -X- _ O
that -X- _ O
do -X- _ O
} -X- _ O
{ -X- _ O
, -X- _ O
search -X- _ O
over -X- _ O
k -X- _ B-HyperparameterName
is -X- _ O
not -X- _ O
update -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
fast, -X- _ O
as -X- _ O
we -X- _ O
only -X- _ O
need -X- _ O
to -X- _ O
run -X- _ O
the -X- _ O
model -X- _ O
once -X- _ O
and -X- _ O
cache -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
[MASK] -X- _ O
token. -X- _ O

When -X- _ O
selecting -X- _ O
k, -X- _ B-HyperparameterName
if -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
k -X- _ B-HyperparameterName
with -X- _ O
identical -X- _ O
performance -X- _ O
(which -X- _ O
happens -X- _ O
occasionally -X- _ O
given -X- _ O
there -X- _ O
are -X- _ O
only -X- _ O
16 -X- _ O
examples -X- _ O
for -X- _ O
each -X- _ O
class -X- _ O
in -X- _ O
Ddev -X- _ O
), -X- _ O
we -X- _ O
always -X- _ O
choose -X- _ O
the -X- _ O
largest -X- _ O
k. -X- _ B-HyperparameterName
For -X- _ O
Settings -X- _ O
1 -X- _ O
and -X- _ O
2, -X- _ O
we -X- _ O
search -X- _ O
k -X- _ B-HyperparameterName
over -X- _ O
1, -X- _ B-HyperparameterValue
2, -X- _ B-HyperparameterValue
4, -X- _ B-HyperparameterValue
. -X- _ O
. -X- _ O
. -X- _ O

Implementation -X- _ O
Details -X- _ O
We -X- _ O
implement -X- _ O
AMuLaP -X- _ B-MethodName
based -X- _ O
on -X- _ O
Hugging -X- _ O
Face -X- _ O
Transformers -X- _ O
(Wolf -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

This -X- _ O
setting -X- _ O
is -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
conventional -X- _ B-MethodName
finetuning, -X- _ I-MethodName
prompt-based -X- _ O
fine-tuning -X- _ O
with -X- _ O
manual -X- _ B-MethodName
prompts, -X- _ I-MethodName
Auto-L -X- _ B-MethodName
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
PETAL -X- _ B-MethodName
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Ddev -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way -X- _ O
as -X- _ O
Setting -X- _ O
2 -X- _ O
but -X- _ O
fine-tune -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O

Dtrain -X- _ O
and -X- _ O

• -X- _ O
Setting -X- _ O
3: -X- _ O
We -X- _ O
use -X- _ O

This -X- _ O
setting -X- _ O
is -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
Auto-L -X- _ B-MethodName
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
PETAL -X- _ B-MethodName
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

The -X- _ O
paand -X- _ O
an -X- _ O
additional -X- _ O
rameters -X- _ O
of -X- _ O
are -X- _ O
not -X- _ O
updated. -X- _ O

• -X- _ O
Setting -X- _ O
2: -X- _ O
We -X- _ O
use -X- _ O
Dtrain -X- _ O
for -X- _ O
label -X- _ O
selection -X- _ O
Ddev -X- _ O
for -X- _ O
k -X- _ B-HyperparameterName
tuning. -X- _ O

The -X- _ O
parameters -X- _ O
Ddev -X- _ O
is -X- _ O
not -X- _ O
used. -X- _ O

Dtrain -X- _ O
alone -X- _ O
for -X- _ O
both -X- _ O
label -X- _ O
selection -X- _ O
and -X- _ O
tuning -X- _ O
k. -X- _ B-HyperparameterName

• -X- _ O
Setting -X- _ O
1: -X- _ O
We -X- _ O
only -X- _ O
use -X- _ O

L -X- _ O

To -X- _ O
fairly -X- _ O
compare -X- _ O
with -X- _ O
different -X- _ O
baselines, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
settings: -X- _ O

We -X- _ O
also -X- _ O
report -X- _ O
the -X- _ O
standard -X- _ O
deviation -X- _ O
for -X- _ O
each -X- _ O
result. -X- _ O

Following -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
the -X- _ O
original -X- _ O
development -X- _ O
split -X- _ O
of -X- _ O
each -X- _ O
dataset -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
in -X- _ O
our -X- _ O
experiments. -X- _ O

For -X- _ O
each -X- _ O
reported -X- _ O
result, -X- _ O
we -X- _ O
measure -X- _ O
average -X- _ O
performance -X- _ O
across -X- _ O
5 -X- _ O
different -X- _ O
randomly -X- _ O
sampled -X- _ O
Dtrain -X- _ O
and -X- _ O
Ddev -X- _ O
splits. -X- _ O

We -X- _ O
use -X- _ O
RoBERTalarge -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
LM -X- _ O
. -X- _ O

We -X- _ O
set -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
16 -X- _ B-HyperparameterValue
throughout -X- _ O
all -X- _ O
experiments. -X- _ O

We -X- _ O
sample -X- _ O
n -X- _ B-HyperparameterValue
training -X- _ B-HyperparameterName
examples -X- _ I-HyperparameterName
and -X- _ O
n -X- _ B-HyperparameterValue
development -X- _ B-HyperparameterName
examples -X- _ I-HyperparameterName
per -X- _ O
class. -X- _ O

Task -X- _ O
Setup -X- _ O
We -X- _ O
closely -X- _ O
follow -X- _ O
the -X- _ O
setup -X- _ O
in -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
officially -X- _ O
released -X- _ O
code -X- _ O
and -X- _ O
same -X- _ O
hyperparameters -X- _ O
for -X- _ O
this -X- _ O
baseline. -X- _ O

The -X- _ O
detailed -X- _ O
description -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
baseline -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
those -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
of -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
since -X- _ O
they -X- _ O
search -X- _ O
for -X- _ O
both -X- _ O
templates -X- _ O
and -X- _ O
label -X- _ O
mapping -X- _ O
whereas -X- _ O
we -X- _ O
fix -X- _ O
the -X- _ O
templates -X- _ O
and -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
label -X- _ O
mapping -X- _ O
alone, -X- _ O
for -X- _ O
the -X- _ O
sake -X- _ O
of -X- _ O
fair -X- _ O
comparison. -X- _ O

• -X- _ O
Auto-L -X- _ B-MethodName
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021): -X- _ O
the -X- _ O
automatic -X- _ O
label -X- _ O
searching -X- _ O
method -X- _ O
with -X- _ O
an -X- _ O
external -X- _ O
pretrained -X- _ O
language -X- _ O
model, -X- _ O
RoBERTa-large -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

• -X- _ O
PETAL-LR -X- _ B-MethodName
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020): -X- _ O
the -X- _ O
variant -X- _ O
of -X- _ O
PETAL -X- _ O
using -X- _ O
the -X- _ O
likelihood -X- _ O
ratio -X- _ O
metric. -X- _ O

• -X- _ O
PETAL-CE -X- _ B-MethodName
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020): -X- _ O
the -X- _ O
variant -X- _ O
of -X- _ O
PETAL -X- _ O
using -X- _ O
the -X- _ O
cross-entropy -X- _ O
metric. -X- _ O

designed -X- _ O
prompts -X- _ O
in -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

• -X- _ O
Manual -X- _ B-MethodName
prompts: -X- _ I-MethodName
we -X- _ O
use -X- _ O
the -X- _ O
human -X- _ O

• -X- _ O
GPT-3-style -X- _ B-MethodName
in-context -X- _ I-MethodName
learning -X- _ I-MethodName
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020): -X- _ O
present -X- _ O
a -X- _ O
few -X- _ O
examples -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
make -X- _ O
it -X- _ O
directly -X- _ O
predict -X- _ O
the -X- _ O
next -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
prediction. -X- _ O

• -X- _ O
Majority: -X- _ B-MethodName
always -X- _ O
predict -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
to -X- _ O
various -X- _ O
baselines: -X- _ O

Baselines -X- _ O

The -X- _ O
metrics -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
are -X- _ O
indicated -X- _ O
in -X- _ O
Table -X- _ O
2. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
manual -X- _ O
templates -X- _ O
in -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
as -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

Natural -X- _ O
Language -X- _ O
Inference -X- _ O
Mismatched -X- _ O
(MNLImm) -X- _ B-DatasetName
(Williams -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
Question -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
(QNLI) -X- _ B-DatasetName
(Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
and -X- _ O
Recognizing -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Entailment -X- _ I-DatasetName
(RTE) -X- _ B-DatasetName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
for -X- _ O
the -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
(NLI) -X- _ B-TaskName
task; -X- _ O
The -X- _ B-DatasetName
Corpus -X- _ I-DatasetName
of -X- _ I-DatasetName
Linguistic -X- _ I-DatasetName
Acceptability -X- _ I-DatasetName
(CoLA) -X- _ B-DatasetName
(Warstadt -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
for -X- _ O
Linguistic -X- _ B-TaskName
Acceptability. -X- _ I-TaskName

We -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
5 -X- _ O
runs -X- _ O
along -X- _ O
with -X- _ O
their -X- _ O
standard -X- _ O
deviation -X- _ O
in -X- _ O
the -X- _ O
parentheses. -X- _ O

Specifically, -X- _ O
we -X- _ O
test -X- _ O
on -X- _ O
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Matching -X- _ I-DatasetName
(MRPC) -X- _ B-DatasetName
(Dolan -X- _ O
and -X- _ O
Brockett, -X- _ O
2005), -X- _ O
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
(QQP) -X- _ B-DatasetName
for -X- _ O
Paraphrase -X- _ B-TaskName
Similarity -X- _ I-TaskName
Matching; -X- _ I-TaskName
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
(SST-2) -X- _ B-DatasetName
(Socher -X- _ O
et -X- _ O
al., -X- _ O
2013) -X- _ O
for -X- _ O
Sentiment -X- _ B-TaskName
Classification; -X- _ I-TaskName
Multi-Genre -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
Matched -X- _ I-DatasetName
(MNLI-m), -X- _ B-DatasetName
Multi-Genre -X- _ O

Datasets -X- _ O
We -X- _ O
evaluate -X- _ O
seven -X- _ O
classification -X- _ B-TaskName
tasks -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

5.1 -X- _ O
Experimental -X- _ O
Setting -X- _ O

5 -X- _ O
Experiments -X- _ O

Then, -X- _ O
we -X- _ O
can -X- _ O
truncate -X- _ O
the -X- _ O
candidate -X- _ O
sets -X- _ O
of -X- _ O
each -X- _ O
class -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
k -X- _ O
most -X- _ O
likely -X- _ O
tokens -X- _ O
from -X- _ O
each -X- _ O
set. -X- _ O

To -X- _ O
ensure -X- _ O
this, -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
iterate -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
and -X- _ O
check -X- _ O
that -X- _ O
for -X- _ O
every -X- _ O
token. -X- _ O

Thus, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
make -X- _ O
sure -X- _ O
that -X- _ O
(2) -X- _ O
Each -X- _ O
token -X- _ O
only -X- _ O
belongs -X- _ O
to -X- _ O
at -X- _ O
most -X- _ O
one -X- _ O
label -X- _ O
set -X- _ O
where -X- _ O
it -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
probability. -X- _ O

For -X- _ O
example, -X- _ O
if -X- _ O
we -X- _ O
simply -X- _ O
take -X- _ O
the -X- _ O
10 -X- _ O
most -X- _ O
likely -X- _ O
tokens -X- _ O
for -X- _ O
the -X- _ O
SST-2 -X- _ B-DatasetName
dataset -X- _ O
(Socher -X- _ O
et -X- _ O
al., -X- _ O
2013), -X- _ O
we -X- _ O
would -X- _ O
find -X- _ O
“good” -X- _ O
in -X- _ O
both -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
label -X- _ O
sets, -X- _ O
although -X- _ O
it -X- _ O
is -X- _ O
ranked -X- _ O
second -X- _ O
place -X- _ O
in -X- _ O
the -X- _ O
positive -X- _ O
set -X- _ O
and -X- _ O
ninth -X- _ O
in -X- _ O
the -X- _ O
negative -X- _ O
set. -X- _ O

However, -X- _ O
in -X- _ O
practice, -X- _ O
we -X- _ O
would -X- _ O
find -X- _ O
common -X- _ O
words -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
label -X- _ O
set. -X- _ O

A -X- _ O
simple -X- _ O
solution -X- _ O
is -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
k -X- _ O
most -X- _ O
likely -X- _ O
tokens -X- _ O
predicted -X- _ O
for -X- _ O
the -X- _ O
[MASK] -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
examples -X- _ O
of -X- _ O
each -X- _ O
class -X- _ O
y. -X- _ O

For -X- _ O
example, -X- _ O
in -X- _ O
a -X- _ O
sentiment -X- _ O
classification -X- _ O
task, -X- _ O
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
see -X- _ O
positive -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
label -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
“positive” -X- _ O
class -X- _ O
while -X- _ O
negative -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
label -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
“negative” -X- _ O
class. -X- _ O

We -X- _ O
aim -X- _ O
to -X- _ O
achieve -X- _ O
two -X- _ O
goals: -X- _ O
(1) -X- _ O
Selecting -X- _ O
the -X- _ O
most -X- _ O
likely -X- _ O
label -X- _ O
mapping -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set. -X- _ O

Finally, -X- _ O
for -X- _ O
each -X- _ O
class, -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
top-k -X- _ B-HyperparameterName
tokens -X- _ O
as -X- _ O
label -X- _ O
words. -X- _ O

Then -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
is -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
class -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
probability -X- _ O
(e.g., -X- _ O
the -X- _ O
token -X- _ O
terrible -X- _ O
is -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
class -X- _ O
negative, -X- _ O
the -X- _ O
token -X- _ O
great -X- _ O
is -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
class -X- _ O
positive). -X- _ O

All -X- _ O
the -X- _ O
obtained -X- _ O
probability -X- _ O
distributions -X- _ O
are -X- _ O
summed -X- _ O
by -X- _ O
class -X- _ O
and -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
normalized -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
of -X- _ O
each -X- _ O
class. -X- _ O

Each -X- _ O
training -X- _ O
sample -X- _ O
with -X- _ O
the -X- _ O
task-specific -X- _ O
template -X- _ O
(the -X- _ O
underlined -X- _ O
text) -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
get -X- _ O
its -X- _ O
own -X- _ O
. -X- _ O

5486 -X- _ O

We -X- _ O
them -X- _ O
and -X- _ O
selecting -X- _ O
the -X- _ O
best -X- _ O
one -X- _ O
with -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
selection -X- _ O
algorithm -X- _ O
for -X- _ O
label -X- _ O
mapping -X- _ O
that -X- _ O
achieves -X- _ O
competitive -X- _ O
results -X- _ O
compared -X- _ O
to -X- _ O
previous -X- _ O
efforts. -X- _ O

(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
exploits -X- _ O
a -X- _ O
large -X- _ O
pretrained -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
(RoBERTa, -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
pruned -X- _ O
set -X- _ O
of -X- _ O
label -X- _ O
words -X- _ O
and -X- _ O
then -X- _ O
determine -X- _ O
the -X- _ O
final -X- _ O
mapping -X- _ O
by -X- _ O
fine-tuning -X- _ O
on -X- _ O
all -X- _ O
of -X- _ O
Ddev -X- _ O
. -X- _ O

(2020) -X- _ O
explores -X- _ O
automatic -X- _ O
label -X- _ O
mapping -X- _ O
searching -X- _ O
but -X- _ O
it -X- _ O
still -X- _ O
requires -X- _ O
manual -X- _ O
pre-filtering -X- _ O
and -X- _ O
significantly -X- _ O
underperforms -X- _ O
the -X- _ O
manual -X- _ O
mapping. -X- _ O

Previously, -X- _ O
Schick -X- _ O
and -X- _ O
Schütze -X- _ O
(2021a,b) -X- _ O
both -X- _ O
use -X- _ O
hand-crafted -X- _ O
label -X- _ O
mappings -X- _ O
while -X- _ O
Schick -X- _ O
et -X- _ O
al. -X- _ O

Selecting -X- _ O
a -X- _ O
good -X- _ O
label -X- _ O
mapping -X- _ O
often -X- _ O
requires -X- _ O
significant -X- _ O
human -X- _ O
effort, -X- _ O
including -X- _ O
domain -X- _ O
knowledge -X- _ O
and -X- _ O
trial-and-error. -X- _ O

Finding -X- _ O
a -X- _ O
good -X- _ O
label -X- _ O
mapping -X- _ O
is -X- _ O
non-trivial, -X- _ O
esM -X- _ O
pecially -X- _ O
when -X- _ O
M′ -X- _ O
maps -X- _ O
an -X- _ O
original -X- _ O
label -X- _ O
to -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
label -X- _ O
words -X- _ O
instead -X- _ O
of -X- _ O
one. -X- _ O

4.2 -X- _ O
Automatic -X- _ O
Label -X- _ O
Selection -X- _ O

l -X- _ O
= -X- _ O

Then, -X- _ O
we -X- _ O
can -X- _ O
simply -X- _ O
make -X- _ O
predictions -X- _ O
by -X- _ O
selecting -X- _ O
the -X- _ O
label -X- _ O
with -X- _ O
the -X- _ O
largest -X- _ O
likelihood. -X- _ O

We -X- _ O
denote -X- _ O
the -X- _ O
k. -X- _ O
For -X- _ O
class -X- _ O
, -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
is -X- _ O
calculated -X- _ O
as: -X- _ O

Instead -X- _ O
of -X- _ O
a -X- _ O
one-to-one -X- _ O
mapping -X- _ O
from -X- _ O
the -X- _ O
origto -X- _ O
to -X- _ O
(y) -X- _ O
of -X- _ O
k -X- _ O
words. -X- _ O

This -X- _ O
design -X- _ O
has -X- _ O
a -X- _ O
similar -X- _ O
advantage -X- _ O
of -X- _ O
exploiting -X- _ O
multiple -X- _ O
labels -X- _ O
without -X- _ O
training -X- _ O
and -X- _ O
ensembling -X- _ O
multiple -X- _ O
models. -X- _ O

We -X- _ O
instead -X- _ O
use -X- _ O
a -X- _ O
straightforward -X- _ O
sum -X- _ O
to -X- _ O
consider -X- _ O
multiple -X- _ O
label -X- _ O
words -X- _ O
when -X- _ O
making -X- _ O
predictions. -X- _ O

Schick -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
use -X- _ O
multiple -X- _ O
label -X- _ O
combinations -X- _ O
for -X- _ O
PET -X- _ O
(Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021a) -X- _ O
and -X- _ O
ensemble -X- _ O
them -X- _ O
afterwards. -X- _ O

This -X- _ O
can -X- _ O
be -X- _ O
resolved -X- _ O
by -X- _ O
introducing -X- _ O
multiple -X- _ O
label -X- _ O
words. -X- _ O

We -X- _ O
also -X- _ O
argue -X- _ O
that -X- _ O
selecting -X- _ O
only -X- _ O
one -X- _ O
label -X- _ O
(especially -X- _ O
automatically) -X- _ O
may -X- _ O
bring -X- _ O
noise. -X- _ O

Selecting -X- _ O
one -X- _ O
label -X- _ O
word -X- _ O
can -X- _ O
be -X- _ O
insufficient -X- _ O
for -X- _ O
some -X- _ O
complicated -X- _ O
tasks, -X- _ O
as -X- _ O
mentioned -X- _ O
in -X- _ O
Schick -X- _ O
et -X- _ O
al. -X- _ O
(2020). -X- _ O

4.1 -X- _ O
Exploiting -X- _ O
Multiple -X- _ O
Labels -X- _ O

4 -X- _ O
Automatic -X- _ O
Multi-Label -X- _ O
Prompting -X- _ O

| -X- _ O
Alternately, -X- _ O
one -X- _ O
can -X- _ O
further -X- _ O
fine-tune -X- _ O
pervised -X- _ O
pairs -X- _ O
performance. -X- _ O

The -X- _ O
templates -X- _ O
used -X- _ O
for -X- _ O
prompting -X- _ O
are -X- _ O
from -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

and -X- _ O

Since -X- _ O
complete -X- _ O
the -X- _ O
[MASK] -X- _ O
token -X- _ O
in -X- _ O
an -X- _ O
input -X- _ O
sequence, -X- _ O
we -X- _ O
can -X- _ O
directly -X- _ O
make -X- _ O
zero-shot -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
class -X- _ O
y -X- _ O
by -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O

Note -X- _ O
that -X- _ O
since -X- _ O
we -X- _ O
T -X- _ O
focus -X- _ O
on -X- _ O
automatically -X- _ O
finding -X- _ O
the -X- _ O
label -X- _ O
mapping -X- _ O
from -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
manual -X- _ O
templates -X- _ O
M -X- _ O
T -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
(2021) -X- _ O
throughout -X- _ O
this -X- _ O
paper. -X- _ O

We -X- _ O
then -X- _ O
map -X- _ O
the -X- _ O
original -X- _ O
label -X- _ O
space -X- _ O
to -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
selected -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
vocabuY -X- _ O
→ -X- _ O
V -X- _ O
′. -X- _ O
Some -X- _ O
examples -X- _ O
of -X- _ O
lary, -X- _ O
denoted -X- _ O
as -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

For -X- _ O
an -X- _ O
input -X- _ O
example -X- _ O
x -X- _ O
(a -X- _ O
single -X- _ O
sentence -X- _ O
or -X- _ O
a -X- _ O
sentence -X- _ O
pair), -X- _ O
we -X- _ O
first -X- _ O
use -X- _ O
a -X- _ O
task-specific -X- _ O
temto -X- _ O
convert -X- _ O
it -X- _ O
to -X- _ O
x′, -X- _ O
a -X- _ O
token -X- _ O
sequence -X- _ O
with -X- _ O
plate -X- _ O
a -X- _ O
[MASK] -X- _ O
token. -X- _ O

Thus, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
few-shot -X- _ O
development -X- _ O
set -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
(i.e., -X- _ O
), -X- _ O
to -X- _ O
be -X- _ O
consistent -X- _ O
with -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
and -X- _ O
constitute -X- _ O
a -X- _ O
“true -X- _ O
few-shot” -X- _ O
setting -X- _ O
(Perez -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

As -X- _ O
pointed -X- _ O
out -X- _ O
in -X- _ O
Perez -X- _ O
et -X- _ O
al. -X- _ O
(2021), -X- _ O
using -X- _ O
the -X- _ O
full -X- _ O
development -X- _ O
set -X- _ O
may -X- _ O
be -X- _ O
misleading -X- _ O
to -X- _ O
claim -X- _ O
a -X- _ O
few-shot -X- _ O
setting. -X- _ O

Given -X- _ O
a -X- _ O
pretrained -X- _ O
and -X- _ O
its -X- _ O
defined -X- _ O
label -X- _ O
language -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
n -X- _ O
training -X- _ O
examples -X- _ O
per -X- _ O
class -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
Dtrain -X- _ O
. -X- _ O

We -X- _ O
follow -X- _ O
the -X- _ O
setup -X- _ O
in -X- _ O
LM-BFF -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
for -X- _ O
few-shot -X- _ B-TaskName
text -X- _ I-TaskName
classification. -X- _ I-TaskName

3 -X- _ O
Prompting -X- _ O
for -X- _ O
Few-Shot -X- _ B-TaskName
Classification -X- _ I-TaskName

Different -X- _ O
from -X- _ O
these -X- _ O
works, -X- _ O
AMuLaP -X- _ B-MethodName
is -X- _ O
a -X- _ O
discrete -X- _ O
prompting -X- _ O
method -X- _ O
that -X- _ O
has -X- _ O
better -X- _ O
interpretability -X- _ O
and -X- _ O
works -X- _ O
well -X- _ O
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting. -X- _ O

Notably, -X- _ O
different -X- _ O
from -X- _ O
discrete -X- _ O
prompting, -X- _ O
these -X- _ O
works -X- _ O
often -X- _ O
use -X- _ O
all -X- _ O
training -X- _ O
data -X- _ O
to -X- _ O
update -X- _ O
model -X- _ O
weights. -X- _ O

Guo -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
introduces -X- _ O
Q-Learning -X- _ O
to -X- _ O
optimize -X- _ O
the -X- _ O
soft -X- _ O
prompt. -X- _ O

Lester -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
reveals -X- _ O
that -X- _ O
prompt -X- _ O
tuning -X- _ O
is -X- _ O
more -X- _ O
competitive -X- _ O
when -X- _ O
scaled -X- _ O
up -X- _ O
and -X- _ O
can -X- _ O
achieve -X- _ O
identical -X- _ O
performance -X- _ O
to -X- _ O
conventional -X- _ O
fine-tuning -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
large -X- _ O
enough. -X- _ O

Li -X- _ O
and -X- _ O
Liang -X- _ O
(2021) -X- _ O
applies -X- _ O
a -X- _ O
similar -X- _ O
method -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
generation -X- _ O
and -X- _ O
achieves -X- _ O
comparable -X- _ O
performance -X- _ O
to -X- _ O
fine-tuning -X- _ O
while -X- _ O
updating -X- _ O
only -X- _ O
0.1% -X- _ O
of -X- _ O
model -X- _ O
parameters. -X- _ O

Zhong -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
and -X- _ O
Qin -X- _ O
and -X- _ O
Eisner -X- _ O
(2021) -X- _ O
propose -X- _ O
continuous -X- _ O
prompts -X- _ O
for -X- _ O
knowledge -X- _ O
probing -X- _ O
by -X- _ O
tuning -X- _ O
some -X- _ O
trainable -X- _ O
vectors -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
while -X- _ O
fixing -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
input. -X- _ O

In -X- _ O
parallel -X- _ O
with -X- _ O
text-based -X- _ O
Continuous -X- _ O
Prompts -X- _ O
discrete -X- _ O
prompts, -X- _ O
there -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
focused -X- _ O
on -X- _ O
tuning -X- _ O
only -X- _ O
a -X- _ O
fraction -X- _ O
of -X- _ O
parameters -X- _ O
of -X- _ O
an -X- _ O
LM -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
continuous -X- _ O
prompts -X- _ O
(i.e., -X- _ O
soft -X- _ O
prompts). -X- _ O

by -X- _ O
manually -X- _ O
writing -X- _ O
prompt -X- _ O
templates -X- _ O
and -X- _ O
shows -X- _ O
that -X- _ O
a -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
multitask -X- _ O
training -X- _ O
can -X- _ O
generalize -X- _ O
to -X- _ O
unseen -X- _ O
tasks. -X- _ O

T0 -X- _ O
(Sanh -X- _ O
et -X- _ O
al., -X- _ O
2022; -X- _ O
Bach -X- _ O
et -X- _ O
al., -X- _ O
2022) -X- _ O
constructs -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
different -X- _ O
NLP -X- _ O
tasks -X- _ O

Concurrently -X- _ O
to -X- _ O
our -X- _ O
work, -X- _ O
Hu -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
propose -X- _ O
a -X- _ O
method -X- _ O
that -X- _ O
exploits -X- _ O
an -X- _ O
external -X- _ O
knowledge -X- _ O
base -X- _ O
to -X- _ O
find -X- _ O
label -X- _ O
mapping. -X- _ O

Different -X- _ O
from -X- _ O
these -X- _ O
prior -X- _ O
studies, -X- _ O
our -X- _ O
proposed -X- _ O
AMuLaP -X- _ B-MethodName
is -X- _ O
a -X- _ O
simple -X- _ O
and -X- _ O
interpretable -X- _ O
method -X- _ O
for -X- _ O
few-shot -X- _ O
prompting -X- _ O
that -X- _ O
can -X- _ O
work -X- _ O
well -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
model -X- _ O
weights. -X- _ O

These -X- _ O
searched -X- _ O
prompts -X- _ O
and -X- _ O
labels -X- _ O
are -X- _ O
often -X- _ O
uninterpretable -X- _ O
by -X- _ O
humans. -X- _ O

AutoPrompt -X- _ O
uses -X- _ O
discretization -X- _ O
techniques -X- _ O
to -X- _ O
approximately -X- _ O
map -X- _ O
a -X- _ O
continuous -X- _ O
vector -X- _ O
back -X- _ O
to -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
(i.e., -X- _ O
“vocablization”). -X- _ O

PET -X- _ O
and -X- _ O
its -X- _ O
variants -X- _ O
also -X- _ O
require -X- _ O
a -X- _ O
large -X- _ O
unlabeled -X- _ O
set -X- _ O
and -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
fine-tuned -X- _ O
multiple -X- _ O
times. -X- _ O

However, -X- _ O
these -X- _ O
methods -X- _ O
require -X- _ O
parameter -X- _ O
updates -X- _ O
with -X- _ O
gradient -X- _ O
descent, -X- _ O
which -X- _ O
is -X- _ O
infeasible -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
weights -X- _ O
(e.g., -X- _ O
GPT-3). -X- _ O

PETAL -X- _ B-MethodName
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
augments -X- _ O
Pattern -X- _ O
Exploiting -X- _ O
Training -X- _ O
(PET, -X- _ O
Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021a,b) -X- _ O
with -X- _ O
automatically -X- _ O
identified -X- _ O
label -X- _ O
words; -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
uses -X- _ O
re-ranking -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
label -X- _ O
words -X- _ O
by -X- _ O
fine-tuning -X- _ O
a -X- _ O
RoBERTa -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
candidates -X- _ O
searched -X- _ O
by -X- _ O
RoBERTa, -X- _ O
and -X- _ O
using -X- _ O
an -X- _ O
external -X- _ O
generation -X- _ O
model -X- _ O
for -X- _ O
data -X- _ O
augmentation -X- _ O
of -X- _ O
prompt -X- _ O
templates; -X- _ O
AutoPrompt -X- _ O
(Shin -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
uses -X- _ O
a -X- _ O
gradient-based -X- _ O
search -X- _ O
to -X- _ O
determine -X- _ O
both -X- _ O
prompts -X- _ O
and -X- _ O
label -X- _ O
words. -X- _ O

Le -X- _ O
Scao -X- _ O
and -X- _ O
Rush -X- _ O
(2021) -X- _ O
analyzes -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
prompting -X- _ O
and -X- _ O
concludes -X- _ O
that -X- _ O
a -X- _ O
single -X- _ O
prompt -X- _ O
may -X- _ O
be -X- _ O
worth -X- _ O
100 -X- _ O
training -X- _ O
examples -X- _ O
in -X- _ O
fine-tuning. -X- _ O

Recent -X- _ O
works -X- _ O
(Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021a,b; -X- _ O
Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
demonstrate -X- _ O
that -X- _ O
even -X- _ O
smaller -X- _ O
PLMs -X- _ O
have -X- _ O
similar -X- _ O
few-shot -X- _ O
learning -X- _ O
capacity. -X- _ O

Recent -X- _ O
works -X- _ O
(Petroni -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Davison -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Jiang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
design -X- _ O
prompts -X- _ O
to -X- _ O
probe -X- _ O
the -X- _ O
factual -X- _ O
and -X- _ O
commonsense -X- _ O
knowledge -X- _ O
encoded -X- _ O
within -X- _ O
a -X- _ O
PLM. -X- _ O

Brown -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
proposes -X- _ O
an -X- _ O
intuitive -X- _ O
in-context -X- _ O
learning -X- _ O
paradigm -X- _ O
by -X- _ O
concatenating -X- _ O
a -X- _ O
few -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
examples -X- _ O
and -X- _ O
feeding -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
let -X- _ O
the -X- _ O
model -X- _ O
autoregressively -X- _ O
generate -X- _ O
answers -X- _ O
for -X- _ O
new -X- _ O
examples. -X- _ O

The -X- _ O
release -X- _ O
of -X- _ O
GPT-3 -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
interest -X- _ O
in -X- _ O
prompting, -X- _ O
a -X- _ O
new -X- _ O
way -X- _ O
to -X- _ O
leverage -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
(PLM). -X- _ O

Discrete -X- _ O
Prompts -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

why -X- _ O
does -X- _ O
AMuLaP -X- _ B-MethodName
work -X- _ O
and -X- _ O
discuss -X- _ O
the -X- _ O
pros -X- _ O
and -X- _ O
cons -X- _ O
of -X- _ O
prompting -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
paradigm. -X- _ O

Moreover, -X- _ O
we -X- _ O
attempt -X- _ O
to -X- _ O
scale -X- _ O
AMuLaP -X- _ B-MethodName
with -X- _ O
different -X- _ O
sizes -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
find -X- _ O
AMuLaP -X- _ B-MethodName
to -X- _ O
work -X- _ O
surprisingly -X- _ O
well -X- _ O
even -X- _ O
with -X- _ O
one -X- _ O
or -X- _ O
two -X- _ O
shots. -X- _ O

We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
and -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
under -X- _ O
multiple -X- _ O
settings. -X- _ O

Compared -X- _ O
with -X- _ O
a -X- _ O
hand-crafted -X- _ O
label -X- _ O
mapping -X- _ O
and -X- _ O
previous -X- _ O
works -X- _ O
on -X- _ O
automatic -X- _ O
label -X- _ O
mapping -X- _ O
(Schick -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Gao -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
AMuLaP -X- _ B-MethodName
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
despite -X- _ O
being -X- _ O
simpler -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
backbone -X- _ O
model, -X- _ O
or -X- _ O
finetune -X- _ O
an -X- _ O
external -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
for -X- _ O
searching -X- _ O
label -X- _ O
mapping. -X- _ O

AMuLaP -X- _ B-MethodName
exploits -X- _ O
multiple -X- _ O
labels -X- _ O
to -X- _ O
suppress -X- _ O
the -X- _ O
noise -X- _ O
and -X- _ O
inherently -X- _ O
extend -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
for -X- _ O
prompt-based -X- _ O
fine-tuning. -X- _ O

AMuLaP -X- _ B-MethodName
is -X- _ O
a -X- _ O
parameter-free -X- _ O
statistical -X- _ O
technique -X- _ O
that -X- _ O
can -X- _ O
identify -X- _ O
the -X- _ O
label -X- _ O
patterns -X- _ O
from -X- _ O
a -X- _ O
few-shot -X- _ O
training -X- _ O
set -X- _ O
given -X- _ O
a -X- _ O
prompt -X- _ O
template. -X- _ O

We -X- _ O
propose -X- _ O
Automatic -X- _ B-MethodName
Multi-Label -X- _ I-MethodName
Prompting -X- _ I-MethodName
(AMuLaP), -X- _ B-MethodName
a -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
method -X- _ O
to -X- _ O
tackle -X- _ O
the -X- _ O
label -X- _ O
selection -X- _ O
problem -X- _ O
for -X- _ O
few-shot -X- _ B-TaskName
classification. -X- _ I-TaskName

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
design -X- _ O
a -X- _ O
method -X- _ O
that -X- _ O
can -X- _ O
automatically -X- _ O
find -X- _ O
a -X- _ O
good -X- _ O
label -X- _ O
mapping -X- _ O
to -X- _ O
save -X- _ O
human -X- _ O
effort -X- _ O
from -X- _ O
label -X- _ O
engineering. -X- _ O

Thus, -X- _ O
an -X- _ O
efficient -X- _ O
automatic -X- _ O
label -X- _ O
mapping -X- _ O
method -X- _ O
is -X- _ O
desirable. -X- _ O

One -X- _ O
may -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
same -X- _ O
effort -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
label -X- _ O
more -X- _ O
supervised -X- _ O
data -X- _ O
for -X- _ O
a -X- _ O
conventional -X- _ O
deep -X- _ O
learning -X- _ O
pipeline. -X- _ O

However, -X- _ O
manually -X- _ O
assigning -X- _ O
the -X- _ O
label -X- _ O
mapping -X- _ O
requires -X- _ O
human -X- _ O
expertise -X- _ O
with -X- _ O
trial -X- _ O
and -X- _ O
error. -X- _ O

Meanwhile, -X- _ O
finding -X- _ O
a -X- _ O
good -X- _ O
mapping -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
task -X- _ O
labels -X- _ O
to -X- _ O
tokens -X- _ O
(i.e., -X- _ O
label -X- _ O
engineering) -X- _ O
is -X- _ O
also -X- _ O
critical -X- _ O
to -X- _ O
few-shot -X- _ O
performance, -X- _ O
as -X- _ O
found -X- _ O
in -X- _ O
Schick -X- _ O
et -X- _ O
al. -X- _ O
(2020); -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

Many -X- _ O
attempts -X- _ O
have -X- _ O
been -X- _ O
made -X- _ O
in -X- _ O
this -X- _ O
emerging -X- _ O
direction -X- _ O
of -X- _ O
prompt -X- _ O
engineering -X- _ O
(Shin -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Gao -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

In -X- _ O
prompting, -X- _ O
the -X- _ O
design -X- _ O
of -X- _ O
prompts -X- _ O
often -X- _ O
plays -X- _ O
an -X- _ O
important -X- _ O
role. -X- _ O

Prompt-based -X- _ O
learning -X- _ O
(i.e., -X- _ O
prompting) -X- _ O
aims -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
template -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
into -X- _ O
a -X- _ O
prompt-based -X- _ O
input -X- _ O
with -X- _ O
some -X- _ O
unfilled -X- _ O
masked -X- _ O

Furthermore, -X- _ O
recent -X- _ O
works -X- _ O
(Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021a,b; -X- _ O
Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
show -X- _ O
that -X- _ O
prompts -X- _ O
can -X- _ O
also -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
generalize -X- _ O
better -X- _ O
in -X- _ O
fine-tuning. -X- _ O

The -X- _ O
use -X- _ O
of -X- _ O
prompts -X- _ O
can -X- _ O
strengthen -X- _ O
the -X- _ O
explicit -X- _ O
connection -X- _ O
between -X- _ O
input -X- _ O
and -X- _ O
output, -X- _ O
helping -X- _ O
the -X- _ O
model -X- _ O
exploit -X- _ O
the -X- _ O
knowledge -X- _ O
learned -X- _ O
from -X- _ O
pretraining -X- _ O
in -X- _ O
a -X- _ O
better -X- _ O
way. -X- _ O

This -X- _ O
setting -X- _ O
of -X- _ O
few-shot -X- _ O
learning -X- _ O
is -X- _ O
closer -X- _ O
to -X- _ O
how -X- _ O
humans -X- _ O
learn -X- _ O
to -X- _ O
solve -X- _ O
a -X- _ O
task, -X- _ O
often -X- _ O
without -X- _ O
many -X- _ O
examples -X- _ O
as -X- _ O
in -X- _ O
a -X- _ O
traditional -X- _ O
deep -X- _ O
learning -X- _ O
paradigm. -X- _ O

These -X- _ O
works -X- _ O
demonstrate -X- _ O
the -X- _ O
potential -X- _ O
of -X- _ O
using -X- _ O
natural -X- _ O
language -X- _ O
prompts -X- _ O
to -X- _ O
encourage -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
recall -X- _ O
similar -X- _ O
patterns -X- _ O
in -X- _ O
its -X- _ O
training -X- _ O
corpus -X- _ O
and -X- _ O
thus -X- _ O
make -X- _ O
accurate -X- _ O
predictions. -X- _ O

Since -X- _ O
the -X- _ O
release -X- _ O
of -X- _ O
GPT-3 -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
several -X- _ O
studies -X- _ O
have -X- _ O
focused -X- _ O
on -X- _ O
exploiting -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
training -X- _ O
examples -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Gao -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Shin -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Introduction -X- _ O

Our -X- _ O
experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
AMuLaP -X- _ B-MethodName
achieves -X- _ O
competitive -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
without -X- _ O
human -X- _ O
effort -X- _ O
or -X- _ O
external -X- _ O
resources.1 -X- _ O

Our -X- _ O
method -X- _ O
exploits -X- _ O
one-to-many -X- _ O
label -X- _ O
mappings -X- _ O
and -X- _ O
a -X- _ O
statistics-based -X- _ O
algorithm -X- _ O
to -X- _ O
select -X- _ O
label -X- _ O
mappings -X- _ O
given -X- _ O
a -X- _ O
prompt -X- _ O
template. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
Automatic -X- _ B-MethodName
Multi-Label -X- _ I-MethodName
Prompting -X- _ I-MethodName
(AMuLaP), -X- _ B-MethodName
a -X- _ O
simple -X- _ O
yet -X- _ O
effective -X- _ O
method -X- _ O
to -X- _ O
automatically -X- _ O
select -X- _ O
label -X- _ O
mappings -X- _ O
for -X- _ O
few-shot -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
with -X- _ O
prompting. -X- _ O

Prompt-based -X- _ O
learning -X- _ O
(i.e., -X- _ O
prompting) -X- _ O
is -X- _ O
an -X- _ O
emerging -X- _ O
paradigm -X- _ O
for -X- _ O
exploiting -X- _ O
knowledge -X- _ O
learned -X- _ O
by -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model. -X- _ O

Abstract -X- _ O

Simple -X- _ O
and -X- _ O
Interpretable -X- _ O
Few-Shot -X- _ B-TaskName
Classification -X- _ I-TaskName

Automatic -X- _ B-MethodName
Multi-Label -X- _ I-MethodName
Prompting: -X- _ I-MethodName

-DOCSTART- -X- O
One -X- _ O
should -X- _ O
be -X- _ O
careful -X- _ O
to -X- _ O
apply -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
and -X- _ O
all -X- _ O
other -X- _ O
prompt -X- _ O
tuning -X- _ O
methods -X- _ O
in -X- _ O
high-stakes -X- _ O
areas -X- _ O
without -X- _ O
a -X- _ O
comprehensive -X- _ O
test. -X- _ O

However, -X- _ O
if -X- _ O
the -X- _ O
backbone -X- _ O
model -X- _ O
stored -X- _ O
online -X- _ O
is -X- _ O
attacked, -X- _ O
whether -X- _ O
IDPG -X- _ B-MethodName
could -X- _ O
still -X- _ O
work -X- _ O
well -X- _ O
remains -X- _ O
unknown. -X- _ O

It -X- _ O
tunes -X- _ O
small -X- _ O
portion -X- _ O
parameters -X- _ O
while -X- _ O
directly -X- _ O
employs -X- _ O
backbone -X- _ O
model -X- _ O
parameters -X- _ O
without -X- _ O
any -X- _ O
changing. -X- _ O

Our -X- _ O
proposed -X- _ O
model -X- _ O
IDPG -X- _ B-MethodName
is -X- _ O
a -X- _ O
novel -X- _ O
efficient -X- _ O
transfer -X- _ O
learning -X- _ O
method. -X- _ O

A.8 -X- _ O
Potential -X- _ O
Risks -X- _ O

IDPG -X- _ B-MethodName
shows -X- _ O
its -X- _ O
stability -X- _ O
when -X- _ O
scaling -X- _ O
to -X- _ O
larger -X- _ O
models -X- _ O
with -X- _ O
longer -X- _ O
prompts. -X- _ O

We -X- _ O
present -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
among -X- _ O
several -X- _ O
prompt -X- _ O
tuning -X- _ O
methods -X- _ O
in -X- _ O
Figure -X- _ O
9. -X- _ O

A.7 -X- _ O
Ablation -X- _ O
Study -X- _ O
on -X- _ O
Prompt -X- _ B-HyperparameterName
Length -X- _ I-HyperparameterName

We -X- _ O
present -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
distributions -X- _ O
when -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
100 -X- _ B-HyperparameterValue
and -X- _ O
k -X- _ B-HyperparameterName
= -X- _ O
300 -X- _ B-HyperparameterValue
in -X- _ O
Figure -X- _ O
8a -X- _ O
and -X- _ O
in -X- _ O
Figure -X- _ O
8b, -X- _ O
respectively. -X- _ O

A.6 -X- _ O
Cosine -X- _ O
Similarity -X- _ O
Distributions -X- _ O
in -X- _ O
STS-B -X- _ B-DatasetName

It -X- _ O
is -X- _ O
interesting -X- _ O
that -X- _ O
IDPG -X- _ B-MethodName
achieves -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
position -X- _ O
0 -X- _ O
while -X- _ O
the -X- _ O
standard -X- _ B-MethodName
prompt-tuning -X- _ I-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
position -X- _ O
4 -X- _ O
for -X- _ O
both -X- _ O
single-sentence -X- _ O
and -X- _ O
sentence-pair -X- _ O
tasks. -X- _ O

Figure -X- _ O
7(b) -X- _ O
illustrates -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
prompt -X- _ O
position -X- _ O
on -X- _ O
the -X- _ O
supplementary -X- _ O
training -X- _ O
phase. -X- _ O

For -X- _ O
sentence-pair -X- _ O
tasks, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
inserting -X- _ O
prompt -X- _ O
into -X- _ O
position -X- _ O
1 -X- _ O
can -X- _ O
better -X- _ O
align -X- _ O
the -X- _ O
two -X- _ O
input -X- _ O
sentences. -X- _ O

This -X- _ O
result -X- _ O
is -X- _ O
intuitive -X- _ O
for -X- _ O
single-sentence -X- _ O
tasks -X- _ O
since -X- _ O
prompt -X- _ O
in -X- _ O
position -X- _ O
0 -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
premise -X- _ O
and -X- _ O
original -X- _ O
input -X- _ O
sentence -X- _ O
as -X- _ O
the -X- _ O
hypothesis. -X- _ O

Looking -X- _ O
at -X- _ O
the -X- _ O
prompt -X- _ O
position -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
first, -X- _ O
Figure -X- _ O
7(a) -X- _ O
shows -X- _ O
that -X- _ O
for -X- _ O
both -X- _ O
standard -X- _ O
prompt -X- _ O
tuning -X- _ O
and -X- _ O
our -X- _ O
proposed -X- _ O
method, -X- _ O
the -X- _ O
best -X- _ O
position -X- _ O
is -X- _ O
0 -X- _ O
for -X- _ O
single-sentence -X- _ O
tasks -X- _ O
and -X- _ O
1 -X- _ O
for -X- _ O
sentence-pair -X- _ O
tasks. -X- _ O

We -X- _ O
conduct -X- _ O
a -X- _ O
comprehensive -X- _ O
study -X- _ O
of -X- _ O
the -X- _ O
prompt -X- _ O
position -X- _ O
for -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
in -X- _ O
both -X- _ O
supplementary -X- _ O
training -X- _ O
and -X- _ O
downstream -X- _ O
fine-tuning -X- _ O
phases. -X- _ O

A.5.2 -X- _ O
Prompt -X- _ O
Position -X- _ O
As -X- _ O
we -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
A.4, -X- _ O
the -X- _ O
prompt -X- _ O
position -X- _ O
has -X- _ O
a -X- _ O
direct -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
prediction -X- _ O
results. -X- _ O

One -X- _ O
surprising -X- _ O
result -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
mixed -X- _ O
model -X- _ O
of -X- _ O
Residual -X- _ O
and -X- _ O
LayerNorm -X- _ O
has -X- _ O
significantly -X- _ O
poorer -X- _ O
performance. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
adding -X- _ O
LayerNorm -X- _ O
slightly -X- _ O
improves -X- _ O
the -X- _ O
voting -X- _ O
results, -X- _ O
while -X- _ O
residual -X- _ O
performs -X- _ O
slightly -X- _ O
worse. -X- _ O

Note -X- _ O
that, -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
token -X- _ O
embedding -X- _ O
and -X- _ O
sentence -X- _ O
embedding, -X- _ O
we -X- _ O
apply -X- _ O
LayerNorm -X- _ O
to -X- _ O
each -X- _ O
embedding -X- _ O
first, -X- _ O
then -X- _ O
after -X- _ O
the -X- _ O
add-up, -X- _ O
use -X- _ O
LayerNorm -X- _ O
again -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
generated -X- _ O
tokens. -X- _ O

et -X- _ O
al., -X- _ O
2016) -X- _ O
is -X- _ O
also -X- _ O
added -X- _ O
to -X- _ O
normalize -X- _ O
the -X- _ O
generated -X- _ O
token -X- _ O
embedding; -X- _ O
(iii) -X- _ O
residual -X- _ O
+ -X- _ O
layerNorm: -X- _ O
a -X- _ O
mixed -X- _ O
model -X- _ O
that -X- _ O
uses -X- _ O
both -X- _ O
the -X- _ O
residual -X- _ O
component -X- _ O
and -X- _ O
LayerNorm. -X- _ O

We -X- _ O
explore -X- _ O
three -X- _ O
different -X- _ O
architectures -X- _ O
for -X- _ O
the -X- _ O
proposed -X- _ O
PHM-based -X- _ O
generator: -X- _ O
(i) -X- _ O
Residual: -X- _ O
a -X- _ O
residual -X- _ O
structure -X- _ O
(He -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
add -X- _ O
the -X- _ O
sentence -X- _ O
representation -X- _ O
to -X- _ O
each -X- _ O
generated -X- _ O
tokens; -X- _ O
(ii) -X- _ O
LayerNorm: -X- _ O
layer -X- _ O
normalization -X- _ O
(Ba -X- _ O

A.5.1 -X- _ O
Generator -X- _ O
Architecture -X- _ O
Exploration -X- _ O

A.5 -X- _ O
Ablation -X- _ O
study -X- _ O
for -X- _ O
single-layer -X- _ O
IDPG -X- _ B-MethodName

We -X- _ O
report -X- _ O
average -X- _ O
results -X- _ O
and -X- _ O
voting -X- _ O
results -X- _ O
across -X- _ O
5 -X- _ O
runs. -X- _ O

We -X- _ O
double -X- _ O
the -X- _ O
MNLI -X- _ B-DatasetName
dataset -X- _ O
by -X- _ O
reordering -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
on -X- _ O
one -X- _ O
shard, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
doubled -X- _ O
dataset -X- _ O
during -X- _ O
intermediate -X- _ O
training. -X- _ O

We -X- _ O
further -X- _ O
reduce -X- _ O
the -X- _ O
distribution -X- _ O
difference -X- _ O
by -X- _ O
reconstructing -X- _ O
the -X- _ O
supplementary -X- _ O
training -X- _ O
data. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6, -X- _ O
we -X- _ O
test -X- _ O
five -X- _ O
different -X- _ O
insertion -X- _ O
positions -X- _ O
(Pos -X- _ O
0–4) -X- _ O
for -X- _ O
sentence -X- _ O
pair -X- _ O
tasks -X- _ O
and -X- _ O
three -X- _ O
different -X- _ O
positions -X- _ O
(Pos -X- _ O
0, -X- _ O
1, -X- _ O
4) -X- _ O
for -X- _ O
single -X- _ O
sentence -X- _ O
tasks. -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
the -X- _ O
length -X- _ O
difference -X- _ O
in -X- _ O
MNLI -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
becomes -X- _ O
more -X- _ O
balanced: -X- _ O
4.8 -X- _ O
vs. -X- _ O
0.6 -X- _ O
+ -X- _ O
5 -X- _ O
= -X- _ O
5.6. -X- _ O

Method -X- _ O

For -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
tasks, -X- _ O
we -X- _ O
report -X- _ O
accuracy. -X- _ B-MetricName

We -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
for -X- _ O
both -X- _ O
MRPC -X- _ B-DatasetName
and -X- _ O
QQP, -X- _ B-DatasetName
and -X- _ O
average -X- _ O
of -X- _ O
Pearson -X- _ B-MetricName
and -X- _ I-MetricName
Spearman -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficients -X- _ I-MetricName
for -X- _ O
STS-B. -X- _ B-DatasetName

We -X- _ O
report -X- _ O
average -X- _ O
results -X- _ O
across -X- _ O
5 -X- _ O
runs -X- _ O
with -X- _ O
different -X- _ O
initialization. -X- _ O

Each -X- _ O
methods -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
full -X- _ O
test -X- _ O
sets -X- _ O
(dev -X- _ O
sets -X- _ O
for -X- _ O
GLUE -X- _ B-DatasetName
tasks). -X- _ O

Then, -X- _ O
when -X- _ O
fine-tuning -X- _ O
downstream -X- _ O
tasks -X- _ O

For -X- _ O
example, -X- _ O
assuming -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
adding -X- _ O
a -X- _ O
prompt -X- _ O
with -X- _ O
a -X- _ O
length -X- _ B-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
5 -X- _ B-HyperparameterValue
after -X- _ O
the -X- _ O
second -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
supplementary -X- _ O
training -X- _ O
stage -X- _ O
on -X- _ O
MNLI. -X- _ B-DatasetName

One -X- _ O
natural -X- _ O
solution -X- _ O
to -X- _ O
smooth -X- _ O
the -X- _ O
length -X- _ O
distribution -X- _ O
difference -X- _ O
between -X- _ O
tasks -X- _ O
is -X- _ O
to -X- _ O
insert -X- _ O
prompt -X- _ O
in -X- _ O
both -X- _ O
supplementary -X- _ O
training -X- _ O
and -X- _ O
downstream -X- _ O
finetuning -X- _ O
stage. -X- _ O

For -X- _ O
example, -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
sentence -X- _ O
in -X- _ O
MNLI -X- _ B-DatasetName
is -X- _ O
9.8 -X- _ O
longer -X- _ O
than -X- _ O
the -X- _ O
second -X- _ O
sentence -X- _ O
on -X- _ O
average, -X- _ O
while -X- _ O
this -X- _ O
length -X- _ O
difference -X- _ O
in -X- _ O
MRPC -X- _ B-DatasetName
is -X- _ O
only -X- _ O
0.6. -X- _ O

Figure -X- _ O
5 -X- _ O
provides -X- _ O
a -X- _ O
comprehensive -X- _ O
statistic -X- _ O
among -X- _ O
all -X- _ O
sentence -X- _ O
pair -X- _ O
tasks -X- _ O
in -X- _ O
GLUE -X- _ B-DatasetName
benchmark. -X- _ O

However, -X- _ O
a -X- _ O
drawback -X- _ O
of -X- _ O
supplementary -X- _ O
training -X- _ O
is -X- _ O
that -X- _ O
if -X- _ O
the -X- _ O
data -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
is -X- _ O
quite -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
supplementary -X- _ O
training -X- _ O
task, -X- _ O
i.e., -X- _ O
MRPC -X- _ B-DatasetName
vs. -X- _ O
MNLI -X- _ B-DatasetName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
it -X- _ O
may -X- _ O
harm -X- _ O
the -X- _ O
downstream -X- _ O
performance. -X- _ O

Following -X- _ O
this -X- _ O
idea, -X- _ O
we -X- _ O
also -X- _ O
conduct -X- _ O
intermediate -X- _ O
training -X- _ O
for -X- _ O
single-layer -X- _ O
IDPG. -X- _ B-MethodName

According -X- _ O
to -X- _ O
previous -X- _ O
works -X- _ O
(Phang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
supplementing -X- _ O
pre-trained -X- _ O
LMs -X- _ O
with -X- _ O
rich -X- _ O
data -X- _ O
helps -X- _ O
tasks -X- _ O
with -X- _ O
limited -X- _ O
labels -X- _ O
and -X- _ O
stabilizes -X- _ O
downstream -X- _ O
fine-tuning. -X- _ O

A.4 -X- _ O
Supplementary -X- _ O
Training -X- _ O
for -X- _ O
Single-layer -X- _ O

While -X- _ O
in -X- _ O
Table -X- _ O
1, -X- _ O
we -X- _ O
tune -X- _ O
the -X- _ O
learning -X- _ O
4 -X- _ O
4, -X- _ O
1e− -X- _ B-HyperparameterValue
3, -X- _ I-HyperparameterValue
5e− -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
rate -X- _ O
from -X- _ O
} -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
other -X- _ O
models. -X- _ O

M-IDPG-PHM), -X- _ B-MethodName
this -X- _ O
is -X- _ O
because -X- _ O
we -X- _ O
tune -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
more -X- _ O
carefully -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
(lr -X- _ B-HyperparameterName
2, -X- _ B-HyperparameterValue
7e− -X- _ B-HyperparameterValue
4, -X- _ I-HyperparameterValue
3, -X- _ B-HyperparameterValue
1e− -X- _ B-HyperparameterValue
1e− -X- _ B-HyperparameterValue
{ -X- _ O
4 -X- _ B-HyperparameterValue
1e− -X- _ B-HyperparameterValue
) -X- _ O
to -X- _ O
seek -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
each -X- _ O
model -X- _ O
can -X- _ O
reach. -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
M -X- _ O
version -X- _ O
model -X- _ O
with -X- _ O
m -X- _ B-HyperparameterName
= -X- _ O
16 -X- _ B-HyperparameterValue
and -X- _ O
previous -X- _ O
layer -X- _ O
as -X- _ O
input -X- _ O
one -X- _ O
is -X- _ O
slightly -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
results -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1(Cf. -X- _ O

We -X- _ O
provide -X- _ O
a -X- _ O
detailed -X- _ O
result -X- _ O
table -X- _ O
for -X- _ O
all -X- _ O
compared -X- _ O
methods -X- _ O
in -X- _ O
Section -X- _ O
4.5.3. -X- _ O

A.3 -X- _ O
Detailed -X- _ O
results -X- _ O
for -X- _ O
Multi-layer -X- _ O
Architecture -X- _ O
Exploration -X- _ O

We -X- _ O
provide -X- _ O
a -X- _ O
detailed -X- _ O
information -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
for -X- _ O
10 -X- _ O
NLU -X- _ B-TaskName
datasets -X- _ O
we -X- _ O
used. -X- _ O

A.2 -X- _ O
Datasets -X- _ O

Total -X- _ O
parameters: -X- _ O
1024 -X- _ O
× -X- _ O
24 -X- _ O
= -X- _ O
216K. -X- _ O
1024 -X- _ O

M-IDPG-DNN: -X- _ B-MethodName
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
generator -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
= -X- _ B-HyperparameterValue
16, -X- _ I-HyperparameterValue
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ B-HyperparameterValue
5. -X- _ I-HyperparameterValue

First -X- _ O
PHM -X- _ O
layer -X- _ O
16 -X- _ O
+ -X- _ O
16 -X- _ O
= -X- _ O
1K -X- _ O
paramW1 -X- _ O
takes -X- _ O
1024/16 -X- _ O
eters, -X- _ O
second -X- _ O
PHM -X- _ O
layer -X- _ O
W2 -X- _ O
takes -X- _ O
16/16 -X- _ O
1024/16 -X- _ O
1024 -X- _ O
the -X- _ O
shared -X- _ O
matrix -X- _ O
Ai -X- _ O
takes -X- _ O
16316 -X- _ O
parameters: -X- _ O

= -X- _ O
5, -X- _ B-HyperparameterValue
user -X- _ O
defined -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
16 -X- _ B-HyperparameterValue
(Cf. -X- _ O
Equation -X- _ O
4). -X- _ O

M-IDPG-PHM: -X- _ B-MethodName
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
generator -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
= -X- _ O
16, -X- _ B-HyperparameterValue
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName

First -X- _ O
PHM -X- _ O
4 -X- _ O
+ -X- _ O
16 -X- _ O
= -X- _ O
1216 -X- _ O
palayer -X- _ O
W1 -X- _ O
takes -X- _ O
300/4 -X- _ O
× -X- _ O
rameters, -X- _ O
second -X- _ O
PHM -X- _ O
layer -X- _ O
W2 -X- _ O
takes -X- _ O
16/4 -X- _ O
1024/4 -X- _ O
1024 -X- _ O
the -X- _ O
shared -X- _ O
matrix -X- _ O
Ai -X- _ O
takes -X- _ O
43 -X- _ O
parameters: -X- _ O
141K. -X- _ O

× -X- _ O
M-IDPG-PHM-GloVe: -X- _ B-MethodName
input -X- _ B-HyperparameterName
vector -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
300, -X- _ B-HyperparameterValue
generator -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
= -X- _ O
16, -X- _ B-HyperparameterValue
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
5, -X- _ B-HyperparameterValue
user -X- _ O
defined -X- _ B-HyperparameterName
n -X- _ I-HyperparameterName
= -X- _ O
4 -X- _ B-HyperparameterValue
(Cf. -X- _ O
Equation -X- _ O
4). -X- _ O

S-IDPG-DNN: -X- _ B-MethodName
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
generator -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
= -X- _ O
256, -X- _ B-HyperparameterValue
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
5. -X- _ B-HyperparameterValue

First -X- _ O
PHM -X- _ O
layer -X- _ O
W1 -X- _ O
takes -X- _ O
1024/16 -X- _ O
16 -X- _ O
+ -X- _ O
256 -X- _ O
= -X- _ O
16.25K -X- _ O
256/16 -X- _ O
parameters, -X- _ O
second -X- _ O
PHM -X- _ O
layer -X- _ O
W2 -X- _ O
takes -X- _ O
256/16 -X- _ O
× -X- _ O
1024 -X- _ O
= -X- _ O
85K -X- _ O
parameters, -X- _ O
5 -X- _ O
× -X- _ O
the -X- _ O
shared -X- _ O
matrix -X- _ O
Ai -X- _ O
takes -X- _ O
163 -X- _ O
= -X- _ O
4K -X- _ O
(Note -X- _ O
we -X- _ O
use -X- _ O
one -X- _ O
shared -X- _ O
matrix -X- _ O
in -X- _ O
single -X- _ O
version -X- _ O
IDPG). -X- _ B-MethodName

P-tuning -X- _ B-MethodName
v2: -X- _ I-MethodName
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
5, -X- _ B-HyperparameterValue
inserted -X- _ O
lay1024 -X- _ O
= -X- _ O
120K. -X- _ O
S-IDPG-PHM: -X- _ B-MethodName
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
generator -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
= -X- _ O
256, -X- _ B-HyperparameterValue
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
5, -X- _ B-HyperparameterValue
user -X- _ O
defined -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
16 -X- _ B-HyperparameterValue
(Cf. -X- _ O
Equation -X- _ O
4). -X- _ O

Prompt-tuning-134: -X- _ B-MethodName
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
134. -X- _ B-HyperparameterValue

Prompt-tuning: -X- _ B-MethodName
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
5. -X- _ B-HyperparameterValue

Total -X- _ O
parameters: -X- _ O
(1024 -X- _ O
2 -X- _ O
= -X- _ O
1.55M. -X- _ O
16 -X- _ O

size -X- _ O
m -X- _ B-HyperparameterName
= -X- _ O
16. -X- _ B-HyperparameterValue

Adapter: -X- _ B-MethodName
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
adapter -X- _ B-MethodName
hidden -X- _ I-MethodName
16 -X- _ B-HyperparameterValue
+ -X- _ O
16 -X- _ O
+ -X- _ O

24 -X- _ O
4 -X- _ O

Down-project -X- _ O
2 -X- _ O
= -X- _ O
48K, -X- _ O
downsi -X- _ O
matrix -X- _ O
takes -X- _ O
1024/4 -X- _ O
4 -X- _ O
× -X- _ O
project -X- _ O
ti -X- _ O
matrix -X- _ O
takes -X- _ O
16/4 -X- _ O
2 -X- _ O
= -X- _ O
0.75K, -X- _ O
24 -X- _ O
× -X- _ O
× -X- _ O
2 -X- _ O
= -X- _ O
0.75K, -X- _ O
up-project -X- _ O
hidden -X- _ O
bias -X- _ O
takes -X- _ O
16 -X- _ O
24 -X- _ O
si -X- _ O
and -X- _ O
ti -X- _ O
matrix -X- _ O
takes -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
as -X- _ O
down-projector, -X- _ O
the -X- _ O
output -X- _ O
bias -X- _ O
takes -X- _ O
2 -X- _ O
= -X- _ O
48K, -X- _ O
the -X- _ O
shared -X- _ O
matrix -X- _ O
Ai -X- _ O
takes -X- _ O
1024 -X- _ O
× -X- _ O
43 -X- _ O
2 -X- _ O
= -X- _ O
3K. -X- _ O
Total -X- _ O
parameters: -X- _ O
48 -X- _ O
+ -X- _ O
0.75 -X- _ O
+ -X- _ O
0.75 -X- _ O
+ -X- _ O
48 -X- _ O
+ -X- _ O
0.75 -X- _ O
+ -X- _ O
48 -X- _ O
+ -X- _ O
3 -X- _ O
= -X- _ O
149.25K. -X- _ O

Compacter: -X- _ O
hidden -X- _ O
size -X- _ O
d -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
adapter -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
= -X- _ O
16, -X- _ B-HyperparameterValue
user -X- _ O
defined -X- _ O
n -X- _ B-HyperparameterName
= -X- _ O
4, -X- _ B-HyperparameterValue
each -X- _ O
transformer -X- _ O
layer -X- _ O
inserts -X- _ O
2 -X- _ B-HyperparameterValue
compacters. -X- _ B-HyperparameterName

We -X- _ O
report -X- _ O
the -X- _ O
detailed -X- _ O
model -X- _ O
hyperparameters -X- _ O
for -X- _ O
each -X- _ O
method -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
illustrate -X- _ O
how -X- _ O
numbers -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
are -X- _ O
computed. -X- _ O

A.1.2 -X- _ O
Model -X- _ O
hyperparameters -X- _ O

For -X- _ O
all -X- _ O
adapter-based -X- _ O
and -X- _ O
prompt-based -X- _ O
methods, -X- _ O
we -X- _ O
train -X- _ O
them -X- _ O
more -X- _ O
sufficiently -X- _ O
(with -X- _ O
fifty -X- _ O
epochs) -X- _ O
on -X- _ O
small -X- _ O
datasets -X- _ O
(i.e., -X- _ O
MPQA, -X- _ B-DatasetName
Subj, -X- _ B-DatasetName
CR, -X- _ B-DatasetName
MR, -X- _ B-DatasetName
RTE, -X- _ B-DatasetName
MRPC, -X- _ B-DatasetName
STS-B). -X- _ B-DatasetName

Note -X- _ O
that -X- _ O
for -X- _ O
both -X- _ O
transformer -X- _ O
fine-tuning -X- _ O
methods, -X- _ O
including -X- _ O
RoBERTa -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
EFL -X- _ B-MethodName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
we -X- _ O
follow -X- _ O
their -X- _ O
official -X- _ O
training -X- _ O
instructions, -X- _ O
i.e., -X- _ O
using -X- _ O
a -X- _ O
polynomial -X- _ O
learning -X- _ O
rate -X- _ O
scheduler -X- _ O
with -X- _ O
6% -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
to -X- _ O
warm -X- _ O
up -X- _ O
and -X- _ O
tuning -X- _ O
for -X- _ O
ten -X- _ B-HyperparameterValue
epochs. -X- _ B-HyperparameterName

The -X- _ O
detailed -X- _ O
model -X- _ O
hyperparameters -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
4. -X- _ O

We -X- _ O
use -X- _ O
RoBERTa-Large -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
model -X- _ O
implemented -X- _ O
by -X- _ O
Fairseq -X- _ O
(Ott -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
as -X- _ O
our -X- _ O
basic -X- _ O
model. -X- _ O

A -X- _ O
Appendix -X- _ O

References -X- _ O

Acknowledgment -X- _ O

This -X- _ O
work -X- _ O
provided -X- _ O
a -X- _ O
new -X- _ O
research -X- _ O
angle -X- _ O
for -X- _ O
prompt-tuning -X- _ B-TaskName
of -X- _ O
a -X- _ O
pre-trained -X- _ O
language -X- _ O
model. -X- _ O

It -X- _ O
is -X- _ O
also -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
the -X- _ O
lightweight -X- _ O
adapter -X- _ O
tuning -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
Compacter -X- _ B-MethodName
while -X- _ O
using -X- _ O
a -X- _ O
similar -X- _ O
amount -X- _ O
of -X- _ O
trainable -X- _ O
parameters. -X- _ O

Despite -X- _ O
adding -X- _ O
fewer -X- _ O
parameters -X- _ O
than -X- _ O
prompt -X- _ O
tuning, -X- _ O
IDPG -X- _ B-MethodName
shows -X- _ O
consistent -X- _ O
improvement. -X- _ O

Parameterized -X- _ O
Hypercomplex -X- _ O
Multiplication -X- _ O
(PHM) -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
shrink -X- _ O
the -X- _ O
training -X- _ O
parameters -X- _ O
in -X- _ O
our -X- _ O
prompt -X- _ O
generator, -X- _ O
which -X- _ O
helps -X- _ O
us -X- _ O
build -X- _ O
an -X- _ O
extreme -X- _ O
lightweight -X- _ O
generation -X- _ O
model. -X- _ O

Our -X- _ O
method -X- _ O
first -X- _ O
factors -X- _ O
in -X- _ O
an -X- _ O
instance-dependent -X- _ O
prompt, -X- _ O
which -X- _ O
is -X- _ O
robust -X- _ O
to -X- _ O
data -X- _ O
variance. -X- _ O

We -X- _ O
have -X- _ O
introduced -X- _ O
IDPG, -X- _ B-MethodName
an -X- _ O
instance-dependent -X- _ B-MethodName
prompt -X- _ I-MethodName
generation -X- _ I-MethodName
model -X- _ O
that -X- _ O
generalizes -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
existing -X- _ O
prompt -X- _ B-TaskName
tuning -X- _ I-TaskName
methods. -X- _ O

6 -X- _ O
Conclusion -X- _ O
and -X- _ O
Discussion -X- _ O

Our -X- _ O
proposed -X- _ O
method, -X- _ B-MethodName
IDPG, -X- _ I-MethodName
is -X- _ O
the -X- _ O
first -X- _ O
prompt -X- _ O
generator -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
only -X- _ O
taskspecific -X- _ O
but -X- _ O
also -X- _ O
instance-specific. -X- _ O

All -X- _ O
these -X- _ O
methods -X- _ O
focus -X- _ O
on -X- _ O
task-specific -X- _ O
prompt -X- _ O
optimization. -X- _ O

Two -X- _ O
contemporaneous -X- _ O
works -X- _ O
– -X- _ O
prompt -X- _ B-MethodName
tuning -X- _ I-MethodName
(Lester -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
P-tuning -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021b), -X- _ O
interleave -X- _ O
the -X- _ O
training -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
embedding -X- _ O
layer -X- _ O
instead -X- _ O
of -X- _ O
each -X- _ O
transformer -X- _ O
layer. -X- _ O

Prefix -X- _ B-MethodName
tuning -X- _ I-MethodName
(Li -X- _ O
and -X- _ O
Liang, -X- _ O
2021) -X- _ O
and -X- _ O
P-tuningv2 -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021a) -X- _ O
prepend -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
trainable -X- _ O
embeddings -X- _ O
at -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
and -X- _ O
optimizes -X- _ O
them. -X- _ O

Recently, -X- _ O
several -X- _ O
researchers -X- _ O
have -X- _ O
proposed -X- _ O
continuous -X- _ O
prompts -X- _ O
training -X- _ O
to -X- _ O
overcome -X- _ O
the -X- _ O
challenges -X- _ O
in -X- _ O
discrete -X- _ O
prompt -X- _ O
searching. -X- _ O

Existing -X- _ O
works -X- _ O
including -X- _ O
LMBFF -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021a; -X- _ O
Wang -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
explored -X- _ O
the -X- _ O
prompt -X- _ O
searching -X- _ O
in -X- _ O
a -X- _ O
few-shot -X- _ O
setting. -X- _ O

Prompting: -X- _ O
Hand-crafted -X- _ O
prompts -X- _ O
were -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
helpful -X- _ O
to -X- _ O
adapt -X- _ O
generation -X- _ O
in -X- _ O
GPT-3 -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

et -X- _ O
al., -X- _ O
2021) -X- _ O
substitutes -X- _ O
the -X- _ O
down-projector -X- _ O
and -X- _ O
upprojector -X- _ O
matrices -X- _ O
by -X- _ O
a -X- _ O
sum -X- _ O
of -X- _ O
Kronecker -X- _ O
products, -X- _ O
reducing -X- _ O
the -X- _ O
parameters -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
while -X- _ O
maintaining -X- _ O
the -X- _ O
overall -X- _ O
performance. -X- _ O

On -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark, -X- _ O
adapters -X- _ O
attain -X- _ O
within -X- _ O
0.4% -X- _ B-MetricValue
of -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
full -X- _ O
fine-tuning -X- _ O
by -X- _ O
only -X- _ O
training -X- _ O
3.6% -X- _ O
parameters -X- _ O
per -X- _ O
task. -X- _ O

Pfeiffer -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
in -X- _ O
which -X- _ O
adapter -X- _ O
layers -X- _ O
– -X- _ O
small -X- _ O
bottleneck -X- _ O
layers -X- _ O
– -X- _ O
are -X- _ O
inserted -X- _ O
and -X- _ O
trained -X- _ O
between -X- _ O
frozen -X- _ O
pre-trained -X- _ O
transformer -X- _ O
layers. -X- _ O

Adapter -X- _ O
tuning -X- _ O
has -X- _ O
emerged -X- _ O
as -X- _ O
a -X- _ O
novel -X- _ O
parameter-efficient -X- _ O
transfer -X- _ O
learning -X- _ O
paradigm -X- _ O
(Houlsby -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

Adapter -X- _ O
Tuning: -X- _ O

More -X- _ O
recently, -X- _ O
EFL -X- _ B-MethodName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
proposed -X- _ O
a -X- _ O
task -X- _ O
transformation -X- _ O
paradigm, -X- _ O
improving -X- _ O
single -X- _ O
sentence -X- _ O
tasks -X- _ O
with -X- _ O
less -X- _ O
labels -X- _ O
using -X- _ O
rich -X- _ O
sentence-pair -X- _ O
datasets. -X- _ O

All -X- _ O
of -X- _ O
them -X- _ O
applied -X- _ O
pre-fine -X- _ O
tuning -X- _ O
on -X- _ O
NLI -X- _ O
datasets. -X- _ O

A -X- _ O
series -X- _ O
of -X- _ O
work -X- _ O
(SentenceBERT -X- _ O
(Reimers -X- _ O
and -X- _ O
Gurevych, -X- _ O
2019), -X- _ O
BERT-flow -X- _ O
(Li -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
SimCSE -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021b)) -X- _ O
explored -X- _ O
intermediate -X- _ O
training -X- _ O
to -X- _ O
improve -X- _ O
STS -X- _ B-DatasetName
tasks. -X- _ O

Existing -X- _ O
works -X- _ O
(Phang -X- _ O
et -X- _ O
al., -X- _ O
2018; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
have -X- _ O
observed -X- _ O
that -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
fine-tuned -X- _ O
MNLI -X- _ O
model -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
directly -X- _ O
from -X- _ O
the -X- _ O
vanilla -X- _ O
pre-trained -X- _ O
models -X- _ O
for -X- _ O
RTE, -X- _ B-DatasetName
STS, -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
tasks. -X- _ O

Supplementary -X- _ O
Training: -X- _ O

5 -X- _ O
Related -X- _ O
Work -X- _ O

In -X- _ O
general, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
IDPG -X- _ B-MethodName
in -X- _ O
downstream -X- _ O
tasks -X- _ O
improves -X- _ O
gradually -X- _ O
when -X- _ O
using -X- _ O
a -X- _ O
larger -X- _ O
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
(Cf. -X- _ O
Appendix -X- _ O
A.7). -X- _ O

4.5.6 -X- _ O
IDPG -X- _ B-MethodName
Scalability -X- _ O
We -X- _ O
study -X- _ O
our -X- _ O
proposed -X- _ O
model’s -X- _ O
scalability -X- _ O
in -X- _ O
this -X- _ O
section. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4, -X- _ O
prompts -X- _ O
bring -X- _ O
the -X- _ O
similar -X- _ O
sentences -X- _ O
closer -X- _ O
while -X- _ O
pushing -X- _ O
the -X- _ O
dissimilar -X- _ O
ones -X- _ O
apart. -X- _ O

Both -X- _ O
models -X- _ O
are -X- _ O
finetuned -X- _ O
on -X- _ O
STS-B -X- _ B-DatasetName
training -X- _ O
set. -X- _ O

We -X- _ O
compare -X- _ O
a -X- _ O
vanilla -X- _ O
model -X- _ O
without -X- _ O
any -X- _ O
prompts -X- _ O
with -X- _ O
M-IDPG-PHM. -X- _ B-MethodName

More -X- _ O
results -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.6. -X- _ O

We -X- _ O
sort -X- _ O
all -X- _ O
sentence -X- _ O
pairs -X- _ O
in -X- _ O
STS-B -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
in -X- _ O
descending -X- _ O
order -X- _ O
by -X- _ O
the -X- _ O
cosine -X- _ O

Given -X- _ O
two -X- _ O
sentences, -X- _ O
we -X- _ O
encode -X- _ O
each -X- _ O
of -X- _ O
them -X- _ O
by -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
comparison -X- _ O
models -X- _ O
and -X- _ O
compute -X- _ O
the -X- _ O
cosine -X- _ O
similarity. -X- _ O

4.5.5 -X- _ O
How -X- _ O
Prompts -X- _ O
Help? -X- _ O

An -X- _ O
interesting -X- _ O
finding -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
supplementary -X- _ O
training -X- _ O
on -X- _ O
S-IDPG -X- _ B-MethodName
is -X- _ O
high -X- _ O
while -X- _ O
it -X- _ O
is -X- _ O
limited -X- _ O
for -X- _ O
M-IDPG. -X- _ B-MethodName

We -X- _ O
come -X- _ O
to -X- _ O
a -X- _ O
similar -X- _ O
conclusion -X- _ O
that -X- _ O
multi-layer -X- _ O
instancedependent -X- _ O
prompt -X- _ O
tuning -X- _ O
model -X- _ O
(M-IDPG) -X- _ B-MethodName
is -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
single-layer -X- _ O
method -X- _ O
(SIDPG) -X- _ B-MethodName
in -X- _ O
both -X- _ O
evaluation -X- _ O
settings. -X- _ O

To -X- _ O
boost -X- _ O
single-layer -X- _ O
IDPG -X- _ B-MethodName
performance, -X- _ O
we -X- _ O
add -X- _ O
supplementary -X- _ O
training -X- _ O
(cf. -X- _ O
Appendix -X- _ O
A.4) -X- _ O
and -X- _ O
conduct -X- _ O
ablation -X- _ O
studies -X- _ O
in -X- _ O
Appendix -X- _ O
A.5. -X- _ O

P-tuning -X- _ B-MethodName
v2 -X- _ I-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021a) -X- _ O
conducted -X- _ O
substantial -X- _ O
ablation -X- _ O
studies -X- _ O
on -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
inserting -X- _ O
prompt -X- _ O
into -X- _ O
different -X- _ O
transformer -X- _ O
layers. -X- _ O

Multi-layer? -X- _ O

4.5.4 -X- _ O
Prompt -X- _ O
Insertion: -X- _ O
Single-layer -X- _ O
or -X- _ O

Detailed -X- _ O
information -X- _ O
for -X- _ O
all -X- _ O
models’ -X- _ O
performance -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.3. -X- _ O

In -X- _ O
Table -X- _ O
1, -X- _ O
M-IDPG-PHM -X- _ B-MethodName
uses -X- _ O
the -X- _ O
previous -X- _ O
layer’s -X- _ O
output -X- _ O
as -X- _ O
input, -X- _ O
M -X- _ O
version -X- _ O
as -X- _ O
the -X- _ O
generator, -X- _ O
and -X- _ O
16 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
generator -X- _ O
hidden -X- _ B-HyperparameterName
size. -X- _ I-HyperparameterName

As -X- _ O
for -X- _ O
the -X- _ O
generator -X- _ O
selection, -X- _ O
the -X- _ O
three -X- _ O
models -X- _ O
perform -X- _ O
as -X- _ O
expected -X- _ O
(S -X- _ O
version -X- _ O
< -X- _ O
M -X- _ O
version -X- _ O
< -X- _ O
L -X- _ O
version). -X- _ O

However, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3, -X- _ O
the -X- _ O
experiment -X- _ O
results -X- _ O
suggest -X- _ O
no -X- _ O
significant -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
input -X- _ O
ways. -X- _ O

In -X- _ O
a -X- _ O
multi-layer -X- _ O
case, -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
each -X- _ O
layer -X- _ O
generator -X- _ O
has -X- _ O
another -X- _ O
option, -X- _ O
i.e., -X- _ O
the -X- _ O
previous -X- _ O
layer’s -X- _ O
output. -X- _ O

in -X- _ O
single-layer -X- _ O
prompt -X- _ O
generation -X- _ O
model, -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
G -X- _ O
is -X- _ O
M(xi) -X- _ O
- -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
input -X- _ O
sequence -X- _ O
xi. -X- _ O

We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
smaller -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
is -X- _ O
already -X- _ O
enough -X- _ O
to -X- _ O
store -X- _ O
useful -X- _ O
instance -X- _ O
information, -X- _ O
and -X- _ O
setting -X- _ O
m -X- _ O
too -X- _ O
large -X- _ O
may -X- _ O
be -X- _ O
less -X- _ O
efficient. -X- _ O

Surprisingly, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
generator -X- _ O
with -X- _ O
a -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
16 -X- _ B-HyperparameterValue
is -X- _ O
not -X- _ O
far -X- _ O
from -X- _ O
the -X- _ O
large -X- _ O
model -X- _ O
(92.0 -X- _ B-MetricValue
vs. -X- _ O
92.1, -X- _ B-MetricValue
respectively, -X- _ O
in -X- _ O
M -X- _ O
version). -X- _ O

We -X- _ O
compare -X- _ O
two -X- _ O
models -X- _ O
with -X- _ O
m -X- _ B-HyperparameterName
= -X- _ O
16 -X- _ B-HyperparameterValue
and -X- _ O
m -X- _ B-HyperparameterName
= -X- _ O
256. -X- _ B-HyperparameterValue

Another -X- _ O
way -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
training -X- _ O
parameters -X- _ O
is -X- _ O
by -X- _ O
adjusting -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
generator. -X- _ O

If -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
requires -X- _ O
an -X- _ O
independent -X- _ O
generator -X- _ O
Gi, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O

When -X- _ O
applying -X- _ O
the -X- _ O
instance-dependent -X- _ O
generation -X- _ O
model -X- _ O
G -X- _ O
into -X- _ O
a -X- _ O
multi-layer -X- _ O
case, -X- _ O
the -X- _ O
first -X- _ O
challenge -X- _ O
we -X- _ O
face -X- _ O
is -X- _ O
the -X- _ O
considerable -X- _ O
increase -X- _ O
in -X- _ O
training -X- _ O
parameters. -X- _ O

4.5.3 -X- _ O
Multi-layer -X- _ O
Architecture -X- _ O
Exploration -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
this -X- _ O
ablation -X- _ O
study -X- _ O
further -X- _ O
verifies -X- _ O
PHM -X- _ O
layers’ -X- _ O
efficiency -X- _ O
in -X- _ O
the -X- _ O
generation -X- _ O
model. -X- _ O

We -X- _ O
observe -X- _ O
that -X- _ O
including -X- _ O
DNN -X- _ O
as -X- _ O
a -X- _ O
generator -X- _ O
doesn’t -X- _ O
improve -X- _ O
performance -X- _ O
signif -X- _ O

Hence, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
PHM-based -X- _ O
prompt -X- _ O
generator -X- _ O
with -X- _ O
the -X- _ O
DNN-based -X- _ O
prompt -X- _ O
generator, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

An -X- _ O
open -X- _ O
question -X- _ O
we -X- _ O
seek -X- _ O
to -X- _ O
answer -X- _ O
is -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
generation -X- _ O
model -X- _ O
for -X- _ O
prompt -X- _ O
regardless -X- _ O
of -X- _ O
training -X- _ O
parameters. -X- _ O

To -X- _ O
reduce -X- _ O
the -X- _ O
tuning -X- _ O
parameters, -X- _ O
we -X- _ O
substitute -X- _ O
the -X- _ O
DNN -X- _ O
layers -X- _ O
with -X- _ O
PHM -X- _ O
layers. -X- _ O

4.5.2 -X- _ O
Prompt -X- _ O
Generator: -X- _ O
PHM -X- _ O
or -X- _ O
DNN? -X- _ O

Adopting -X- _ O
GloVe -X- _ O
as -X- _ O
sentence -X- _ O
encoder -X- _ O
would -X- _ O
avoid -X- _ O
going -X- _ O
through -X- _ O
the -X- _ O
LM -X- _ O
twice, -X- _ O
thus -X- _ O
effectively -X- _ O
reducing -X- _ O
IDPG’s -X- _ B-MethodName
run-time -X- _ O
complexity -X- _ O
by -X- _ O
half. -X- _ O

One -X- _ O
of -X- _ O
the -X- _ O
drawbacks -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
twice -X- _ O
as -X- _ O
expensive -X- _ O
to -X- _ O
run -X- _ O
compared -X- _ O
to -X- _ O
Compacter, -X- _ B-MethodName
even -X- _ O
though -X- _ O
it -X- _ O
uses -X- _ O
slightly -X- _ O
fewer -X- _ O
parameters. -X- _ O

According -X- _ O
to -X- _ O
Table -X- _ O
1, -X- _ O
using -X- _ O
GloVe -X- _ O
as -X- _ O
sentence -X- _ O
encoder -X- _ O
to -X- _ O
generate -X- _ O
prompts -X- _ O
doesn’t -X- _ O
sacrifice -X- _ O
much -X- _ O
performance -X- _ O
over -X- _ O
the -X- _ O
ten -X- _ O
tasks -X- _ O
and -X- _ O
outperforms -X- _ O
prompt -X- _ B-MethodName
tuning -X- _ I-MethodName
and -X- _ O
P-tuning -X- _ B-MethodName
v2. -X- _ I-MethodName

Method -X- _ O

For -X- _ O
all -X- _ O
other -X- _ O
tasks, -X- _ O
we -X- _ O
report -X- _ O
accuracy. -X- _ B-MetricName

We -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
for -X- _ O
both -X- _ O
MRPC -X- _ B-DatasetName
and -X- _ O
QQP, -X- _ B-DatasetName
and -X- _ O
average -X- _ O
of -X- _ O
Pearson -X- _ B-MetricName
and -X- _ I-MetricName
Spearman -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficients -X- _ I-MetricName
for -X- _ O
STS-B. -X- _ B-DatasetName

Underline -X- _ O
marks -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
among -X- _ O
all -X- _ O
prompt -X- _ O
tuning -X- _ O
methods. -X- _ O

Bold -X- _ O
marks -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
among -X- _ O
all -X- _ O
competing -X- _ O
methods. -X- _ O

We -X- _ O
report -X- _ O
average -X- _ O
results -X- _ O
across -X- _ O
5 -X- _ O
runs -X- _ O
with -X- _ O
different -X- _ O
initialization. -X- _ O

Specifically, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
word -X- _ O
vectors -X- _ O
as -X- _ O
the -X- _ O
sentence -X- _ O
embeddings: -X- _ O

To -X- _ O
answer -X- _ O
this -X- _ O
question, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
pre-trained -X- _ O
GloVe -X- _ O
word -X- _ O
vectors2 -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
sentence -X- _ O
representation. -X- _ O

One -X- _ O
open -X- _ O
question -X- _ O
is -X- _ O
to -X- _ O
explore -X- _ O
reliability -X- _ O
on -X- _ O
lightweight -X- _ O
sentence -X- _ O
representations -X- _ O
such -X- _ O
as -X- _ O
GloVe -X- _ O
embedding -X- _ O
(Pennington -X- _ O
et -X- _ O
al., -X- _ O
2014) -X- _ O
or -X- _ O
token -X- _ O
embedding -X- _ O
of -X- _ O
pre-trained -X- _ O
language -X- _ O
models. -X- _ O

Obtaining -X- _ O
contextualized -X- _ O
transformer -X- _ O
sentence -X- _ O
embedding -X- _ O
is -X- _ O
often -X- _ O
expensive -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
pre-computed. -X- _ O

The -X- _ O
proposed -X- _ O
IDPG -X- _ B-MethodName
method -X- _ O
relies -X- _ O
on -X- _ O
pre-trained -X- _ O
LM -X- _ O
to -X- _ O
extract -X- _ O
sentence -X- _ O
representation, -X- _ O
i.e., -X- _ O
[CLS] -X- _ O
token -X- _ O
embedding. -X- _ O

4.5.1 -X- _ O
Sentence -X- _ O
Encoder: -X- _ O
GloVe -X- _ O
or -X- _ O
LMs? -X- _ O

We -X- _ O
conduct -X- _ O
several -X- _ O
ablation -X- _ O
studies -X- _ O
including -X- _ O
exploration -X- _ O
of -X- _ O
different -X- _ O
generator -X- _ O
architectures -X- _ O
and -X- _ O
impact -X- _ O
of -X- _ O
selecting -X- _ O
different -X- _ O
prompt -X- _ O
positions. -X- _ O

4.5 -X- _ O
Intrinsic -X- _ O
Study -X- _ O

Testing -X- _ O
the -X- _ O
limitation -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
without -X- _ O
freezing -X- _ O
any -X- _ O
parameters -X- _ O
would -X- _ O
be -X- _ O
an -X- _ O
interesting -X- _ O
investigation, -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
main -X- _ O
focus -X- _ O
of -X- _ O
this -X- _ O
paper. -X- _ O

We -X- _ O
want -X- _ O
to -X- _ O
highlight -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
exploring -X- _ O
a -X- _ O
solution -X- _ O
by -X- _ O
training -X- _ O
as -X- _ O
few -X- _ O
parameters -X- _ O
as -X- _ O
possible -X- _ O
while -X- _ O
maintaining -X- _ O
good -X- _ O
performance. -X- _ O

We -X- _ O
also -X- _ O
note -X- _ O
that -X- _ O
other -X- _ O
state-of-the-art -X- _ O
models, -X- _ O
such -X- _ O
as -X- _ O
LM-BFF -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
attempt -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
few-shot -X- _ B-TaskName
learning -X- _ I-TaskName
problem -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
perspective. -X- _ O

We -X- _ O
suspect -X- _ O
that -X- _ O
this -X- _ O
may -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
poor -X- _ O
initialization -X- _ O
leading -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
non-optimal -X- _ O
parameters. -X- _ O

We -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
sometimes -X- _ O
when -X- _ O
K -X- _ O
is -X- _ O
small, -X- _ O
our -X- _ O
method -X- _ O
results -X- _ O
have -X- _ O
high -X- _ O
variance -X- _ O
(e.g., -X- _ O
4.6 -X- _ O
on -X- _ O
MPQA, -X- _ B-DatasetName
when -X- _ O
K -X- _ O
= -X- _ O
100). -X- _ O

When -X- _ O
K -X- _ O
becomes -X- _ O
larger, -X- _ O
IDPG-PHM -X- _ B-MethodName
still -X- _ O
maintains -X- _ O
good -X- _ O
results -X- _ O
with -X- _ O
1.9pt -X- _ B-MetricValue
and -X- _ O
0.2pt -X- _ B-MetricValue
improvement -X- _ O
(K=500); -X- _ O
and -X- _ O
2.0pt -X- _ B-MetricValue
and -X- _ O
0.2pt -X- _ B-MetricValue
improvement -X- _ O
(K=1000) -X- _ O
in -X- _ O
accuracy -X- _ B-MetricName
with -X- _ O
traditional -X- _ B-MethodName
prompt -X- _ I-MethodName
tuning -X- _ I-MethodName
and -X- _ O
P-tuning -X- _ B-MethodName
v2 -X- _ I-MethodName
approaches, -X- _ O
respectively. -X- _ O

This -X- _ O
improvement -X- _ O
illustrates -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
has -X- _ O
better -X- _ O
generalization -X- _ O
in -X- _ O
few-shot -X- _ O
settings. -X- _ O

In -X- _ O
the -X- _ O
extreme -X- _ O
low-resource -X- _ O
case -X- _ O
when -X- _ O
K=100, -X- _ O
M-IDPG-PHM -X- _ B-MethodName
performs -X- _ O
2.5pt -X- _ B-MetricValue
better -X- _ O
than -X- _ O
the -X- _ O
traditional -X- _ O
prompt -X- _ O
tuning -X- _ O
method -X- _ O
and -X- _ O
0.5pt -X- _ B-MetricValue
better -X- _ O
than -X- _ O
the -X- _ O
multi-layer -X- _ O
P-Tuning -X- _ B-MethodName
v2 -X- _ I-MethodName
method. -X- _ O

Following -X- _ O
the -X- _ O
existing -X- _ O
evaluation -X- _ O
protocols -X- _ O
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting -X- _ O
(He -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
we -X- _ O
sample -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
with -X- _ O
size -X- _ O
K -X- _ B-HyperparameterName
as -X- _ O
our -X- _ O
∈ -X- _ O
{ -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
another -X- _ O
subset -X- _ O
with -X- _ O
size -X- _ B-HyperparameterName
1000 -X- _ B-HyperparameterValue
as -X- _ O
a -X- _ O
development -X- _ O
set. -X- _ O

4.4 -X- _ O
Performance -X- _ O
in -X- _ O
low-resource -X- _ O
scenario -X- _ O

# -X- _ O
Parameters -X- _ O

Method -X- _ O

Our -X- _ O
proposed -X- _ O
method, -X- _ O
especially -X- _ O
the -X- _ O
M-IDPGPHM, -X- _ B-MethodName
falls -X- _ O
in -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
prompt-tuning -X- _ O
and -X- _ O
adapter -X- _ O
model, -X- _ O
since -X- _ O
it -X- _ O
only -X- _ O
requires -X- _ O
training -X- _ O
134K -X- _ O
parameters -X- _ O
and -X- _ O
performs -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
Compacter. -X- _ B-MethodName

However, -X- _ O
its -X- _ O
performance -X- _ O
is -X- _ O
worse -X- _ O
than -X- _ O
a -X- _ O
lightweight -X- _ O
adapter -X- _ O
model -X- _ O
(e.g., -X- _ O
Compacter -X- _ B-MethodName
with -X- _ O
149K -X- _ O
parameters). -X- _ O

Traditional -X- _ O
prompt-tuning -X- _ O
method -X- _ O
only -X- _ O
requires -X- _ O
training -X- _ O
a -X- _ O
token -X- _ O
embedding -X- _ O
table -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
thousand -X- _ O
parameters. -X- _ O

The -X- _ O
general -X- _ O
goal -X- _ O
for -X- _ O
efficient -X- _ O
transfer -X- _ O
learning -X- _ O
is -X- _ O
to -X- _ O
train -X- _ O
models -X- _ O
with -X- _ O
fewer -X- _ O
parameters -X- _ O
while -X- _ O
achieving -X- _ O
better -X- _ O
performance. -X- _ O

Table -X- _ O
2 -X- _ O
lists -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
for -X- _ O
different -X- _ O
methods -X- _ O
excluding -X- _ O
the -X- _ O
classification -X- _ O
head. -X- _ O

4.3 -X- _ O
Efficiency -X- _ O

(vi) -X- _ O
When -X- _ O
we -X- _ O
fix -X- _ O
the -X- _ O
training -X- _ O
parameters -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
same, -X- _ O
the -X- _ O
comparison -X- _ O
between -X- _ O
Prompttuning-134 -X- _ B-MethodName
and -X- _ O
M-IDPG-PHM -X- _ B-MethodName
illustrates -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
works -X- _ O
better -X- _ O
than -X- _ O
prompt -X- _ O
tuning -X- _ O
not -X- _ O
just -X- _ O
because -X- _ O
of -X- _ O
using -X- _ O
more -X- _ O
parameters. -X- _ O

(v) -X- _ O
GloVe-based -X- _ O
sentence -X- _ O
encoder -X- _ O
also -X- _ O
performs -X- _ O
similar -X- _ O
to -X- _ O
LMbased -X- _ O
sentence -X- _ O
encoder, -X- _ O
indicating -X- _ O
the -X- _ O
advancement -X- _ O
of -X- _ O
instance-dependent -X- _ O
prompt -X- _ O
generation -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
robust -X- _ O
contextual -X- _ O
sentence -X- _ O
encoder. -X- _ O

based -X- _ O
generator -X- _ O
performs -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
the -X- _ O
DNNbased -X- _ O
generator -X- _ O
while -X- _ O
having -X- _ O
a -X- _ O
significantly -X- _ O
lower -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters. -X- _ O

Specifically, -X- _ O
M-IDPG-PHM -X- _ B-MethodName
performs -X- _ O
0.84pt -X- _ B-MetricValue
and -X- _ O
0.36pt -X- _ B-MetricValue
better -X- _ O
than -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
EFL, -X- _ B-MethodName
respectively. -X- _ O

The -X- _ O
four -X- _ O
best -X- _ O
results -X- _ O
(MPQA, -X- _ B-DatasetName
Subj, -X- _ B-DatasetName
CR, -X- _ B-DatasetName
MR) -X- _ B-DatasetName
among -X- _ O
all -X- _ O
competing -X- _ O
methods -X- _ O
in -X- _ O
single-sentence -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
are -X- _ O
made -X- _ O
by -X- _ O
IDPG -X- _ B-MethodName
models. -X- _ O

The -X- _ O
improvement -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
more -X- _ O
prominent -X- _ O
in -X- _ O
the -X- _ O
single-sentence -X- _ B-TaskName
classification -X- _ I-TaskName
task. -X- _ O

M-IDPG-PHM -X- _ B-MethodName
is -X- _ O
better -X- _ O
than -X- _ O
Compacter -X- _ B-MethodName
on -X- _ O
four -X- _ O
tasks -X- _ O
and -X- _ O
has -X- _ O
the -X- _ O
same -X- _ O
performance -X- _ O
on -X- _ O
three -X- _ O
tasks. -X- _ O

Note -X- _ O
that -X- _ O
IDPG -X- _ B-MethodName
uses -X- _ O
15K -X- _ O
fewer -X- _ O
parameters -X- _ O
than -X- _ O
the -X- _ O
Compacter. -X- _ B-MethodName

However, -X- _ O
the -X- _ O
gap -X- _ O
is -X- _ O
mostly -X- _ O
from -X- _ O
RTE -X- _ B-DatasetName
and -X- _ O
QQP. -X- _ B-DatasetName

(ii) -X- _ O
Compared -X- _ O
with -X- _ O
other -X- _ O
efficient -X- _ O
transfer -X- _ O
learning -X- _ O
methods, -X- _ O
IDPG -X- _ B-MethodName
performs -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
Compacter -X- _ B-MethodName
(Mahabadi -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
Adapter -X- _ B-MethodName
(Houlsby -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
across -X- _ O
the -X- _ O
ten -X- _ O
tasks. -X- _ O

We -X- _ O
observe -X- _ O
that: -X- _ O
(i) -X- _ O
Our -X- _ O
proposed -X- _ O
method -X- _ O
M-IDPG-PHM -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
the -X- _ O
prompt -X- _ O
tuning -X- _ O
method -X- _ O
and -X- _ O
Ptuning -X- _ B-MethodName
v2 -X- _ I-MethodName
by -X- _ O
average -X- _ O
3.1pt -X- _ B-MetricValue
and -X- _ O
1.6pt, -X- _ B-MetricValue
respectively -X- _ O
(except -X- _ O
on -X- _ O
the -X- _ O
RTE -X- _ B-DatasetName
dataset). -X- _ O

Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
methods -X- _ O
on -X- _ O
full -X- _ O
datasets -X- _ O
across -X- _ O
10 -X- _ O
NLU -X- _ B-TaskName
tasks. -X- _ O

4.2 -X- _ O
Performance -X- _ O
in -X- _ O
high-resource -X- _ O
scenario -X- _ O

Notably, -X- _ O
Prompt-tuning134 -X- _ B-MethodName
uses -X- _ O
134 -X- _ O
prompt -X- _ B-HyperparameterName
lengths -X- _ I-HyperparameterName
in -X- _ O
Table -X- _ O
1, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
set -X- _ O
so -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
training -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method, -X- _ O
M-IDPG-PHM. -X- _ B-MethodName

Additional -X- _ O
training -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.1. -X- _ O

For -X- _ O
a -X- _ O
fair -X- _ O
comparison, -X- _ O
all -X- _ O
the -X- _ O
pre-trained -X- _ O
LMs -X- _ O
are -X- _ O
24-layer -X- _ B-HyperparameterValue
16-head -X- _ B-HyperparameterValue
RoBERTa-Large -X- _ O
models -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Again, -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
prompt -X- _ O
generator, -X- _ O
while -X- _ O
M-IDPG-PHMGloVe -X- _ B-MethodName
uses -X- _ O
GloVe -X- _ O
to -X- _ O
encode -X- _ O
input -X- _ O
sequences. -X- _ O

We -X- _ O
also -X- _ O
explore -X- _ O
three -X- _ O
versions -X- _ O
of -X- _ O
multilayer -X- _ O
instance-dependent -X- _ O
generation -X- _ O
methods: -X- _ O
M-IDPG-DNN, -X- _ B-MethodName
M-IDPG-PHM, -X- _ B-MethodName
M-IDPG-PHM -X- _ B-MethodName

The -X- _ O
second -X- _ O
one -X- _ O
uses -X- _ O
the -X- _ O
PHM -X- _ O
layer -X- _ O
and -X- _ O
only -X- _ O
contains -X- _ O
105K -X- _ O
parameters. -X- _ O

The -X- _ O
first -X- _ O
version -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
2-layer -X- _ O
perceptron -X- _ O
generator, -X- _ O
which -X- _ O
contains -X- _ O
1.5M -X- _ O
parameters. -X- _ O

We -X- _ O
compare -X- _ O
these -X- _ O
against -X- _ O
two -X- _ O
versions -X- _ O
of -X- _ O
singlelayer -X- _ O
instance-dependent -X- _ O
generation -X- _ O
methods: -X- _ O
SIDPG-DNN -X- _ B-MethodName
and -X- _ O
S-IDPG-PHM. -X- _ B-MethodName

Adapter-based -X- _ B-MethodName
fine-tuning: -X- _ I-MethodName
This -X- _ O
efficient -X- _ O
transfer -X- _ O
learning -X- _ O
method -X- _ O
inserts -X- _ O
an -X- _ O
adaptation -X- _ O
module -X- _ O
inside -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
including -X- _ O
Compactor -X- _ B-MethodName
(Mahabadi -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
Adapter -X- _ B-MethodName
(Houlsby -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Prompt -X- _ B-MethodName
tuning: -X- _ I-MethodName
We -X- _ O
implemented -X- _ O
two -X- _ O
versions -X- _ O
– -X- _ O
standard -X- _ B-MethodName
prompt -X- _ I-MethodName
tuning -X- _ I-MethodName
(Lester -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
multi-layer -X- _ B-MethodName
prompt -X- _ I-MethodName
tuning -X- _ I-MethodName
(Li -X- _ O
and -X- _ O
Liang, -X- _ O
2021; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2021a). -X- _ O

Transformer -X- _ B-MethodName
fine-tuning: -X- _ I-MethodName
We -X- _ O
instantiated -X- _ O
two -X- _ O
versions -X- _ O
– -X- _ O
a -X- _ O
vanilla -X- _ O
transformer -X- _ O
fine-tuning -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
the -X- _ O
entailment-based -X- _ O
finetuning -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
with -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
methods, -X- _ O
as -X- _ O
follows: -X- _ O

SST-2, -X- _ B-MethodName
QNLI, -X- _ B-MethodName
RTE, -X- _ B-MethodName
MRPC, -X- _ B-MethodName
STS-B -X- _ B-MethodName
(Cer -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
and -X- _ O
QQP. -X- _ B-MethodName

We -X- _ O
evaluate -X- _ O
on -X- _ O
ten -X- _ O
standard -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
(NLU) -X- _ B-TaskName
datasets -X- _ O
– -X- _ O
MPQA -X- _ B-DatasetName
(Wiebe -X- _ O
et -X- _ O
al., -X- _ O
2005), -X- _ O
Subj -X- _ B-DatasetName
(Pang -X- _ O
and -X- _ O
Lee, -X- _ O
2004), -X- _ O
CR -X- _ B-DatasetName
(Hu -X- _ O
and -X- _ O
Liu, -X- _ O
2004), -X- _ O
MR -X- _ B-DatasetName
(Pang -X- _ O
and -X- _ O
Lee, -X- _ O
2005), -X- _ O
and -X- _ O
six -X- _ O
tasks -X- _ O
from -X- _ O
GLUE -X- _ B-DatasetName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
viz. -X- _ O

4.1 -X- _ O
Experimental -X- _ O
Setup -X- _ O

4 -X- _ O
Experiment -X- _ O
Results -X- _ O

Method -X- _ O

For -X- _ O
all -X- _ O
the -X- _ O
other -X- _ O
tasks, -X- _ O
we -X- _ O
report -X- _ O
accuracy. -X- _ B-MetricName

We -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
accuracy -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
for -X- _ O
both -X- _ O
MRPC -X- _ B-DatasetName
and -X- _ O
QQP, -X- _ B-DatasetName
and -X- _ O
average -X- _ O
of -X- _ O
Pearson -X- _ B-MetricName
and -X- _ I-MetricName
Spearman -X- _ I-MetricName
correlation -X- _ I-MetricName
coefficients -X- _ I-MetricName
for -X- _ O
STS-B. -X- _ B-DatasetName

Underline -X- _ O
marks -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
among -X- _ O
all -X- _ O
prompt -X- _ B-TaskName
tuning -X- _ I-TaskName
methods. -X- _ O

Bold -X- _ O
marks -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
among -X- _ O
all -X- _ O
competing -X- _ O
methods. -X- _ O

We -X- _ O
report -X- _ O
average -X- _ O
results -X- _ O
across -X- _ O
5 -X- _ O
runs -X- _ O
with -X- _ O
different -X- _ O
initialization. -X- _ O

Each -X- _ O
methods -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
full -X- _ O
test -X- _ O
sets -X- _ O
(dev -X- _ O
sets -X- _ O
for -X- _ O
GLUE -X- _ B-DatasetName
tasks). -X- _ O

In -X- _ O
short, -X- _ O
assuming -X- _ O
each -X- _ O
layer -X- _ O
generator -X- _ O
Gi -X- _ O
has -X- _ O
form -X- _ O
y -X- _ O
= -X- _ O
Wx -X- _ O
+ -X- _ O
bi, -X- _ O
we -X- _ O
share -X- _ O
the -X- _ O
weight -X- _ O
matrix -X- _ O
Rm -X- _ O
W -X- _ O
across -X- _ O
generators -X- _ O
and -X- _ O
set -X- _ O
the -X- _ O
bias -X- _ O
term -X- _ O
bi -X- _ O
∈ -X- _ O
to -X- _ O
be -X- _ O
layer-specific, -X- _ O
where -X- _ O
i -X- _ O
= -X- _ O
1, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O

However, -X- _ O
simply -X- _ O
generalizing -X- _ O
our -X- _ O
model -X- _ O
(IDPG) -X- _ B-MethodName
to -X- _ O
a -X- _ O
multi-layer -X- _ O
version -X- _ O
(M-IDPG), -X- _ B-MethodName
will -X- _ O
significantly -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
parameters, -X- _ O
since -X- _ O
each -X- _ O
layer -X- _ O
requires -X- _ O
an -X- _ O
independent -X- _ O
generator -X- _ O
G. -X- _ O
Instead, -X- _ O
we -X- _ O
explore -X- _ O
different -X- _ O
architectures -X- _ O
in -X- _ O
Section -X- _ O
4.5.3 -X- _ O
to -X- _ O
balance -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tuned -X- _ O
parameters -X- _ O
against -X- _ O
model -X- _ O
performance. -X- _ O

Following -X- _ O
Prefix -X- _ B-MethodName
tuning -X- _ I-MethodName
(Li -X- _ O
and -X- _ O
Liang, -X- _ O
2021) -X- _ O
and -X- _ O
P-tuning -X- _ B-MethodName
v2 -X- _ I-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
we -X- _ O
prepend -X- _ O
our -X- _ O
generated -X- _ O
prompts -X- _ O
at -X- _ O
each -X- _ O
transformer -X- _ O
layer -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
above -X- _ O
issues. -X- _ O

(ii) -X- _ O
Generalizing -X- _ O
to -X- _ O
long -X- _ O
sequence -X- _ O
tasks: -X- _ O
it -X- _ O
is -X- _ O
unclear -X- _ O
that -X- _ O
prompt -X- _ O
tuning -X- _ O
can -X- _ O
perform -X- _ O
well -X- _ O
in -X- _ O
tasks -X- _ O
with -X- _ O
long -X- _ O
input -X- _ O
when -X- _ O
only -X- _ O
a -X- _ O
limited -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
can -X- _ O
be -X- _ O
inserted -X- _ O
in -X- _ O
single -X- _ O
layer. -X- _ O

While -X- _ O
proven -X- _ O
efficient -X- _ O
in -X- _ O
some -X- _ O
specific -X- _ O
settings, -X- _ O
single -X- _ O
layer -X- _ O
prompt -X- _ O
tuning -X- _ O
has -X- _ O
two -X- _ O
main -X- _ O
limitations: -X- _ O
(i) -X- _ O
Capturing -X- _ O
deep -X- _ O
contextual -X- _ O
information: -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
first-layer -X- _ O
prompts -X- _ O
on -X- _ O
final -X- _ O
prediction -X- _ O
is -X- _ O
low -X- _ O
when -X- _ O
transformer -X- _ O
goes -X- _ O
deeper. -X- _ O

Prompt -X- _ B-MethodName
tuning -X- _ I-MethodName
(Lester -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
and -X- _ O
Ptuning -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021b) -X- _ O
both -X- _ O
insert -X- _ O
continuous -X- _ O
prompts -X- _ O
into -X- _ O
the -X- _ O
first -X- _ O
transformer -X- _ O
layer -X- _ O
(cf. -X- _ O

3.2.2 -X- _ O
Multi-layer -X- _ O
Prompt -X- _ O
Tuning -X- _ O

By -X- _ O
substituting -X- _ O
the -X- _ O
W1 -X- _ O
and -X- _ O
W2 -X- _ O
by -X- _ O
two -X- _ O
PHM -X- _ O
layers -X- _ O
and -X- _ O
letting -X- _ O
Ai -X- _ O
shared -X- _ O
by -X- _ O
both -X- _ O
layers, -X- _ O
we -X- _ O
can -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
from -X- _ O
1.5M -X- _ O
to -X- _ O
105K. -X- _ O

For -X- _ O
example, -X- _ O
we -X- _ O
use -X- _ O
RoBERTa-Large -X- _ O
with -X- _ O
hidden -X- _ O
size -X- _ O
d -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
generator -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
m -X- _ B-HyperparameterName
= -X- _ O
256, -X- _ B-HyperparameterValue
n -X- _ B-HyperparameterName
= -X- _ O
16, -X- _ B-HyperparameterValue
prompt -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
t -X- _ B-HyperparameterName
= -X- _ O
5. -X- _ B-HyperparameterValue

Suppose -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
two -X- _ O
layer -X- _ O
perceptron -X- _ O
d -X- _ O
and -X- _ O
upwith -X- _ O
down-sample -X- _ O
projection -X- _ O
W1 -X- _ O
∈ -X- _ O
× -X- _ O
m, -X- _ O
where -X- _ O
d -X- _ O
is -X- _ O
the -X- _ O
sample -X- _ O
projection -X- _ O
W2 -X- _ O
∈ -X- _ O
× -X- _ O
input -X- _ O
embedding -X- _ O
dimension, -X- _ O
m -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
layer -X- _ I-HyperparameterName
dimension, -X- _ I-HyperparameterName
and -X- _ O
t -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
we -X- _ O
generate. -X- _ O

As -X- _ O
n -X- _ B-HyperparameterName
is -X- _ O
usually -X- _ O
much -X- _ O
smaller -X- _ O
than -X- _ O
m -X- _ B-HyperparameterName
and -X- _ O
d, -X- _ B-HyperparameterName
PHM -X- _ O
reduces -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
parameters -X- _ O
by -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
n. -X- _ B-MethodName

PHM -X- _ O
replaces -X- _ O
the -X- _ O
matrix -X- _ O
W -X- _ O
by -X- _ O
a -X- _ O
sum -X- _ O
of -X- _ O
Kronecker -X- _ O
products -X- _ O
of -X- _ O
several -X- _ O
small -X- _ O
matrices. -X- _ O

When -X- _ O
m -X- _ O
and -X- _ O
d -X- _ O
are -X- _ O
large, -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
learning -X- _ O
W -X- _ O
becomes -X- _ O
the -X- _ O
main -X- _ O
bottleneck. -X- _ O

Inspired -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
application -X- _ O
of -X- _ O
parameterized -X- _ O
hypercomplex -X- _ O
multiplication -X- _ O
(PHM) -X- _ O
layers -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
in -X- _ O
Compacter -X- _ O
(Mahabadi -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
we -X- _ O
leverage -X- _ O
PHM -X- _ O
layers -X- _ O
to -X- _ O
optimize -X- _ O
our -X- _ O
prompt -X- _ O
generator, -X- _ O
G. -X- _ O
Generally, -X- _ O
the -X- _ O
PHM -X- _ O
layer -X- _ O
is -X- _ O
a -X- _ O
fullyconnected -X- _ O
layer -X- _ O
with -X- _ O
form -X- _ O

3.2.1 -X- _ O
Parameterized -X- _ O
Hypercomplex -X- _ O
Multiplication -X- _ O
(PHM) -X- _ O
Layers -X- _ O

We -X- _ O
propose -X- _ O
two -X- _ O
optimization -X- _ O
techniques -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
our -X- _ O
proposed -X- _ O
method. -X- _ O

3.2 -X- _ O
Optimization -X- _ O

In -X- _ O
practice, -X- _ O
we -X- _ O
can -X- _ O
cache -X- _ O
the -X- _ O
prediction -X- _ O
M(xi) -X- _ O
and -X- _ O
use -X- _ O
it -X- _ O
in -X- _ O
various -X- _ O
downstream -X- _ O
tasks -X- _ O
or -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
lightweight -X- _ O
sentence -X- _ O
representation -X- _ O
such -X- _ O
as -X- _ O
GloVe -X- _ O
(Pennington -X- _ O
et -X- _ O
al., -X- _ O
2014) -X- _ O
(Cf. -X- _ O
Section -X- _ O
4.5.1). -X- _ O

However, -X- _ O
the -X- _ O
sentence -X- _ O
representation -X- _ O
M(xi) -X- _ O
used -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
task-agnostic. -X- _ O

One -X- _ O
caveat -X- _ O
is -X- _ O
that -X- _ O
this -X- _ O
method -X- _ O
will -X- _ O
have -X- _ O
two -X- _ O
forward -X- _ O
passes -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
LM -X- _ O
during -X- _ O
inference -X- _ O
time -X- _ O
– -X- _ O
first -X- _ O
to -X- _ O
generate -X- _ O
M(xi) -X- _ O
and -X- _ O
then -X- _ O
to -X- _ O
generate -X- _ O
classification -X- _ O
results. -X- _ O

Note -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
representation -X- _ O
M(xi) -X- _ O
to -X- _ O
generate -X- _ O
prompts. -X- _ O

In -X- _ O
the -X- _ O
sequel, -X- _ O
we -X- _ O
will -X- _ O
introduce -X- _ O
a -X- _ O
parameter -X- _ O
squeezing -X- _ O
method -X- _ O
to -X- _ O
further -X- _ O
reduce -X- _ O
trainable -X- _ O
parameters -X- _ O
without -X- _ O
sacrificing -X- _ O
performance. -X- _ O

We -X- _ O
can -X- _ O
control -X- _ O
the -X- _ O
added -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
by -X- _ O
setting -X- _ O
m -X- _ B-HyperparameterName
d, -X- _ B-HyperparameterName
but -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
expensive -X- _ O
since -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
d -X- _ B-MethodName
is -X- _ O
usually -X- _ O
large -X- _ O
(1024 -X- _ B-HyperparameterValue
in -X- _ O
BERT/RoBERTa-Large). -X- _ O

An -X- _ O
optimization -X- _ O
of -X- _ O
multi-layer -X- _ O
prompt -X- _ O
generation -X- _ O
will -X- _ O
be -X- _ O
introduced -X- _ O
in -X- _ O
Section -X- _ O
3.2.2. -X- _ O

In -X- _ O
short, -X- _ O
what -X- _ O
we -X- _ O
discussed -X- _ O
here -X- _ O
is -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
t-length -X- _ O
prompt -X- _ O
for -X- _ O
one -X- _ O
Transformer -X- _ O
layer. -X- _ O

The -X- _ O
final -X- _ O
prompt -X- _ O
our -X- _ O
method -X- _ O
generated -X- _ O
is -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
both. -X- _ O

This -X- _ O
model -X- _ O
can -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
the -X- _ O
general -X- _ O
version -X- _ O
of -X- _ O
prompt -X- _ O
tuning: -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
layer -X- _ O
of -X- _ O
G, -X- _ O
the -X- _ O
bias -X- _ O
term -X- _ O
td -X- _ O
is -X- _ O
a -X- _ O
task-specific -X- _ O
prompt, -X- _ O
with -X- _ O
preceding -X- _ O
parts -X- _ O
td -X- _ O
m -X- _ O
generating -X- _ O
an -X- _ O
instance-dependent -X- _ O
prompt. -X- _ O

5510 -X- _ O

After -X- _ O
passing -X- _ O
through -X- _ O
a -X- _ O
nonlinear -X- _ O
function, -X- _ O
generator -X- _ O
G -X- _ O
projects -X- _ O
the -X- _ O
hidden -X- _ O
representation -X- _ O
back -X- _ O
to -X- _ O
a -X- _ O
d -X- _ O
dimensions -X- _ O

As -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
(c), -X- _ O
the -X- _ O
generator -X- _ O
G -X- _ O
first -X- _ O
projects -X- _ O
the -X- _ O
original -X- _ O
d-dimensional -X- _ O
sentence -X- _ O
representation -X- _ O
hi -X- _ O
into -X- _ O
m -X- _ O
dimensions. -X- _ O

To -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
in -X- _ O
G, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
lightweight -X- _ O
bottleneck -X- _ O
architecture -X- _ O
(i.e., -X- _ O
a -X- _ O
two-layer -X- _ O
perceptron) -X- _ O
for -X- _ O
generation. -X- _ O

If -X- _ O
M(xi) -X- _ O

Specifically, -X- _ O
we -X- _ O
suppose -X- _ O
that -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
prompt -X- _ O
should -X- _ O
not -X- _ O
only -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
T -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
be -X- _ O
affected -X- _ O
by -X- _ O
input -X- _ O
sequence -X- _ O
Rd -X- _ O
is -X- _ O
a -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sexi. -X- _ O

Different -X- _ O
from -X- _ O
all -X- _ O
previous -X- _ O
works -X- _ O
that -X- _ O
only -X- _ O
define -X- _ O
a -X- _ O
task-specific -X- _ O
prompt -X- _ O
t, -X- _ O
where -X- _ O
t -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
Wp(T -X- _ O
) -X- _ O
× -X- _ O
in -X- _ O
prompt -X- _ O
representation -X- _ O
and -X- _ O
d -X- _ O
is -X- _ O
the -X- _ O
hidden -X- _ O
dimension, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
instance-dependent -X- _ O
prompt -X- _ O
generation -X- _ O
method. -X- _ O

Following -X- _ O
prompt -X- _ O
tuning, -X- _ O
we -X- _ O
define -X- _ O
{ -X- _ O
} -X- _ O
the -X- _ O
input -X- _ O
xi -X- _ O
= -X- _ O
E([SEP]S1[SEP]S2[EOS]) -X- _ O
for -X- _ O
sentence-pair -X- _ O
task -X- _ O
or -X- _ O
xi -X- _ O
= -X- _ O
E([SEP]S1[EOS]) -X- _ O
for -X- _ O
single-sentence -X- _ O
task, -X- _ O
where -X- _ O
E( -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
token -X- _ O
em· -X- _ O
bedding -X- _ O
for -X- _ O
input -X- _ O
sentences. -X- _ O

Let -X- _ O
us -X- _ O
assume -X- _ O
a -X- _ O
task -X- _ O
T -X- _ O
with -X- _ O
training -X- _ O
data -X- _ O
Dtrain -X- _ O
= -X- _ O

In -X- _ O
this -X- _ O
way, -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
unified -X- _ O
template -X- _ O

Then, -X- _ O
we -X- _ O
insert -X- _ O
a -X- _ O
prompt -X- _ O
Wp(T -X- _ O
) -X- _ O
together -X- _ O
with -X- _ O
input -X- _ O
sequence -X- _ O
xi -X- _ O
to -X- _ O
infer -X- _ O
yi -X- _ O
during -X- _ O
fine-tuning. -X- _ O

Instance-Dependent -X- _ O
Generation -X- _ O

3.1 -X- _ O

The -X- _ O
main -X- _ O
procedure -X- _ O
is -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O

We -X- _ O
now -X- _ O
introduce -X- _ O
our -X- _ O
proposed -X- _ O
method, -X- _ O
IDPG, -X- _ B-MethodName
along -X- _ O
with -X- _ O
various -X- _ O
model -X- _ O
optimizations. -X- _ O

Apart -X- _ O
from -X- _ O
LM-BFF -X- _ O
and -X- _ O
EFL, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
corresponding -X- _ O
real -X- _ O
text -X- _ O
for -X- _ O
the -X- _ O
prompt -X- _ O
as -X- _ O
Wp -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
random-initialized -X- _ O
tensors -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
soft -X- _ O
prompt. -X- _ O

Specifically, -X- _ O
they -X- _ O
reformulate -X- _ O
the -X- _ O
input -X- _ O
for -X- _ O
single -X- _ O
sentence -X- _ O
tasks -X- _ O
as -X- _ O

Prompt -X- _ B-MethodName
tuning -X- _ I-MethodName
(Lester -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
prefix -X- _ B-MethodName
tuning -X- _ I-MethodName
(Li -X- _ O
and -X- _ O
Liang, -X- _ O
2021), -X- _ O
and -X- _ O
P-tuning -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021a,b) -X- _ O
methods -X- _ O
propose -X- _ O
to -X- _ O
insert -X- _ O
a -X- _ O
trainable -X- _ O
prefix -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sequence. -X- _ O

2.2 -X- _ O
Prompt -X- _ O
Tuning -X- _ O

EFL -X- _ B-MethodName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
further -X- _ O
suggests -X- _ O
that -X- _ O
reformulating -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
entailment -X- _ O
can -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
both -X- _ O
lowresource -X- _ O
and -X- _ O
high-resource -X- _ O
scenarios. -X- _ O

LM-BFF -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021a) -X- _ O
shows -X- _ O
that -X- _ O
adding -X- _ O
a -X- _ O
specifically -X- _ O
designed -X- _ O
prompt -X- _ O
during -X- _ O
fine-tuning -X- _ O
can -X- _ O
benefit -X- _ O
the -X- _ O
few-shot -X- _ O
scenario. -X- _ O

Using -X- _ O
the -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
M, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
sentence -X- _ O
representation -X- _ O
h[CLS] -X- _ O
= -X- _ O
M(xin), -X- _ O
and -X- _ O
train -X- _ O
a -X- _ O
task-specific -X- _ O
head -X- _ O
softmax(Wh[CLS]) -X- _ O
to -X- _ O
maximize -X- _ O
the -X- _ O
logprobability -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
label. -X- _ O

xin -X- _ O
= -X- _ O

For -X- _ O
example, -X- _ O
it -X- _ O
reformulates -X- _ O
a -X- _ O
sentence -X- _ O
sentiment -X- _ O
classification -X- _ O
task -X- _ O
with -X- _ O
an -X- _ O
input -X- _ O
sentence -X- _ O
S1 -X- _ O
as -X- _ O

Manual -X- _ O
prompt -X- _ O
learning -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021) -X- _ O
inserts -X- _ O
a -X- _ O
pre-defined -X- _ O
label -X- _ O
words -X- _ O
in -X- _ O
each -X- _ O
input -X- _ O
sentence. -X- _ O

2.1 -X- _ O
Manual -X- _ O
Prompt -X- _ O

2 -X- _ O
Preliminary -X- _ O

We -X- _ O
conduct -X- _ O
substantial -X- _ O
intrinsic -X- _ O
studies, -X- _ O
revealing -X- _ O
how -X- _ O
and -X- _ O
why -X- _ O
each -X- _ O
component -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
prompts -X- _ O
could -X- _ O
help -X- _ O
the -X- _ O
downstream -X- _ O
tasks. -X- _ O

Additionally, -X- _ O
it -X- _ O
offers -X- _ O
comparable -X- _ O
performance -X- _ O
to -X- _ O
Adapter-based -X- _ O
methods -X- _ O
while -X- _ O
using -X- _ O
fewer -X- _ O
parameters. -X- _ O

consistently -X- _ O
outperforms -X- _ O
task-specific -X- _ O
prompt -X- _ O
tuning -X- _ O
methods -X- _ O
by -X- _ O
1.6–3.1 -X- _ B-MetricValue
points. -X- _ O

• -X- _ O
Extensive -X- _ O
evaluations -X- _ O
on -X- _ O
ten -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
(NLU) -X- _ B-TaskName
tasks -X- _ O
show -X- _ O
that -X- _ O
IDPG -X- _ B-MethodName

We -X- _ O
introduce -X- _ O
an -X- _ O
input-dependent -X- _ O
prompt -X- _ O
generation -X- _ O
method—IDPG—that -X- _ B-MethodName
only -X- _ O
requires -X- _ O
training -X- _ O
134K -X- _ O
parameters -X- _ O
per -X- _ O
task, -X- _ O
corresponding -X- _ O
to -X- _ O
0.04% -X- _ O
of -X- _ O
a -X- _ O
pre-trained -X- _ O
LM -X- _ O
such -X- _ O
as -X- _ O
RoBERTa-Large -X- _ O

To -X- _ O
summarize, -X- _ O
this -X- _ O
work -X- _ O
makes -X- _ O
the -X- _ O
following -X- _ O
contributions: -X- _ O

To -X- _ O
further -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
in -X- _ O
the -X- _ O
generator -X- _ O
f -X- _ O
(x; -X- _ O
W), -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
apply -X- _ O
a -X- _ O
lightweight -X- _ O
bottleneck -X- _ O
architecture -X- _ O
(i.e., -X- _ O
a -X- _ O
two-layer -X- _ O
perceptron) -X- _ O
and -X- _ O
then -X- _ O
decompose -X- _ O
it -X- _ O
by -X- _ O
a -X- _ O
parameterized -X- _ O
hypercomplex -X- _ O
multiplication -X- _ O
(PHM) -X- _ O
layer -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Note -X- _ O
that -X- _ O
by -X- _ O
setting -X- _ O
W -X- _ O
to -X- _ O
a -X- _ O
zero -X- _ O
matrix -X- _ O
and -X- _ O
only -X- _ O
training -X- _ O
the -X- _ O
bias, -X- _ O
IDPG -X- _ B-MethodName
would -X- _ O
degenerate -X- _ O
into -X- _ O
the -X- _ O
traditional -X- _ O
prompt -X- _ O
tuning -X- _ O
process -X- _ O
(Lester -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Formally, -X- _ O
the -X- _ O
IDPG -X- _ B-MethodName
generator -X- _ O
can -X- _ O
be -X- _ O
denoted -X- _ O
as -X- _ O
f -X- _ O
(x; -X- _ O
W), -X- _ O
where -X- _ O
x -X- _ O
is -X- _ O
the -X- _ O
instance -X- _ O
representation -X- _ O
and -X- _ O
W -X- _ O
represents -X- _ O
the -X- _ O
trainable -X- _ O
parameters. -X- _ O

Unlike -X- _ O
traditional -X- _ O
prompttuning -X- _ O
methods -X- _ O
that -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
fixed -X- _ O
prompt -X- _ O
for -X- _ O
each -X- _ O
task, -X- _ O
IDPG -X- _ B-MethodName
instead -X- _ O
develops -X- _ O
a -X- _ O
conditional -X- _ O
prompt -X- _ O
generation -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
prompts -X- _ O
for -X- _ O
each -X- _ O
instance. -X- _ O

This -X- _ O
paper -X- _ O
presents -X- _ O
the -X- _ O
instance-dependent -X- _ B-MethodName
prompt -X- _ I-MethodName
generation -X- _ I-MethodName
(IDPG) -X- _ B-MethodName
strategy -X- _ O
for -X- _ O
efficiently -X- _ O
tuning -X- _ O
large-scale -X- _ O
LMs. -X- _ O

In -X- _ O
light -X- _ O
of -X- _ O
these -X- _ O
limitations, -X- _ O
we -X- _ O
instead -X- _ O
ask -X- _ O
the -X- _ O
following -X- _ O
question: -X- _ O
Can -X- _ O
we -X- _ O
generate -X- _ O
input-dependent -X- _ O
prompts -X- _ O
to -X- _ O
smooth -X- _ O
the -X- _ O
domain -X- _ O
difference? -X- _ O

Thus, -X- _ O
a -X- _ O
unified -X- _ O
prompt -X- _ O
may -X- _ O
disturb -X- _ O
the -X- _ O
prediction -X- _ O
and -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
performance -X- _ O
drop. -X- _ O

Specifically, -X- _ O
it -X- _ O
is -X- _ O
unlikely -X- _ O
to -X- _ O
see -X- _ O
many -X- _ O
different -X- _ O
sentences -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
prefix -X- _ O
in -X- _ O
the -X- _ O
pretraining -X- _ O
corpus. -X- _ O

However, -X- _ O
all -X- _ O
existing -X- _ O
prompt-tuning -X- _ O
methods -X- _ O
have -X- _ O
thus -X- _ O
far -X- _ O
focused -X- _ O
on -X- _ O
task-specific -X- _ O
prompts, -X- _ O
which -X- _ O
are -X- _ O
inadequate -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
pre-training -X- _ O
and -X- _ O
fine-tuning -X- _ O
objectives. -X- _ O

This -X- _ O
significantly -X- _ O
reduced -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
to -X- _ O
just -X- _ O
a -X- _ O
few -X- _ O
thousand. -X- _ O

In -X- _ O
doing -X- _ O
so, -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
searching -X- _ O
discrete -X- _ O
prompts -X- _ O
is -X- _ O
converted -X- _ O
to -X- _ O
a -X- _ O
continuous -X- _ O
optimization -X- _ O
task, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
solved -X- _ O
by -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
optimization -X- _ O
techniques -X- _ O
such -X- _ O
as -X- _ O
SGD. -X- _ O

To -X- _ O
tackle -X- _ O
this -X- _ O
issue, -X- _ O
prompt -X- _ B-MethodName
tuning -X- _ I-MethodName
(Lester -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
prefix -X- _ B-MethodName
tuning -X- _ I-MethodName
(Li -X- _ O
and -X- _ O
Liang, -X- _ O
2021), -X- _ O
and -X- _ O
Ptuning -X- _ B-MethodName
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2021a,b) -X- _ O
approaches -X- _ O
propose -X- _ O
to -X- _ O
prepend -X- _ O
trainable -X- _ O
prefix -X- _ O
tokens -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
layer -X- _ O
and -X- _ O
train -X- _ O
these -X- _ O
soft -X- _ O
prompts -X- _ O
only -X- _ O
during -X- _ O
the -X- _ O
finetuning -X- _ O
stage. -X- _ O

However, -X- _ O
these -X- _ O
methods -X- _ O
rely -X- _ O
on -X- _ O
grid-search -X- _ O
for -X- _ O
a -X- _ O
natural -X- _ O
language-based -X- _ O
prompt -X- _ O
from -X- _ O
an -X- _ O
ample -X- _ O
search -X- _ O
space, -X- _ O
leading -X- _ O
to -X- _ O
optimization -X- _ O
challenges. -X- _ O

LMBFF -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021a), -X- _ O
EFL -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
and -X- _ O
AutoPrompt -X- _ O
(Shin -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
extend -X- _ O
this -X- _ O
direction -X- _ O
by -X- _ O
inserting -X- _ O
prompts -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
embedding -X- _ O

The -X- _ O
GPT-3 -X- _ O
models -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021) -X- _ O
find -X- _ O
that, -X- _ O
with -X- _ O
proper -X- _ O
manual -X- _ O
prompts, -X- _ O
a -X- _ O
pre-trained -X- _ O
LM -X- _ O
can -X- _ O
successfully -X- _ O
match -X- _ O
the -X- _ O
fine-tuning -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ O
models. -X- _ O

Another -X- _ O
line -X- _ O
of -X- _ O
work -X- _ O
focuses -X- _ O
on -X- _ O
prompting. -X- _ O

Compacter -X- _ B-MethodName
(Mahabadi -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
optimizes -X- _ O
the -X- _ O
training -X- _ O
parameters -X- _ O
further -X- _ O
by -X- _ O
designing -X- _ O
a -X- _ O
lightweight -X- _ O
module -X- _ O
to -X- _ O
replace -X- _ O
the -X- _ O
bottleneck -X- _ O
architecture -X- _ O
in -X- _ O
Adapters. -X- _ O

Only -X- _ O
these -X- _ O
additional -X- _ O
and -X- _ O
task-specific -X- _ O
modules -X- _ O
are -X- _ O
trained -X- _ O
during -X- _ O
fine-tuning, -X- _ O
reducing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters -X- _ O
to -X- _ O
1–3% -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
transformer -X- _ O
model -X- _ O
per -X- _ O
task. -X- _ O

One -X- _ O
line -X- _ O
of -X- _ O
research -X- _ O
(Li -X- _ O
and -X- _ O
Liang, -X- _ O
2021) -X- _ O
suggests -X- _ O
augmenting -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
smaller, -X- _ O
trainable -X- _ O
modules -X- _ O
and -X- _ O
freezing -X- _ O
the -X- _ O
original -X- _ O
transformer -X- _ O
weights. -X- _ O

Previous -X- _ O
studies -X- _ O
have -X- _ O
attempted -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
question -X- _ O
from -X- _ O
different -X- _ O
perspectives. -X- _ O

Our -X- _ O
method -X- _ O
approaches -X- _ O
RoBERTaFT’s -X- _ O
performance -X- _ O
and -X- _ O
uses -X- _ O
fewer -X- _ O
parameters -X- _ O
than -X- _ O
Adapter-based -X- _ O
methods. -X- _ O

Thus, -X- _ O
it -X- _ O
is -X- _ O
natural -X- _ O
to -X- _ O
ask -X- _ O
whether -X- _ O
we -X- _ O
can -X- _ O
transfer -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
a -X- _ O
pre-trained -X- _ O
LM -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
by -X- _ O
keeping -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
fixed -X- _ O
and -X- _ O
tuning -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
fraction -X- _ O
of -X- _ O
them. -X- _ O

As -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
proliferates -X- _ O
(e.g., -X- _ O
330M -X- _ O
parameters -X- _ O
for -X- _ O
BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
175B -X- _ O
for -X- _ O
GPT-3 -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
2020)), -X- _ O
it -X- _ O
becomes -X- _ O
computationally -X- _ O
expensive -X- _ O
and -X- _ O
challenging -X- _ O
to -X- _ O
fine-tune -X- _ O
the -X- _ O
entire -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
(LM). -X- _ O

Notably, -X- _ O
this -X- _ O
paradigm -X- _ O
requires -X- _ O
updating -X- _ O
and -X- _ O
storing -X- _ O
all -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
for -X- _ O
each -X- _ O
downstream -X- _ O
task. -X- _ O

In -X- _ O
recent -X- _ O
years, -X- _ O
pre-training -X- _ O
a -X- _ O
transformer -X- _ O
model -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
with -X- _ O
language -X- _ O
modeling -X- _ O
tasks -X- _ O
and -X- _ O
fine-tuning -X- _ O
it -X- _ O
on -X- _ O
different -X- _ O
downstream -X- _ O
tasks -X- _ O
has -X- _ O
become -X- _ O
the -X- _ O
primary -X- _ O
transfer -X- _ O
learning -X- _ O
paradigm -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Introduction -X- _ O

Extensive -X- _ O
experiments -X- _ O
on -X- _ O
ten -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
(NLU) -X- _ B-TaskName
tasks -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
strategy -X- _ O
consistently -X- _ O
outperforms -X- _ O
various -X- _ O
prompt -X- _ O
tuning -X- _ O
baselines -X- _ O
and -X- _ O
is -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
other -X- _ O
efficient -X- _ O
transfer -X- _ O
learning -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
Compacter -X- _ B-MethodName
while -X- _ O
tuning -X- _ O
far -X- _ O
fewer -X- _ O
model -X- _ O
parameters.1 -X- _ O

Unlike -X- _ O
traditional -X- _ O
prompt -X- _ B-TaskName
tuning -X- _ I-TaskName
methods -X- _ O
that -X- _ O
use -X- _ O
a -X- _ O
fixed -X- _ O
prompt, -X- _ O
IDPG -X- _ B-MethodName
introduces -X- _ O
a -X- _ O
lightweight -X- _ O
and -X- _ O
trainable -X- _ O
component -X- _ O
to -X- _ O
generate -X- _ O
prompts -X- _ O
based -X- _ O
on -X- _ O
each -X- _ O
input -X- _ O
sentence. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
conditional -X- _ B-TaskName
prompt -X- _ I-TaskName
generation -X- _ I-TaskName
method -X- _ O
to -X- _ O
generate -X- _ O
prompts -X- _ O
for -X- _ O
each -X- _ O
input -X- _ O
instance, -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
the -X- _ O
Instance-Dependent -X- _ B-MethodName
Prompt -X- _ I-MethodName
Generation -X- _ I-MethodName
(IDPG). -X- _ B-MethodName

It -X- _ O
freezes -X- _ O
the -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
only -X- _ O
optimizes -X- _ O
a -X- _ O
few -X- _ O
taskspecific -X- _ O
prompts. -X- _ O

Prompt -X- _ B-TaskName
tuning -X- _ I-TaskName
is -X- _ O
a -X- _ O
new, -X- _ O
efficient -X- _ O
NLP -X- _ O
transfer -X- _ O
learning -X- _ O
paradigm -X- _ O
that -X- _ O
adds -X- _ O
a -X- _ O
task-specific -X- _ O
prompt -X- _ O
in -X- _ O
each -X- _ O
input -X- _ O
instance -X- _ O
during -X- _ O
the -X- _ O
model -X- _ O
training -X- _ O
stage. -X- _ O

Abstract -X- _ O

An -X- _ O
Instance-Dependent -X- _ O
Prompt -X- _ B-TaskName
Generation -X- _ I-TaskName
Method -X- _ O

IDPG: -X- _ B-MethodName

-DOCSTART- -X- O
The -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
D.1 -X- _ O
are -X- _ O
generated -X- _ O
by -X- _ O
running -X- _ O
the -X- _ O
baselines -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
2 -X- _ B-HyperparameterValue
and -X- _ O
different -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
5 -X- _ O
suggested -X- _ O
by -X- _ O
Gao -X- _ O
et -X- _ O
al. -X- _ O
(2021). -X- _ O

As -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
Table -X- _ O
D.1, -X- _ O
this -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
produces -X- _ O
reasonably -X- _ O
good -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
baselines, -X- _ O
being -X- _ O
the -X- _ O
best -X- _ O
for -X- _ O
13 -X- _ O
tasks -X- _ O
and -X- _ O
only -X- _ O
marginally -X- _ O
under-performing -X- _ O
in -X- _ O
the -X- _ O
other -X- _ O
2 -X- _ O
tasks. -X- _ O

We -X- _ O
choose -X- _ O
1e− -X- _ O
common -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
to -X- _ O
finetune -X- _ O
BERT/RoBERTa. -X- _ O

for -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
search -X- _ O
for -X- _ O
this -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
for -X- _ O
5, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
our -X- _ O
method. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
Lreal -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
baselines -X- _ O
and -X- _ O
ours -X- _ O
are -X- _ O
kept -X- _ O
the -X- _ O
same. -X- _ O

The -X- _ O
baseline -X- _ O
has -X- _ O
only -X- _ O
one -X- _ O
loss -X- _ O
Lreal, -X- _ O
whereas -X- _ O
we -X- _ O
are -X- _ O
learning -X- _ O
with -X- _ O
an -X- _ O
additional -X- _ O
loss -X- _ O
Lhalluc, -X- _ O
making -X- _ O
the -X- _ O
total -X- _ O
loss -X- _ O
to -X- _ O
be -X- _ O
Lhalluc. -X- _ O

D -X- _ O
Learning -X- _ B-HyperparameterName
Rate -X- _ I-HyperparameterName
for -X- _ O
Baselines -X- _ O

Qualitatively -X- _ O
similar -X- _ O
to -X- _ O
what -X- _ O
we -X- _ O
observe -X- _ O
with -X- _ O
experiments -X- _ O
using -X- _ O
RoBERTa-large -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
paper, -X- _ O
Re-Init -X- _ B-MethodName
and -X- _ O
Mixout -X- _ B-MethodName
fail -X- _ O
to -X- _ O
outperform -X- _ O
EmbedHalluc -X- _ B-MethodName
in -X- _ O
most -X- _ O
tasks, -X- _ O
with -X- _ O
the -X- _ O
exceptions -X- _ O
of -X- _ O
SNLI -X- _ B-DatasetName
and -X- _ O
QNLI. -X- _ B-DatasetName

The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
C.1. -X- _ O

Besides -X- _ O
the -X- _ O
experiments -X- _ O
with -X- _ O
RoBERTa-large -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
paper, -X- _ O
we -X- _ O
present -X- _ O
Re-Init -X- _ B-MethodName
and -X- _ O
Mixout -X- _ B-MethodName
using -X- _ O
BERT-large-cased -X- _ O
in -X- _ O
this -X- _ O
section. -X- _ O

C -X- _ O
Regularization -X- _ O
Methods -X- _ O
with -X- _ O
BERT -X- _ O

EmbedHalluc -X- _ B-MethodName
outperforms -X- _ O
the -X- _ O
baseline -X- _ O
across -X- _ O
14 -X- _ O
of -X- _ O
the -X- _ O
15 -X- _ O
tasks -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
improvement -X- _ O
of -X- _ O
2.43 -X- _ B-MetricValue
over -X- _ O
the -X- _ O
baseline. -X- _ O

Table -X- _ O
B.1 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
experiments. -X- _ O

In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
experiments -X- _ O
using -X- _ O
RoBERTa -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
paper, -X- _ O
here -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
BERT-large-cased -X- _ B-MethodName
with -X- _ O
conventional -X- _ O
fine-tuning -X- _ O
as -X- _ O
a -X- _ O
further -X- _ O
check -X- _ O
on -X- _ O
robustness -X- _ O
of -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
model. -X- _ O

Best -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
for -X- _ O
RoBERTa-large -X- _ O
prompt-based -X- _ O
fine-tuning. -X- _ O

Here, -X- _ O
we -X- _ O
provide -X- _ O
best -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
(LR, -X- _ B-HyperparameterName
searched -X- _ O
6 -X- _ O
as -X- _ O
discussed -X- _ O
in -X- _ O
main -X- _ O
paper) -X- _ O
from -X- _ O
1e− -X- _ O
for -X- _ O
Lhalluc -X- _ O
of -X- _ O
EmbedHalluc -X- _ B-MethodName
for -X- _ O
each -X- _ O
task -X- _ O
used -X- _ O
in -X- _ O
RoBERTa-large -X- _ O
prompt-based -X- _ O
fine-tuning. -X- _ O

References -X- _ O

As -X- _ O
such, -X- _ O
users -X- _ O
of -X- _ O
such -X- _ O
models, -X- _ O
specially -X- _ O
for -X- _ O
sensitive -X- _ O
applications, -X- _ O
should -X- _ O
be -X- _ O
aware -X- _ O
of -X- _ O
and -X- _ O
if -X- _ O
possible -X- _ O
address -X- _ O
such -X- _ O
issues. -X- _ O

However, -X- _ O
our -X- _ O
work -X- _ O
relies -X- _ O
on -X- _ O
pre-trained -X- _ O
language -X- _ O
models, -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
biased -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
(Liang -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

As -X- _ O
far -X- _ O
as -X- _ O
we -X- _ O
are -X- _ O
aware, -X- _ O
our -X- _ O
proposed -X- _ O
work -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
any -X- _ O
explicit -X- _ O
ethical -X- _ O
concerns. -X- _ O

8 -X- _ O
Ethics -X- _ O
Statement -X- _ O

The -X- _ O
proposed -X- _ O
method -X- _ O
improves -X- _ O
over -X- _ O
the -X- _ O
baselines -X- _ O
in -X- _ O
15 -X- _ O
tasks -X- _ O
and -X- _ O
outperforms -X- _ O
a -X- _ O
common -X- _ O
augmentation -X- _ O
method, -X- _ O
and -X- _ O
two -X- _ O
recent -X- _ O
regularization -X- _ O
methods. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
introduce -X- _ O
an -X- _ O
embedding -X- _ B-MethodName
hallucination -X- _ I-MethodName
method -X- _ O
for -X- _ O
data -X- _ O
augmentation -X- _ O
for -X- _ O
few-shot -X- _ B-TaskName
learning, -X- _ I-TaskName
based -X- _ O
on -X- _ O
cWGAN. -X- _ O

7 -X- _ O
Conclusion -X- _ O

Besides, -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
cWGAN -X- _ O
requires -X- _ O
careful -X- _ O
human -X- _ O
attention -X- _ O
to -X- _ O
maintain -X- _ O
a -X- _ O
stable -X- _ O
training. -X- _ O

While -X- _ O
EmbedHalluc -X- _ B-MethodName
works -X- _ O
well -X- _ O
empirically, -X- _ O
it -X- _ O
relies -X- _ O
on -X- _ O
hallucinating -X- _ O
non-interpretable -X- _ O
embeddings -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
learning -X- _ O
process. -X- _ O

6 -X- _ O
Limitations -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5, -X- _ O
with -X- _ O
one -X- _ O
exception, -X- _ O
our -X- _ O
method -X- _ O
largely -X- _ O
outperforms -X- _ O
freeLB -X- _ B-MethodName
and -X- _ O
SMART. -X- _ B-MethodName

We -X- _ O
use -X- _ O
the -X- _ O
default -X- _ O
setting -X- _ O
for -X- _ O
SMART. -X- _ B-MethodName

In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
default -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
used -X- _ O
in -X- _ O
the -X- _ O
baseline -X- _ B-MethodName
fine-tuning -X- _ I-MethodName
and -X- _ O
EmbedHalluc, -X- _ B-MethodName
we -X- _ O
also -X- _ O
search -X- _ O
additional -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
and -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
for -X- _ O
freeLB. -X- _ B-MethodName

suggested -X- _ O
hyper-parameters -X- _ O
for -X- _ O
each -X- _ O
task. -X- _ O

For -X- _ O
freeLB, -X- _ B-MethodName
we -X- _ O
use -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
code -X- _ O
and -X- _ O

Comparing -X- _ O
to -X- _ O
Adversarial -X- _ O
Training -X- _ O

Adversarial -X- _ O
training -X- _ O
adds -X- _ O
noise -X- _ O
into -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
a -X- _ O
model. -X- _ O

It -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
adversarial -X- _ O
training -X- _ O
can -X- _ O
also -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
language -X- _ O
models. -X- _ O

Here, -X- _ O
we -X- _ O
compare -X- _ O
EmbedHalluc -X- _ B-MethodName
to -X- _ O
two -X- _ O
recent -X- _ O
adversarial -X- _ O
training -X- _ O
methods, -X- _ O
freeLB -X- _ B-MethodName
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
SMART -X- _ B-MethodName
(Jiang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
adapted -X- _ O
to -X- _ O
our -X- _ O
setting. -X- _ O

We -X- _ O
find -X- _ O
that -X- _ O
those -X- _ O
two -X- _ O
methods -X- _ O
fail -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
over-fitting -X- _ O
problem -X- _ O
in -X- _ O
such -X- _ O
extreme -X- _ O
setting, -X- _ O
though -X- _ O
they -X- _ O
have -X- _ O
been -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
when -X- _ O
given -X- _ O
a -X- _ O
few -X- _ O
thousands -X- _ O
examples. -X- _ O

Results -X- _ O
for -X- _ O
BERT-large-cased -X- _ B-MethodName
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
C. -X- _ O

For -X- _ O
Re-Init, -X- _ B-MethodName
we -X- _ O
search -X- _ O
the -X- _ O
top -X- _ O
1,2,3,4,5 -X- _ B-HyperparameterValue
layers; -X- _ B-HyperparameterName
and -X- _ O
for -X- _ O
Mixout, -X- _ B-MethodName
we -X- _ O
search -X- _ O
mixout -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
from -X- _ O
0.1, -X- _ B-HyperparameterValue
0.2, -X- _ B-HyperparameterValue
..., -X- _ O
0.9 -X- _ B-HyperparameterValue
and -X- _ O
report -X- _ O
their -X- _ O
best -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
4, -X- _ O
using -X- _ O
RoBERTa-large. -X- _ O

Since -X- _ O
we -X- _ O
adapt -X- _ O
their -X- _ O
code -X- _ O
to -X- _ O
our -X- _ O
extreme -X- _ O
data -X- _ O
deficient -X- _ O
setting, -X- _ O
we -X- _ O
re-search -X- _ O
the -X- _ O
hyper-parameters -X- _ O
of -X- _ O
both -X- _ O
methods -X- _ O
(including -X- _ O
their -X- _ O
suggested -X- _ O
values). -X- _ O

We -X- _ O
used -X- _ O
the -X- _ O
public -X- _ O
code -X- _ O
for -X- _ O
both -X- _ O
of -X- _ O
these -X- _ O
methods. -X- _ O

We -X- _ O
further -X- _ O
compare -X- _ O
against -X- _ O
Mixout -X- _ B-MethodName
(Lee -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
which -X- _ O
is -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
effective -X- _ O
regularization -X- _ O
when -X- _ O
fine-tuning -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
thousand -X- _ O
examples. -X- _ O

Thus, -X- _ O
we -X- _ O
consider -X- _ O
reinitialization -X- _ B-MethodName
(Re-Init) -X- _ B-MethodName
of -X- _ O
top -X- _ O
layers -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
comparisons. -X- _ O

Correcting -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
optimizer -X- _ O
is -X- _ O
already -X- _ O
fixed -X- _ O
by -X- _ O
the -X- _ O
default -X- _ O
optimizer -X- _ O
in -X- _ O
Huggingface -X- _ O
Transformer -X- _ O
and -X- _ O
training -X- _ O
longer -X- _ O
surely -X- _ O
will -X- _ O
lead -X- _ O
to -X- _ O
further -X- _ O
over-fitting -X- _ O
in -X- _ O
our -X- _ O
extreme -X- _ O
data -X- _ O
scarce -X- _ O
scenario. -X- _ O

Zhang -X- _ O
et -X- _ O
al. -X- _ O
(2021) -X- _ O
find -X- _ O
that -X- _ O
fine-tuning -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
by: -X- _ O
correcting -X- _ O
bias -X- _ O
in -X- _ O
the -X- _ O
optimizer, -X- _ O
re-initialization -X- _ O
of -X- _ O
top -X- _ O
layers, -X- _ O
and -X- _ O
training -X- _ O
longer. -X- _ O

Our -X- _ O
method -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
an -X- _ O
implicit -X- _ O
regularization -X- _ O
method. -X- _ O

The -X- _ O
relatively -X- _ O
smaller -X- _ O
improvements -X- _ O
for -X- _ O
promptbased -X- _ O
methods -X- _ O
may -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
inconsistency -X- _ O
and -X- _ O

4.6 -X- _ O
Negative -X- _ O
Results -X- _ O
from -X- _ O
Regularizations -X- _ O

EmbedHalluc -X- _ B-MethodName
is -X- _ O
still -X- _ O
competitive -X- _ O
when -X- _ O
comparing -X- _ O
against -X- _ O
SSL -X- _ B-MethodName
which -X- _ O
assumes -X- _ O
to -X- _ O
have -X- _ O
additional -X- _ O
64 -X- _ O
examples -X- _ O
per -X- _ O
class -X- _ O
from -X- _ O
the -X- _ O
task -X- _ O
distribution. -X- _ O

Thus, -X- _ O
we -X- _ O
observe -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
that -X- _ O
EmbedHalluc -X- _ B-MethodName
is -X- _ O
overall -X- _ O
superior -X- _ O
to -X- _ O
EDA. -X- _ B-MethodName

Since -X- _ O
it -X- _ O
operates -X- _ O
in -X- _ O
the -X- _ O
continuous -X- _ O
embedding -X- _ O
space, -X- _ O
EmbedHalluc -X- _ B-MethodName
hallucinates -X- _ O
diverse -X- _ O
embeddings -X- _ O
that -X- _ O
follow -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
few-shot -X- _ O
set. -X- _ O

EDA -X- _ B-MethodName
either -X- _ O
greatly -X- _ O
change -X- _ O
the -X- _ O
sentence -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
α -X- _ B-HyperparameterName
or -X- _ O
fails -X- _ O
to -X- _ O
introduce -X- _ O
substantial -X- _ O
variations -X- _ O
(which -X- _ O
is -X- _ O
crucial -X- _ O
in -X- _ O
the -X- _ O
extreme -X- _ O
low -X- _ O
data -X- _ O
setting) -X- _ O
of -X- _ O
inputs -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
α. -X- _ B-HyperparameterName

EDA -X- _ B-MethodName
edits -X- _ O
the -X- _ O
input -X- _ O
sentences -X- _ O
by -X- _ O
applying -X- _ O
synonym -X- _ O
replacement, -X- _ O
random -X- _ O
swap, -X- _ O
random -X- _ O
deletion -X- _ O
and -X- _ O
random -X- _ O
insertion -X- _ O
for -X- _ O
a -X- _ O
default -X- _ O
10% -X- _ B-HyperparameterValue
(α) -X- _ B-HyperparameterName
of -X- _ O
tokens. -X- _ O

We -X- _ O
apply -X- _ O
pseudo-labeling -X- _ O
(Cascante-Bonilla -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
for -X- _ O
SSL, -X- _ B-MethodName
i.e., -X- _ O
we -X- _ O
first -X- _ O
fine-tune -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
few-shot -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
fine-tuned -X- _ O
model -X- _ O
to -X- _ O
pseudo-label -X- _ O
the -X- _ O
unlabeled -X- _ O
data, -X- _ O
finally -X- _ O
we -X- _ O
finetune -X- _ O
the -X- _ O
model -X- _ O
again -X- _ O
with -X- _ O
the -X- _ O
few-shot -X- _ O
training -X- _ O
set -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
pseudo-labeled -X- _ O
set. -X- _ O

We -X- _ O
also -X- _ O
consider -X- _ O
semi-supervised -X- _ B-MethodName
learning -X- _ I-MethodName
(SSL) -X- _ B-MethodName
which -X- _ O
relies -X- _ O
on -X- _ O
unlabeled -X- _ O
data -X- _ O
(64 -X- _ O
examples -X- _ O
per -X- _ O
class -X- _ O
in -X- _ O
our -X- _ O
experiments). -X- _ O

Since -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
a -X- _ O
generative -X- _ O
data -X- _ O
augmentation -X- _ O
(DA) -X- _ O
method, -X- _ O
we -X- _ O
compare -X- _ O
it -X- _ O
to -X- _ O
another -X- _ O
DA -X- _ O
method -X- _ O
EDA. -X- _ B-MethodName

4.5 -X- _ O
Comparing -X- _ O
to -X- _ O
EDA -X- _ B-MethodName
and -X- _ O
SSL -X- _ B-MethodName

Whereas, -X- _ O
in -X- _ O
conventional -X- _ B-MethodName
fine-tuning, -X- _ I-MethodName
the -X- _ O
[CLS] -X- _ O
token -X- _ O
is -X- _ O
always -X- _ O
appended -X- _ O
to -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
shalluc -X- _ O
and -X- _ O
the -X- _ O
classification -X- _ O
is -X- _ O
performed -X- _ O
at -X- _ O
the -X- _ O
[CLS] -X- _ O
token. -X- _ O

randomness -X- _ O
in -X- _ O
the -X- _ O
learning -X- _ O
process -X- _ O
since -X- _ O
we -X- _ O
have -X- _ O
to -X- _ O
insert -X- _ O
[mask] -X- _ O
token -X- _ O
to -X- _ O
a -X- _ O
random -X- _ O
position -X- _ O
in -X- _ O
the -X- _ O
hallucinated -X- _ O
embedding -X- _ O
shalluc, -X- _ O
for -X- _ O
the -X- _ O
calculation -X- _ O
of -X- _ O
the -X- _ O
loss. -X- _ O

When -X- _ O
applying -X- _ O
to -X- _ O
prompt-based -X- _ O
fine-tuning, -X- _ O
while -X- _ O
our -X- _ O
method -X- _ O
under-performs -X- _ O
in -X- _ O
MNLI, -X- _ B-DatasetName
MNLI-mm -X- _ B-DatasetName
and -X- _ O
RTE, -X- _ B-DatasetName
it -X- _ O
outperforms -X- _ O
for -X- _ O
all -X- _ O
other -X- _ O
tasks, -X- _ O
with -X- _ O
substantial -X- _ O
improvements -X- _ O
over -X- _ O
the -X- _ O
baseline -X- _ O
in -X- _ O
CoLA, -X- _ B-DatasetName
TREC, -X- _ B-DatasetName
QNLI, -X- _ B-DatasetName
MRPC. -X- _ B-DatasetName

When -X- _ O
combining -X- _ O
with -X- _ O
LabelCalib, -X- _ B-MethodName
our -X- _ O
method -X- _ O
outperforms -X- _ O
in -X- _ O
all -X- _ O
tasks. -X- _ O

In -X- _ O
conventional -X- _ O
fine-tuning, -X- _ O
EmbedHalluc -X- _ B-MethodName
imthe -X- _ O
baseline -X- _ O
in -X- _ O
14 -X- _ O
tasks, -X- _ O
only -X- _ O
proves -X- _ O
over -X- _ O
marginally -X- _ O
under-performs -X- _ O
in -X- _ O
SST-5 -X- _ B-DatasetName
(40.3 -X- _ B-MetricValue
vs. -X- _ O
40.6 -X- _ B-MetricValue
of -X- _ O
baseline). -X- _ O

Our -X- _ O
Label -X- _ B-MethodName
Calibration -X- _ I-MethodName
(LabelCalib) -X- _ B-MethodName
can -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
results. -X- _ O

Results -X- _ O
for -X- _ O
BERT-large-cased -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O

We -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
EmbedHalluc -X- _ B-MethodName
(w/o -X- _ O
or -X- _ O
w/ -X- _ B-MethodName
LabelCalib) -X- _ I-MethodName
using -X- _ O
RoBERTa-large -X- _ O
on -X- _ O
15 -X- _ O
tasks -X- _ O
with -X- _ O
two -X- _ O
fine-tuning -X- _ O
methods: -X- _ O
conventional -X- _ B-MethodName
(Table -X- _ O
1) -X- _ O
and -X- _ O
prompt-based -X- _ B-MethodName
fine-tuning -X- _ I-MethodName
(Table -X- _ O
2). -X- _ O

4.4 -X- _ O
Main -X- _ O
Results -X- _ O
on -X- _ O
15 -X- _ O
Tasks -X- _ O

The -X- _ O
algorithm -X- _ O
is -X- _ O
implemented -X- _ O
in -X- _ O
PyTorch-1.10 -X- _ O
and -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
Nvidia -X- _ O
RTX-6000 -X- _ O
and -X- _ O
RTX-A6000 -X- _ O
GPU. -X- _ O

Finally, -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
by -X- _ O
testing -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
testing -X- _ O
dataset. -X- _ O

The -X- _ O
models -X- _ O
are -X- _ O
selected -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
accuracy -X- _ O
every -X- _ O
100 -X- _ O
steps. -X- _ O

We -X- _ O
use -X- _ O
1e− -X- _ O
the -X- _ O
same -X- _ O
search -X- _ O
for -X- _ O
EDA -X- _ B-MethodName
(Wei -X- _ O
and -X- _ O
Zou, -X- _ O
2019) -X- _ O
and -X- _ O
semi-supervised -X- _ B-MethodName
pseduo-labeling -X- _ I-MethodName
(SSL) -X- _ B-MethodName
when -X- _ O
learning -X- _ O
with -X- _ O
additional -X- _ O
augmented -X- _ O
or -X- _ O
pseudo-labeled -X- _ O
data. -X- _ O

Our -X- _ O
method -X- _ O
learns -X- _ O
from -X- _ O
hallucinated -X- _ O
embeddings -X- _ O
with -X- _ O
a -X- _ O
grid -X- _ O
search -X- _ O
of -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
6, -X- _ B-HyperparameterValue
and -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
4, -X- _ B-HyperparameterValue
6, -X- _ B-HyperparameterValue
8. -X- _ B-HyperparameterValue

To -X- _ O
fairly -X- _ O
compare -X- _ O
our -X- _ O
method -X- _ O
with -X- _ O
baselines -X- _ O
and -X- _ O
other -X- _ O
methods, -X- _ O
when -X- _ O
learning -X- _ O
with -X- _ O
real -X- _ O
sentences, -X- _ O
5 -X- _ O
(further -X- _ O
juswe -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e− -X- _ O
tification -X- _ O
of -X- _ O
using -X- _ O
this -X- _ O
learning -X- _ O
rate -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
D). -X- _ O

sampling -X- _ O
the -X- _ O
hallucinators -X- _ O
(see -X- _ O
Algorithm -X- _ O
1). -X- _ O

We -X- _ O
draw -X- _ O
two -X- _ O
mini-batches -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
our -X- _ O
few-shot -X- _ O
language -X- _ O
learners, -X- _ O
i.e., -X- _ O
one -X- _ O
from -X- _ O
the -X- _ O
real -X- _ O
language -X- _ O
few-shot -X- _ O
training -X- _ O
set, -X- _ O
another -X- _ O
one -X- _ O
by -X- _ O

4.3 -X- _ O
Training -X- _ O
Details -X- _ O
for -X- _ O
Few-Shot -X- _ O
Language -X- _ O

We -X- _ O
apply -X- _ O
gradient -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
with -X- _ O
weight -X- _ O
of -X- _ O
loss -X- _ O
100 -X- _ B-HyperparameterValue
for -X- _ O
training -X- _ O
the -X- _ O
cWGAN. -X- _ O

The -X- _ O
real -X- _ O
embeddings -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
language -X- _ O
few-shot -X- _ O
training -X- _ O
set -X- _ O
by -X- _ O
passing -X- _ O
text -X- _ O
into -X- _ O
the -X- _ O
embedding -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model. -X- _ O

We -X- _ O
train -X- _ O
the -X- _ O
Embedding -X- _ O
Hallucinators -X- _ O
for -X- _ O
150 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
using -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
64, -X- _ B-HyperparameterValue
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
(β -X- _ B-HyperparameterName
= -X- _ O
(0.5, -X- _ B-HyperparameterValue
0.999)), -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
0.0002. -X- _ B-HyperparameterValue

The -X- _ O
discriminator -X- _ O
is -X- _ O
a -X- _ O
3blocks -X- _ O
model, -X- _ O
each -X- _ O
bock -X- _ O
having -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
FullyConnect-BatchNorm-LeakyReLU -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ O
512. -X- _ B-HyperparameterValue

L -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
128. -X- _ B-HyperparameterValue

The -X- _ O
hallucinated -X- _ O
embeddings, -X- _ O
i.e., -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
generator -X- _ O
are -X- _ O
tensors -X- _ O
of -X- _ O
L -X- _ B-HyperparameterName
1024, -X- _ B-HyperparameterValue
where -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
embeddings -X- _ O

The -X- _ O
hidden -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
generator -X- _ O
are -X- _ O
128, -X- _ B-HyperparameterValue
256, -X- _ B-HyperparameterValue
512, -X- _ B-HyperparameterValue
1024. -X- _ B-HyperparameterValue

The -X- _ O
generator -X- _ O
is -X- _ O
a -X- _ O
4-blocks -X- _ O
model, -X- _ O
with -X- _ O
each -X- _ O
block -X- _ O
containing -X- _ O
a -X- _ O
FullyConnect -X- _ O
layer -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
BatchNorm -X- _ O
and -X- _ O
LeakyReLU. -X- _ O

The -X- _ O
training -X- _ O
of -X- _ O
Embedding -X- _ O
Hallucinators -X- _ O
involves -X- _ O
training -X- _ O
a -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
in -X- _ O
the -X- _ O
cWGAN -X- _ O
framework. -X- _ O

4.2 -X- _ O
Training -X- _ O
Details -X- _ O
for -X- _ O
Embedding -X- _ O

We -X- _ O
sample -X- _ O
16 -X- _ O
examples -X- _ O
per -X- _ O
class -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
construct -X- _ O
a -X- _ O
validation -X- _ O
set -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
training -X- _ O
set. -X- _ O

The -X- _ O
evaluations -X- _ O
are -X- _ O
conducted -X- _ O
by -X- _ O
averaging -X- _ O
results -X- _ O
on -X- _ O
5 -X- _ O
different -X- _ O
train -X- _ O
test -X- _ O
splits. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
15 -X- _ O
classification -X- _ O
tasks. -X- _ O

4.1 -X- _ O
Evaluation -X- _ O
Datasets -X- _ O
and -X- _ O
Protocol -X- _ O

4 -X- _ O
Experiments -X- _ O

Thus, -X- _ O
our -X- _ O
method -X- _ O
has -X- _ O
about -X- _ O
× -X- _ O
computational -X- _ O
overhead -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baselines. -X- _ O

Computing -X- _ O
total -X- _ O
loss -X- _ O
one -X- _ O
additional -X- _ O
forward -X- _ O
pass -X- _ O
of -X- _ O
the -X- _ O
hallucinator -X- _ O
and -X- _ O
one -X- _ O
more -X- _ O
forward -X- _ O
pass -X- _ O
and -X- _ O
backward -X- _ O
pass -X- _ O
of -X- _ O
the -X- _ O
2 -X- _ O
language -X- _ O
model. -X- _ O

Note -X- _ O
that -X- _ O
baselines -X- _ O
considered -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
use -X- _ O
Lhalluc -X- _ O
requires -X- _ O
Lreal. -X- _ O

The -X- _ O
pseudo-code -X- _ O
for -X- _ O
finetuning -X- _ O
of -X- _ O
few-shot -X- _ O
language -X- _ O
learners -X- _ O
with -X- _ O
hallucinated -X- _ O
embeddings -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Algorithm -X- _ O
1. -X- _ O

Finally, -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
learns -X- _ O
from -X- _ O
the -X- _ O
hallucinated -X- _ O
emM -X- _ O
bedding -X- _ O
by -X- _ O
KL-divergence -X- _ O

The -X- _ O
soft-label -X- _ O
of -X- _ O
the -X- _ O
embedding -X- _ O
shalluc(ci) -X- _ O
is -X- _ O
then -X- _ O
cpseudo,i -X- _ O
= -X- _ O
FGEN0(shalluc(ci)). -X- _ O

We -X- _ O
propose -X- _ O
Label -X- _ B-MethodName
Calibration -X- _ I-MethodName
(LabelCalib) -X- _ B-MethodName
by -X- _ O
pseudoFGEN0 -X- _ O
(LM1 -X- _ O
in -X- _ O
labeling -X- _ O
from -X- _ O
a -X- _ O
teacher -X- _ O
model -X- _ O
Algorithm -X- _ O
1), -X- _ O
where -X- _ O
FGEN0 -X- _ O
is -X- _ O
first -X- _ O
fine-tuned -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
set -X- _ O
(without -X- _ O
augmentation). -X- _ O

However, -X- _ O
this -X- _ O
hard -X- _ O
label -X- _ O
may -X- _ O
not -X- _ O
best -X- _ O
represent -X- _ O
the -X- _ O
class -X- _ O
information -X- _ O
of -X- _ O
the -X- _ O
hallucinated -X- _ O
embedding. -X- _ O

For -X- _ O
a -X- _ O
single -X- _ O
input -X- _ O
sentence, -X- _ O
we -X- _ O
first -X- _ O
pass -X- _ O
it -X- _ O
through -X- _ O
the -X- _ O
embedding -X- _ O
layer -X- _ O
to -X- _ O
get -X- _ O
the -X- _ O
sentence -X- _ O
embedding -X- _ O
ssent. -X- _ O

3.2 -X- _ O
Fine-tuning -X- _ O
with -X- _ O
Hallucinated -X- _ O
Embedding -X- _ O

The -X- _ O
hallucinated -X- _ O
embeddings -X- _ O
shalluc, -X- _ O
in -X- _ O
principal, -X- _ O
are -X- _ O
indiscriminative -X- _ O
to -X- _ O
the -X- _ O
embeddings -X- _ O
of -X- _ O
observed -X- _ O
examples -X- _ O
in -X- _ O
that -X- _ O
class. -X- _ O

After -X- _ O
the -X- _ O
training, -X- _ O
we -X- _ O
use -X- _ O
it -X- _ O
to -X- _ O
generate -X- _ O
pseudo-embeddings -X- _ O
of -X- _ O
examples -X- _ O
by -X- _ O
feeding -X- _ O
it -X- _ O
with -X- _ O
random -X- _ O
noisy -X- _ O
vectors -X- _ O
z -X- _ O
sampled -X- _ O
from -X- _ O
(0, -X- _ O
1) -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
condition -X- _ O
class -X- _ O
laN -X- _ O
bels -X- _ O
ci. -X- _ O

Our -X- _ O
hallucinator -X- _ O
is -X- _ O
trained -X- _ O
under -X- _ O
the -X- _ O
conditional -X- _ O
WGAN -X- _ O
framework. -X- _ O

(Arjovsky -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
uses -X- _ O
the -X- _ O
Wasserstein -X- _ O
distance -X- _ O
as -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
to -X- _ O
stabilize -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
GAN. -X- _ O

GAN -X- _ O
(Goodfellow -X- _ O
et -X- _ O
al., -X- _ O
2014) -X- _ O
has -X- _ O
led -X- _ O
the -X- _ O
revolution -X- _ O
of -X- _ O
generative -X- _ O
models -X- _ O
to -X- _ O
achieve -X- _ O
impressive -X- _ O
results -X- _ O
in -X- _ O
synthesizing -X- _ O
images -X- _ O
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
and -X- _ O
higher -X- _ O
dimensional -X- _ O
data -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

3.1 -X- _ O
Conditional -X- _ O
Wasserstein -X- _ O
GAN -X- _ O

3 -X- _ O
Method -X- _ O

Also, -X- _ O
different -X- _ O
from -X- _ O
FDA -X- _ O
which -X- _ O
is -X- _ O
focused -X- _ O
on -X- _ O
two -X- _ O
intent -X- _ O
classification -X- _ O
tasks, -X- _ O
our -X- _ O
method -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
a -X- _ O
wide-range -X- _ O
of -X- _ O
NLP -X- _ O
task -X- _ O
as -X- _ O
shown -X- _ O
by -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
15 -X- _ O
diverse -X- _ O
tasks. -X- _ O

Our -X- _ O
method -X- _ O
shares -X- _ O
similarity -X- _ O
to -X- _ O
FDA -X- _ O
(Kumar -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
generative -X- _ O
data -X- _ O
augmentation -X- _ O
method, -X- _ O
but -X- _ O
at -X- _ O
the -X- _ O
feature -X- _ O
space. -X- _ O

Different -X- _ O
from -X- _ O
(Wei -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
which -X- _ O
uses -X- _ O
EDA -X- _ B-MethodName
(Wei -X- _ O
and -X- _ O
Zou, -X- _ O
2019) -X- _ O
to -X- _ O
augment -X- _ O
examples -X- _ O
at -X- _ O
the -X- _ O
discrete -X- _ O
input -X- _ O

Our -X- _ O
method -X- _ O
is -X- _ O
a -X- _ O
generative -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
in -X- _ O
the -X- _ O
embedding -X- _ O
space. -X- _ O

Ram -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
and -X- _ O
entity -X- _ O
recognition -X- _ O
(de -X- _ O
Lichy -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Tong -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Ding -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
by -X- _ O
meta -X- _ O
learning -X- _ O
(Li -X- _ O
and -X- _ O
Zhang, -X- _ O
2021; -X- _ O
Bansal -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Sharaf -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
data -X- _ O
augmentation -X- _ O
(Wei -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Wei -X- _ O
and -X- _ O
Zou, -X- _ O
2019; -X- _ O
Karimi -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Jian -X- _ O
et -X- _ O
al., -X- _ O
2022), -X- _ O
and -X- _ O
prompts -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Tam -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

In -X- _ O
NLP, -X- _ O
few-shot -X- _ B-TaskName
learning -X- _ I-TaskName
has -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
machine -X- _ O
translation -X- _ O
(Arthaud -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
abstract -X- _ O
summarizing -X- _ O
(Fabbri -X- _ O
et -X- _ O
al., -X- _ O
2021), -X- _ O
question -X- _ O
and -X- _ O
answering -X- _ O
(Hua -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O

Learning -X- _ O
from -X- _ O
limited -X- _ O
labeled -X- _ O
data -X- _ O
(few-shot -X- _ B-TaskName
learning) -X- _ I-TaskName
in -X- _ O
Computer -X- _ O
Vision -X- _ O
is -X- _ O
usually -X- _ O
achieved -X- _ O
by -X- _ O
meta-learning -X- _ O
(Ren -X- _ O
et -X- _ O
al., -X- _ O
2018a,b; -X- _ O
Jian -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Jian -X- _ O
and -X- _ O
Gao, -X- _ O
2021) -X- _ O
or -X- _ O
transfer -X- _ O
learning -X- _ O
(Tian -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O

Label -X- _ O
Hallucination -X- _ O
(Jian -X- _ O
and -X- _ O
Torresani, -X- _ O
2022) -X- _ O
assigns -X- _ O
soft -X- _ O
pseudo-labels -X- _ O
for -X- _ O
unlabelled -X- _ O
images -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
fine-tuning -X- _ O
few-shot -X- _ O
dataset. -X- _ O

Tjio -X- _ O
et -X- _ O
al., -X- _ O
2022). -X- _ O

Feature -X- _ O
Hallucination -X- _ O
of -X- _ O
examples -X- _ O
is -X- _ O
first -X- _ O
introduced -X- _ O
for -X- _ O
visual -X- _ O
recognition -X- _ O
(Hariharan -X- _ O
and -X- _ O
Girshick, -X- _ O
2017) -X- _ O
by -X- _ O
metalearning -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
variational -X- _ O
inference -X- _ O
(Luo -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Lazarou -X- _ O
et -X- _ O
al., -X- _ O
2022), -X- _ O
and -X- _ O
adversarial -X- _ O
learning -X- _ O
(Li -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O

Hallucination -X- _ O
Methods. -X- _ O

Guo -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
or -X- _ O
a -X- _ O
few -X- _ O
additional -X- _ O
parameters -X- _ O
(Houlsby -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

Instead -X- _ O
of -X- _ O
fine-tuning -X- _ O
all -X- _ O
parameters -X- _ O
in -X- _ O
a -X- _ O
model, -X- _ O
other -X- _ O
work -X- _ O
explore -X- _ O
only -X- _ O
learning -X- _ O
a -X- _ O
few -X- _ O
vectors -X- _ O
(Lester -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Li -X- _ O
and -X- _ O
Liang, -X- _ O
2021; -X- _ O

Other -X- _ O
tricks -X- _ O
include -X- _ O
bias -X- _ O
correction -X- _ O
in -X- _ O
optimizer -X- _ O
and -X- _ O
re-initialization -X- _ O
of -X- _ O
top -X- _ O
layers -X- _ O
in -X- _ O
Transformer -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Better -X- _ O
finetuning -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
by -X- _ O
proper -X- _ O
initialization -X- _ O
(Dodge -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
regularization -X- _ O
(Lee -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
or -X- _ O
prompts -X- _ O
(Schick -X- _ O
and -X- _ O
Schütze, -X- _ O
2021). -X- _ O

Fine-tuning -X- _ O
of -X- _ O
Language -X- _ O
Models. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

Finally, -X- _ O
since -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
data -X- _ O
augmentation, -X- _ O
we -X- _ O
also -X- _ O
compare -X- _ O
EmbedHalluc -X- _ B-MethodName
to -X- _ O
a -X- _ O
common -X- _ O
data -X- _ O
augmentation -X- _ O
technique -X- _ O
EDA, -X- _ B-MethodName
and -X- _ O
semi-supervised -X- _ B-MethodName
learning -X- _ I-MethodName
where -X- _ O
unlabeled -X- _ O
data -X- _ O
is -X- _ O
already -X- _ O
available. -X- _ O

We -X- _ O
further -X- _ O
experimentally -X- _ O
show -X- _ O
the -X- _ O
overall -X- _ O
superiority -X- _ O
of -X- _ O
EmbedHalluc -X- _ O
when -X- _ O
comparing -X- _ O
to -X- _ O
regularization -X- _ O
methods -X- _ O
proposed -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
over-fitting -X- _ O
during -X- _ O
fine-tuning -X- _ O
of -X- _ O
LMs, -X- _ O
such -X- _ O
as -X- _ O
Mixout -X- _ B-MethodName
(Lee -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
Re-Init -X- _ B-MethodName
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
method, -X- _ O
called -X- _ O
Embedding -X- _ B-MethodName
Hallucination -X- _ I-MethodName
(Embedhalluc), -X- _ B-MethodName
on -X- _ O
15 -X- _ O
tasks -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
generally -X- _ O
improves -X- _ O
over -X- _ O
recent -X- _ O
fine-tuning -X- _ O

This -X- _ O
effectively -X- _ O
extends -X- _ O
the -X- _ O
fine-tuning -X- _ O
dataset -X- _ O
with -X- _ O
diverse -X- _ O
embedding-label -X- _ O
pairs -X- _ O
which -X- _ O
carry -X- _ O
intra-class -X- _ O
variation -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
a -X- _ O
useful -X- _ O
learning -X- _ O
signal -X- _ O
for -X- _ O
the -X- _ O
language -X- _ O
learner. -X- _ O

Once -X- _ O
the -X- _ O
halluciantor -X- _ O
is -X- _ O
trained, -X- _ O
we -X- _ O
condition -X- _ O
it -X- _ O
on -X- _ O
labels -X- _ O
to -X- _ O
generate -X- _ O
diverse -X- _ O
embeddings -X- _ O
at -X- _ O
each -X- _ O
fine-tuning -X- _ O
step. -X- _ O

By -X- _ O
observing -X- _ O
the -X- _ O
real -X- _ O
embeddings -X- _ O
of -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
fine-tuning -X- _ O
dataset, -X- _ O
the -X- _ O
cWGAN -X- _ O
plays -X- _ O
an -X- _ O
adversarial -X- _ O
game -X- _ O
to -X- _ O
hallucinate -X- _ O
embeddings -X- _ O
that -X- _ O
can -X- _ O
fool -X- _ O
the -X- _ O
discriminator, -X- _ O
while -X- _ O
the -X- _ O
discriminator -X- _ O
is -X- _ O
trying -X- _ O
to -X- _ O
classify -X- _ O
the -X- _ O
fake -X- _ O
embeddings -X- _ O
from -X- _ O
the -X- _ O
real -X- _ O
ones. -X- _ O

To -X- _ O
be -X- _ O
specific, -X- _ O
we -X- _ O
adapt -X- _ O
a -X- _ O
conditional -X- _ O
Wasserstein -X- _ O
Generative -X- _ O
Adversarial -X- _ O
Network -X- _ O
(cWGAN) -X- _ O
(Arjovsky -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
as -X- _ O
our -X- _ O
hallucinator -X- _ O
to -X- _ O
hallucinate -X- _ O
embeddings -X- _ O
of -X- _ O
sentences. -X- _ O

The -X- _ O
underlying -X- _ O
hypothesis -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
intra-class -X- _ O
relation -X- _ O
of -X- _ O
the -X- _ O
observed -X- _ O
examples -X- _ O
can -X- _ O
be -X- _ O
modeled -X- _ O
and -X- _ O
that -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
a -X- _ O
few-samples -X- _ O
to -X- _ O
hallucinate -X- _ O
diverse -X- _ O
unseen -X- _ O
examples. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
generative -X- _ O
augmentation -X- _ O
method -X- _ O
at -X- _ O
the -X- _ O
embedding -X- _ O
space -X- _ O
for -X- _ O
few-shot -X- _ B-TaskName
learning. -X- _ I-TaskName

Current -X- _ O
common -X- _ O
text -X- _ O
data -X- _ O
augmentation -X- _ O
methods, -X- _ O
such -X- _ O
as -X- _ O
EDA -X- _ B-MethodName
(Wei -X- _ O
and -X- _ O
Zou, -X- _ O
2019) -X- _ O
(which -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
in -X- _ O
recent -X- _ O
few-shot -X- _ O
learning -X- _ O
papers -X- _ O
(Wei -X- _ O
et -X- _ O
al., -X- _ O
2021; -X- _ O
Basu -X- _ O
et -X- _ O
al., -X- _ O
2021)) -X- _ O
and -X- _ O
AEDA -X- _ O
(Karimi -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
operate -X- _ O
at -X- _ O
the -X- _ O
lexical -X- _ O
level, -X- _ O
which -X- _ O
while -X- _ O
resulting -X- _ O
in -X- _ O
human -X- _ O
readable -X- _ O
texts, -X- _ O
lead -X- _ O
to -X- _ O
limited -X- _ O
diversity -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
discrete -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
lexical -X- _ O
space. -X- _ O

We -X- _ O
speculate -X- _ O
that -X- _ O
the -X- _ O
key -X- _ O
to -X- _ O
solve -X- _ O
this -X- _ O
issue -X- _ O
is -X- _ O
by -X- _ O
data -X- _ O
augmentation. -X- _ O

However, -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
that -X- _ O
these -X- _ O
methods -X- _ O
fail -X- _ O
in -X- _ O
extreme -X- _ O
data -X- _ O
scarce -X- _ O
setting. -X- _ O

Prior -X- _ O
work -X- _ O
have -X- _ O
proposed -X- _ O
regularization -X- _ O
methods -X- _ O
to -X- _ O
overcome -X- _ O
this -X- _ O
problem -X- _ O
(Lee -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021). -X- _ O

Indeed, -X- _ O
tuning -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
hundreds -X- _ O
of -X- _ O
millions -X- _ O
of -X- _ O
parameters -X- _ O
(e.g., -X- _ O
BERT-large -X- _ O
has -X- _ O
300M -X- _ O
parameters) -X- _ O
with -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
examples -X- _ O
inevitably -X- _ O
faces -X- _ O
the -X- _ O
over-fitting -X- _ O
problem. -X- _ O

Experiments -X- _ O
from -X- _ O
recent -X- _ O
work -X- _ O
(Gao -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
fine-tuning -X- _ O
performs -X- _ O
poorly -X- _ O
in -X- _ O
the -X- _ O
setting -X- _ O
where -X- _ O
only -X- _ O
16 -X- _ O
examples -X- _ O
per -X- _ O
class -X- _ O
are -X- _ O

the -X- _ O
performance -X- _ O
drops -X- _ O
drastically -X- _ O
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
falls -X- _ O
to -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
dozens. -X- _ O

Data -X- _ O
augmentation -X- _ O
(Wei -X- _ O
and -X- _ O
Zou, -X- _ O
2019), -X- _ O
regularization -X- _ O
(Lee -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
re-initialization -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
results. -X- _ O

Conventional -X- _ O
finetuning -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
when -X- _ O
a -X- _ O
few -X- _ O
thousands -X- _ O
of -X- _ O
labeled -X- _ O
examples -X- _ O
are -X- _ O
available. -X- _ O

Fine-tuning -X- _ O
a -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
(LM) -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task -X- _ O
with -X- _ O
the -X- _ O
labeled -X- _ O
data -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
de -X- _ O
facto -X- _ O
approach -X- _ O
in -X- _ O
many -X- _ O
NLP -X- _ O
tasks -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

Introduction -X- _ O

The -X- _ O
code -X- _ O
will -X- _ O
be -X- _ O
made -X- _ O
available -X- _ O
at: -X- _ O
https://github.com/yiren-jian/EmbedHalluc. -X- _ O

Further, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
EmbedHalluc -X- _ B-MethodName
outperforms -X- _ O
other -X- _ O
methods -X- _ O
that -X- _ O
address -X- _ O
this -X- _ O
over-fitting -X- _ O
problem, -X- _ O
such -X- _ O
as -X- _ O
common -X- _ O
data -X- _ O
augmentation, -X- _ O
semi-supervised -X- _ O
pseudo-labeling, -X- _ O
and -X- _ O
regularization. -X- _ O

Experiments -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
method -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
language -X- _ O
tasks, -X- _ O
outperforming -X- _ O
current -X- _ O
fine-tuning -X- _ O
methods. -X- _ O

By -X- _ O
training -X- _ O
with -X- _ O
the -X- _ O
extended -X- _ O
dataset, -X- _ O
the -X- _ O
language -X- _ O
learner -X- _ O
effectively -X- _ O
learns -X- _ O
from -X- _ O
the -X- _ O
diverse -X- _ O
hallucinated -X- _ O
embeddings -X- _ O
to -X- _ O
overcome -X- _ O
the -X- _ O
over-fitting -X- _ O
issue. -X- _ O

The -X- _ O
hallucinator -X- _ O
is -X- _ O
trained -X- _ O
by -X- _ O
playing -X- _ O
an -X- _ O
adversarial -X- _ O
game -X- _ O
with -X- _ O
the -X- _ O
discriminator, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
hallucinated -X- _ O
embedding -X- _ O
is -X- _ O
indiscriminative -X- _ O
to -X- _ O
the -X- _ O
real -X- _ O
ones -X- _ O
in -X- _ O
the -X- _ O
finetuning -X- _ O
dataset. -X- _ O

In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
Embedding -X- _ B-MethodName
Hallucination -X- _ I-MethodName
(EmbedHalluc) -X- _ B-MethodName
method, -X- _ O
which -X- _ O
generates -X- _ O
auxiliary -X- _ O
embedding-label -X- _ O
pairs -X- _ O
to -X- _ O
expand -X- _ O
the -X- _ O
finetuning -X- _ O
dataset. -X- _ O

In -X- _ O
such -X- _ O
settings, -X- _ O
fine-tuning -X- _ O
a -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
can -X- _ O
cause -X- _ O
severe -X- _ O
over-fitting. -X- _ O

Few-shot -X- _ O
language -X- _ O
learners -X- _ O
adapt -X- _ O
knowledge -X- _ O
from -X- _ O
a -X- _ O
pre-trained -X- _ O
model -X- _ O
to -X- _ O
recognize -X- _ O
novel -X- _ O
classes -X- _ O
from -X- _ O
a -X- _ O
few-labeled -X- _ O
sentences. -X- _ O

Abstract -X- _ O

Embedding -X- _ B-MethodName
Hallucination -X- _ I-MethodName
for -X- _ O
Few-Shot -X- _ B-TaskName
Language -X- _ I-TaskName
Fine-tuning -X- _ I-TaskName

-DOCSTART- -X- O
References -X- _ O

Therefore, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
extended -X- _ O
to -X- _ O
Korean -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
English, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
in -X- _ O
other -X- _ O
countries. -X- _ O

However, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
context -X- _ O
modeling -X- _ O
is -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
pre-trained -X- _ O
memory -X- _ O
for -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ I-TaskName
conversation, -X- _ I-TaskName
and -X- _ O
future -X- _ O
research -X- _ O
will -X- _ O
focus -X- _ O
on -X- _ O
context -X- _ O
modeling. -X- _ O

Since -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
pre-trained -X- _ O
memory -X- _ O
is -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
a -X- _ O
language -X- _ O
model, -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
training -X- _ O
corpus -X- _ O
and -X- _ O
many -X- _ O
parameters -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
effective. -X- _ O

By -X- _ O
combining -X- _ O
other -X- _ O
pre-trained -X- _ O
memories, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
extracted -X- _ O
with -X- _ O
RoBERTa -X- _ O
is -X- _ O
richer -X- _ O
and -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
extracted -X- _ O
with -X- _ O
BERT -X- _ O
or -X- _ O
GPT2. -X- _ O

In -X- _ O
addition, -X- _ O
CoMPM -X- _ B-MethodName
achieves -X- _ O
performance -X- _ O
comparable -X- _ O
to -X- _ O
cutting-edge -X- _ O
systems -X- _ O
that -X- _ O
leverage -X- _ O
structured -X- _ O
external -X- _ O
knowledge, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
pre-trained -X- _ O
memory -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model. -X- _ O

CoMPM -X- _ B-MethodName
outperforms -X- _ O
baselines -X- _ O
on -X- _ O
both -X- _ O
dyadic-party -X- _ O
and -X- _ O
multi-party -X- _ O
datasets -X- _ O
and -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
among -X- _ O
systems -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
external -X- _ O
knowledge. -X- _ O

CoMPM -X- _ B-MethodName
consists -X- _ O
of -X- _ O
a -X- _ O
context -X- _ B-MethodName
embedding -X- _ I-MethodName
module -X- _ I-MethodName
(CoM) -X- _ B-MethodName
and -X- _ O
a -X- _ O
pre-trained -X- _ B-MethodName
memory -X- _ I-MethodName
module -X- _ I-MethodName
(PM), -X- _ B-MethodName
and -X- _ O
the -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
each -X- _ O
module -X- _ O
is -X- _ O
effective -X- _ O
in -X- _ O
improving -X- _ O
the -X- _ O
performance. -X- _ O

We -X- _ O
propose -X- _ O
CoMPM -X- _ B-MethodName
that -X- _ O
leverages -X- _ O
pre-trained -X- _ O
memory -X- _ O
using -X- _ O
a -X- _ O
pre-trained -X- _ O
language -X- _ O
model. -X- _ O

5 -X- _ O
Conclusion -X- _ O

Models -X- _ O

Our -X- _ O
approach -X- _ O

In -X- _ O
the -X- _ O
Korean -X- _ O
dataset, -X- _ O
like -X- _ O
the -X- _ O
English -X- _ O
dataset, -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
good -X- _ O
in -X- _ O
the -X- _ O
order -X- _ O
of -X- _ O
CoMPM, -X- _ B-MethodName
CoM, -X- _ B-MethodName
and -X- _ O
PM. -X- _ B-MethodName

The -X- _ O
backbone -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
is -X- _ O
Korean-BERT -X- _ O
owned -X- _ O
by -X- _ O
the -X- _ O
company, -X- _ O
respectively. -X- _ O

4.7.2 -X- _ O
Results -X- _ O
in -X- _ O
the -X- _ O
Korean -X- _ O
Dataset -X- _ O
In -X- _ O
Korean, -X- _ O
our -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4. -X- _ O

This -X- _ O
dataset -X- _ O
is -X- _ O
for -X- _ O
actual -X- _ O
service -X- _ O
and -X- _ O
is -X- _ O
not -X- _ O
released -X- _ O
to -X- _ O
the -X- _ O
public. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
data -X- _ O
randomly -X- _ O
divided -X- _ O
into -X- _ O
train:dev:test -X- _ B-HyperparameterName
in -X- _ O
a -X- _ O
ratio -X- _ O
of -X- _ O
8:1:1. -X- _ B-HyperparameterValue

The -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
sessions -X- _ O
is -X- _ O
1000, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
utterance -X- _ O
turns -X- _ O
is -X- _ O
13.4. -X- _ O

4.7.1 -X- _ O
Korean -X- _ O
Dataset -X- _ O
We -X- _ O
constructed -X- _ O
data -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
speakers -X- _ O
in -X- _ O
Korean, -X- _ O
and -X- _ O
emotion-inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
"surprise, -X- _ O
fear, -X- _ O
ambiguous, -X- _ O
sad, -X- _ O
disgust, -X- _ O
joy, -X- _ O
bored, -X- _ O
embarrassed, -X- _ O
neutral". -X- _ O

Our -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
without -X- _ O
building -X- _ O
additional -X- _ O
external -X- _ O
knowledge -X- _ O
and -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
simply -X- _ O
using -X- _ O
a -X- _ O
pre-trained -X- _ O
model. -X- _ O

Indeed, -X- _ O
structured -X- _ O
knowledge -X- _ O
and -X- _ O
ERC -X- _ B-TaskName
data -X- _ O
are -X- _ O
lacking -X- _ O
in -X- _ O
other -X- _ O
languages. -X- _ O

Previous -X- _ O
studies -X- _ O
mostly -X- _ O
utilize -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
improve -X- _ O
performance, -X- _ O
but -X- _ O
these -X- _ O
approaches -X- _ O
require -X- _ O
additional -X- _ O
publicly -X- _ O
available -X- _ O
data, -X- _ O
which -X- _ O
are -X- _ O
mainly -X- _ O
available -X- _ O
for -X- _ O
English. -X- _ O

4.7 -X- _ O
ERC -X- _ B-TaskName
in -X- _ O
other -X- _ O
languages -X- _ O

Therefore, -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
real-world -X- _ O
application, -X- _ O
CoMPM -X- _ B-MethodName
is -X- _ O
expected -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
performance, -X- _ O
otherwise -X- _ O
it -X- _ O
is -X- _ O
CoMPM(f). -X- _ B-MethodName

Figure -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
data -X- _ O
decreases, -X- _ O
CoMPM(f) -X- _ B-MethodName
shows -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
CoMPM, -X- _ B-MethodName
which -X- _ O
indicates -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
better -X- _ O
to -X- _ O
freeze -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
PM -X- _ B-MethodName
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
insufficient. -X- _ O

On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
if -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
training -X- _ O
data, -X- _ O
CoMPM -X- _ B-MethodName
shows -X- _ O
better -X- _ O
performance. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
that -X- _ O
CoMPM(f) -X- _ B-MethodName
achieves -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
CoMPM -X- _ B-MethodName
in -X- _ O
the -X- _ O
emotion -X- _ B-TaskName
classification -X- _ I-TaskName
of -X- _ O
IMEOCAP -X- _ B-DatasetName
and -X- _ O
EmoryNLP, -X- _ B-DatasetName
which -X- _ O
has -X- _ O
fewer -X- _ O
training -X- _ O
data -X- _ O
than -X- _ O
other -X- _ O
settings. -X- _ O

In -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP, -X- _ B-DatasetName
even -X- _ O
if -X- _ O
only -X- _ O
60% -X- _ O
and -X- _ O
80% -X- _ O
are -X- _ O
used, -X- _ O
respectively, -X- _ O
the -X- _ O
performance -X- _ O
decreases -X- _ O
by -X- _ O
only -X- _ O
3 -X- _ B-MetricValue
points. -X- _ O

Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data. -X- _ O

Therefore, -X- _ O
we -X- _ O
conduct -X- _ O
additional -X- _ O
experiments -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
use -X- _ O
ratio -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP, -X- _ B-DatasetName
where -X- _ O
there -X- _ O
is -X- _ O
neither -X- _ O
too -X- _ O
much -X- _ O
nor -X- _ O
too -X- _ O
little -X- _ O
data. -X- _ O

However, -X- _ O
the -X- _ O
insufficient -X- _ O
number -X- _ O
of -X- _ O
emotional -X- _ O
data -X- _ O
available -X- _ O
in -X- _ O
other -X- _ O
countries -X- _ O
(or -X- _ O
actual -X- _ O
service) -X- _ O
remains -X- _ O
a -X- _ O
problem. -X- _ O

CoMPM -X- _ B-MethodName
is -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
eliminates -X- _ O
dependence -X- _ O
on -X- _ O
external -X- _ O
sources -X- _ O
and -X- _ O
is -X- _ O
easily -X- _ O
extensible -X- _ O
to -X- _ O
any -X- _ O
language. -X- _ O

RoBERTa+BERT -X- _ O
and -X- _ O
RoBERTa+GPT2 -X- _ O
(combination -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM(f)) -X- _ O
have -X- _ O
lower -X- _ O
performance -X- _ O
than -X- _ O
RoBERTa+RoBERTa, -X- _ O
which -X- _ O
is -X- _ O
inferred -X- _ O
because -X- _ O
pre-trained -X- _ O
memory -X- _ O
of -X- _ O
RoBERTa -X- _ O
contains -X- _ O

If -X- _ O
PM -X- _ B-MethodName
and -X- _ O
CoM -X- _ B-MethodName
are -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
backbones, -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
is -X- _ O
projected -X- _ O
through -X- _ O
Wp -X- _ O
as -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
output. -X- _ O

Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
memory -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
different -X- _ O
language -X- _ O
models. -X- _ O

To -X- _ O
eliminate -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
PM -X- _ B-MethodName
structure, -X- _ O
we -X- _ O
freeze -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
PM -X- _ B-MethodName
and -X- _ O
use -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor. -X- _ O

We -X- _ O
experiment -X- _ O
with -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
pre-trained -X- _ O
memory -X- _ O
of -X- _ O
different -X- _ O
language -X- _ O
models. -X- _ O

4.6 -X- _ O
Training -X- _ O
with -X- _ O
Less -X- _ O
Data -X- _ O

4.5 -X- _ O
Combinations -X- _ O
of -X- _ O
CoM -X- _ O
and -X- _ O
PM -X- _ O

In -X- _ O
other -X- _ O
words, -X- _ O
we -X- _ O
confirm -X- _ O
that -X- _ O
CoM -X- _ B-MethodName
is -X- _ O
more -X- _ O
important -X- _ O
than -X- _ O
PM -X- _ B-MethodName
in -X- _ O
our -X- _ O
system -X- _ O
for -X- _ O
performance, -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
effective -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
context -X- _ O
modeling -X- _ O
rather -X- _ O
than -X- _ O
external -X- _ O
knowledge -X- _ O
in -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ I-TaskName
conversation. -X- _ I-TaskName

In -X- _ O
addition, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT+RoBERTa -X- _ O
is -X- _ O
lower -X- _ O
than -X- _ O
CoM -X- _ B-MethodName
(RoBERTa), -X- _ O
which -X- _ O
supports -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
is -X- _ O
a -X- _ O
more -X- _ O
important -X- _ O
factor -X- _ O
than -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
pre-trained -X- _ O
memory. -X- _ O

In -X- _ O
particular, -X- _ O
in -X- _ O
IEMOCAP -X- _ B-DatasetName
data -X- _ O
with -X- _ O
a -X- _ O
long -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
turns -X- _ O
in -X- _ O
the -X- _ O
context, -X- _ O
the -X- _ O
performance -X- _ O
deteriorates -X- _ O
significantly. -X- _ O

BERT+RoBERTa -X- _ O
has -X- _ O
a -X- _ O
larger -X- _ O
performance -X- _ O
decrease -X- _ O
than -X- _ O
RoBERTa+BERT. -X- _ O

However, -X- _ O
even -X- _ O
if -X- _ O
other -X- _ O
PMs -X- _ B-MethodName
are -X- _ O
used, -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
improved -X- _ O
compared -X- _ O
to -X- _ O
using -X- _ O
only -X- _ O
CoM, -X- _ B-MethodName
so -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
of -X- _ O
other -X- _ O
language -X- _ O
models -X- _ O
is -X- _ O
also -X- _ O
effective -X- _ O
for -X- _ O
emotion -X- _ B-TaskName
recognition. -X- _ I-TaskName

Therefore, -X- _ O
we -X- _ O
infer -X- _ O
that -X- _ O
performance -X- _ O
does -X- _ O
not -X- _ O
decrease -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
PM -X- _ B-MethodName
changes -X- _ O
from -X- _ O
the -X- _ O
dailydialog. -X- _ O

Since -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
diallydialog -X- _ O
and -X- _ O
Wp -X- _ O
is -X- _ O
fine-tuned -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
mutually -X- _ O
understand -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
and -X- _ O
context -X- _ O
representation. -X- _ O

Figure -X- _ O
3: -X- _ O
Performance -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
MELD -X- _ O
and -X- _ O
EmoryNLP -X- _ O

Therefore, -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
without -X- _ O
structured -X- _ O
external -X- _ O
data -X- _ O
as -X- _ O
well, -X- _ O
which -X- _ O
is -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.7. -X- _ O

We -X- _ O
achieve -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
among -X- _ O
all -X- _ O
systems -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
leverage -X- _ O
structured -X- _ O
external -X- _ O
data -X- _ O
and -X- _ O
achieve -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
second -X- _ O
performance -X- _ O
even -X- _ O
including -X- _ O
systems -X- _ O
that -X- _ O
leverage -X- _ O
external -X- _ O
data. -X- _ O

The -X- _ O
best -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
approaches -X- _ O
is -X- _ O
CoMPM -X- _ B-MethodName
or -X- _ O
CoMPM(f), -X- _ B-MethodName
both -X- _ O
of -X- _ O
which -X- _ O
combine -X- _ O
pre-trained -X- _ O
memory. -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
we -X- _ O
regard -X- _ O
pre-trained -X- _ O
memory -X- _ O
as -X- _ O
compressed -X- _ O
knowledge, -X- _ O
which -X- _ O
can -X- _ O
play -X- _ O
a -X- _ O
role -X- _ O
similar -X- _ O
to -X- _ O
external -X- _ O
knowledge -X- _ O
used -X- _ O
in -X- _ O
cuttingedge -X- _ O
systems. -X- _ O

In -X- _ O
other -X- _ O
words, -X- _ O
ConceptNet -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoMPM, -X- _ B-MethodName
but -X- _ O
is -X- _ O
not -X- _ O
as -X- _ O
effective -X- _ O
as -X- _ O
pretrained -X- _ O
memory. -X- _ O

In -X- _ O
IEMOCAP, -X- _ B-DatasetName
CoMPM(k) -X- _ B-MethodName
has -X- _ O
lower -X- _ O
performance -X- _ O
than -X- _ O
CoM. -X- _ B-MethodName
For -X- _ O
all -X- _ O
datasets, -X- _ O
CoMPM(k) -X- _ B-MethodName
performs -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
CoMPM. -X- _ B-MethodName

In -X- _ O
addition, -X- _ O
CoMPM(k) -X- _ B-MethodName
shows -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
CoM, -X- _ B-MethodName
PM, -X- _ B-MethodName
and -X- _ O
CoMPM(s) -X- _ B-MethodName
except -X- _ O
for -X- _ O
IEMOCAP. -X- _ B-DatasetName

The -X- _ O
comparison -X- _ O
between -X- _ O
PM -X- _ B-MethodName
and -X- _ O
PM(f) -X- _ O
will -X- _ O
be -X- _ O
further -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.6. -X- _ O

PM(f) -X- _ O
is -X- _ O
not -X- _ O
fine-tuned -X- _ O
on -X- _ O
the -X- _ O
data, -X- _ O
but -X- _ O
it -X- _ O
extracts -X- _ O
general -X- _ O
pre-trained -X- _ O
memory -X- _ O
from -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model. -X- _ O

CoMPM(f) -X- _ B-MethodName
shows -X- _ O
similar -X- _ O
performance -X- _ O
to -X- _ O
CoMPM -X- _ B-MethodName
and -X- _ O
achieves -X- _ O
better -X- _ O
performance -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
data. -X- _ O

That -X- _ O
is, -X- _ O
PM(s) -X- _ O
cannot -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
pre-trained -X- _ O
memory -X- _ O
because -X- _ O
the -X- _ O
parameters -X- _ O
are -X- _ O
randomly -X- _ O
initialized, -X- _ O
and -X- _ O
simply -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
complexity -X- _ O
does -X- _ O
not -X- _ O
help -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance. -X- _ O

CoMPM(s) -X- _ B-MethodName
performs -X- _ O
worse -X- _ O
than -X- _ O
CoMPM, -X- _ B-MethodName
and -X- _ O
even -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
CoM -X- _ B-MethodName
on -X- _ O
the -X- _ O
other -X- _ O
datasets -X- _ O
except -X- _ O
for -X- _ O
MELD. -X- _ B-DatasetName

If -X- _ O
PM -X- _ B-MethodName
parameters -X- _ O
are -X- _ O
not -X- _ O
frozen -X- _ O
and -X- _ O
are -X- _ O
instead -X- _ O
randomly -X- _ O
initialized -X- _ O
(i.e. -X- _ O
PM(s)), -X- _ O
the -X- _ O
performance -X- _ O
deteriorates. -X- _ O

We -X- _ O
confirm -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
PM -X- _ B-MethodName
structure -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
through -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoMPM(s). -X- _ B-MethodName

As -X- _ O
a -X- _ O
result, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
is -X- _ O
effective -X- _ O
in -X- _ O
achieving -X- _ O
better -X- _ O
performance. -X- _ O

Since -X- _ O
PM -X- _ B-MethodName
does -X- _ O
not -X- _ O
consider -X- _ O
context, -X- _ O
it -X- _ O
showed -X- _ O
worse -X- _ O
performance -X- _ O
than -X- _ O
CoM, -X- _ B-MethodName
and -X- _ O
the -X- _ O
performance -X- _ O
gap -X- _ O
is -X- _ O
larger -X- _ O
in -X- _ O
the -X- _ O
IEMOCAP -X- _ B-DatasetName
dataset -X- _ O
with -X- _ O
a -X- _ O
higher -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
conversation -X- _ O
turns. -X- _ O

The -X- _ O
effect -X- _ O
of -X- _ O
PM -X- _ B-MethodName
can -X- _ O
be -X- _ O
confirmed -X- _ O
through -X- _ O
the -X- _ O
performance -X- _ O
comparison -X- _ O
between -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
CoMPM, -X- _ B-MethodName
and -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
can -X- _ O
be -X- _ O
confirmed -X- _ O
by -X- _ O
comparing -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM. -X- _ B-MethodName

We -X- _ O
use -X- _ O
the -X- _ O
pre-trained -X- _ O
model -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
site -X- _ O
4 -X- _ O
as -X- _ O
PM(k). -X- _ O

Following -X- _ O
previous -X- _ O
studies, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
average -X- _ O
vector -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
PM(k) -X- _ O
as -X- _ O
the -X- _ O
feature -X- _ O
of -X- _ O
the -X- _ O
utterance. -X- _ O

CoMPM(k) -X- _ B-MethodName
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
PM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
ConceptNet. -X- _ O

CoMPM -X- _ B-MethodName
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
both -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
parameters -X- _ O
are -X- _ O
updated -X- _ O
in -X- _ O
the -X- _ O
initial -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
LM. -X- _ O
CoMPM(f) -X- _ B-MethodName
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
PM -X- _ B-MethodName
parameters -X- _ O
are -X- _ O
frozen -X- _ O
in -X- _ O
the -X- _ O
initial -X- _ O
state -X- _ O
(pre-trained -X- _ O
LM) -X- _ O
and -X- _ O
is -X- _ O
not -X- _ O
trained -X- _ O
further, -X- _ O
and -X- _ O
CoMPM(s) -X- _ B-MethodName
is -X- _ O
a -X- _ O
model -X- _ O
in -X- _ O
which -X- _ O
PM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
from -X- _ O
scratch. -X- _ O

PM -X- _ B-MethodName
used -X- _ O
alone -X- _ O
predicts -X- _ O
emotion -X- _ O
only -X- _ O
with -X- _ O
the -X- _ O
utterance -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
without -X- _ O
considering -X- _ O
the -X- _ O
context. -X- _ O

PM -X- _ B-MethodName
used -X- _ O
alone -X- _ O
is -X- _ O
not -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
memory -X- _ O
module, -X- _ O
but -X- _ O
the -X- _ O
same -X- _ O
backbone -X- _ O
is -X- _ O
used. -X- _ O

CoM -X- _ B-MethodName
used -X- _ O
alone -X- _ O
does -X- _ O
not -X- _ O
leverage -X- _ O
PM -X- _ B-MethodName
and -X- _ O
predicts -X- _ O
emotions -X- _ O
by -X- _ O
considering -X- _ O
only -X- _ O
the -X- _ O
dialogue -X- _ O
context. -X- _ O

Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
and -X- _ O
our -X- _ O
models. -X- _ O

4.4 -X- _ O
Result -X- _ O
and -X- _ O
Analysis -X- _ O

3https://github.com/something678/TodKat -X- _ O

The -X- _ O
performance -X- _ O
of -X- _ O
ToDKAT -X- _ B-MethodName
in -X- _ O
MELD -X- _ B-DatasetName
was -X- _ O
re-released -X- _ O
on -X- _ O
github -X- _ O
3. -X- _ O

ToDKAT -X- _ B-MethodName
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
proposes -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
topic -X- _ O
detection -X- _ O
added, -X- _ O
and -X- _ O
improves -X- _ O
performance -X- _ O
by -X- _ O
combining -X- _ O
it -X- _ O
with -X- _ O
commonsense -X- _ O
knowledge. -X- _ O

DialogueCRN -X- _ B-MethodName
(Hu -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
introduces -X- _ O
an -X- _ O
intuitive -X- _ O
retrieving -X- _ O
process, -X- _ O
the -X- _ O
reasoning -X- _ O
module, -X- _ O
which -X- _ O
understands -X- _ O
both -X- _ O
situation-level -X- _ O
and -X- _ O
speakerlevel -X- _ O
contexts. -X- _ O

Psychological -X- _ B-MethodName
performs -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
by -X- _ O
utilizing -X- _ O
intention -X- _ O
of -X- _ O
utterances -X- _ O
from -X- _ O
not -X- _ O
only -X- _ O
past -X- _ O
contexts -X- _ O
but -X- _ O
also -X- _ O
future -X- _ O
context. -X- _ O

Psychological -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
uses -X- _ O
commonsense -X- _ O
knowledge -X- _ O
as -X- _ O
enrich -X- _ O
edges -X- _ O
and -X- _ O
processes -X- _ O
it -X- _ O
with -X- _ O
graph -X- _ O
transformer. -X- _ O

ERMC-DisGCN -X- _ B-MethodName
(Sun -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
proposes -X- _ O
a -X- _ O
discourse-aware -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
that -X- _ O
utilizes -X- _ O
self-speaker -X- _ O
dependency -X- _ O
of -X- _ O
interlocutors -X- _ O
as -X- _ O
a -X- _ O
relational -X- _ O
convolution -X- _ O
and -X- _ O
informative -X- _ O
cues -X- _ O
of -X- _ O
dependent -X- _ O
utterances -X- _ O
as -X- _ O
a -X- _ O
gated -X- _ O
convolution. -X- _ O

This -X- _ O
model -X- _ O
uses -X- _ O
pre-trained -X- _ O
RoBERTa -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
and -X- _ O
leverages -X- _ O
COMET -X- _ O
trained -X- _ O
with -X- _ O
ATOMIC -X- _ O
as -X- _ O
the -X- _ O
commonsense -X- _ O
knowledge. -X- _ O

COSMIC -X- _ B-MethodName
(Ghosal -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
incorporates -X- _ O
different -X- _ O
elements -X- _ O
of -X- _ O
commonsense -X- _ O
such -X- _ O
as -X- _ O
mental -X- _ O
states, -X- _ O
events -X- _ O
and -X- _ O
causal -X- _ O
relations, -X- _ O
and -X- _ O
learns -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
participants -X- _ O
in -X- _ O
the -X- _ O
conversation. -X- _ O

Models -X- _ O

HiTrans -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
proposes -X- _ O
a -X- _ O
transformerbased -X- _ O
context- -X- _ O
and -X- _ O
speaker-sensitive -X- _ O
model. -X- _ O

RGAT+P -X- _ B-MethodName
(Ishiwatari -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
(relational -X- _ B-MethodName
graph -X- _ I-MethodName
attention -X- _ I-MethodName
networks) -X- _ I-MethodName
proposes -X- _ O
relational -X- _ O
position -X- _ O
encodings -X- _ O
with -X- _ O
sequential -X- _ O
information -X- _ O
reflecting -X- _ O
the -X- _ O
relational -X- _ O
graph -X- _ O
structure, -X- _ O
which -X- _ O
shows -X- _ O
that -X- _ O
both -X- _ O
the -X- _ O
speaker -X- _ O
dependency -X- _ O
and -X- _ O
the -X- _ O
sequential -X- _ O
information -X- _ O
can -X- _ O
be -X- _ O
captured. -X- _ O

(2020) -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
RoBERTa+DialogueRNN -X- _ B-MethodName
when -X- _ O
the -X- _ O
vectors -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
are -X- _ O
extracted -X- _ O
with -X- _ O
a -X- _ O
pretrained -X- _ O
RoBERTa. -X- _ O

This -X- _ O
model -X- _ O
assumes -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
factors -X- _ O
in -X- _ O
emotion -X- _ O
prediction: -X- _ O
the -X- _ O
speaker, -X- _ O
the -X- _ O
context -X- _ O
from -X- _ O
the -X- _ O
preceding -X- _ O
utterances -X- _ O
and -X- _ O
the -X- _ O
emotion -X- _ O
of -X- _ O
the -X- _ O
preceding -X- _ O
utterances. -X- _ O

DialogueRNN -X- _ B-MethodName
(Majumder -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
uses -X- _ O
a -X- _ O
GRU -X- _ O
network -X- _ O
to -X- _ O
keep -X- _ O
track -X- _ O
of -X- _ O
the -X- _ O
individual -X- _ O
party -X- _ O
states -X- _ O
in -X- _ O
the -X- _ O
conversation -X- _ O
to -X- _ O
predict -X- _ O
emotions. -X- _ O

KET -X- _ B-MethodName
(Zhong -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
is -X- _ O
a -X- _ O
Knowledge -X- _ B-MethodName
Enriched -X- _ I-MethodName
Transformer -X- _ I-MethodName
that -X- _ O
reflects -X- _ O
contextual -X- _ O
utterances -X- _ O
with -X- _ O
a -X- _ O
hierarchical -X- _ O
self-attention -X- _ O
and -X- _ O
leverages -X- _ O
external -X- _ O
commonsense -X- _ O
knowledge -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
context-aware -X- _ O
affective -X- _ O
graph -X- _ O
attention -X- _ O
mechanism. -X- _ O

We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
is -X- _ O
effective -X- _ O
by -X- _ O
comparing -X- _ O
it -X- _ O
with -X- _ O
various -X- _ O
baselines -X- _ O
and -X- _ O
the -X- _ O
stateof-the-art -X- _ O
methods. -X- _ O

4.3 -X- _ O
Previous -X- _ O
Method -X- _ O

All -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
one -X- _ O
V100 -X- _ O
GPU -X- _ O
with -X- _ O
32GB -X- _ O
memory. -X- _ O

We -X- _ O
select -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set. -X- _ O

The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
scheduler -X- _ I-HyperparameterName
used -X- _ O
for -X- _ O
training -X- _ O
is -X- _ O
get_linear_schedule_with_warmup, -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
maximum -X- _ O
value -X- _ O
of -X- _ O
10 -X- _ B-HyperparameterValue
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
gradient -X- _ B-HyperparameterName
clipping. -X- _ I-HyperparameterName

The -X- _ O
optimizer -X- _ O
is -X- _ O
AdamW -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
1e-5 -X- _ B-HyperparameterValue
as -X- _ O
an -X- _ O
initial -X- _ O
value. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
pre-trained -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
huggingface -X- _ O
library -X- _ O
2. -X- _ O

4.2 -X- _ O
Training -X- _ O
Setup -X- _ O

Sentiment -X- _ O
labels -X- _ O
are -X- _ O
not -X- _ O
provided, -X- _ O
but -X- _ O
sentiment -X- _ O
classes -X- _ O
can -X- _ O
be -X- _ O
grouped -X- _ O
as -X- _ O
follows: -X- _ O
positive: -X- _ O
{joyful, -X- _ O
peaceful, -X- _ O
powerful}, -X- _ O
negative: -X- _ O
{scared, -X- _ O
mad, -X- _ O
sad}, -X- _ O
neutral: -X- _ O
{neutral} -X- _ O

EmoryNLP, -X- _ B-DatasetName
like -X- _ O
MELD, -X- _ B-DatasetName
is -X- _ O
also -X- _ O
a -X- _ O
dataset -X- _ O
based -X- _ O
on -X- _ O
Friends -X- _ O
TV -X- _ O
show, -X- _ O
but -X- _ O
the -X- _ O
emotion-inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
"joyful, -X- _ O
peaceful, -X- _ O
powerful, -X- _ O
scared, -X- _ O
mad, -X- _ O
sad -X- _ O
and -X- _ O
neutral". -X- _ O

MELD’s -X- _ B-DatasetName
emotion-inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
"anger, -X- _ O
disgust, -X- _ O
sadness, -X- _ O
joy, -X- _ O
surprise, -X- _ O
fear -X- _ O
and -X- _ O
neutrality" -X- _ O
following -X- _ O
Ekman -X- _ O
(Ekman, -X- _ O
1992) -X- _ O
and -X- _ O
sentiment-inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
"positive, -X- _ O
negative -X- _ O
and -X- _ O
neutral". -X- _ O

MELD -X- _ B-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
based -X- _ O
on -X- _ O
Friends -X- _ O
TV -X- _ O
show -X- _ O
and -X- _ O
provides -X- _ O
two -X- _ O
taxonomy: -X- _ O
emotion -X- _ O
and -X- _ O
sentiment. -X- _ O

Since -X- _ O
more -X- _ O
than -X- _ O
82% -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
are -X- _ O
tagged -X- _ O
as -X- _ O
neutral, -X- _ O
neutral -X- _ O
emotions -X- _ O
are -X- _ O
excluded -X- _ O
when -X- _ O
evaluating -X- _ O
systems -X- _ O
with -X- _ O
Micro-F1 -X- _ B-MetricName
as -X- _ O
did -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
studies. -X- _ O

DailyDialog -X- _ B-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
daily -X- _ O
conversations -X- _ O
between -X- _ O
two -X- _ O
speakers -X- _ O
and -X- _ O
the -X- _ O
emotion-inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
"anger, -X- _ O
disgust, -X- _ O
fear, -X- _ O
joy, -X- _ O
surprise, -X- _ O
sadness -X- _ O
and -X- _ O
neutral". -X- _ O

The -X- _ O
test -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
conversation -X- _ O
involving -X- _ O
two -X- _ O
later -X- _ O
speakers. -X- _ O

The -X- _ O
train -X- _ O
and -X- _ O
development -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
conversation -X- _ O
involving -X- _ O
the -X- _ O
previous -X- _ O
eight -X- _ O
speakers, -X- _ O
and -X- _ O
the -X- _ O
train -X- _ O
and -X- _ O
development -X- _ O
are -X- _ O
divided -X- _ O
into -X- _ O
random -X- _ O
splits -X- _ O
at -X- _ O
a -X- _ O
ratio -X- _ B-HyperparameterName
of -X- _ O
9:1. -X- _ B-HyperparameterValue

IEMOCAP -X- _ B-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
involving -X- _ O
10 -X- _ O
speakers, -X- _ O
and -X- _ O
each -X- _ O
conversation -X- _ O
involves -X- _ O
2 -X- _ O
speakers -X- _ O
and -X- _ O
the -X- _ O
emotion-inventory -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
"happy, -X- _ O
sad, -X- _ O
angry, -X- _ O
excited, -X- _ O
frustrated -X- _ O
and -X- _ O
neutral". -X- _ O

The -X- _ O
statistics -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O

MELD -X- _ B-DatasetName
(Poria -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
EmoryNLP -X- _ B-DatasetName
(Zahiri -X- _ O
and -X- _ O
Choi, -X- _ O
2018) -X- _ O
are -X- _ O
multi-party -X- _ O
datasets, -X- _ O
while -X- _ O
IEMOCAP -X- _ B-DatasetName
(Busso -X- _ O
et -X- _ O
al., -X- _ O
2008) -X- _ O
and -X- _ O
DailyDialog -X- _ B-DatasetName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
are -X- _ O
dyadic-party -X- _ O
datasets. -X- _ O

We -X- _ O
experiment -X- _ O
on -X- _ O
four -X- _ O
benchmark -X- _ O
datasets. -X- _ O

4.1 -X- _ O
Dataset -X- _ O

4 -X- _ O
Experiments -X- _ O

MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
are -X- _ O
used -X- _ O
to -X- _ O
measure -X- _ O
weighted -X- _ B-MetricName
avg -X- _ I-MetricName
F1 -X- _ I-MetricName
for -X- _ O
both -X- _ O
emotion -X- _ O
(7) -X- _ O
and -X- _ O
sentiment -X- _ O
(3) -X- _ O
classes. -X- _ O

DailyDialog -X- _ B-DatasetName
uses -X- _ O
7 -X- _ O
classes -X- _ O
for -X- _ O
training, -X- _ O
but -X- _ O
we -X- _ O
measure -X- _ O
Macro-F1 -X- _ B-MetricName
for -X- _ O
only -X- _ O
6 -X- _ O
classes -X- _ O
excluding -X- _ O
neutral. -X- _ O

Dataset -X- _ O

The -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
so -X- _ O
that -X- _ O
et -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
emotional -X- _ O
label. -X- _ O

3.5.2 -X- _ O
Emotion -X- _ O
Prediction -X- _ O

where, -X- _ O
Wp -X- _ O
is -X- _ O
a -X- _ O
matrix -X- _ O
that -X- _ O
projects -X- _ O
the -X- _ O
pretrained -X- _ O
memory -X- _ O
to -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
output, -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
only -X- _ O
when -X- _ O
PM -X- _ B-MethodName
and -X- _ O
CoM -X- _ B-MethodName
are -X- _ O
different -X- _ O
pre-trained -X- _ O
language -X- _ O
models. -X- _ O

ot -X- _ O
= -X- _ O
ct -X- _ O
+ -X- _ O
Wp(ktt) -X- _ O

Finally, -X- _ O
the -X- _ O
output -X- _ O
vector -X- _ O
ot -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
adding -X- _ O
ktt -X- _ O
and -X- _ O
ct -X- _ O
in -X- _ O
Equation -X- _ O
4. -X- _ O

GRU -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
2-layers, -X- _ O
the -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
output -X- _ I-HyperparameterName
vector -X- _ I-HyperparameterName
is -X- _ O
hc, -X- _ B-HyperparameterName
and -X- _ O
the -X- _ O
dropout -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.3 -X- _ B-HyperparameterValue
during -X- _ O
training. -X- _ O

R1 -X- _ O

We -X- _ O
track -X- _ O
and -X- _ O
capture -X- _ O
the -X- _ O
sequential -X- _ O
position -X- _ O
information -X- _ O
of -X- _ O
ki -X- _ O
using -X- _ O
a -X- _ O
unidirectional -X- _ O
GRU: -X- _ O

In -X- _ O
other -X- _ O
words, -X- _ O
since -X- _ O
the -X- _ O
flow -X- _ O
of -X- _ O
conversation -X- _ O
changes -X- _ O
as -X- _ O
it -X- _ O
progresses, -X- _ O
the -X- _ O
effect -X- _ O
on -X- _ O
emotion -X- _ O
may -X- _ O
differ -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
distance -X- _ O
from -X- _ O
the -X- _ O
current -X- _ O
utterance. -X- _ O

The -X- _ O
tracking -X- _ O
method -X- _ O
assumes -X- _ O
that -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
all -X- _ O
previous -X- _ O
speaker -X- _ O
utterances -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
emotion -X- _ O
is -X- _ O
not -X- _ O
equal -X- _ O
and -X- _ O
varies -X- _ O
with -X- _ O
the -X- _ O
distance -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
utterance. -X- _ O

3.5.1 -X- _ O
Tracking -X- _ O
Method -X- _ O
We -X- _ O
use -X- _ O
ki -X- _ O
tracking -X- _ O
method -X- _ O
using -X- _ O
GRU. -X- _ O

Therefore, -X- _ O
we -X- _ O
assume -X- _ O
that -X- _ O
utterances -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
will -X- _ O
be -X- _ O
important -X- _ O
in -X- _ O
emotional -X- _ B-TaskName
recognition. -X- _ I-TaskName

In -X- _ O
many -X- _ O
dialogue -X- _ O
systems -X- _ O
(Zhang -X- _ O
et -X- _ O
al., -X- _ O
2018b; -X- _ O
Ma -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
it -X- _ O
is -X- _ O
known -X- _ O
that -X- _ O
utterances -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
are -X- _ O
important -X- _ O
for -X- _ O
response. -X- _ O

We -X- _ O
combine -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
to -X- _ O
predict -X- _ O
the -X- _ O
speaker’s -X- _ O
emotion. -X- _ O

3.5 -X- _ O
CoMPM: -X- _ B-MethodName
Combination -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName

Wo -X- _ O
and -X- _ O
Wp -X- _ O
are -X- _ O
linear -X- _ O
matrices. -X- _ O

A, -X- _ O
B, -X- _ O
and -X- _ O
C -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
participants -X- _ O
in -X- _ O
the -X- _ O
conversation, -X- _ O
where -X- _ O
sA -X- _ O
= -X- _ O
pu1 -X- _ O
= -X- _ O
pu3 -X- _ O
= -X- _ O
pu6, -X- _ O
sB -X- _ O
= -X- _ O
pu2 -X- _ O
= -X- _ O
pu5, -X- _ O
sC -X- _ O
= -X- _ O
pu3 -X- _ O
. -X- _ O

Since -X- _ O
<cls> -X- _ O
is -X- _ O
mostly -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
classifying -X- _ O
sentences, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
embedding -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
<cls> -X- _ O
token -X- _ O
as -X- _ O
a -X- _ O
vector -X- _ O
representing -X- _ O
the -X- _ O
utterance -X- _ O
as -X- _ O
follows: -X- _ O

If -X- _ O
the -X- _ O
speaker -X- _ O
has -X- _ O
never -X- _ O
appeared -X- _ O
before -X- _ O
the -X- _ O
current -X- _ O
turn, -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
is -X- _ O
considered -X- _ O
a -X- _ O
zero -X- _ O
vector. -X- _ O

Inspired -X- _ O
by -X- _ O
previous -X- _ O
studies -X- _ O
that -X- _ O
the -X- _ O
speaker’s -X- _ O
knowledge -X- _ O
helps -X- _ O
to -X- _ O
judge -X- _ O
emotions, -X- _ O
we -X- _ O
extract -X- _ O
and -X- _ O
track -X- _ O
pre-trained -X- _ O
memory -X- _ O
from -X- _ O
the -X- _ O
speaker’s -X- _ O
previous -X- _ O
utterances -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
emotions -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
utterance -X- _ O
ut. -X- _ O

Pre-trained -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
numerous -X- _ O
corpora -X- _ O
and -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
an -X- _ O
external -X- _ O
knowledge -X- _ O
base. -X- _ O

External -X- _ O
knowledge -X- _ O
is -X- _ O
known -X- _ O
to -X- _ O
play -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
understanding -X- _ O
conversation. -X- _ O

The -X- _ O
<cls> -X- _ O
token -X- _ O
is -X- _ O
concatenated -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
model -X- _ O
is -X- _ O
as -X- _ O
follows: -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
special -X- _ O
token -X- _ O
<cls> -X- _ O
to -X- _ O
predict -X- _ O
emotion. -X- _ O

RoBERTa -X- _ O
is -X- _ O
an -X- _ O
unsupervised -X- _ O
pre-trained -X- _ O
model -X- _ O
with -X- _ O
largescale -X- _ O
open-domain -X- _ O
corpora -X- _ O
of -X- _ O
unlabeled -X- _ O
text. -X- _ O

In -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks, -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
has -X- _ O
been -X- _ O
proven, -X- _ O
and -X- _ O
we -X- _ O
also -X- _ O
set -X- _ O
the -X- _ O
initial -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
RoBERTa -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

We -X- _ O
use -X- _ O
an -X- _ O
Transformer -X- _ O
encoder -X- _ O
as -X- _ O
a -X- _ O
context -X- _ O
model. -X- _ O

In -X- _ O
other -X- _ O
words, -X- _ O
the -X- _ O
same -X- _ O
special -X- _ O
token -X- _ O
appears -X- _ O
before -X- _ O
the -X- _ O
utterances -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
speaker. -X- _ O

A -X- _ O
special -X- _ O
token -X- _ O
<sP> -X- _ O
is -X- _ O
introduced -X- _ O
to -X- _ O
distinguish -X- _ O
participants -X- _ O
in -X- _ O
the -X- _ O
conversation -X- _ O
and -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
speaker’s -X- _ O
dependency -X- _ O
where -X- _ O
P -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
participants. -X- _ O

We -X- _ O
consider -X- _ O
multi-party -X- _ O
conversations -X- _ O
where -X- _ O
2 -X- _ O
or -X- _ O
more -X- _ O
speakers -X- _ O
are -X- _ O
involved. -X- _ O

u1, -X- _ O
{ -X- _ O

The -X- _ O
previous -X- _ O
utterances -X- _ O
are -X- _ O
and -X- _ O
e6 -X- _ O
is -X- _ O
predicted -X- _ O
while -X- _ O
considh6 -X- _ O
= -X- _ O
ering -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
u6 -X- _ O
and -X- _ O
h6. -X- _ O

The -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
how -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
emotion -X- _ O
of -X- _ O
u6 -X- _ O
uttered -X- _ O
by -X- _ O
sA, -X- _ O
given -X- _ O
a -X- _ O
conversation -X- _ O
of -X- _ O
three -X- _ O
participants -X- _ O
(sA, -X- _ O
sB, -X- _ O
sC). -X- _ O

3.3 -X- _ O
CoM: -X- _ B-MethodName
Context -X- _ B-MethodName
Embedding -X- _ I-MethodName
Module -X- _ I-MethodName
The -X- _ O
context -X- _ B-MethodName
embedding -X- _ I-MethodName
module -X- _ I-MethodName
predicts -X- _ O
et -X- _ O
by -X- _ O
considering -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
utterances -X- _ O
before -X- _ O
the -X- _ O
t-th -X- _ O
turn -X- _ O
as -X- _ O
the -X- _ O
dialogue -X- _ O
context. -X- _ O

The -X- _ O
combination -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
is -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.5. -X- _ O

If -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
are -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
architectures, -X- _ O
CoMPM -X- _ B-MethodName
is -X- _ O
trained -X- _ O
to -X- _ O
understand -X- _ O
each -X- _ O
other’s -X- _ O
representations -X- _ O

Therefore, -X- _ O
we -X- _ O
design -X- _ O
the -X- _ O
PM -X- _ B-MethodName
to -X- _ O
follow -X- _ O
CoM -X- _ B-MethodName
so -X- _ O
that -X- _ O
the -X- _ O
output -X- _ O
representations -X- _ O
of -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
can -X- _ O
mutually -X- _ O
understand -X- _ O
each -X- _ O
other. -X- _ O

If -X- _ O
the -X- _ O
CoM -X- _ B-MethodName
and -X- _ O
PM -X- _ B-MethodName
are -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
backbones, -X- _ O
we -X- _ O
consider -X- _ O
them -X- _ O
to -X- _ O
be -X- _ O
unaligned -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
each -X- _ O
other’s -X- _ O
output -X- _ O
representations. -X- _ O

The -X- _ O
second -X- _ O
one -X- _ O
is -X- _ O
PM -X- _ B-MethodName
that -X- _ O
leverages -X- _ O
only -X- _ O
the -X- _ O
speaker’s -X- _ O
previous -X- _ O
utterances, -X- _ O
through -X- _ O
which -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
reflect -X- _ O
the -X- _ O
speaker’s -X- _ O
knowledge. -X- _ O

Therefore, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
context -X- _ O
model -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
current -X- _ O
and -X- _ O
the -X- _ O
previous -X- _ O
utterances. -X- _ O

The -X- _ O
first -X- _ O
is -X- _ O
CoM -X- _ B-MethodName
which -X- _ O
catches -X- _ O
the -X- _ O
underlying -X- _ O
effect -X- _ O
of -X- _ O
all -X- _ O
previous -X- _ O
utterances -X- _ O
on -X- _ O
the -X- _ O
current -X- _ O
speaker’s -X- _ O
emotions. -X- _ O

Our -X- _ O
ERC -X- _ B-TaskName
neural -X- _ O
network -X- _ O
model -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
modules. -X- _ O

Figure -X- _ O
2 -X- _ O
shows -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
model. -X- _ O

3.2 -X- _ O
Model -X- _ O
Overview -X- _ O

We -X- _ O
also -X- _ O
experimented -X- _ O
with -X- _ O
a -X- _ O
sentiment -X- _ O
classification -X- _ O
dataset -X- _ O
which -X- _ O
provides -X- _ O
sentiment -X- _ O
labels -X- _ O
consisting -X- _ O
of -X- _ O
positive, -X- _ O
negative -X- _ O
and -X- _ O
neutral. -X- _ O

Emotions -X- _ O
are -X- _ O
labeled -X- _ O
as -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
predefined -X- _ O
classes -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
dataset, -X- _ O
and -X- _ O
the -X- _ O
emotions -X- _ O
we -X- _ O
experimented -X- _ O
with -X- _ O
are -X- _ O
either -X- _ O
6 -X- _ O
or -X- _ O
7. -X- _ O

The -X- _ O
ERC -X- _ B-TaskName
is -X- _ O
a -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
emotion -X- _ O
et -X- _ O
of -X- _ O
ut, -X- _ O
the -X- _ O
utterance -X- _ O
of -X- _ O
the -X- _ O
t-th -X- _ O
turn, -X- _ O
given -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
ht -X- _ O
= -X- _ O
. -X- _ O

While -X- _ O
pui -X- _ O
and -X- _ O
puj -X- _ O
(i -X- _ O
= -X- _ O
j) -X- _ O
can -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
speaker, -X- _ O
the -X- _ O
minimum -X- _ O
number -X- _ O
of -X- _ O
the -X- _ O
unique -X- _ O
conversation -X- _ O
participants -X- _ O
should -X- _ O
be -X- _ O
2 -X- _ O
or -X- _ O
more. -X- _ O

ui -X- _ O
is -X- _ O
the -X- _ O
utterance -X- _ O
which -X- _ O
the -X- _ O
speaker -X- _ O
pui -X- _ O
uttered, -X- _ O
where -X- _ O
pui -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
conversation -X- _ O
participants. -X- _ O

In -X- _ O
a -X- _ O
conversation, -X- _ O
M -X- _ O
sequential -X- _ O
utterances -X- _ O
are -X- _ O
given -X- _ O
as -X- _ O
[(u1, -X- _ O
pu1), -X- _ O
(u2, -X- _ O
pu2), -X- _ O
..., -X- _ O
(uM -X- _ O
, -X- _ O
puM -X- _ O
)]. -X- _ O

3.1 -X- _ O
Problem -X- _ O
Statement -X- _ O

3 -X- _ O
Approach -X- _ O

EDA -X- _ O
(Bothe -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
expands -X- _ O
the -X- _ O
multi-modal -X- _ O
emotion -X- _ O
datasets -X- _ O
by -X- _ O
extracting -X- _ O
dialog -X- _ O
acts -X- _ O
from -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
IEMOCAP -X- _ B-DatasetName
and -X- _ O
finds -X- _ O
out -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
correlation -X- _ O
between -X- _ O
dialogue -X- _ O
acts -X- _ O
and -X- _ O
emotion -X- _ O
labels. -X- _ O

Liu -X- _ O
et -X- _ O
al. -X- _ O
(2020) -X- _ O
reports -X- _ O
that -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
external -X- _ O
knowledge -X- _ O
makes -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
classify -X- _ O
implicit -X- _ O
emotions -X- _ O
from -X- _ O
the -X- _ O
conversation -X- _ O
history. -X- _ O

Zhou -X- _ O
et -X- _ O
al. -X- _ O
(2018); -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O
(2018a) -X- _ O
shows -X- _ O
that -X- _ O
commonsense -X- _ O
knowledge -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
understanding -X- _ O
conversations -X- _ O
and -X- _ O
generating -X- _ O
appropriate -X- _ O
responses. -X- _ O

dyadic-party -X- _ O
dialogues, -X- _ O
therefore -X- _ O
have -X- _ O
more -X- _ O
conditions -X- _ O
to -X- _ O
consider -X- _ O
and -X- _ O
result -X- _ O
in -X- _ O
poor -X- _ O
performance. -X- _ O

In -X- _ O
general, -X- _ O
the -X- _ O
multi-party -X- _ O
conversations -X- _ O
have -X- _ O
higher -X- _ O
speaker -X- _ O
dependency -X- _ O
than -X- _ O
the -X- _ O

However, -X- _ O
as -X- _ O
the -X- _ O
multi-party -X- _ O
conversation -X- _ O
datasets -X- _ O
including -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
EmoryNLP -X- _ B-DatasetName
have -X- _ O
become -X- _ O
available, -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
recent -X- _ O
research -X- _ O
is -X- _ O
being -X- _ O
conducted -X- _ O
on -X- _ O
multi-party -X- _ O
dialogues -X- _ O
such -X- _ O
as -X- _ O
Zhang -X- _ O
et -X- _ O
al. -X- _ O

; -X- _ O
Zadeh -X- _ O
et -X- _ O
al. -X- _ O
(2017); -X- _ O
Majumder -X- _ O
et -X- _ O
al. -X- _ O
(2019), -X- _ O
most -X- _ O
works -X- _ O
focused -X- _ O
on -X- _ O
dyadic-party -X- _ O
conversation. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
design -X- _ O
and -X- _ O
introduce -X- _ O
a -X- _ O
text-based -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
system -X- _ O
using -X- _ O
neural -X- _ O
networks. -X- _ O

Multimodal -X- _ O
information -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
given -X- _ O
in -X- _ O
most -X- _ O
social -X- _ O
media, -X- _ O
especially -X- _ O
in -X- _ O
chatbot -X- _ O
systems -X- _ O
where -X- _ O
they -X- _ O
are -X- _ O
mainly -X- _ O
composed -X- _ O
of -X- _ O
text-based -X- _ O
systems. -X- _ O

MELD -X- _ B-DatasetName
and -X- _ O
ICON -X- _ O
(Hazarika -X- _ O
et -X- _ O
al., -X- _ O
2018a) -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
more -X- _ O
multi-modal -X- _ O
information -X- _ O
is -X- _ O
used, -X- _ O
the -X- _ O
better -X- _ O
the -X- _ O
performance -X- _ O
and -X- _ O
the -X- _ O
text -X- _ O
information -X- _ O
plays -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
role. -X- _ O

Datcu -X- _ O
and -X- _ O
Rothkrantz -X- _ O
(2014) -X- _ O
uses -X- _ O
speech -X- _ O
and -X- _ O
visual -X- _ O
information -X- _ O
to -X- _ O
recognize -X- _ O
emotions, -X- _ O
and -X- _ O
(Alm -X- _ O
et -X- _ O
al., -X- _ O
2005) -X- _ O
attempts -X- _ O
to -X- _ O
recognize -X- _ O
emotions -X- _ O
based -X- _ O
on -X- _ O
text -X- _ O
information. -X- _ O

The -X- _ O
multi-modal -X- _ O
data -X- _ O
such -X- _ O
as -X- _ O
MELD -X- _ B-DatasetName
and -X- _ O
IEMOCAP -X- _ B-DatasetName
are -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
available -X- _ O
standard -X- _ O
datasets -X- _ O
for -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
and -X- _ O
they -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
text, -X- _ O
speech -X- _ O
and -X- _ O
vision-based -X- _ O
data. -X- _ O

In -X- _ O
addition, -X- _ O
Ekman -X- _ O
explains -X- _ O
that -X- _ O
a -X- _ O
multimodal -X- _ O
view -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
multiple -X- _ O
emotions -X- _ O
recognition. -X- _ O

Ekman -X- _ O
(Ekman, -X- _ O
1992) -X- _ O
constructs -X- _ O
taxonomy -X- _ O
of -X- _ O
six -X- _ O
common -X- _ O
emotions -X- _ O
(Joy, -X- _ O
Sadness, -X- _ O
Fear, -X- _ O
Anger, -X- _ O
Surprise, -X- _ O
and -X- _ O
Disgust) -X- _ O
from -X- _ O
human -X- _ O
facial -X- _ O
expressions. -X- _ O

ToDKAT -X- _ B-MethodName
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
improves -X- _ O
performance -X- _ O
by -X- _ O
combining -X- _ O
commonsense -X- _ O
knowledge -X- _ O
using -X- _ O
COMET -X- _ O
and -X- _ O
topic -X- _ O
discovery -X- _ O
using -X- _ O
VHRED -X- _ O
(Serban -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
to -X- _ O
the -X- _ O
model. -X- _ O

ATOMIC -X- _ O
has -X- _ O
9 -X- _ O
sentence -X- _ O
relation -X- _ O
types -X- _ O
with -X- _ O
inferential -X- _ O
if-then -X- _ O
commonsense -X- _ O
knowledge -X- _ O
expressed -X- _ O
in -X- _ O
text. -X- _ O

Commonsense -X- _ O
knowledge -X- _ O
feature -X- _ O
is -X- _ O
extracted -X- _ O
and -X- _ O
leveraged -X- _ O
with -X- _ O
COMET -X- _ B-MethodName
(Bosselut -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
trained -X- _ O
with -X- _ O
ATOMIC -X- _ O
(The -X- _ O
Atlas -X- _ O
of -X- _ O
Machine -X- _ O
Commonsense) -X- _ O
(Sap -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

COSMIC -X- _ B-MethodName
(Ghosal -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
and -X- _ O
Psychological -X- _ B-MethodName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2021) -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
by -X- _ O
extracting -X- _ O
commonsense -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
utterances. -X- _ O

NRC_VAD -X- _ O
Lexicon -X- _ O
has -X- _ O
human -X- _ O
ratings -X- _ O
of -X- _ O
valence, -X- _ O
arousal, -X- _ O
and -X- _ O
dominance -X- _ O
for -X- _ O
more -X- _ O
than -X- _ O
20,000 -X- _ O
English -X- _ O
words. -X- _ O

ConceptNet -X- _ O
is -X- _ O
a -X- _ O
knowledge -X- _ O
graph -X- _ O
that -X- _ O
connects -X- _ O
words -X- _ O
and -X- _ O
phrases -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
using -X- _ O
labeled -X- _ O
edges. -X- _ O

KET -X- _ B-MethodName
(Zhong -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
external -X- _ O
knowledge -X- _ O
based -X- _ O
on -X- _ O
ConceptNet -X- _ O
(Speer -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
and -X- _ O
emotion -X- _ O
lex -X- _ O

Many -X- _ O
recent -X- _ O
studies -X- _ O
use -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
performance. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

Further -X- _ O
experiments -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
approach -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
other -X- _ O
languages -X- _ O
and -X- _ O
show -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CoMPM -X- _ B-MethodName
when -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
data -X- _ O
is -X- _ O
limited. -X- _ O

We -X- _ O
perform -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
on -X- _ O
each -X- _ O
module -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
proposed -X- _ O
approach -X- _ O
is -X- _ O
effective. -X- _ O

CoMPM -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
second -X- _ O
performance -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
compared -X- _ O
to -X- _ O
all -X- _ O
previous -X- _ O
systems. -X- _ O

Multi-party -X- _ O
datasets -X- _ O
are -X- _ O
MELD -X- _ B-DatasetName
(Poria -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
EmoryNLP -X- _ B-DatasetName
(Zahiri -X- _ O
and -X- _ O
Choi, -X- _ O
2018), -X- _ O
and -X- _ O
dyadic -X- _ O
datasets -X- _ O
are -X- _ O
IEMOCAP -X- _ B-DatasetName
(Busso -X- _ O
et -X- _ O
al., -X- _ O
2008) -X- _ O
and -X- _ O
DailyDialog -X- _ B-DatasetName
(Li -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

We -X- _ O
experiment -X- _ O
on -X- _ O
4 -X- _ O
different -X- _ O
English -X- _ O
ERC -X- _ B-TaskName
datasets. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
PM -X- _ B-MethodName
to -X- _ O
help -X- _ O
predict -X- _ O
the -X- _ O
emotion -X- _ O
of -X- _ O
the -X- _ O
speaker -X- _ O
by -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
speaker’s -X- _ O
linguistic -X- _ O
preferences -X- _ O
and -X- _ O
characteristics. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
as -X- _ O
the -X- _ O
memory -X- _ O
embedding -X- _ O
where -X- _ O
the -X- _ O
utterances -X- _ O
are -X- _ O
passed -X- _ O
into -X- _ O
the -X- _ O
language -X- _ O
model. -X- _ O

The -X- _ O
second -X- _ O
is -X- _ O
a -X- _ O
pre-trained -X- _ B-MethodName
memory -X- _ I-MethodName
module -X- _ I-MethodName
(PM) -X- _ B-MethodName
that -X- _ O
extracts -X- _ O
memory -X- _ O
from -X- _ O
utterances. -X- _ O

(1) -X- _ O
The -X- _ O
first -X- _ O
is -X- _ O
a -X- _ O
context -X- _ B-MethodName
embedding -X- _ I-MethodName
module -X- _ I-MethodName
(CoM) -X- _ B-MethodName
that -X- _ O
reflects -X- _ O
all -X- _ O
previous -X- _ O
utterances -X- _ O
as -X- _ O
context. -X- _ O

CoM -X- _ B-MethodName
is -X- _ O
an -X- _ O
auto-regressive -X- _ O
model -X- _ O
that -X- _ O
predicts -X- _ O
the -X- _ O
current -X- _ O
emotion -X- _ O
through -X- _ O
attention -X- _ O
between -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
of -X- _ O
the -X- _ O
conversation -X- _ O
and -X- _ O
the -X- _ O
current -X- _ O
utterance. -X- _ O

CoMPM, -X- _ B-MethodName
introduced -X- _ O
in -X- _ O
this -X- _ O
paper, -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
modules -X- _ O
that -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
previous -X- _ O
utterances -X- _ O
in -X- _ O
dialogue. -X- _ O

Based -X- _ O
on -X- _ O
these -X- _ O
studies, -X- _ O
we -X- _ O
eliminate -X- _ O
the -X- _ O
dependence -X- _ O
on -X- _ O
structured -X- _ O
external -X- _ O
data -X- _ O
used -X- _ O
in -X- _ O
cutting-edge -X- _ O
systems -X- _ O
and -X- _ O
use -X- _ O
a -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
extractor -X- _ O
of -X- _ O
knowledge. -X- _ O

Petroni -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
introduces -X- _ O
that -X- _ O
these -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
knowledge -X- _ O
bases -X- _ O
and -X- _ O
have -X- _ O
many -X- _ O
advantages -X- _ O
over -X- _ O
the -X- _ O
structured -X- _ O
knowledge -X- _ O
bases. -X- _ O

Since -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
by -X- _ O
unsupervised -X- _ O
learning, -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
relatively -X- _ O
usable -X- _ O
approaches -X- _ O
regardless -X- _ O
of -X- _ O
language -X- _ O
types. -X- _ O

In -X- _ O
recent -X- _ O
NLP -X- _ O
studies, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
language -X- _ O
model, -X- _ O
it -X- _ O
has -X- _ O
already -X- _ O
been -X- _ O
developed -X- _ O
in -X- _ O
many -X- _ O
countries. -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
previous -X- _ O
methods -X- _ O
in -X- _ O
languages -X- _ O
of -X- _ O
other -X- _ O
countries, -X- _ O
it -X- _ O
is -X- _ O
expensive -X- _ O
and -X- _ O
difficult -X- _ O
to -X- _ O
utilize -X- _ O
because -X- _ O
external -X- _ O
knowledge -X- _ O
data -X- _ O
must -X- _ O
be -X- _ O
newly -X- _ O
constructed. -X- _ O

Many -X- _ O
recent -X- _ O
studies -X- _ O
use -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
ERC -X- _ B-TaskName
performance. -X- _ O

AGHMN -X- _ O
(Jiao -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
considers -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
through -X- _ O
memory -X- _ O
summarizing -X- _ O
using -X- _ O
GRU -X- _ O
with -X- _ O
attention. -X- _ O

Representatively, -X- _ O
DialogueRNN -X- _ O
(Majumder -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
recognizes -X- _ O
the -X- _ O
present -X- _ O
emotion -X- _ O
by -X- _ O
tracking -X- _ O
context -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
and -X- _ O
the -X- _ O
speaker’s -X- _ O
emotion. -X- _ O

Therefore, -X- _ O
recent -X- _ O
studies -X- _ O
are -X- _ O
attempting -X- _ O
to -X- _ O
recognize -X- _ O
emotions -X- _ O
while -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
previous -X- _ O
utterances. -X- _ O

Like -X- _ O
the -X- _ O
previous -X- _ O
studies -X- _ O
(Ghosal -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
utterance-level -X- _ O
emotion -X- _ O
recognition, -X- _ O
which -X- _ O
does -X- _ O
not -X- _ O
consider -X- _ O
the -X- _ O
previous -X- _ O
utterance, -X- _ O
have -X- _ O
limitations -X- _ O
and -X- _ O
experiments -X- _ O
result -X- _ O
in -X- _ O
poor -X- _ O
performances. -X- _ O

If -X- _ O
the -X- _ O
system -X- _ O
does -X- _ O
not -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
previous -X- _ O
utterances, -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
properly -X- _ O
recognize -X- _ O
emotions. -X- _ O

The -X- _ O
emotion -X- _ O
of -X- _ O
speaker -X- _ O
B’s -X- _ O
utterance -X- _ O
("How’d -X- _ O
you -X- _ O
get -X- _ O
to -X- _ O
that?") -X- _ O
is -X- _ O
angry. -X- _ O

Figure -X- _ O
1 -X- _ O
is -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
a -X- _ O
conversation -X- _ O
in -X- _ O
which -X- _ O
two -X- _ O
speakers -X- _ O
are -X- _ O
angry -X- _ O
at -X- _ O
each -X- _ O
other. -X- _ O

As -X- _ O
these -X- _ O
interactive -X- _ O
machines -X- _ O
increase, -X- _ O
the -X- _ O
ERC -X- _ O
module -X- _ O
plays -X- _ O
an -X- _ O
increasingly -X- _ O
important -X- _ O
role. -X- _ O

In -X- _ O
addition, -X- _ O
emotion -X- _ O
recognition -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
used -X- _ O
for -X- _ O
opinion -X- _ O
mining, -X- _ O
recommender -X- _ O
systems, -X- _ O
and -X- _ O
healthcare -X- _ O
systems -X- _ O
where -X- _ O
it -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
service -X- _ O
qualities -X- _ O
by -X- _ O
providing -X- _ O
personalized -X- _ O
results. -X- _ O

As -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
applications -X- _ O
such -X- _ O
as -X- _ O
interactive -X- _ O
chatbots -X- _ O
or -X- _ O
social -X- _ O
media -X- _ O
that -X- _ O
are -X- _ O
used -X- _ O
by -X- _ O
many -X- _ O
users -X- _ O
has -X- _ O
recently -X- _ O
increased -X- _ O
dramatically, -X- _ O
Emotion -X- _ B-TaskName
Recognition -X- _ I-TaskName
in -X- _ I-TaskName
Conversation -X- _ I-TaskName
(ERC) -X- _ B-TaskName
plays -X- _ O
a -X- _ O
more -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing, -X- _ O
and -X- _ O
as -X- _ O
a -X- _ O
proof, -X- _ O
a -X- _ O
lot -X- _ O
of -X- _ O
research -X- _ O
(Poria -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Zhang -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Ghosal -X- _ O
et -X- _ O
al., -X- _ O
2020; -X- _ O
Jiao -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
has -X- _ O
been -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
task. -X- _ O

Introduction -X- _ O

Our -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
on -X- _ O
github -X- _ O
1. -X- _ O

In -X- _ O
addition, -X- _ O
our -X- _ O
method -X- _ O
shows -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
other -X- _ O
languages -X- _ O
because -X- _ O
structured -X- _ O
knowledge -X- _ O
is -X- _ O
not -X- _ O
required, -X- _ O
unlike -X- _ O
previous -X- _ O
methods. -X- _ O

CoMPM -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
first -X- _ O
or -X- _ O
second -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
data -X- _ O
and -X- _ O
is -X- _ O
state-of-the-art -X- _ O
among -X- _ O
systems -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
leverage -X- _ O
structured -X- _ O
data. -X- _ O

We -X- _ O
introduce -X- _ O
CoMPM, -X- _ B-MethodName
which -X- _ O
combines -X- _ O
the -X- _ O
speaker’s -X- _ O
pre-trained -X- _ O
memory -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
model, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
significantly -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
context -X- _ O
model. -X- _ O

Therefore, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
pre-trained -X- _ O
memory -X- _ O
using -X- _ O
the -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
as -X- _ O
an -X- _ O
extractor -X- _ O
of -X- _ O
external -X- _ O
knowledge. -X- _ O

However, -X- _ O
structured -X- _ O
data -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
access -X- _ O
in -X- _ O
non-English -X- _ O
languages, -X- _ O
making -X- _ O
it -X- _ O
difficult -X- _ O
to -X- _ O
extend -X- _ O
to -X- _ O
other -X- _ O
languages. -X- _ O

Many -X- _ O
recent -X- _ O
approaches -X- _ O
show -X- _ O
performance -X- _ O
improvement -X- _ O
by -X- _ O
combining -X- _ O
knowledge -X- _ O
into -X- _ O
modules -X- _ O
learned -X- _ O
from -X- _ O
external -X- _ O
structured -X- _ O
data. -X- _ O

Since -X- _ O
emotion -X- _ B-TaskName
recognition -X- _ I-TaskName
in -X- _ I-TaskName
conversation -X- _ I-TaskName
is -X- _ O
inaccurate -X- _ O
if -X- _ O
the -X- _ O
previous -X- _ O
utterances -X- _ O
are -X- _ O
not -X- _ O
taken -X- _ O
into -X- _ O
account, -X- _ O
many -X- _ O
studies -X- _ O
reflect -X- _ O
the -X- _ O
dialogue -X- _ O
context -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performances. -X- _ O

If -X- _ O
the -X- _ O
machine-generated -X- _ O
sentences -X- _ O
reflect -X- _ O
emotion, -X- _ O
more -X- _ O
human-like -X- _ O
sympathetic -X- _ O
conversations -X- _ O
are -X- _ O
possible. -X- _ O

As -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
interactive -X- _ O
machines -X- _ O
grow, -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
Emotion -X- _ B-TaskName
Recognition -X- _ I-TaskName
in -X- _ I-TaskName
Conversation -X- _ I-TaskName
(ERC) -X- _ B-TaskName
became -X- _ O
more -X- _ O
important. -X- _ O

Abstract -X- _ O

CoMPM: -X- _ B-MethodName
Context -X- _ O
Modeling -X- _ O
with -X- _ O
Speaker’s -X- _ O
Pre-trained -X- _ O
Memory -X- _ O
Tracking -X- _ O
for -X- _ O
Emotion -X- _ B-TaskName
Recognition -X- _ I-TaskName
in -X- _ I-TaskName
Conversation -X- _ I-TaskName

-DOCSTART- -X- O
Figure -X- _ O
4b -X- _ O
demonstrates -X- _ O
a -X- _ O
termination -X- _ O
of -X- _ O
stock -X- _ O
sale -X- _ O

Herein, -X- _ O
we -X- _ O
visualize -X- _ O
the -X- _ O
heatmaps -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
to -X- _ O
investigate -X- _ O
how -X- _ O
to -X- _ O
assign -X- _ O
attention -X- _ O
weights -X- _ O
to -X- _ O
text. -X- _ O

A.4 -X- _ O
Case -X- _ O
Study: -X- _ O
Visualization -X- _ O
of -X- _ O
Attention -X- _ O

We -X- _ O
summarize -X- _ O
the -X- _ O
hyperparameters -X- _ O
in -X- _ O
Table -X- _ O
5. -X- _ O

In -X- _ O
addition, -X- _ O
the -X- _ O
coefficient -X- _ B-HyperparameterName
λ -X- _ B-HyperparameterName
of -X- _ O
the -X- _ O
regularization -X- _ O
term -X- _ O
was -X- _ O
set -X- _ O
as -X- _ O
0.0001. -X- _ B-HyperparameterValue

We -X- _ O
used -X- _ O
the -X- _ O
Adam -X- _ O
optimizer -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
and -X- _ O
0.001 -X- _ B-HyperparameterValue
in -X- _ O
the -X- _ O
inner -X- _ O
and -X- _ O
outer -X- _ O
updates, -X- _ O
that -X- _ O
is, -X- _ O
α -X- _ B-HyperparameterName
and -X- _ O
β -X- _ B-HyperparameterName
in -X- _ O
, -X- _ O
respectively. -X- _ O

After -X- _ O
that, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
adapted -X- _ O
task -X- _ O
model -X- _ O
is -X- _ O
obtained -X- _ O
using -X- _ O
queries. -X- _ O

In -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
process, -X- _ O
we -X- _ O
val -X- _ O
and -X- _ O
sampled -X- _ O
30 -X- _ O
tasks -X- _ O
with -X- _ O
15 -X- _ O
queries -X- _ O
from -X- _ O
test, -X- _ O
and -X- _ O
only -X- _ O
performed -X- _ O
task -X- _ O
adaptation -X- _ O
using -X- _ O
S -X- _ O
K-shots. -X- _ O

During -X- _ O
the -X- _ O
meta-training -X- _ O
process, -X- _ O
we -X- _ O
sampled -X- _ O
four -X- _ O
tasks -X- _ O
with -X- _ O
15 -X- _ O
queries -X- _ O
tr, -X- _ O
and -X- _ O
it -X- _ O
leads -X- _ O
to -X- _ O
performing -X- _ O
task -X- _ O
adaptation -X- _ O
from -X- _ O
four -X- _ O
times -X- _ O
per -X- _ O
each -X- _ O
meta-optimization -X- _ O
update -X- _ O
and -X- _ O
early -X- _ O
stop -X- _ O
when -X- _ O
the -X- _ O
validation -X- _ O
loss -X- _ O
fails -X- _ O
to -X- _ O
improve -X- _ O
for -X- _ O
20 -X- _ O
steps. -X- _ O

In -X- _ O
our -X- _ O
work, -X- _ O
we -X- _ O
train -X- _ O
all -X- _ O
experiments -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
NVIDIA -X- _ O
A100 -X- _ O
32G -X- _ O
GPU. -X- _ O

A.3 -X- _ O
Training -X- _ O
Details -X- _ O
and -X- _ O
Hyperparameter -X- _ O

Table -X- _ O
3 -X- _ O
summarizes -X- _ O
the -X- _ O
above -X- _ O
model -X- _ O
parameters. -X- _ O

We -X- _ O
set -X- _ O
the -X- _ O
size -X- _ O
to -X- _ O
150 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
meta-attention-aspects -X- _ O
dictionary, -X- _ O
and -X- _ O
importantly -X- _ O
fixed -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
top-k -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
aspects -X- _ I-HyperparameterName
to -X- _ O
20. -X- _ B-HyperparameterValue

For -X- _ O
each -X- _ O
task -X- _ O
classifier, -X- _ O
that -X- _ O
is, -X- _ O
fθ′τi -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
designed -X- _ O
as -X- _ O
single-layer -X- _ O
fully -X- _ O
connected -X- _ O
neural -X- _ O
network. -X- _ O

The -X- _ O
gating -X- _ O
network, -X- _ O
Wg -X- _ O
is -X- _ O
linear -X- _ O
transformation -X- _ O
and -X- _ O
its -X- _ O
size -X- _ O
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
meta-attention-aspects. -X- _ I-HyperparameterName

As -X- _ O
shown -X- _ O
in -X- _ O
these -X- _ O
cases, -X- _ O
LEA -X- _ B-MethodName
properly -X- _ O
captures -X- _ O
important -X- _ O
words -X- _ O
under -X- _ O
a -X- _ O
certain -X- _ O
topic -X- _ O
and -X- _ O
assigns -X- _ O
attention -X- _ O
weights -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
text. -X- _ O

Figure -X- _ O
4d -X- _ O
talks -X- _ O
about -X- _ O
the -X- _ O
authority -X- _ O
of -X- _ O
platinum -X- _ O
and -X- _ O
gold -X- _ O
coins -X- _ O
under -X- _ O
the -X- _ O
Economics -X- _ O
topic, -X- _ O
and -X- _ O
the -X- _ O
words -X- _ O
“US,” -X- _ O
“Mint,” -X- _ O
“authority,” -X- _ O
“gold,” -X- _ O
“platinum,” -X- _ O
and -X- _ O
“coin” -X- _ O
are -X- _ O
hence -X- _ O
highlighted. -X- _ O

Figure -X- _ O
4c -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
Turkish -X- _ O
market -X- _ O
was -X- _ O
closed -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
Market -X- _ O
topic, -X- _ O
and -X- _ O
its -X- _ O
relevant -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
“Turkish,” -X- _ O
“markets,” -X- _ O
and -X- _ O
“closed” -X- _ O
are -X- _ O
highly -X- _ O
attended -X- _ O
as -X- _ O
expected. -X- _ O

These -X- _ O
were -X- _ O
extracted -X- _ O
under -X- _ O
the -X- _ O
Corporate -X- _ O
and -X- _ O
Industrial -X- _ O
topic -X- _ O
in -X- _ O
the -X- _ O
RCV-1 -X- _ B-DatasetName
dataset -X- _ O
and -X- _ O
some -X- _ O
seminal -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
“agreement”, -X- _ O
“contractual” -X- _ O
and -X- _ O
“receivership” -X- _ O
are -X- _ O
highlighted -X- _ O
to -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
topic. -X- _ O

The -X- _ O
texts -X- _ O
in -X- _ O
(a) -X- _ O
and -X- _ O
(b) -X- _ O
are -X- _ O
different -X- _ O
samples -X- _ O
under -X- _ O
a -X- _ O
topic -X- _ O
Corporate -X- _ O
and -X- _ O
Industrial. -X- _ O

The -X- _ O
relation -X- _ O
network, -X- _ O
fθr -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
two-layers -X- _ B-HyperparameterValue
neural -X- _ O
network -X- _ O
with -X- _ O
ReLU -X- _ O
activation -X- _ O
and -X- _ O
input -X- _ O
size -X- _ O
is -X- _ O
two -X- _ O
times -X- _ O
of -X- _ O
encoder -X- _ O
outputs -X- _ O
and -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
output -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
meta-attention-aspects, -X- _ I-HyperparameterName
i.e., -X- _ O
150. -X- _ B-HyperparameterValue

In -X- _ O
the -X- _ O
encoding -X- _ O
process -X- _ O
of -X- _ O
our -X- _ O
experiments, -X- _ O
the -X- _ O
768-dimensional -X- _ B-HyperparameterValue
[CLS] -X- _ O
vector, -X- _ O
which -X- _ O
is -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
BERTbase-uncased, -X- _ O
is -X- _ O
linearly -X- _ O
transformed -X- _ O
through -X- _ O
fθe -X- _ O
into -X- _ O
a -X- _ O
300-dimensional -X- _ B-HyperparameterValue
vector. -X- _ O

We -X- _ O
share -X- _ O
the -X- _ O
breakdown -X- _ O
of -X- _ O
LEA’s -X- _ B-MethodName
implementation. -X- _ O

A.2 -X- _ O
Implementation -X- _ O
Details -X- _ O

We -X- _ O
summarize -X- _ O
the -X- _ O
above -X- _ O
information -X- _ O
in -X- _ O
Table -X- _ O
4. -X- _ O

For -X- _ O
the -X- _ O
20 -X- _ B-DatasetName
Newsgroup -X- _ I-DatasetName
dataset, -X- _ O
we -X- _ O
randomly -X- _ O
selected -X- _ O
20 -X- _ O
topic -X- _ O
classes, -X- _ O
and -X- _ O
the -X- _ O
metatraining -X- _ O
set, -X- _ O
meta-validation -X- _ O
set, -X- _ O
and -X- _ O
meta-test -X- _ O
set -X- _ O
contained -X- _ O
10, -X- _ B-HyperparameterValue
5, -X- _ I-HyperparameterValue
and -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
disjoint -X- _ O
classes, -X- _ O
respectively. -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
Amazon -X- _ B-DatasetName
product -X- _ I-DatasetName
data -X- _ I-DatasetName
is -X- _ O
divided -X- _ O
into -X- _ O
15, -X- _ B-HyperparameterValue
and -X- _ I-HyperparameterValue
9 -X- _ I-HyperparameterValue
disjoint -X- _ O
classes -X- _ O
for -X- _ O
meta-training -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
and -X- _ O
meta-validation -X- _ O
set -X- _ O
is -X- _ O
not -X- _ O
used -X- _ O
in -X- _ O
Amazon -X- _ B-DatasetName
product -X- _ I-DatasetName
data. -X- _ I-DatasetName

In -X- _ O
Amazon -X- _ B-DatasetName
product -X- _ I-DatasetName
data, -X- _ I-DatasetName
we -X- _ O
split -X- _ O
the -X- _ O
data -X- _ O
using -X- _ O
rules -X- _ O
in -X- _ O
(Bao -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
and -X- _ O
its -X- _ O
training -X- _ O
and -X- _ O

In -X- _ O
terms -X- _ O
of -X- _ O
Reuters-21678, -X- _ B-DatasetName
15, -X- _ B-HyperparameterValue
5, -X- _ I-HyperparameterValue
and -X- _ I-HyperparameterValue
11 -X- _ I-HyperparameterValue
disjoint -X- _ O
classes -X- _ O
are -X- _ O
used -X- _ O
for -X- _ O
meta-training/validation/test -X- _ B-HyperparameterName
sets -X- _ O
and -X- _ O
37, -X- _ B-HyperparameterValue
10, -X- _ I-HyperparameterValue
and -X- _ I-HyperparameterValue
24 -X- _ I-HyperparameterValue
disjoint -X- _ O
classes -X- _ O
for -X- _ O
RCV-1. -X- _ B-DatasetName

Hence, -X- _ O
the -X- _ O
Huffpost -X- _ B-DatasetName
headline -X- _ I-DatasetName
is -X- _ O
divided -X- _ O
into -X- _ O
20, -X- _ B-HyperparameterValue
5, -X- _ I-HyperparameterValue
and -X- _ I-HyperparameterValue
16 -X- _ I-HyperparameterValue
disjoint -X- _ O
classes -X- _ O
for -X- _ O
meta-training, -X- _ O
validation, -X- _ O
and -X- _ O
test -X- _ O
sets. -X- _ O

In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
split -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
classes -X- _ I-HyperparameterName
as -X- _ O
in -X- _ O
(Bao -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
for -X- _ O
the -X- _ O
Huffpost -X- _ B-DatasetName
headline(Misra -X- _ I-DatasetName
and -X- _ O
Grover, -X- _ O
2021), -X- _ O
Reuters-21578(Lewis., -X- _ B-DatasetName
1997), -X- _ O
and -X- _ O
RCV-1(Lewis -X- _ B-DatasetName
et -X- _ O
al., -X- _ O
2004) -X- _ O
datasets. -X- _ O

To -X- _ O
train -X- _ O
and -X- _ O
evaluate -X- _ O
the -X- _ O
models, -X- _ O
we -X- _ O
divided -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
aforementioned -X- _ O
datasets -X- _ O
into -X- _ O
a -X- _ O
metaval), -X- _ O
and -X- _ O
training -X- _ O
set -X- _ O
( -X- _ O
S -X- _ O
test) -X- _ O
as -X- _ O
disjoint -X- _ O
sets -X- _ O
of -X- _ O
classes -X- _ O
meta-test -X- _ O
set -X- _ O
( -X- _ O
within -X- _ O
the -X- _ O
experimental -X- _ O
setting. -X- _ O

Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
match -X- _ O
reviews -X- _ O
to -X- _ O
their -X- _ O
own -X- _ O
corresponding -X- _ O
product -X- _ O
categories. -X- _ O

Amazon -X- _ B-DatasetName
data -X- _ I-DatasetName
is -X- _ O
a -X- _ O
real-world -X- _ O
dataset -X- _ O
collected -X- _ O
from -X- _ O
Amazon.com -X- _ O
as -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
customer -X- _ O
reviews -X- _ O
from -X- _ O
24 -X- _ O
types -X- _ O
of -X- _ O
product -X- _ O
categories(He -X- _ O
and -X- _ O
McAuley, -X- _ O
2016). -X- _ O

RCV-1 -X- _ B-DatasetName
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
newswire -X- _ O
stories -X- _ O
published -X- _ O
by -X- _ O
Reuters -X- _ O
journalists -X- _ O
from -X- _ O
1996 -X- _ O
to -X- _ O
1997 -X- _ O
(Lewis -X- _ O
et -X- _ O
al., -X- _ O
2004) -X- _ O
and -X- _ O
comprises -X- _ O
71 -X- _ O
topic -X- _ O
classes. -X- _ O

In -X- _ O
addition, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
ApteMod -X- _ O
version -X- _ O
and -X- _ O
discard -X- _ O
documents -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
label -X- _ O
to -X- _ O
avoid -X- _ O
ambiguity, -X- _ O
and -X- _ O
thus -X- _ O
31 -X- _ O
classes -X- _ O
remain. -X- _ O

Reuters-21578 -X- _ B-DatasetName
is -X- _ O
composed -X- _ O
of -X- _ O
documents -X- _ O
that -X- _ O
appeared -X- _ O
on -X- _ O
the -X- _ O
Reuters -X- _ O
newswire -X- _ O
in -X- _ O
1987 -X- _ O
(Lewis., -X- _ O
1997). -X- _ O

It -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
41 -X- _ O
topics. -X- _ O

Huffpost -X- _ B-DatasetName
Headlines -X- _ I-DatasetName
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
news -X- _ O
headlines -X- _ O
published -X- _ O
in -X- _ O
the -X- _ O
Huffington -X- _ O
Post -X- _ O
from -X- _ O
2012 -X- _ O
to -X- _ O
2018 -X- _ O
(Misra -X- _ O
and -X- _ O
Grover, -X- _ O
2021). -X- _ O

newsgroup -X- _ O
posts -X- _ O
for -X- _ O
20 -X- _ O
topics -X- _ O
(Lang, -X- _ O
1995). -X- _ O

20 -X- _ B-DatasetName
Newsgroups -X- _ I-DatasetName
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
discourses -X- _ O
in -X- _ O

We -X- _ O
introduce -X- _ O
the -X- _ O
datasets -X- _ O
and -X- _ O
the -X- _ O
split -X- _ B-HyperparameterName
(i.e., -X- _ O
train/val/test) -X- _ B-HyperparameterName
which -X- _ O
had -X- _ O
been -X- _ O
maintained -X- _ O
in -X- _ O
our -X- _ O
experiments. -X- _ O

A.1 -X- _ O
Datasets -X- _ O

A -X- _ O
Appendix -X- _ O

References -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
we -X- _ O
proposed -X- _ O
a -X- _ O
novel -X- _ O
meta-learning -X- _ O
framework -X- _ O
for -X- _ O
the -X- _ O
learning-to-attend -X- _ O
and -X- _ O
showed -X- _ O
that -X- _ O
LEA -X- _ B-MethodName
is -X- _ O
an -X- _ O
effective -X- _ O
method -X- _ O
that -X- _ O
facilitates -X- _ O
the -X- _ O
utilization -X- _ O
of -X- _ O
large-sized -X- _ O
PTMs -X- _ O
in -X- _ O
few-shot -X- _ B-TaskName
learning. -X- _ I-TaskName

We -X- _ O
have -X- _ O
attempted -X- _ O
to -X- _ O
design -X- _ O
a -X- _ O
novel -X- _ O
embedding -X- _ O
transfer -X- _ O
method -X- _ O
for -X- _ O
deriving -X- _ O
a -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
dictionary -X- _ O
to -X- _ O
enable -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
to -X- _ O
simply -X- _ O
borrow -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
attention -X- _ O
aspects -X- _ O
from -X- _ O
the -X- _ O
dictionary. -X- _ O

We -X- _ O
hypothesized -X- _ O
that -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
task-specific -X- _ O
selfattentive -X- _ O
mechanism -X- _ O
might -X- _ O
improve -X- _ O
few-shot -X- _ O
learning -X- _ O
performance, -X- _ O
especially -X- _ O
when -X- _ O
it -X- _ O
is -X- _ O
prohibitive -X- _ O
to -X- _ O
fine-tune -X- _ O
a -X- _ O
large-sized -X- _ O
PTM. -X- _ O

This -X- _ O
empirical -X- _ O
result -X- _ O
indicates -X- _ O
that -X- _ O
each -X- _ O
task -X- _ O
derives -X- _ O
its -X- _ O
optimal -X- _ O
document -X- _ O
embedding -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2, -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
exhibit -X- _ O
their -X- _ O
best -X- _ O
performance -X- _ O
when -X- _ O
setting -X- _ O
the -X- _ O
top-k -X- _ B-HyperparameterName
attention -X- _ I-HyperparameterName
aspects -X- _ I-HyperparameterName
to -X- _ O
20. -X- _ B-HyperparameterValue

We -X- _ O
fixed -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
meta -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
aspects -X- _ I-HyperparameterName
dictionary -X- _ I-HyperparameterName
to -X- _ O
150 -X- _ B-HyperparameterValue
and -X- _ O
measured -X- _ O
the -X- _ O
performances -X- _ O
by -X- _ O
gradually -X- _ O
scaling -X- _ O
the -X- _ O
k -X- _ B-HyperparameterName
up -X- _ O
to -X- _ O
1, -X- _ B-HyperparameterValue
10, -X- _ B-HyperparameterValue
20, -X- _ B-HyperparameterValue
30, -X- _ B-HyperparameterValue
50, -X- _ B-HyperparameterValue
75, -X- _ B-HyperparameterValue
150. -X- _ B-HyperparameterValue

This -X- _ O
specific -X- _ O
study -X- _ O
was -X- _ O
conducted -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
frozen -X- _ O
BERTBASE -X- _ O
as -X- _ O
the -X- _ O
underlying -X- _ O
PTM -X- _ O
with -X- _ O
the -X- _ O
5-way -X- _ B-TaskName
5-shot -X- _ I-TaskName
experiment -X- _ O
for -X- _ O
the -X- _ O
all -X- _ O
datasets. -X- _ O

We -X- _ O
also -X- _ O
investigate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
(i.e., -X- _ O
k) -X- _ B-HyperparameterName
of -X- _ O
task-specific -X- _ O
attention -X- _ O
aspects. -X- _ O

6 -X- _ O
Conclusion -X- _ O

Number -X- _ O
of -X- _ O
Top-k -X- _ O
Attention -X- _ O
Aspects -X- _ O

5.3 -X- _ O
Hyperparameter -X- _ O
Study: -X- _ O
Effect -X- _ O
of -X- _ O
the -X- _ O

These -X- _ O
plots -X- _ O
demonstrate -X- _ O
that -X- _ O
LEA -X- _ B-MethodName
produces -X- _ O
a -X- _ O
structured -X- _ O
task-specific -X- _ O
embedding -X- _ O
space -X- _ O
after -X- _ O
our -X- _ O
task-adaptation -X- _ O
step. -X- _ O

Figure -X- _ O
3c -X- _ O
shows -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
the -X- _ O
four -X- _ O
classes -X- _ O
of -X- _ O
the -X- _ O
‘science’ -X- _ O
domain -X- _ O
and -X- _ O
the -X- _ O
others -X- _ O
on -X- _ O
the -X- _ O
space. -X- _ O

Figure -X- _ O
3b -X- _ O
shows -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
the -X- _ O
‘recreation’ -X- _ O
domain -X- _ O
composed -X- _ O
of -X- _ O
four -X- _ O
classes -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
on -X- _ O
the -X- _ O
space. -X- _ O

To -X- _ O
qualitatively -X- _ O
characterize -X- _ O
the -X- _ O
task-specific -X- _ O
document -X- _ O
embedding -X- _ O
space, -X- _ O
we -X- _ O
split -X- _ O
20 -X- _ B-DatasetName
Newsgroup -X- _ I-DatasetName
into -X- _ O
seven -X- _ O
top-level -X- _ O
domains, -X- _ O
that -X- _ O
is, -X- _ O
‘atheism’, -X- _ O
‘computer’, -X- _ O
‘for-sale’, -X- _ O
‘recreation’, -X- _ O
‘science’, -X- _ O
‘religion’, -X- _ O
and -X- _ O
‘talk’ -X- _ O
and -X- _ O
projected -X- _ O
them -X- _ O
via -X- _ O
t-SNE -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3a. -X- _ O

In -X- _ O
addition, -X- _ O
we -X- _ O
plots -X- _ O
the -X- _ O
task-specific -X- _ O
document -X- _ O
embeddings -X- _ O
and -X- _ O
observe -X- _ O
the -X- _ O
relationships -X- _ O
among -X- _ O
classes -X- _ O
on -X- _ O
20 -X- _ B-DatasetName
Newsgroups -X- _ I-DatasetName
dataset. -X- _ O

Visualization -X- _ O

5.4 -X- _ O
Task-Specific -X- _ O
Document -X- _ O
Embedding -X- _ O

by -X- _ O
referring -X- _ O
only -X- _ O
to -X- _ O
the -X- _ O
most -X- _ O
relevant -X- _ O
subset -X- _ O
rather -X- _ O
than -X- _ O
exploiting -X- _ O
all -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects. -X- _ O

Namely, -X- _ O
the -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
LEA -X- _ B-MethodName
quickly -X- _ O
recognizes -X- _ O
how -X- _ O
to -X- _ O
attend -X- _ O
for -X- _ O
new -X- _ O
tasks -X- _ O
using -X- _ O
the -X- _ O
established -X- _ O
meta-attention -X- _ O
aspects -X- _ O
and -X- _ O
provides -X- _ O
a -X- _ O
robust -X- _ O
performance -X- _ O
in -X- _ O
few-shot -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
problems. -X- _ O

As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
and -X- _ O
2, -X- _ O
LEA -X- _ B-MethodName
exhibits -X- _ O
the -X- _ O
competitive -X- _ O
performance -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
5-way -X- _ B-TaskName
1-shot -X- _ I-TaskName
and -X- _ O
5-way -X- _ B-TaskName
5-shot, -X- _ I-TaskName
compared -X- _ O
to -X- _ O
the -X- _ O
state-of-the-arts -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
datasets. -X- _ O

All -X- _ O
performance -X- _ O
scores -X- _ O
are -X- _ O
reported -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
for -X- _ O
three -X- _ O
repetitions. -X- _ O

We -X- _ O
additionally -X- _ O
applied -X- _ O
LEA -X- _ B-MethodName
on -X- _ O
RoBERTaBASE -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
fastText -X- _ O
(Bojanowski -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
applicability -X- _ O
of -X- _ O
LEA. -X- _ B-MethodName

For -X- _ O
the -X- _ O
comparison -X- _ O
with -X- _ O
Frog-GNN, -X- _ B-MethodName
we -X- _ O
referred -X- _ O
to -X- _ O
the -X- _ O
reported -X- _ O
results -X- _ O
from -X- _ O
(Xu -X- _ O
and -X- _ O
Xiang, -X- _ O
2021). -X- _ O

As -X- _ O
in -X- _ O
LEA, -X- _ B-MethodName
DS -X- _ B-MethodName
is -X- _ O
given -X- _ O
the -X- _ O
[CLS] -X- _ O
embedding -X- _ O
and -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
from -X- _ O
BERT’s -X- _ O
last -X- _ O
layer, -X- _ O
whereas -X- _ O
the -X- _ O
other -X- _ O
algorithms -X- _ O
used -X- _ O
the -X- _ O
[CLS] -X- _ O
embedding -X- _ O
of -X- _ O
BERT. -X- _ O

5.2 -X- _ O
Overall -X- _ O
Performance -X- _ O

Here, -X- _ O
MAML -X- _ B-MethodName
(Finn -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
denotes -X- _ O
the -X- _ O
representative -X- _ O
optimization-based -X- _ O
meta-learning -X- _ O
algorithm, -X- _ O
PROTO -X- _ B-MethodName
(Snell -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
indicates -X- _ O
the -X- _ O
prototype -X- _ B-MethodName
network, -X- _ I-MethodName
LEO -X- _ B-MethodName
(Rusu -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
denotes -X- _ O
the -X- _ O
meta-learning -X- _ O
algorithm -X- _ O
using -X- _ O
latent -X- _ O
embedding -X- _ O
optimization, -X- _ O
INDUCTION -X- _ B-MethodName
indicates -X- _ O
the -X- _ O
induction -X- _ B-MethodName
network -X- _ I-MethodName
(Geng -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
DS -X- _ B-MethodName
(Bao -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
denotes -X- _ O
few-shot -X- _ O
text -X- _ O
classification -X- _ O
algorithm -X- _ O
using -X- _ O
the -X- _ O
underlying -X- _ O
word -X- _ O
distributions, -X- _ O
and -X- _ O
Frog-GNN -X- _ B-MethodName
(Xu -X- _ O
and -X- _ O
Xiang, -X- _ O
2021) -X- _ O
denotes -X- _ O
the -X- _ O
multi-perspective -X- _ O
aggregation -X- _ O
based -X- _ O
graph -X- _ O
neural -X- _ O
network. -X- _ O

MAML -X- _ B-MethodName
alternates -X- _ O
between -X- _ O
two -X- _ O
update -X- _ O
processes -X- _ O
during -X- _ O
meta-training: -X- _ O
(1) -X- _ O
task-adaptation -X- _ O
and -X- _ O
(2) -X- _ O
meta-optimization. -X- _ O

For -X- _ O
a -X- _ O
parametric -X- _ O
model -X- _ O
fθ, -X- _ O
MAML -X- _ B-MethodName
seeks -X- _ O
to -X- _ O
find -X- _ O
task-specific -X- _ O
parameters -X- _ O
θi -X- _ O
for -X- _ O
any -X- _ O
new -X- _ O
task -X- _ O
τi -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
particular -X- _ O
disp(τ -X- _ O
), -X- _ O
tribution -X- _ O
of -X- _ O
tasks. -X- _ O

In -X- _ O
this -X- _ O
experiment, -X- _ O
we -X- _ O
evaluate -X- _ O
and -X- _ O
compare -X- _ O
LEA -X- _ B-MethodName
with -X- _ O
six -X- _ O
state-of-art -X- _ O
methods -X- _ O
as -X- _ O
follows: -X- _ O

5.1 -X- _ O
Baselines -X- _ O

The -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
are -X- _ O
introduced -X- _ O
in -X- _ O
Appendix -X- _ O
A.1. -X- _ O

We -X- _ O
conducted -X- _ O
two -X- _ O
different -X- _ O
experiments: -X- _ O
5-way -X- _ O
1-shot -X- _ O
and -X- _ O
5-way -X- _ O
5shot -X- _ O
all -X- _ O
over -X- _ O
datasets. -X- _ O

We -X- _ O
evaluated -X- _ O
LEA -X- _ B-MethodName
on -X- _ O
five -X- _ O
text -X- _ O
datasets -X- _ O
— -X- _ O
20 -X- _ B-DatasetName
Newsgroup(Lang, -X- _ I-DatasetName
1995), -X- _ O
Huffpost -X- _ B-DatasetName
headline(Misra -X- _ I-DatasetName
and -X- _ O
Grover, -X- _ O
2021), -X- _ O
Reuters-21578(Lewis., -X- _ B-DatasetName
1997), -X- _ O
RCV1(Lewis -X- _ B-DatasetName
et -X- _ O
al., -X- _ O
2004), -X- _ O
and -X- _ O
Amazon -X- _ B-DatasetName
product -X- _ I-DatasetName
reviews -X- _ I-DatasetName
(He -X- _ O
and -X- _ O
McAuley, -X- _ O
2016) -X- _ O
— -X- _ O
and -X- _ O
compared -X- _ O
it -X- _ O
with -X- _ O
current -X- _ O
state-of-art -X- _ O
methods. -X- _ O

5 -X- _ O
Experimental -X- _ O
Results -X- _ O

During -X- _ O
the -X- _ O
meta-optimization -X- _ O
step, -X- _ O
the -X- _ O
groups -X- _ O
are -X- _ O
. -X- _ O

The -X- _ O
former -X- _ O
proceeds -X- _ O
as -X- _ O
follows: -X- _ O

As -X- _ O
noted -X- _ O
in -X- _ O
Algorithm -X- _ O
1, -X- _ O
LEA -X- _ B-MethodName
alternates -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
update -X- _ O
steps: -X- _ O
(1) -X- _ O
task -X- _ O
adaptation -X- _ O
(or -X- _ O
inner-update) -X- _ O
and -X- _ O
(2) -X- _ O
meta-optimization -X- _ O
(or -X- _ O
outerupdate). -X- _ O

4.4 -X- _ O
Meta-Training -X- _ O
Objectives -X- _ O

E -X- _ O
L -X- _ O
is -X- _ O
the -X- _ O
self-attentive -X- _ O
document -X- _ O
where -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
jth -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
τi, -X- _ O
and -X- _ O
H -X- _ O
τi -X- _ O
L -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
token -X- _ O
embedding -X- _ O
vectors -X- _ O
for -X- _ O
the -X- _ O
jth -X- _ O
instance -X- _ O
with -X- _ O
L -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
τi. -X- _ O

This -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
follows: -X- _ O

For -X- _ O
a -X- _ O
text -X- _ O
input, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
corresponding -X- _ O
embedding -X- _ O
vectors -X- _ O
for -X- _ O
the -X- _ O
individual -X- _ O
tokens, -X- _ O
which -X- _ O
are -X- _ O
denoted -X- _ O
as -X- _ O
H -X- _ O
τi -X- _ O
j,L] -X- _ O
for -X- _ O
the -X- _ O
jth -X- _ O
text -X- _ O
example -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
τi. -X- _ O

We -X- _ O
then -X- _ O
apply -X- _ O
it -X- _ O
into -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
document -X- _ O
embeddings -X- _ O
for -X- _ O
text -X- _ O

Here, -X- _ O
we -X- _ O
perform -X- _ O
the -X- _ O
self-attentive -X- _ O
feature -X- _ O
extraction -X- _ O
using -X- _ O
the -X- _ O
aforementioned -X- _ O
top-k -X- _ O
task-specific -X- _ O
attention -X- _ O
aspects -X- _ O
for -X- _ O
a -X- _ O
task. -X- _ O

4.3 -X- _ O
Task-Specific -X- _ O
Self-Attentive -X- _ O
Document -X- _ O

This -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
follows: -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
we -X- _ O
can -X- _ O
extract -X- _ O
the -X- _ O
top-k -X- _ O
task-specific -X- _ O
attention -X- _ O
aspects -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
τi. -X- _ O

The -X- _ O
gating -X- _ O
process -X- _ O
G -X- _ O
produces -X- _ O
a -X- _ O
sparse -X- _ O
output -X- _ O
vector -X- _ O
by -X- _ O
beAN -X- _ O
, -X- _ O
Wn -X- _ O
∈ -X- _ O
ing -X- _ O
parameterized -X- _ O
with -X- _ O
RAN -X- _ O
× -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
remaining -X- _ O
values -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
k -X- _ O
elements -X- _ O
are -X- _ O
forced -X- _ O
to -X- _ O
become -X- _ O
zeros, -X- _ O
and -X- _ O
the -X- _ O
top-k -X- _ O
weights -X- _ O
are -X- _ O
finally -X- _ O
generated -X- _ O
through -X- _ O
a -X- _ O
softmax -X- _ O
function. -X- _ O

where -X- _ O
gτi -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
gating -X- _ O
output -X- _ O
vector -X- _ O
whose -X- _ O
number -X- _ O
of -X- _ O
dimensions -X- _ O
must -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
meta-attention-aspects -X- _ O
dictionary. -X- _ O

The -X- _ O
gating -X- _ O
output -X- _ O
vector -X- _ O
is -X- _ O
calculated -X- _ O
through -X- _ O
the -X- _ O
following -X- _ O
formulation: -X- _ O

Using -X- _ O
the -X- _ O
aforementioned -X- _ O
class -X- _ O
embedding, -X- _ O
we -X- _ O
attempt -X- _ O
to -X- _ O
selectively -X- _ O
(i.e., -X- _ O
top-k) -X- _ O
collect -X- _ O
taskspecific -X- _ O
attention -X- _ O
aspects -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
task -X- _ O
by -X- _ O
employing -X- _ O
a -X- _ O
gating -X- _ O
mechanism -X- _ O
(Shazeer -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

As -X- _ O
a -X- _ O
result, -X- _ O
the -X- _ O
class -X- _ O
embedding -X- _ O
eτi -X- _ O
n -X- _ O
is -X- _ O
enforced -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
pairwise -X- _ O
relationship -X- _ O
with -X- _ O
other -X- _ O
classes. -X- _ O

[CLS] -X- _ O
(denoted -X- _ O
as -X- _ O
cτi -X- _ O
j -X- _ O
for -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
the -X- _ O
jth -X- _ O
text -X- _ O
instance -X- _ O
of -X- _ O
a -X- _ O
specific -X- _ O
task -X- _ O
τi) -X- _ O
of -X- _ O
a -X- _ O
text -X- _ O
instance -X- _ O
in -X- _ O
PTMs -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Lan -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Liu -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

(cid:0) -X- _ O
(3) -X- _ O
where -X- _ O
eτi -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
representative -X- _ O
embedding -X- _ O
for -X- _ O
the -X- _ O
particular -X- _ O
class -X- _ O
n -X- _ O
under -X- _ O
a -X- _ O
given -X- _ O
task -X- _ O
τi, -X- _ O
fθr -X- _ O
indicates -X- _ O
the -X- _ O
relation -X- _ O
network -X- _ O
(Sung -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
and -X- _ O
fθe -X- _ O
is -X- _ O
an -X- _ O
encoder -X- _ O
network -X- _ O
that -X- _ O
transforms -X- _ O
the -X- _ O
delegate -X- _ O
embedding -X- _ O

First, -X- _ O
each -X- _ O
task -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
encoding -X- _ O
process, -X- _ O
which -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
follows: -X- _ O

To -X- _ O
do -X- _ O
so, -X- _ O
we -X- _ O
assess -X- _ O
the -X- _ O
relevance -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
among -X- _ O
the -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
WA. -X- _ O

Note -X- _ O
that -X- _ O
k -X- _ O
and -X- _ O
K -X- _ O
are -X- _ O
different -X- _ O
in -X- _ O
that -X- _ O
the -X- _ O
former -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
topmost -X- _ O
relevant -X- _ O
attention -X- _ O
aspects, -X- _ O
whereas -X- _ O
the -X- _ O
latter, -X- _ O
indicates -X- _ O
as -X- _ O
K-shot, -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
samples -X- _ O
in -X- _ O
few-shot -X- _ O
learning. -X- _ O

A -X- _ O
∈ -X- _ O

Here, -X- _ O
W -X- _ O
τi -X- _ O
u -X- _ O
indicates -X- _ O
the -X- _ O
selected -X- _ O
k -X- _ O
attention -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
τi. -X- _ O

When -X- _ O
a -X- _ O
novel -X- _ O
task -X- _ O
τi -X- _ O
is -X- _ O
given, -X- _ O
its -X- _ O
related -X- _ O
attention -X- _ O
aspects, -X- _ O
denoted -X- _ O
by -X- _ O
W -X- _ O
τi -X- _ O
A -X- _ O
, -X- _ O
are -X- _ O
selectively -X- _ O
obtained -X- _ O
by -X- _ O
assigning -X- _ O
the -X- _ O
corresponding -X- _ O
weights -X- _ O
to -X- _ O
members -X- _ O
of -X- _ O
the -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
WA -X- _ O
in -X- _ O
the -X- _ O
task-adaptation -X- _ O
process. -X- _ O

4.2 -X- _ O
Top-k -X- _ O
Attention -X- _ O
Aspects -X- _ O
Selection -X- _ O
through -X- _ O

In -X- _ O
addition, -X- _ O
AN -X- _ B-HyperparameterName
and -X- _ O
u -X- _ B-HyperparameterName
are -X- _ O
the -X- _ O
total -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
aspects -X- _ I-HyperparameterName
and -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
aspect, -X- _ I-HyperparameterName
respectively. -X- _ O

Herein, -X- _ O
we -X- _ O
u -X- _ O
as -X- _ O
the -X- _ O
meta-level -X- _ O
define -X- _ O
a -X- _ O
matrix -X- _ O
WA -X- _ O
∈ -X- _ O
attention -X- _ O
aspect -X- _ O
dictionary. -X- _ O

The -X- _ O
meta-attention -X- _ O
aspects -X- _ O
in -X- _ O
the -X- _ O
dictionary -X- _ O
are -X- _ O
established -X- _ O
throughout -X- _ O
the -X- _ O
meta-optimization -X- _ O
process -X- _ O
during -X- _ O
which -X- _ O
it -X- _ O
seeks -X- _ O
to -X- _ O
learn -X- _ O
how -X- _ O
to -X- _ O
attend -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
tasks. -X- _ O

The -X- _ O
concept -X- _ O
was -X- _ O
inspired -X- _ O
by -X- _ O
(Lin -X- _ O
et -X- _ O
al., -X- _ O
τi -X- _ O
∼ -X- _ O
2017). -X- _ O

In -X- _ O
this -X- _ O
study, -X- _ O
the -X- _ O
meta-level -X- _ O
knowledge -X- _ O
dictionary -X- _ O
maintains -X- _ O
all -X- _ O
attention -X- _ O
aspects -X- _ O
derived -X- _ O
across -X- _ O
tasks -X- _ O
p(τ -X- _ O
). -X- _ O

4.1 -X- _ O
Meta -X- _ O
Attention -X- _ O
Aspects -X- _ O
Dictionary -X- _ O

The -X- _ O
high-level -X- _ O
operation -X- _ O
is -X- _ O
described -X- _ O
in -X- _ O
Algorithm -X- _ O
1. -X- _ O

processes: -X- _ O
(1) -X- _ O
deriving -X- _ O
all -X- _ O
valid -X- _ O
meta-attention -X- _ O
aspects -X- _ O
across -X- _ O
tasks -X- _ O
(namely, -X- _ O
meta-optimization), -X- _ O
and -X- _ O
(2) -X- _ O
choosing -X- _ O
a -X- _ O
task-specific -X- _ O
subset -X- _ O
from -X- _ O
all -X- _ O
the -X- _ O
meta-attention -X- _ O
aspects -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
(called, -X- _ O
task -X- _ O
adaptation). -X- _ O

Output: -X- _ O
WA: -X- _ O
Meta-attention-aspects -X- _ O
Output: -X- _ O

Algorithm -X- _ O
1 -X- _ O
Our -X- _ O
Proposed -X- _ O
Meta-Training -X- _ O
tr -X- _ O
Require: -X- _ O
Meta -X- _ O
training -X- _ O
set -X- _ O
Require: -X- _ O
Learning-rates -X- _ B-HyperparameterName
α -X- _ B-MethodName
(inner-update), -X- _ O
β -X- _ B-MethodName
(outer-update) -X- _ O

It -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
an -X- _ O
end-to-end -X- _ O
manner -X- _ O
using -X- _ O
our -X- _ O
proposed -X- _ O
metalearning -X- _ O
strategy. -X- _ O

It -X- _ O
represents -X- _ O
our -X- _ O
meta -X- _ O
learning -X- _ O
framework -X- _ O
for -X- _ O
the -X- _ O
task-specific -X- _ O
feature -X- _ O
extraction. -X- _ O

The -X- _ O
overall -X- _ O
architecture -X- _ O
of -X- _ O
LEA -X- _ B-MethodName
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O

4 -X- _ O
Proposed -X- _ O
Method -X- _ O

Likewise, -X- _ O
the -X- _ O
corresponding -X- _ O
[CLS] -X- _ O
embedding -X- _ O
is -X- _ O
denoted -X- _ O
as -X- _ O
cτi -X- _ O
j -X- _ O
. -X- _ O

In -X- _ O
manufacturing -X- _ O
a -X- _ O
task-specific -X- _ O
embedding, -X- _ O
we -X- _ O
especially -X- _ O
utilize -X- _ O
the -X- _ O
token-level -X- _ O
output -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
individual -X- _ O
tokens -X- _ O
of -X- _ O
the -X- _ O
jth -X- _ O
text -X- _ O
instance -X- _ O
under -X- _ O
a -X- _ O
particular -X- _ O
task -X- _ O
τi, -X- _ O
which -X- _ O
we -X- _ O
denote -X- _ O
as -X- _ O
H -X- _ O
τi -X- _ O
j,L]. -X- _ O

In -X- _ O
this -X- _ O
study, -X- _ O
the -X- _ O
[CLS] -X- _ O
vector -X- _ O
plays -X- _ O
an -X- _ O
important -X- _ O
role -X- _ O
in -X- _ O
probing -X- _ O
the -X- _ O
distinctive -X- _ O
properties -X- _ O
for -X- _ O
an -X- _ O
incoming -X- _ O
task. -X- _ O

For -X- _ O
downstream -X- _ O
classification -X- _ B-TaskName
tasks, -X- _ O
the -X- _ O
special -X- _ O
embedding -X- _ O
vector -X- _ O
[CLS] -X- _ O
is -X- _ O
typically -X- _ O
used -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
prediction -X- _ O
as -X- _ O
the -X- _ O
representative -X- _ O
of -X- _ O
an -X- _ O
text -X- _ O
instance. -X- _ O

The -X- _ O
PTMs -X- _ O
end -X- _ O
up -X- _ O
with -X- _ O
providing -X- _ O
the -X- _ O
corresponding -X- _ O
embedding -X- _ O
vectors -X- _ O
(i.e., -X- _ O
denoted -X- _ O
as -X- _ O
[CLS] -X- _ O
and -X- _ O
[SEP]) -X- _ O
for -X- _ O
the -X- _ O
artificial -X- _ O
tokens -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
embeddings -X- _ O
for -X- _ O
original -X- _ O
tokens -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
text. -X- _ O

Given -X- _ O
a -X- _ O
text -X- _ O
input, -X- _ O
a -X- _ O
dummy -X- _ O
token -X- _ O
(CLS) -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
input, -X- _ O
and -X- _ O
another -X- _ O
token -X- _ O
(SEP) -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
sentence. -X- _ O

We -X- _ O
conducted -X- _ O
all -X- _ O
experiments -X- _ O
with -X- _ O
BERT -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
RoBERTa -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
as -X- _ O
the -X- _ O
underlying -X- _ O
PTMs -X- _ O
in -X- _ O
the -X- _ O
study. -X- _ O

In -X- _ O
this -X- _ O
meta-testing, -X- _ O
the -X- _ O
dataset -X- _ O
of -X- _ O
task -X- _ O
τi -X- _ O
is -X- _ O
given -X- _ O
as -X- _ O
Dτi -X- _ O
= -X- _ O
D -X- _ O
3.3 -X- _ O
Pre-Trained -X- _ O
Models -X- _ O

Subsequently, -X- _ O
each -X- _ O
task -X- _ O
learner -X- _ O
is -X- _ O
individually -X- _ O
tailored -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
optimal -X- _ O
parameters -X- _ O
θ′ -X- _ O
τi -X- _ O
by -X- _ O
applying -X- _ O
the -X- _ O
above -X- _ O
task -X- _ O
adaptation -X- _ O
process. -X- _ O

In -X- _ O
the -X- _ O
meta-testing -X- _ O
phase, -X- _ O
the -X- _ O
meta-learner -X- _ O
provides -X- _ O
the -X- _ O
initial -X- _ O
parameters -X- _ O
for -X- _ O
task-specific -X- _ O
model -X- _ O
learners. -X- _ O

fixed -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
α -X- _ B-HyperparameterName
and -X- _ O
β, -X- _ B-HyperparameterName
respectively, -X- _ O
which -X- _ O
are -X- _ O
given -X- _ O
as -X- _ O
hyperparameters. -X- _ O

The -X- _ O
metalearner -X- _ O
updates -X- _ O
its -X- _ O
parameters -X- _ O
through -X- _ O
a -X- _ O
gradient -X- _ O
val -X- _ O
descent -X- _ O
using -X- _ O
the -X- _ O
loss -X- _ O
evaluated -X- _ O
by -X- _ O
τi -X- _ O
with -X- _ O
reD -X- _ O
spect -X- _ O
to -X- _ O
the -X- _ O
task-specific -X- _ O
parameters -X- _ O
θ′ -X- _ O
τi. -X- _ O

The -X- _ O
task-adaptation -X- _ O
process -X- _ O
is -X- _ O
formulated -X- _ O
as -X- _ O
in -X- _ O
Equation -X- _ O
1. -X- _ O

Task -X- _ O
adaptation -X- _ O
(or -X- _ O
inner -X- _ O
update): -X- _ O
Each -X- _ O
task -X- _ O
learner -X- _ O
updates -X- _ O
its -X- _ O
own -X- _ O
parameters -X- _ O
through -X- _ O
a -X- _ O
gradient -X- _ O
descent -X- _ O
using -X- _ O
the -X- _ O
loss -X- _ O
evaluated -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
tr -X- _ O
τi -X- _ O
with -X- _ O
the -X- _ O
initial -X- _ O
parameter -X- _ O
θm -X- _ O
own -X- _ O
training -X- _ O
data -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
outer -X- _ O
meta-optimization -X- _ O
process. -X- _ O

For -X- _ O
a -X- _ O
particular -X- _ O
task -X- _ O
τi -X- _ O
∼ -X- _ O
val -X- _ O
τi -X- _ O
during -X- _ O
the -X- _ O
the -X- _ O
task -X- _ O
data -X- _ O
meta-training -X- _ O
phase. -X- _ O

Our -X- _ O
proposed -X- _ O
meta -X- _ O
training -X- _ O
strategy -X- _ O
follows -X- _ O
the -X- _ O
overall -X- _ O
procedure -X- _ O
of -X- _ O
optimization-based -X- _ O
metalearning -X- _ O
(Finn -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

tr), -X- _ O
meta-validation -X- _ O
set -X- _ O
( -X- _ O
test) -X- _ O
as -X- _ O
disjoint -X- _ O
sets -X- _ O
of -X- _ O
classes. -X- _ O

In -X- _ O
a -X- _ O
meta-learning -X- _ O
setting, -X- _ O
tasks -X- _ O
are -X- _ O
divided -X- _ O
into -X- _ O
a -X- _ O
meta-training -X- _ O
set -X- _ O
val), -X- _ O
and -X- _ O
meta-test -X- _ O
set -X- _ O
( -X- _ O
S -X- _ O
( -X- _ O
S -X- _ O
3.2 -X- _ O
Model-Agnostic -X- _ O
Meta-Learning -X- _ O

In -X- _ O
the -X- _ O
literature, -X- _ O
this -X- _ O
is -X- _ O
called -X- _ O
a -X- _ O
C-way -X- _ B-TaskName
K-shot -X- _ I-TaskName
problem -X- _ O
in -X- _ O
which -X- _ O
K-labeled -X- _ O
examples -X- _ O
are -X- _ O
given -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
C -X- _ O
number -X- _ O
of -X- _ O
classes. -X- _ O

Few-shot -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
is -X- _ O
a -X- _ O
task -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
classifier -X- _ O
must -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
accommodate -X- _ O
new -X- _ O
classes -X- _ O
using -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
labeled -X- _ O
examples. -X- _ O

3.1 -X- _ O
Problem -X- _ O
Setup -X- _ O

3 -X- _ O
Background -X- _ O

In -X- _ O
addition, -X- _ O
LEO -X- _ B-MethodName
(Rusu -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
learns -X- _ O
a -X- _ O
lowdimensional -X- _ O
latent -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
classifiers -X- _ O
are -X- _ O
generated -X- _ O
from -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
into -X- _ O
which -X- _ O
the -X- _ O
tasks -X- _ O
are -X- _ O
mapped. -X- _ O

ilar -X- _ O
to -X- _ O
PROTO, -X- _ B-MethodName
a -X- _ O
deep -X- _ O
neural -X- _ O
network, -X- _ O
called -X- _ O
a -X- _ O
relation -X- _ O
network, -X- _ O
is -X- _ O
proposed -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
non-linear -X- _ O
distance -X- _ O
metric -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
Euclidean -X- _ O
distance. -X- _ O

Meta-learning: -X- _ O
As -X- _ O
a -X- _ O
metric -X- _ O
learning-based -X- _ O
method, -X- _ O
(Snell -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
suggested -X- _ O
a -X- _ O
deep -X- _ O
neural -X- _ O
network, -X- _ O
called -X- _ O
a -X- _ O
prototype -X- _ B-MethodName
network -X- _ I-MethodName
(PROTO), -X- _ B-MethodName
through -X- _ O
which -X- _ O
class -X- _ O
representations -X- _ O
are -X- _ O
composed -X- _ O
using -X- _ O
a -X- _ O
learning -X- _ O
similarity -X- _ O
metric -X- _ O
for -X- _ O
members -X- _ O
In -X- _ O
(Sung -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
simof -X- _ O
the -X- _ O
same -X- _ O
class. -X- _ O

In -X- _ O
(Bao -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
DS -X- _ B-MethodName
is -X- _ O
introduced -X- _ O
to -X- _ O
keep -X- _ O
track -X- _ O
of -X- _ O
underlying -X- _ O
word -X- _ O
distributions -X- _ O
across -X- _ O
all -X- _ O
available -X- _ O
classes -X- _ O
and -X- _ O
to -X- _ O
specify -X- _ O
important -X- _ O
lexical -X- _ O
features -X- _ O
for -X- _ O
new -X- _ O
classes. -X- _ O

In -X- _ O
(Geng -X- _ O
et -X- _ O
al., -X- _ O
Few-shot -X- _ O
text -X- _ O
classification: -X- _ O
2019), -X- _ O
INDUCTION -X- _ B-MethodName
is -X- _ O
proposed -X- _ O
to -X- _ O
build -X- _ O
classwise -X- _ O
embedding -X- _ O
to -X- _ O
represent -X- _ O
each -X- _ O
class -X- _ O
using -X- _ O
a -X- _ O
particular -X- _ O
dynamic -X- _ O
routing -X- _ O
algorithm -X- _ O
coalesced -X- _ O
with -X- _ O
meta-learning. -X- _ O

2 -X- _ O
Related -X- _ O
Work -X- _ O

While -X- _ O
LEA -X- _ B-MethodName
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
downstream -X- _ O
tasks, -X- _ O
we -X- _ O
demonstrate -X- _ O
LEA -X- _ B-MethodName
on -X- _ O
few-shot -X- _ B-TaskName
text -X- _ I-TaskName
classification -X- _ I-TaskName
problems -X- _ O
in -X- _ O
the -X- _ O
paper. -X- _ O

The -X- _ O
latter -X- _ O
refers -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
task-adaption -X- _ O
process, -X- _ O
where -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
taskspecific -X- _ O
attention -X- _ O
aspects -X- _ O
is -X- _ O
inferred -X- _ O
by -X- _ O
determining -X- _ O
the -X- _ O
top-k -X- _ O
most -X- _ O
relevant -X- _ O
attention -X- _ O
aspects -X- _ O
from -X- _ O
the -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
dictionary. -X- _ O

The -X- _ O
former -X- _ O
is -X- _ O
a -X- _ O
process -X- _ O
by -X- _ O
which -X- _ O
useful -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
across -X- _ O
tasks -X- _ O
are -X- _ O
derived -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
particular -X- _ O
PTM -X- _ O
via -X- _ O
our -X- _ O
meta-learning -X- _ O
framework. -X- _ O

LEA -X- _ B-MethodName
includes -X- _ O
two -X- _ O
key -X- _ O
ideas: -X- _ O
(1) -X- _ O
construction -X- _ O
of -X- _ O
a -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
dictionary -X- _ O
and -X- _ O
(2) -X- _ O
inference -X- _ O
of -X- _ O
the -X- _ O
task-specific -X- _ O
attention -X- _ O
aspects -X- _ O
upon -X- _ O
the -X- _ O
arrival -X- _ O
of -X- _ O
a -X- _ O
new -X- _ O
task. -X- _ O

Our -X- _ O
approach -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
feature-based -X- _ O
transfer. -X- _ O

There -X- _ O
are -X- _ O
the -X- _ O
two -X- _ O
common -X- _ O
transfer -X- _ O
learning -X- _ O
paradigms -X- _ O
in -X- _ O
NLP: -X- _ O
feature-based -X- _ O
transfer -X- _ O
(Cer -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
and -X- _ O
fine-tuning -X- _ O
(Houlsby -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O

LEA -X- _ B-MethodName
is -X- _ O
an -X- _ O
efficient -X- _ O
and -X- _ O
practical -X- _ O
method -X- _ O
that -X- _ O
facilitates -X- _ O
the -X- _ O
utilization -X- _ O
of -X- _ O
large-sized -X- _ O
PTMs -X- _ O
in -X- _ O
few-shot -X- _ O
learning. -X- _ O

To -X- _ O
address -X- _ O
this -X- _ O
subtle -X- _ O
problem -X- _ O
(Sun -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
meta-knowledge -X- _ O
driven -X- _ O
self-attentive -X- _ O
embedding -X- _ O
transfer -X- _ O
method, -X- _ O
called -X- _ O
LEA -X- _ B-MethodName
(LEarningto-Attend), -X- _ B-MethodName
based -X- _ O
on -X- _ O
a -X- _ O
novel -X- _ O
meta-learning -X- _ O
framework, -X- _ O
through -X- _ O
which -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
are -X- _ O
derived -X- _ O
by -X- _ O
encoding -X- _ O
how -X- _ O
to -X- _ O
attend -X- _ O
for -X- _ O
given -X- _ O
tasks. -X- _ O

Unfortunately, -X- _ O
it -X- _ O
is -X- _ O
still -X- _ O
challenging -X- _ O
to -X- _ O
utilize -X- _ O
PTMs -X- _ O
(Lee -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
in -X- _ O
few-shot -X- _ O
learning. -X- _ O

Liu -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
most -X- _ O
successful -X- _ O
approach -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
of -X- _ O
NLP. -X- _ O

Meanwhile, -X- _ O
fine-tuning -X- _ O
pre-trained -X- _ O
models -X- _ O
(PTMs) -X- _ O
(Howard -X- _ O
and -X- _ O
Ruder, -X- _ O
2018; -X- _ O
Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O
Lan -X- _ O
et -X- _ O
al., -X- _ O
2019; -X- _ O

Few-shot -X- _ O
learning -X- _ O
aims -X- _ O
to -X- _ O
yield -X- _ O
an -X- _ O
AI-driven -X- _ O
NLP -X- _ O
model -X- _ O
capable -X- _ O
of -X- _ O
recognizing -X- _ O
unseen -X- _ O
tasks -X- _ O
using -X- _ O
a -X- _ O
few -X- _ O
labeled -X- _ O
data. -X- _ O

A -X- _ O
deficiency -X- _ O
of -X- _ O
supervised -X- _ O
data -X- _ O
is -X- _ O
often -X- _ O
experienced -X- _ O
in -X- _ O
real-world -X- _ O
NLP -X- _ O
applications. -X- _ O

Introduction -X- _ O

1 -X- _ O

The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
novel -X- _ O
method -X- _ O
robustly -X- _ O
provides -X- _ O
the -X- _ O
competitive -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
recent -X- _ O
few-shot -X- _ O
learning -X- _ O
methods. -X- _ O

We -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
five -X- _ O
text -X- _ O
classification -X- _ O
benchmark -X- _ O
datasets. -X- _ O

LEA -X- _ B-MethodName
derives -X- _ O
meta-level -X- _ O
attention -X- _ O
aspects -X- _ O
using -X- _ O
our -X- _ O
new -X- _ O
meta-learning -X- _ O
framework. -X- _ O

In -X- _ O
the -X- _ O
study, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
embedding -X- _ O
transfer -X- _ O
method, -X- _ O
called -X- _ O
LEA, -X- _ B-MethodName
for -X- _ O
leveraging -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
even -X- _ O
only -X- _ O
few-shot -X- _ O
instances. -X- _ O

When -X- _ O
only -X- _ O
given -X- _ O
a -X- _ O
few -X- _ O
instances -X- _ O
for -X- _ O
a -X- _ O
new -X- _ O
task, -X- _ O
extracting -X- _ O
task-aware -X- _ O
features -X- _ O
from -X- _ O
a -X- _ O
pre-trained -X- _ O
language -X- _ O
model -X- _ O
regardless -X- _ O
of -X- _ O
the -X- _ O
adaptation -X- _ O
is -X- _ O
a -X- _ O
promising -X- _ O
alternative. -X- _ O

However, -X- _ O
in -X- _ O
real-world -X- _ O
applications, -X- _ O
we -X- _ O
often -X- _ O
encounter -X- _ O
the -X- _ O
deficiency -X- _ O
of -X- _ O
labeled -X- _ O
data. -X- _ O

The -X- _ O
pre-trained -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
also -X- _ O
properly -X- _ O
adapted -X- _ O
to -X- _ O
downstream -X- _ O
tasks -X- _ O
when -X- _ O
there -X- _ O
is -X- _ O
sufficient -X- _ O
labeled -X- _ O
data. -X- _ O

In -X- _ O
recent -X- _ O
years, -X- _ O
NLP -X- _ O
has -X- _ O
advanced -X- _ O
greatly -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
proliferation -X- _ O
of -X- _ O
pre-trained -X- _ O
language -X- _ O
models. -X- _ O

Abstract -X- _ O

LEA: -X- _ B-MethodName
Meta -X- _ O
Knowledge-Driven -X- _ O
Self-Attentive -X- _ O
Document -X- _ O
Embedding -X- _ O
for -X- _ O
Few-Shot -X- _ O
Text -X- _ O
Classification -X- _ O

